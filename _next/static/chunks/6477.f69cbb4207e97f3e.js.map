{"version":3,"file":"static/chunks/6477.f69cbb4207e97f3e.js","mappings":"qHAGA,gBCCA,2BACA,8CACA,OAAe,SDFR,OACP,kBACA,aACA,gCACA,sBACA,EACA,0BACA,qBACA,ECN0B,SAC1B,GAEA,2BACA,+CACA,ODEO,YCFoB,CDEpB,GACP,uBACA,qBACA,cACA,aAIA,0BACA,eACA,ECZ2B,SAC3B,8ECRe,SACf,eACA,aACA,CACA,UACA,0BAEA,UACA,8BAEA,YACA,yBACA,sBACA,SAGA,QACA,CACA,eACA,2BACA,CACA,YACA,kCAAiD,oBAAwB,GACzE,CACA,WACA,8BAAwC,MAAM,GAAG,MAAM,aACvD,CACA,SACA,yDACA,YACA,GAEA,YACA,EAEA,YACA,MAEA,eAOA,KACA,OACA,eACA,eACA,UACA,KAEA,aACA,WAAuC,oBAAgC,IAIvE,OADA,UACA,0BACA,CACA,eE/DO,uBACP,eACA,SACA,uBACA,CACA,CAmCO,cACP,MAGA,WACA,qCACA,sBAEA,OADA,qBACA,CACA,CAEA,8CAEA,CACA,CCjDA,oEAUO,SACP,uBAUA,GATA,WACA,kBACA,qBACA,oBACA,iBACA,sBAAgC,GAAqB,EACrD,SAAuB,MAAQ,CAAG,YAAe,EACjD,YAA2B,kBAAgB,wBAA6C,SAAQ,CAChG,CAAS,EACT,QACA,qCAEA,CACA,6BACA,IACA,8BACA,OACA,aAEA,aAA8B,gBAC9B,sBACA,6DAEA,gCAEA,EADA,uBACA,gBACA,KACA,IACA,YACA,IACA,oBAEA,eADA,EACA,OADA,EACA,WADA,EACA,QACA,IACA,gBACA,KACA,CADiC,GACjC,oBAEA,GADA,KACA,OACA,SACA,YAAwC,IAAS,KACjD,wBACA,KACA,wBACA,KACA,wBACA,KACA,wBACA,KACA,mCACA,KACA,mCACA,KACA,QACA,aACA,YACA,UACA,WACA,cACA,YACA,QACA,CAA6B,CAC7B,CACA,aACA,gBACA,SACA,qBACA,mBACA,GACA,MACA,UACA,SACA,YAAwC,IAAS,KACjD,wBACA,KACA,wBACA,KACA,wBACA,KACA,wBACA,KACA,mCACA,KACA,QACA,aACA,YACA,WACA,UACA,cACA,QACA,CAA6B,CAC7B,CACA,QACA,gBACA,qBACA,aACA,QAEA,CACA,CACA,SACA,UACA,CACA,EACA,MACA,eAAwB,oCAA2C,EACnE,0BACA,kBACA,EACA,iBACA,IACA,kBACA,QACA,iCAAwE,EAAO,GAAG,EAAO,UAAK,WAAgB,YAC9G,eACA,gBACA,WACA,KACA,OACA,uBACA,KACA,SACA,CAAiC,YACjC,UACA,CAAiC,EAIjC,CACA,SACA,UACA,CACA,EACA,UACA,IACA,YAEA,aACA,MAAoC,EAAK,CACzC,CACA,CAFyC,GAEzC,KACA,UACA,CAAyB,CACzB,EACA,YAAoC,WAAmB,MACvD,UAA8C,EAAK,CACnD,CACA,CAFmD,GAEnD,KACA,UACA,CAA6B,CAC7B,EACA,YACA,CAEA,8BACA,CACA,SACA,UACA,CACA,EACA,qCACA,MACA,CACA,SACA,UACA,CACA,CACA,yBACA,SACA,IACA,+CACA,0BAtLA,EAyLA,wBACA,KACA,wBACA,KACA,wBACA,KACA,wBACA,KACA,yBACA,KACA,yBACA,KACA,yBACA,KAGA,KACA,KACA,cA3MA,EA4MA,QA3MA,EA2MA,UA3MA,EA4MA,GACA,QACA,QACA,MACA,WACA,WACA,WACA,cACA,CAAiB,CAEjB,CACA,QACA,CACA,0BACA,SACA,IAEA,eADA,EACA,oBADA,EACA,QACA,sBACA,QACA,oBACA,KACA,uBACA,KACA,uBAEA,EADA,KAEA,KAAmB,YACnB,SADoC,KAKpC,sBACA,6BACA,MACA,QACA,UACA,QACA,MACA,OACA,eAAgC,IAAY,EAC/B,CACb,CACA,SACA,iBAzPA,eAyPA,QAzPA,EAyPA,MAzPA,EAyPA,QAxPA,EAwPA,OAxPA,OAyPA,CACA,CACA,4BAGA,EAFA,oBACA,+CAEA,IACA,uBACA,KACA,wBACA,KACA,wBACA,KACA,oBACA,KACA,wBACA,KACA,eACA,UACA,OACA,YAAgC,IAAe,KAC/C,uBACA,KACA,uBACA,KACA,yBACA,KACA,MACA,QACA,MACA,OACA,CACA,CACA,KAEA,QACA,YAAgC,IAAe,KAC/C,uBACA,KACA,yBACA,KACA,MACA,QACA,QACA,OACA,CACA,CACA,KAEA,QACA,YAAgC,IAAe,KAC/C,yBACA,KACA,WACA,OACA,QACA,QACA,OACA,CACA,CAGA,CACA,SACA,iBA1TA,eA0TA,QA1TA,EA0TA,MA1TA,EA0TA,QAzTA,EAyTA,OAzTA,OA0TA,CACA,CACA,2BAAkD,EAClD,IACA,cAAoB,kBAA0B,KAC9C,QAAoB,aAAkB,EACtC,ED/TO,WC+T2C,KD5TlD,EACA,EAHA,iCACA,SAGA,eACA,uBACA,SACA,6BACA,kBAGA,UACA,WACA,gBACA,gBACa,EAEb,oBAEA,QACA,EC0SkD,GACtC,EAAgB,GAC5B,WAD4B,GAC5B,oBACgB,EAAgB,GAChC,WADgC,CACR,WAAiB,EACzC,iCAA4D,EAAO,GAAG,EAAO,OAC7E,uBACoB,EAAgB,GACpC,WADoC,KACpC,oCACA,UF/UO,IEgVmC,EAA1C,EF/UW,QAAU,QE+UqB,GF/UrB,IEgVrB,CAEA,OADoB,EAAgB,GACpC,GACA,QAFoC,MAGpC,sCACA,KAEA,cACA,qCACA,KAEA,cACA,0DACA,KAEA,SACA,2CAAuE,EAAU,EAEjF,CACA,CACA,CAAa,GACb,YACA,CACA,SACA,UACA,CACA,CACA,CCvWO,QACP,aAOA,OANA,cACA,2CAEA,MADA,oBACA,CACA,EAAa,EAEb,aAYA,eACA,eAAgB,qCAAgD,EAEhE,GADA,qBACA,EACA,gBAEA,KACA,aAA2B,YAAU,SAErC,KACA,aAA2B,WAAS,SAGpC,4BAEA,CACA,oBACA,mCACA,iCACA,OACA,KACA,KAEA,CACA,kCAuDA,EAtDA,iCACA,+CACA,mBACA,oCACA,wCAEA,QACA,mBACA,KACA,wBACA,KACA,wBACA,KACA,mCACA,KACA,mCACA,KACA,mCACA,KACA,wBACA,KACA,wBACA,KACA,mCACA,KACA,mCACA,KACA,wBACA,KACA,mCACA,KACA,SACA,YAAwB,IAAmB,KAC3C,wBACA,KACA,wBACA,KACA,mCACA,KACA,mCACA,KACA,QACA,iBACA,WACA,aACA,aACA,CAAa,CACb,CAIA,eACA,kCAGA,MACA,4BACA,IACA,+CACA,+BACA,KACA,yBACA,KACA,yBACA,KACA,yBACA,KACA,yBACA,KACA,GACA,WACA,WACA,WACA,kBACA,cACA,CACA,MAEA,wBAEA,8BACA,OACA,aACA,QACA,kBACA,gBACA,aACA,eACA,oBACA,oBACA,WACA,kBACA,qBACA,qBACA,sBACA,SA/CA,kCAgDA,UACA,UACA,uCACA,EACA,CACA,CACA,8BAWA,EAVA,SACA,KACA,uBACA,oBACA,aACA,KAEA,UACA,qCACA,+CAOA,IACA,wBAOA,MAEA,8BACA,YACA,QACA,eACA,4CAEA,oBACA,KACA,CADyB,GACzB,oBAEA,GADA,KACA,EACA,YAAgC,IAAS,KACzC,QACA,0BACA,oBACA,KACA,wBACA,KACA,wBACA,KACA,2BACA,MACA,OACA,KACA,QACA,CACA,KAEA,CAEA,SACA,YAAgC,IAAS,KACzC,KACA,mCACA,KACA,8BACA,CACA,oBACA,CACA,EAEA,OADA,QAzCA,IA0CA,CACA,aACA,cACA,CACA,CAKA,yBACA,wBAAgB,+CAA+D,wBAC/E,WAAmB,EAAS,mBAC5B,CAaA,oCAGA,CAFA,yBACA,4BAEA,cAAgB,WAAsB,MAUtC,OARA,EADA,EACA,0BAEA,EACA,wBAGA,wBAEA,IAAmB,GAAU,KAC7B,EACA,uBACA,UACA,UACA,CAAa,CACb,CAAS,CACT,CACA,2BACA,2CAEA,MADA,OAA0B,OAAc,QAAS,OAAO,MACxD,MACA,CACA,CC/QO,gBAAqB,EAS5B,CAT+B,KAS/B,aACA,eAAgB,oCAA4C,wBAC5D,MACA,aACA,YAA+B,KAAQ,MACvC,WAEA,4BACA,WAA2B,EAAS,uCAEpC,CACA,8BACA,CACA,oCChBO,iBAAqB,EAC5B,CAD+B,YAC/B,CACA,oBACA,0BAAoC,GAAqB,EACzD,SAAuB,MAAQ,CAAG,UAAY,EAC9C,+BAAwD,cAAiB,CACzE,CAAS,CACT,CACA,gBAAyB,EACzB,IAAgB,eAAkB,EAClC,uDACA,CAIA,mBACA,8BACA,CAQA,0BAIA,EAHA,oBAAgB,GAAkB,wBAClC,oCACA,+CAGA,IACA,wBACA,KACA,mCAGA,GAFA,KAEA,MACA,SAIA,0BAFA,GACA,EACA,WACA,KACA,YAAwB,IAAW,MACnC,uBACA,+CACA,IACA,mBACA,KACA,uBACA,KACA,mCACA,MACA,IAD6B,EAC7B,iBACA,aAA2B,wCAAqD,CAChF,CACA,QACA,CAWA,mCAAgD,EAChD,gCACA,gBACA,SAEA,8BACA,sBAIA,EAHA,IAAoB,kBAAyB,EAC7C,8BACA,+CAGA,IACA,uBACA,KACA,uBACA,KACA,uBAGA,MACA,gBACA,gBAEA,sBADA,UACA,KAEA,wBADA,EACA,WADA,EACA,QACA,IACA,eACA,KACA,CAD6B,GAC7B,mBACA,KACA,SACA,UACA,SACA,YAAoC,IAAS,KAC7C,QACA,0BACA,oBACA,KACA,mCACA,KACA,QACA,MACA,QACA,CAAyB,CACzB,CACA,QACA,YAAiC,YAAc,KAC/C,2BACA,MAEA,GACA,CACA,WACA,CACA,UACA,YAAoC,IAAS,KAC7C,QACA,OAlCA,EAkCA,iBACA,oBACA,KACA,mCACA,KACA,wBACA,KACA,wBACA,KACA,QACA,MACA,SACA,SACA,UACA,CAAyB,CACzB,CACA,eACA,aACA,OAAqC,cAGrC,MACA,CACA,EAEA,WADA,GAEA,CAAS,EACT,MA7JA,CA6JA,sBA7JA,cA8JA,CAYA,6BAA0C,EAC1C,6CACA,gBACA,SAEA,oCACA,WACA,IAAuB,GAAU,KACjC,kCACA,UACA,CAAiB,CACjB,CAAa,OAAO,OAAM,qBAAmC,OAAG,KAChE,eACA,gBAEA,QACA,CAAa,IAGb,MADA,OAA0B,OAAc,CAAC,OAAK,SAC9C,iDACA,CACA","sources":["webpack://_N_E/./node_modules/@gmod/bbi/esm/bigint-polyfill/pure.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/bigint-polyfill/polyfill.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/range.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/unzip-pako.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/util.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/block-view.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/bbi.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/bigwig.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/bigbed.js","webpack://_N_E/./node_modules/@gmod/bbi/esm/index.js"],"sourcesContent":["// from https://github.com/yume-chan/ya-webadb/blob/main/libraries/dataview-bigint-polyfill\n// license:MIT\n// needed for browsers including safari 14\nconst BigInt32 = BigInt(32);\nexport function getBigInt64(dataView, byteOffset, littleEndian) {\n    const littleEndianMask = Number(!!littleEndian);\n    const bigEndianMask = Number(!littleEndian);\n    return ((BigInt(dataView.getInt32(byteOffset, littleEndian) * bigEndianMask +\n        dataView.getInt32(byteOffset + 4, littleEndian) * littleEndianMask) <<\n        BigInt32) |\n        BigInt(dataView.getUint32(byteOffset, littleEndian) * littleEndianMask +\n            dataView.getUint32(byteOffset + 4, littleEndian) * bigEndianMask));\n}\nexport function getBigUint64(dataView, byteOffset, littleEndian) {\n    const a = dataView.getUint32(byteOffset, littleEndian);\n    const b = dataView.getUint32(byteOffset + 4, littleEndian);\n    const littleEndianMask = Number(!!littleEndian);\n    const bigEndianMask = Number(!littleEndian);\n    // This branch-less optimization is 77x faster than normal ternary operator.\n    // and only 3% slower than native implementation\n    // https://jsbench.me/p8kyhg1eqv/1\n    return ((BigInt(a * bigEndianMask + b * littleEndianMask) << BigInt32) |\n        BigInt(a * littleEndianMask + b * bigEndianMask));\n}\n//# sourceMappingURL=pure.js.map","// from https://github.com/yume-chan/ya-webadb/blob/main/libraries/dataview-bigint-polyfill\n// license:MIT\n// needed for browsers including safari 14\nimport { getBigInt64, getBigUint64 } from './pure';\nif (!('getBigInt64' in DataView)) {\n    DataView.prototype.getBigInt64 = function (byteOffset, littleEndian) {\n        return getBigInt64(this, byteOffset, littleEndian);\n    };\n}\nif (!('getBigUint64' in DataView)) {\n    DataView.prototype.getBigUint64 = function (byteOffset, littleEndian) {\n        return getBigUint64(this, byteOffset, littleEndian);\n    };\n}\n//# sourceMappingURL=polyfill.js.map","/**\n * Adapted from a combination of Range and _Compound in the\n * Dalliance Genome Explorer, (c) Thomas Down 2006-2010.\n */\nexport default class Range {\n    constructor(arg1) {\n        this.ranges = arg1;\n    }\n    get min() {\n        return this.ranges[0].min;\n    }\n    get max() {\n        return this.ranges.at(-1).max;\n    }\n    contains(pos) {\n        for (const r of this.ranges) {\n            if (r.min <= pos && r.max >= pos) {\n                return true;\n            }\n        }\n        return false;\n    }\n    isContiguous() {\n        return this.ranges.length > 1;\n    }\n    getRanges() {\n        return this.ranges.map(r => new Range([{ min: r.min, max: r.max }]));\n    }\n    toString() {\n        return this.ranges.map(r => `[${r.min}-${r.max}]`).join(',');\n    }\n    union(s1) {\n        const ranges = [...this.getRanges(), ...s1.getRanges()].sort((a, b) => {\n            if (a.min < b.min) {\n                return -1;\n            }\n            else if (a.min > b.min) {\n                return 1;\n            }\n            else if (a.max < b.max) {\n                return -1;\n            }\n            else if (b.max > a.max) {\n                return 1;\n            }\n            else {\n                return 0;\n            }\n        });\n        const oranges = [];\n        let current = ranges[0];\n        for (const nxt of ranges) {\n            if (nxt.min > current.max + 1) {\n                oranges.push(current);\n                current = nxt;\n            }\n            else if (nxt.max > current.max) {\n                current = new Range([{ min: current.min, max: nxt.max }]);\n            }\n        }\n        oranges.push(current);\n        return oranges.length === 1 ? oranges[0] : new Range(oranges);\n    }\n}\n//# sourceMappingURL=range.js.map","import { inflateRaw } from 'pako';\nexport function unzip(input) {\n    return inflateRaw(input.subarray(2));\n}\n//# sourceMappingURL=unzip-pako.js.map","export class AbortError extends Error {\n    constructor(message) {\n        super(message);\n        this.code = 'ERR_ABORTED';\n    }\n}\n// sort blocks by file offset and\n// group blocks that are within 2KB of eachother\nexport function groupBlocks(blocks) {\n    blocks.sort((b0, b1) => b0.offset - b1.offset);\n    const blockGroups = [];\n    let lastBlock;\n    let lastBlockEnd;\n    for (const block of blocks) {\n        if (lastBlock && lastBlockEnd && block.offset - lastBlockEnd <= 2000) {\n            lastBlock.length =\n                lastBlock.length + block.length - lastBlockEnd + block.offset;\n            lastBlock.blocks.push(block);\n        }\n        else {\n            blockGroups.push((lastBlock = {\n                blocks: [block],\n                length: block.length,\n                offset: block.offset,\n            }));\n        }\n        lastBlockEnd = lastBlock.offset + lastBlock.length;\n    }\n    return blockGroups;\n}\n/**\n * Properly check if the given AbortSignal is aborted. Per the standard, if the\n * signal reads as aborted, this function throws either a DOMException\n * AbortError, or a regular error with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal) {\n    if (!signal) {\n        return;\n    }\n    if (signal.aborted) {\n        if (typeof DOMException === 'undefined') {\n            const e = new AbortError('aborted');\n            e.code = 'ERR_ABORTED';\n            throw e;\n        }\n        else {\n            throw new DOMException('aborted', 'AbortError');\n        }\n    }\n}\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal) {\n    await Promise.resolve();\n    checkAbortSignal(signal);\n}\n//# sourceMappingURL=util.js.map","import AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport QuickLRU from 'quick-lru';\nimport Range from './range';\nimport { unzip } from './unzip';\nimport { checkAbortSignal, groupBlocks } from './util';\nconst decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder('utf8') : undefined;\nfunction coordFilter(s1, e1, s2, e2) {\n    return s1 < e2 && e1 >= s2;\n}\n/**\n * View into a subset of the data in a BigWig file.\n *\n * Adapted by Robert Buels and Colin Diesh from bigwig.js in the Dalliance\n * Genome Explorer by Thomas Down.\n */\nexport class BlockView {\n    constructor(bbi, refsByName, cirTreeOffset, isCompressed, blockType) {\n        this.bbi = bbi;\n        this.refsByName = refsByName;\n        this.cirTreeOffset = cirTreeOffset;\n        this.isCompressed = isCompressed;\n        this.blockType = blockType;\n        this.featureCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: 1000 }),\n            fill: async ({ length, offset }, signal) => this.bbi.read(length, offset, { signal }),\n        });\n        if (!(cirTreeOffset >= 0)) {\n            throw new Error('invalid cirTreeOffset!');\n        }\n    }\n    async readWigData(chrName, start, end, observer, opts) {\n        try {\n            const chrId = this.refsByName[chrName];\n            if (chrId === undefined) {\n                observer.complete();\n            }\n            const request = { chrId, start, end };\n            if (!this.cirTreePromise) {\n                this.cirTreePromise = this.bbi.read(48, this.cirTreeOffset, opts);\n            }\n            const buffer = await this.cirTreePromise;\n            const dataView = new DataView(buffer.buffer);\n            const cirBlockSize = dataView.getUint32(4, true);\n            let blocksToFetch = [];\n            let outstanding = 0;\n            const cirFobRecur2 = (cirBlockData, offset2, level) => {\n                try {\n                    const data = cirBlockData.subarray(offset2);\n                    const b = data;\n                    const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n                    let offset = 0;\n                    const isLeaf = dataView.getUint8(offset);\n                    offset += 2; // 1 skip\n                    const cnt = dataView.getUint16(offset, true);\n                    offset += 2;\n                    if (isLeaf === 1) {\n                        const blocksToFetch2 = [];\n                        for (let i = 0; i < cnt; i++) {\n                            const startChrom = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const startBase = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const endChrom = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const endBase = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const blockOffset = Number(dataView.getBigUint64(offset, true));\n                            offset += 8;\n                            const blockSize = Number(dataView.getBigUint64(offset, true));\n                            offset += 8;\n                            blocksToFetch2.push({\n                                startChrom,\n                                startBase,\n                                endBase,\n                                endChrom,\n                                blockOffset,\n                                blockSize,\n                                offset,\n                            });\n                        }\n                        blocksToFetch = blocksToFetch.concat(blocksToFetch2\n                            .filter(f => filterFeats(f))\n                            .map(l => ({\n                            offset: l.blockOffset,\n                            length: l.blockSize,\n                        })));\n                    }\n                    else if (isLeaf === 0) {\n                        const recurOffsets = [];\n                        for (let i = 0; i < cnt; i++) {\n                            const startChrom = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const startBase = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const endChrom = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const endBase = dataView.getUint32(offset, true);\n                            offset += 4;\n                            const blockOffset = Number(dataView.getBigUint64(offset, true));\n                            offset += 8;\n                            recurOffsets.push({\n                                startChrom,\n                                startBase,\n                                endChrom,\n                                endBase,\n                                blockOffset,\n                                offset,\n                            });\n                        }\n                        const recurOffsets2 = recurOffsets\n                            .filter(f => filterFeats(f))\n                            .map(l => l.blockOffset);\n                        if (recurOffsets2.length > 0) {\n                            cirFobRecur(recurOffsets2, level + 1);\n                        }\n                    }\n                }\n                catch (e) {\n                    observer.error(e);\n                }\n            };\n            const filterFeats = (b) => {\n                const { startChrom, startBase, endChrom, endBase } = b;\n                return ((startChrom < chrId || (startChrom === chrId && startBase <= end)) &&\n                    (endChrom > chrId || (endChrom === chrId && endBase >= start)));\n            };\n            const cirFobStartFetch = async (off, fr, level) => {\n                try {\n                    const length = fr.max - fr.min;\n                    const offset = fr.min;\n                    const resultBuffer = await this.featureCache.get(`${length}_${offset}`, { length, offset }, opts?.signal);\n                    for (const element of off) {\n                        if (fr.contains(element)) {\n                            cirFobRecur2(resultBuffer, element - offset, level);\n                            outstanding -= 1;\n                            if (outstanding === 0) {\n                                this.readFeatures(observer, blocksToFetch, {\n                                    ...opts,\n                                    request,\n                                }).catch((e) => {\n                                    observer.error(e);\n                                });\n                            }\n                        }\n                    }\n                }\n                catch (e) {\n                    observer.error(e);\n                }\n            };\n            const cirFobRecur = (offset, level) => {\n                try {\n                    outstanding += offset.length;\n                    // Upper bound on size, based on a completely full leaf node.\n                    const maxCirBlockSpan = 4 + cirBlockSize * 32;\n                    let spans = new Range([\n                        {\n                            min: offset[0],\n                            max: offset[0] + maxCirBlockSpan,\n                        },\n                    ]);\n                    for (let i = 1; i < offset.length; i += 1) {\n                        const blockSpan = new Range([\n                            {\n                                min: offset[i],\n                                max: offset[i] + maxCirBlockSpan,\n                            },\n                        ]);\n                        spans = spans.union(blockSpan);\n                    }\n                    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n                    spans.getRanges().map(fr => cirFobStartFetch(offset, fr, level));\n                }\n                catch (e) {\n                    observer.error(e);\n                }\n            };\n            cirFobRecur([Number(this.cirTreeOffset) + 48], 1);\n            return;\n        }\n        catch (e) {\n            observer.error(e);\n        }\n    }\n    parseSummaryBlock(b, startOffset, request) {\n        const features = [];\n        let offset = startOffset;\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        while (offset < b.byteLength) {\n            // this was extracted from looking at the runtime code generated by\n            // binary-parser\n            const chromId = dataView.getUint32(offset, true);\n            offset += 4;\n            const start = dataView.getUint32(offset, true);\n            offset += 4;\n            const end = dataView.getUint32(offset, true);\n            offset += 4;\n            const validCnt = dataView.getUint32(offset, true);\n            offset += 4;\n            const minScore = dataView.getFloat32(offset, true);\n            offset += 4;\n            const maxScore = dataView.getFloat32(offset, true);\n            offset += 4;\n            const sumData = dataView.getFloat32(offset, true);\n            offset += 4;\n            // unused\n            // const sumSqData = dataView.getFloat32(offset, true)\n            offset += 4;\n            if (request\n                ? chromId === request.chrId &&\n                    coordFilter(start, end, request.start, request.end)\n                : true) {\n                features.push({\n                    start,\n                    end,\n                    maxScore,\n                    minScore,\n                    summary: true,\n                    score: sumData / (validCnt || 1),\n                });\n            }\n        }\n        return features;\n    }\n    parseBigBedBlock(data, startOffset, offset, request) {\n        const items = [];\n        let currOffset = startOffset;\n        const b = data;\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        while (currOffset < data.byteLength) {\n            const c2 = currOffset;\n            const chromId = dataView.getUint32(currOffset, true);\n            currOffset += 4;\n            const start = dataView.getInt32(currOffset, true);\n            currOffset += 4;\n            const end = dataView.getInt32(currOffset, true);\n            currOffset += 4;\n            let i = currOffset;\n            for (; i < data.length; i++) {\n                if (data[i] === 0) {\n                    break;\n                }\n            }\n            const b = data.subarray(currOffset, i);\n            const rest = decoder?.decode(b) ?? b.toString();\n            currOffset = i + 1;\n            items.push({\n                chromId,\n                start,\n                end,\n                rest,\n                uniqueId: `bb-${offset + c2}`,\n            });\n        }\n        return request\n            ? items.filter((f) => coordFilter(f.start, f.end, request.start, request.end))\n            : items;\n    }\n    parseBigWigBlock(buffer, startOffset, req) {\n        const b = buffer.subarray(startOffset);\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        offset += 4;\n        const blockStart = dataView.getInt32(offset, true);\n        offset += 8;\n        const itemStep = dataView.getUint32(offset, true);\n        offset += 4;\n        const itemSpan = dataView.getUint32(offset, true);\n        offset += 4;\n        const blockType = dataView.getUint8(offset);\n        offset += 2;\n        const itemCount = dataView.getUint16(offset, true);\n        offset += 2;\n        const items = new Array(itemCount);\n        switch (blockType) {\n            case 1: {\n                for (let i = 0; i < itemCount; i++) {\n                    const start = dataView.getInt32(offset, true);\n                    offset += 4;\n                    const end = dataView.getInt32(offset, true);\n                    offset += 4;\n                    const score = dataView.getFloat32(offset, true);\n                    offset += 4;\n                    items[i] = {\n                        start,\n                        end,\n                        score,\n                    };\n                }\n                break;\n            }\n            case 2: {\n                for (let i = 0; i < itemCount; i++) {\n                    const start = dataView.getInt32(offset, true);\n                    offset += 4;\n                    const score = dataView.getFloat32(offset, true);\n                    offset += 4;\n                    items[i] = {\n                        score,\n                        start,\n                        end: start + itemSpan,\n                    };\n                }\n                break;\n            }\n            case 3: {\n                for (let i = 0; i < itemCount; i++) {\n                    const score = dataView.getFloat32(offset, true);\n                    offset += 4;\n                    const start = blockStart + i * itemStep;\n                    items[i] = {\n                        score,\n                        start,\n                        end: start + itemSpan,\n                    };\n                }\n                break;\n            }\n        }\n        return req\n            ? items.filter(f => coordFilter(f.start, f.end, req.start, req.end))\n            : items;\n    }\n    async readFeatures(observer, blocks, opts = {}) {\n        try {\n            const { blockType, isCompressed } = this;\n            const { signal, request } = opts;\n            const blockGroupsToFetch = groupBlocks(blocks);\n            checkAbortSignal(signal);\n            await Promise.all(blockGroupsToFetch.map(async (blockGroup) => {\n                checkAbortSignal(signal);\n                const { length, offset } = blockGroup;\n                const data = await this.featureCache.get(`${length}_${offset}`, blockGroup, signal);\n                for (const block of blockGroup.blocks) {\n                    checkAbortSignal(signal);\n                    let resultData = data.subarray(Number(block.offset) - Number(blockGroup.offset));\n                    if (isCompressed) {\n                        resultData = unzip(resultData);\n                    }\n                    checkAbortSignal(signal);\n                    switch (blockType) {\n                        case 'summary': {\n                            observer.next(this.parseSummaryBlock(resultData, 0, request));\n                            break;\n                        }\n                        case 'bigwig': {\n                            observer.next(this.parseBigWigBlock(resultData, 0, request));\n                            break;\n                        }\n                        case 'bigbed': {\n                            observer.next(this.parseBigBedBlock(resultData, 0, Number(block.offset) * (1 << 8), request));\n                            break;\n                        }\n                        default: {\n                            console.warn(`Don't know what to do with ${blockType}`);\n                        }\n                    }\n                }\n            }));\n            observer.complete();\n        }\n        catch (e) {\n            observer.error(e);\n        }\n    }\n}\n//# sourceMappingURL=block-view.js.map","import { LocalFile, RemoteFile } from 'generic-filehandle2';\nimport { Observable, firstValueFrom } from 'rxjs';\nimport { toArray } from 'rxjs/operators';\nimport { BlockView } from './block-view';\nconst BIG_WIG_MAGIC = -2003829722;\nconst BIG_BED_MAGIC = -2021002517;\nexport class BBI {\n    getHeader(opts) {\n        if (!this.headerP) {\n            this.headerP = this._getHeader(opts).catch((e) => {\n                this.headerP = undefined;\n                throw e;\n            });\n        }\n        return this.headerP;\n    }\n    /*\n     * @param filehandle - a filehandle from generic-filehandle2\n     *\n     * @param path - a Local file path as a string\n     *\n     * @param url - a URL string\n     *\n     * @param renameRefSeqs - an optional method to rename the internal reference\n     * sequences using a mapping function\n     */\n    constructor(args) {\n        const { filehandle, renameRefSeqs = s => s, path, url } = args;\n        this.renameRefSeqs = renameRefSeqs;\n        if (filehandle) {\n            this.bbi = filehandle;\n        }\n        else if (url) {\n            this.bbi = new RemoteFile(url);\n        }\n        else if (path) {\n            this.bbi = new LocalFile(path);\n        }\n        else {\n            throw new Error('no file given');\n        }\n    }\n    async _getHeader(opts) {\n        const header = await this._getMainHeader(opts);\n        const chroms = await this._readChromTree(header, opts);\n        return {\n            ...header,\n            ...chroms,\n        };\n    }\n    async _getMainHeader(opts, requestSize = 2000) {\n        const b = await this.bbi.read(requestSize, 0, opts);\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        const r1 = dataView.getInt32(0, true);\n        if (r1 !== BIG_WIG_MAGIC && r1 !== BIG_BED_MAGIC) {\n            throw new Error('not a BigWig/BigBed file');\n        }\n        let offset = 0;\n        const magic = dataView.getInt32(offset, true);\n        offset += 4;\n        const version = dataView.getUint16(offset, true);\n        offset += 2;\n        const numZoomLevels = dataView.getUint16(offset, true);\n        offset += 2;\n        const chromTreeOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        const unzoomedDataOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        const unzoomedIndexOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        const fieldCount = dataView.getUint16(offset, true);\n        offset += 2;\n        const definedFieldCount = dataView.getUint16(offset, true);\n        offset += 2;\n        const asOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        const totalSummaryOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        const uncompressBufSize = dataView.getUint32(offset, true);\n        offset += 4;\n        const extHeaderOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        const zoomLevels = [];\n        for (let i = 0; i < numZoomLevels; i++) {\n            const reductionLevel = dataView.getUint32(offset, true);\n            offset += 4;\n            const reserved = dataView.getUint32(offset, true);\n            offset += 4;\n            const dataOffset = Number(dataView.getBigUint64(offset, true));\n            offset += 8;\n            const indexOffset = Number(dataView.getBigUint64(offset, true));\n            offset += 8;\n            zoomLevels.push({\n                reductionLevel,\n                reserved,\n                dataOffset,\n                indexOffset,\n            });\n        }\n        const fileType = magic === BIG_BED_MAGIC ? 'bigbed' : 'bigwig';\n        // refetch header if it is too large on first pass,\n        // 8*5 is the sizeof the totalSummary struct\n        if (asOffset > requestSize || totalSummaryOffset > requestSize - 8 * 5) {\n            return this._getMainHeader(opts, requestSize * 2);\n        }\n        let totalSummary;\n        if (totalSummaryOffset) {\n            const b2 = b.subarray(Number(totalSummaryOffset));\n            let offset = 0;\n            const dataView = new DataView(b2.buffer, b2.byteOffset, b2.length);\n            const basesCovered = Number(dataView.getBigUint64(offset, true));\n            offset += 8;\n            const scoreMin = dataView.getFloat64(offset, true);\n            offset += 8;\n            const scoreMax = dataView.getFloat64(offset, true);\n            offset += 8;\n            const scoreSum = dataView.getFloat64(offset, true);\n            offset += 8;\n            const scoreSumSquares = dataView.getFloat64(offset, true);\n            offset += 8;\n            totalSummary = {\n                scoreMin,\n                scoreMax,\n                scoreSum,\n                scoreSumSquares,\n                basesCovered,\n            };\n        }\n        else {\n            throw new Error('no stats');\n        }\n        const decoder = new TextDecoder('utf8');\n        return {\n            zoomLevels,\n            magic,\n            extHeaderOffset,\n            numZoomLevels,\n            fieldCount,\n            totalSummary,\n            definedFieldCount,\n            uncompressBufSize,\n            asOffset,\n            chromTreeOffset,\n            totalSummaryOffset,\n            unzoomedDataOffset,\n            unzoomedIndexOffset,\n            fileType,\n            version,\n            autoSql: asOffset\n                ? decoder.decode(b.subarray(asOffset, b.indexOf(0, asOffset)))\n                : '',\n        };\n    }\n    async _readChromTree(header, opts) {\n        const refsByNumber = [];\n        const refsByName = {};\n        let unzoomedDataOffset = header.unzoomedDataOffset;\n        const chromTreeOffset = header.chromTreeOffset;\n        while (unzoomedDataOffset % 4 !== 0) {\n            unzoomedDataOffset += 1;\n        }\n        const off = unzoomedDataOffset - chromTreeOffset;\n        const b = await this.bbi.read(off, Number(chromTreeOffset), opts);\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        // unused:\n        //    const magic = dataView.getUint32(offset, true)\n        offset += 4;\n        // unused:\n        //   const blockSize = dataView.getUint32(offset, true)\n        offset += 4;\n        const keySize = dataView.getUint32(offset, true);\n        offset += 4;\n        // unused:\n        //  const valSize = dataView.getUint32(offset, true)\n        offset += 4;\n        // unused:\n        // const itemCount = dataView.getBigUint64(offset, true)\n        offset += 8;\n        const rootNodeOffset = 32;\n        const decoder = new TextDecoder('utf8');\n        const bptReadNode = async (currentOffset) => {\n            let offset = currentOffset;\n            if (offset >= b.length) {\n                throw new Error('reading beyond end of buffer');\n            }\n            const isLeafNode = dataView.getUint8(offset);\n            offset += 2; //skip 1\n            const cnt = dataView.getUint16(offset, true);\n            offset += 2;\n            if (isLeafNode) {\n                for (let n = 0; n < cnt; n++) {\n                    const key = decoder\n                        .decode(b.subarray(offset, offset + keySize))\n                        .replaceAll('\\0', '');\n                    offset += keySize;\n                    const refId = dataView.getUint32(offset, true);\n                    offset += 4;\n                    const refSize = dataView.getUint32(offset, true);\n                    offset += 4;\n                    refsByName[this.renameRefSeqs(key)] = refId;\n                    refsByNumber[refId] = {\n                        name: key,\n                        id: refId,\n                        length: refSize,\n                    };\n                }\n            }\n            else {\n                // parse index node\n                const nextNodes = [];\n                for (let n = 0; n < cnt; n++) {\n                    offset += keySize;\n                    const childOffset = Number(dataView.getBigUint64(offset, true));\n                    offset += 8;\n                    nextNodes.push(bptReadNode(Number(childOffset) - Number(chromTreeOffset)));\n                }\n                await Promise.all(nextNodes);\n            }\n        };\n        await bptReadNode(rootNodeOffset);\n        return {\n            refsByName,\n            refsByNumber,\n        };\n    }\n    /*\n     * fetches the \"unzoomed\" view of the bigwig data. this is the default for bigbed\n     * @param abortSignal - a signal to optionally abort this operation\n     */\n    async getUnzoomedView(opts) {\n        const { unzoomedIndexOffset, refsByName, uncompressBufSize, fileType } = await this.getHeader(opts);\n        return new BlockView(this.bbi, refsByName, unzoomedIndexOffset, uncompressBufSize > 0, fileType);\n    }\n    /**\n     * Gets features from a BigWig file\n     *\n     * @param refName - The chromosome name\n     *\n     * @param start - The start of a region\n     *\n     * @param end - The end of a region\n     *\n     * @param opts - An object containing basesPerSpan (e.g. pixels per basepair)\n     * or scale used to infer the zoomLevel to use\n     */\n    async getFeatureStream(refName, start, end, opts) {\n        await this.getHeader(opts);\n        const chrName = this.renameRefSeqs(refName);\n        let view;\n        const { basesPerSpan, scale } = opts || {};\n        if (basesPerSpan) {\n            view = await this.getView(1 / basesPerSpan, opts);\n        }\n        else if (scale) {\n            view = await this.getView(scale, opts);\n        }\n        else {\n            view = await this.getView(1, opts);\n        }\n        return new Observable(observer => {\n            view\n                .readWigData(chrName, start, end, observer, opts)\n                .catch((e) => {\n                observer.error(e);\n            });\n        });\n    }\n    async getFeatures(refName, start, end, opts) {\n        const ob = await this.getFeatureStream(refName, start, end, opts);\n        const ret = await firstValueFrom(ob.pipe(toArray()));\n        return ret.flat();\n    }\n}\n//# sourceMappingURL=bbi.js.map","import { BBI } from './bbi';\nimport { BlockView } from './block-view';\nexport class BigWig extends BBI {\n    /**\n     * Retrieves a BlockView of a specific zoomLevel\n     *\n     * @param scale - number\n     *\n     * @param opts - An object containing basesPerSpan (e.g. pixels per basepair)\n     * or scale used to infer the zoomLevel to use\n     */\n    async getView(scale, opts) {\n        const { zoomLevels, refsByName, uncompressBufSize } = await this.getHeader(opts);\n        const basesPerPx = 1 / scale;\n        const maxLevel = zoomLevels.length - 1;\n        for (let i = maxLevel; i >= 0; i -= 1) {\n            const zh = zoomLevels[i];\n            // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n            if (zh && zh.reductionLevel <= 2 * basesPerPx) {\n                return new BlockView(this.bbi, refsByName, zh.indexOffset, uncompressBufSize > 0, 'summary');\n            }\n        }\n        return this.getUnzoomedView(opts);\n    }\n}\n//# sourceMappingURL=bigwig.js.map","import AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport QuickLRU from 'quick-lru';\nimport { Observable, firstValueFrom, merge } from 'rxjs';\nimport { map, reduce } from 'rxjs/operators';\nimport { BBI } from './bbi';\nexport function filterUndef(ts) {\n    return ts.filter((t) => !!t);\n}\nexport class BigBed extends BBI {\n    constructor() {\n        super(...arguments);\n        this.readIndicesCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: 1 }),\n            fill: (args, signal) => this._readIndices({ ...args, signal }),\n        });\n    }\n    readIndices(opts = {}) {\n        const { signal, ...rest } = opts;\n        return this.readIndicesCache.get(JSON.stringify(rest), opts, signal);\n    }\n    /*\n     * retrieve unzoomed view for any scale\n     */\n    async getView(_scale, opts) {\n        return this.getUnzoomedView(opts);\n    }\n    /*\n     * parse the bigbed extraIndex fields\n     *\n     *\n     * @return a Promise for an array of Index data structure since there can be\n     * multiple extraIndexes in a bigbed, see bedToBigBed documentation\n     */\n    async _readIndices(opts) {\n        const { extHeaderOffset } = await this.getHeader(opts);\n        const b = await this.bbi.read(64, Number(extHeaderOffset));\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        // const _size = dataView.getUint16(offset, true)\n        offset += 2;\n        const count = dataView.getUint16(offset, true);\n        offset += 2;\n        const dataOffset = Number(dataView.getBigUint64(offset, true));\n        offset += 8;\n        // no extra index is defined if count==0\n        if (count === 0) {\n            return [];\n        }\n        const blocklen = 20;\n        const len = blocklen * count;\n        const buffer = await this.bbi.read(len, Number(dataOffset));\n        const indices = [];\n        for (let i = 0; i < count; i += 1) {\n            const b = buffer.subarray(i * blocklen);\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            let offset = 0;\n            const type = dataView.getInt16(offset, true);\n            offset += 2;\n            const fieldcount = dataView.getInt16(offset, true);\n            offset += 2;\n            const dataOffset = Number(dataView.getBigUint64(offset, true));\n            offset += 8 + 4; //4 skip\n            const field = dataView.getInt16(offset, true);\n            indices.push({ type, fieldcount, offset: Number(dataOffset), field });\n        }\n        return indices;\n    }\n    /*\n     * perform a search in the bigbed extraIndex to find which blocks in the\n     * bigbed data to look for the actual feature data\n     *\n     * @param name - the name to search for\n     *\n     * @param opts - a SearchOptions argument with optional signal\n     *\n     * @return a Promise for an array of bigbed block Loc entries\n     */\n    async searchExtraIndexBlocks(name, opts = {}) {\n        const indices = await this.readIndices(opts);\n        if (indices.length === 0) {\n            return [];\n        }\n        const decoder = new TextDecoder('utf8');\n        const locs = indices.map(async (index) => {\n            const { offset: offset2, field } = index;\n            const b = await this.bbi.read(32, offset2, opts);\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            let offset = 0;\n            // const _magic = dataView.getInt32(offset, true)\n            offset += 4;\n            const blockSize = dataView.getInt32(offset, true);\n            offset += 4;\n            const keySize = dataView.getInt32(offset, true);\n            offset += 4;\n            const valSize = dataView.getInt32(offset, true);\n            offset += 4;\n            // const _itemCount = Number(dataView.getBigUint64(offset, true))\n            offset += 8;\n            const bptReadNode = async (nodeOffset) => {\n                const val = Number(nodeOffset);\n                const len = 4 + blockSize * (keySize + valSize);\n                const buffer = await this.bbi.read(len, val, opts);\n                const b = buffer;\n                const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n                let offset = 0;\n                const nodeType = dataView.getInt8(offset);\n                offset += 2; //skip 1\n                const cnt = dataView.getInt16(offset, true);\n                offset += 2;\n                const keys = [];\n                if (nodeType === 0) {\n                    const leafkeys = [];\n                    for (let i = 0; i < cnt; i++) {\n                        const key = decoder\n                            .decode(b.subarray(offset, offset + keySize))\n                            .replaceAll('\\0', '');\n                        offset += keySize;\n                        const dataOffset = Number(dataView.getBigUint64(offset, true));\n                        offset += 8;\n                        leafkeys.push({\n                            key,\n                            offset: dataOffset,\n                        });\n                    }\n                    let lastOffset = 0;\n                    for (const { key, offset } of leafkeys) {\n                        if (name.localeCompare(key) < 0 && lastOffset) {\n                            return bptReadNode(lastOffset);\n                        }\n                        lastOffset = offset;\n                    }\n                    return bptReadNode(lastOffset);\n                }\n                else if (nodeType === 1) {\n                    for (let i = 0; i < cnt; i++) {\n                        const key = decoder\n                            .decode(b.subarray(offset, offset + keySize))\n                            .replaceAll('\\0', '');\n                        offset += keySize;\n                        const dataOffset = Number(dataView.getBigUint64(offset, true));\n                        offset += 8;\n                        const length = dataView.getUint32(offset, true);\n                        offset += 4;\n                        const reserved = dataView.getUint32(offset, true);\n                        offset += 4;\n                        keys.push({\n                            key,\n                            offset: dataOffset,\n                            length,\n                            reserved,\n                        });\n                    }\n                    for (const n of keys) {\n                        if (n.key === name) {\n                            return { ...n, field };\n                        }\n                    }\n                    return undefined;\n                }\n            };\n            const rootNodeOffset = 32;\n            return bptReadNode(offset2 + rootNodeOffset);\n        });\n        return filterUndef(await Promise.all(locs));\n    }\n    /*\n     * retrieve the features from the bigbed data that were found through the\n     * lookup of the extraIndex note that there can be multiple extraIndex, see\n     * the BigBed specification and the -extraIndex argument to bedToBigBed\n     *\n     * @param name - the name to search for\n     *\n     * @param opts - options object with optional AboutSignal\n     *\n     * @return array of Feature\n     */\n    async searchExtraIndex(name, opts = {}) {\n        const blocks = await this.searchExtraIndexBlocks(name, opts);\n        if (blocks.length === 0) {\n            return [];\n        }\n        const view = await this.getUnzoomedView(opts);\n        const res = blocks.map(block => {\n            return new Observable(observer => {\n                view.readFeatures(observer, [block], opts).catch((e) => {\n                    observer.error(e);\n                });\n            }).pipe(reduce((acc, curr) => acc.concat(curr)), map(x => {\n                for (const element of x) {\n                    element.field = block.field;\n                }\n                return x;\n            }));\n        });\n        const ret = await firstValueFrom(merge(...res));\n        return ret.filter(f => f.rest?.split('\\t')[(f.field || 0) - 3] === name);\n    }\n}\n//# sourceMappingURL=bigbed.js.map","import './bigint-polyfill/polyfill';\nexport { BigWig } from './bigwig';\nexport { BigBed } from './bigbed';\n//# sourceMappingURL=index.js.map"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9]}