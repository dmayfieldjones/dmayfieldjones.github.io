{"version":3,"file":"static/chunks/564.ac9bba4a8b1fcb02.js","mappings":"yFAcC,IAP0B,EAAQ,KAAY,EAA/C,UAQA,MACA,GADyB,UAEzB,QAGA,IAEA,iCAAwC,42gBAExC,CAAO,CAEP,IAEA,WAEA,CAAO,CACP,CAGA,KAGA,SAAmB,EAAmB,GAEtC,WACA,cACA,EAJsC,KAItC,UAGA,YAGA,UACA,EAMA,OAHA,iBAAiE,GAGjE,UAOW,EAAmB,UAC9B,OAXoF,CAWpF,OACgB,EAAmB,GAFL,CAEK,KAAwB,EAAmB,QAC9E,WADmC,UACnC,CAD8E,EAC9E,GAAoD,uBAAwC,CAG5F,EAKW,EAAmB,mDAMnB,EAAmB,MAC9B,wBAD8B,IAC9B,oBACA,4CAAkE,eAAiB,EAEnF,sCAA2D,SAAa,CACxE,EAIA,IAAI,EAAmB,GAiIvB,MA/HA,MACA,EAAmB,EAAG,GACD,EAJE,CAIiB,CAAG,EAAmB,CAC9D,gBAFyC,CAEzC,CAFmB,GAEnB,CACA,CAAsB,EACtB,MAAwF,EAAmB,GAG3G,2BAH2G,IAG3G,EAGQ,EAAmB,wBAK3B,EACA,IAN2B,QAM3B,GACA,uBACA,gCACA,uCACA,gBACA,2BACA,oCACA,qCACA,qCAGA,eACA,gBAEA,IADA,wCACA,SACA,iDACA,eACA,CAEA,gBACA,6CAEA,GADA,gBACA,aACA,sDAAsE,EAAO,GAG7E,OAAiB,SADjB,2DACiB,SA7BjB,IA6BiB,EACjB,CAEA,iBACA,qCAGA,qBACA,oCAGA,oBACA,2BACA,CAEA,UACA,uCACA,iBACA,CAEA,WACA,yCACA,sDACA,wDAEA,CACA,CAEA,kBACA,qCACA,6BACA,qBACA,uCAAuH,aACvH,qDAGA,kBADA,iCADA,GACA,EACA,SAGA,mBACA,EACA,WACA,gBAEA,OACA,eACA,mBACA,oFAEA,0BACA,CAAa,CAEb,cACA,uBACA,+BACA,SAAgC,WAAc,eAC9C,GACA,KAEA,CACA,uCACA,+BACA,eACA,CAEA,wBACA,sBACA,sBAEA,aACA,YACA,CADyC,CACzC,QAEA,CAAa,CACb,YACA,YACA,CADqC,CACrC,SAEA,CAAS,CACT,CACA,EAEA,CAAC,GAEgB,CACjB,EAAU,uBAD0B,ICrNpC,mBAGA,gCACA,yDACA,EAGA,iCACA,QACA,WACA,sBACA,OAEA,iBAEA,UACA,GACA,CACA,QACA,EACA,6BACA,qDACA,EAEA,kCACA,yDACA,EACA,kCACA,MACA,QAAgB,IAAY,IAC5B,uBAEA,QACA,EACA,+BACA,yECUA,MAjDA,CACA,UAgDe,SAAS,EAAC,UAhDzB,EACA,qBACA,4BACA,mBAOA,cAEA,mBAEA,aAEA,cAEA,gBAEA,iBAEA,cAEA,eAEA,mBAEA,gBAEA,cAEA,uBAeA,EC2CA,GACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GACA,EAiDA,cACA,SACA,iBACA,OAAe,EAAK,cACpB,QAAgB,EAAK,UAErB,QACA,CACO,QAvCA,CACP,aACA,qBACA,sBACA,mBACA,2BAEA,+BAEA,aAEA,cAEA,kBAEA,iBAEA,mBAEA,uBACA,EAoBO,IAnBA,CACP,8BACA,eACA,yBACA,2BACA,EAeO,IAdA,CACP,uBACA,eACA,CAee,SACf,mBAAkB,4NAAkN,EACpO,aACA,iBACA,kBACA,sBACA,mBACA,qBACA,GACA,mBAEA,mBACA,gBACA,kBACA,gBACA,oBACA,sBACA,YAEA,GACA,sBAEA,GACA,YACA,kBACA,wBACA,4BACA,oCACA,EAEA,GACA,yBAEA,CAIA,WACA,oBAA+B,EAAS,YACxC,CAEA,mBACA,oBAA+B,EAAS,iBACxC,CAEA,oBACA,oBAA+B,EAAS,WACxC,CAEA,iBACA,oBAA+B,EAAS,YACxC,CAEA,wBACA,oBAA+B,EAAS,aACxC,CAEA,4BACA,oBAA+B,EAAS,cACxC,CAEA,UACA,oBAA+B,EAAS,WACxC,CAEA,UACA,oBAA+B,EAAS,WACxC,CAEA,cACA,oBAA+B,EAAS,eACxC,CAEA,aACA,oBAA+B,EAAS,YACxC,CAEA,cACA,oBAA+B,EAAS,SACxC,CAEA,kBACA,oBAA+B,EAAS,mBACxC,CAIA,aACA,wBAAmC,EAAS,mBAC5C,CAEA,oBACA,wBAAmC,EAAS,0BAC5C,CAEA,4BACA,wBAAmC,EAAS,+BAC5C,CAEA,iBACA,wBAAmC,EAAS,iBAC5C,CAKA,eACA,qCACA,MAhRA,cAEA,kCAGA,mBAFA,YAMA,+BACA,mBACA,aACA,8BACA,cAEA,SACA,IACA,IACA,4BACA,4BACA,wBACA,8BACA,UAEA,uBAGA,GADA,KACA,cAEA,aACA,KACA,gBAEA,cAGA,aACA,MAEA,cAEA,SACA,MAEA,aAEA,UAEA,aAEA,UAEA,aAEA,UAEA,aAIA,UAEA,aAGA,UAEA,cAGA,YAIA,4BAEA,wCACA,KACA,YAEA,KACA,CAEA,6CACA,KACA,YAGA,sBACA,EAuLA,sBACA,GACA,kBAEA,CACA,sBAMA,qBACA,8BACA,iBACA,wBACA,WACA,wCACA,2CACA,2CACA,MACA,MACA,gBACA,MACA,OAEA,iBACA,MACA,OAEA,SACA,yCACA,cACA,kEAiBA,OAfA,mDACA,OAEA,KACA,OACA,OACA,OACA,SAGA,OACA,OACA,OACA,QAEA,UACA,CACA,WACA,CAcA,0BACA,mBAGA,8BACA,cAjPA,kBAEA,uBACA,kBACA,GACA,UAEA,gBACA,OACA,MAGA,MADA,uBACA,SACA,GACA,SAEA,EAkOA,QAEA,CAAa,EAIb,iBACA,8BACA,OACA,2DACA,mBAEA,CACA,SACA,SAQA,OAPA,+BACA,mBAGA,cACA,CAAS,EACT,gCACA,CACA,CACA,8CCjXO,uBACP,CAEO,sBACP,CAEO,kBACP,CASO,kBACP,CCfA,OACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,CACA,aACA,YAAgB,MAAW,IAC3B,QAAuB,YAA4B,EAAE,QAAoB,ECYzE,uCACe,EACf,eACA,cACA,iBACA,eACA,eACA,CACA,cACA,eACA,oCACA,gBAEA,CAKA,QACA,QACA,WACA,mBACA,uBAEA,QACA,MACA,qBACA,gBACA,iBACA,SAEA,CACA,MACA,UACA,6BACA,kBACA,GACA,CACA,CACA,QACA,CAKA,QACA,SAEA,kBACA,iBAFA,SAGA,eACA,CAIA,KACA,wBACA,YAAwB,WAAgB,IACxC,kBAEA,ODrEO,KCqEa,IDrEb,GACP,SACA,uBAA2C,IAAW,IACtD,WAEA,QACA,EC+DoB,EACpB,CACA,6CC/CA,oBACA,WACA,YAAwB,IAAO,IAC/B,YAGA,OADA,OACA,CACA,EACA,GAEA,cACA,iBACA,wBACA,yBACA,cACA,iBACA,iBAEA,EACA,KACA,oCACA,mCACA,iDACA,mDACA,6BACA,mCACA,oBACA,kDACA,oBACA,4BACA,GACA,YAEA,kBAEA,OADA,cACA,CACA,CACA,SACA,iBACA,kDACA,uBACA,CACA,qBACA,wBAKA,iBAA4B,MAAK,CACjC,IAJA,mBACA,GAIA,CAEA,IAN0B,UAM1B,KAEA,wBACA,oBACA,8CACA,+BAEA,cACA,YACA,wCAEA,gBAA0B,EAAS,GAGnC,IAHmC,CAGnC,eACA,kBACA,oBACA,gBACA,CACA,sBACA,MACA,kBAIA,SACA,sBAEA,QAlFA,MAkF0B,YAE1B,GACA,mBAEA,mCACA,CADqD,GACrD,WACA,qBACA,2CACA,EAIA,WACA,oBAEA,iBACA,iBACA,iDAOA,iBACA,0BACA,QAAoB,KAAQ,IAC5B,cACA,WAEA,QADA,aAC4B,KAAQ,IACpC,WACA,YAGA,CAGA,gBACA,GA7HA,GA6HA,EA5HA,CA4HA,GACA,gBAMA,gBACA,QACA,gBAEA,0BACA,QAAoB,IAAgB,IACpC,OAEA,wBACA,QAAoB,IAAgB,KAEpC,QAAwB,UAAgB,IACxC,MACA,eAIA,YACA,CAGA,UACA,OACA,QAAoB,IAAgB,SA0BpC,IAzBA,8CAKA,QADA,YACwB,CADQ,CACR,EAAc,KACtC,KACA,EADuB,CACvB,KAvKA,EAuKA,GACA,gBAIA,WAGA,UAIA,IAHA,GAMA,OACA,CAIA,QADA,SACwB,IAAc,IACtC,OACA,OAEA,QACA,SAaA,KACA,UACA,0BA9MA,KA+MA,4BACA,2BACA,WACA,WAEA,QACA,QAA6B,KAAa,IAE1C,QADA,kBAC4B,IAAc,IAC1C,UACA,mBAKA,QAAwB,IAAc,IACtC,UAOA,IADA,MACA,IAA6B,IAAY,IACzC,QAOA,eACA,MACA,QACA,eAEA,cACA,iBACA,CADkC,CAClC,kBACA,WACA,CAKA,2BACA,QAAoB,MAAS,IAC7B,OAGA,kBACA,2CAEA,IADA,GACe,IAYf,IAVA,MACA,KACA,MACA,gBAEA,aAGA,WACA,YAEA,YACA,iBAEA,gBAJoB,IAOpB,iBAIA,EADA,cACA,MA3RA,GA2RA,GACA,gBAEA,mBAKA,iBAEA,IACA,IACA,KASA,eACA,MACA,QACA,CAKA,KAOA,IANA,IACA,mBACA,gBAEA,UACA,QACA,KACA,SAIA,OACA,MASA,kBACA,gBAIA,IADA,MADA,OAEA,CAEA,OACA,QACA,CAYA,IALA,aACA,gBAGA,IACA,IAAoB,MAAS,IAC7B,SACA,OACA,IAGA,QAAoB,IAAe,IACnC,WACA,cACA,OAKA,gBAWA,OAVA,IAEA,MADA,SAEA,MACA,MAEA,gBACA,oBACA,kBACA,gBACA,EACA,CAOA,IARqB,SAQrB,SACA,MAKA,qBACA,SAGA,oDACA,kCACA,oBACA,SAgBA,IAfA,IACA,IAEA,MADA,SAEA,MACA,QACA,IACA,IACA,OAGA,IACA,KAEA,gCACA,KACA,+BACA,kBAEA,MACA,KAEA,CAWA,OAVA,kBAEA,8CACA,qCAEA,oCACA,aACA,iCACA,KAEA,gBAEA,CACA,kBACA,kBACA,SAEA,SAA4B,MAAM,OAClC,QACA,sBACA,sBAEA,mBACA,UACA,EACA,iBACA,yBACA,EACA,CACA,EACA,cACA,SAA6B,MAAM,EACnC,GACA,MACA,sBACA,2BACA,UAEA,mBACA,QAGA,YACA,WAIA,+BAwBA,OAtBA,QACA,wBACA,oCACA,2CACA,mBACA,aACA,CACA,yBACA,EACA,uBAEA,kCACA,MACA,2DAEA,+BACA,qCACA,aACA,CACA,oBAEA,cACA,CACA,EAIO,kBAEP,WACA,OACA,aACA,MACA,sBAGA,mBACA,qBAEA,CACA,4BASA,CAT8D,EAC9D,iBACA,sCAEA,yBACA,aACA,eACA,KAEA,uBAEA,0BAGA,KAEA,CAEA,mBACA,oBAEA,CCthBe,QACf,eACA,WACA,sBACA,YACA,aACA,aACA,YACA,CACA,oBACA,YAAwB,IAAO,IAC/B,qCAEA,uBACA,cACA,CACA,CAF0B,iBAE1B,GAGA,OAFA,oCAEA,gCAGA,CACA,qBAKA,IAFA,wBACA,cACA,sBACA,gBACA,oCAEA,CACA,iBAUA,mCAIA,IAFA,mCAEA,YACA,0BACA,YAGA,0BACA,YACA,MAEA,YAEA,EAF0B,GAE1B,SACA,aACA,CACA,CAFyB,WAEzB,SACA,eAeA,IAdA,oCACA,uBACA,cACA,CADyB,GACzB,UAIA,aACA,eACA,qCAEA,cAGA,sBACA,gBACA,qBAEA,CACA,qBACA,YAAwB,IAAO,IAC/B,qBAEA,CACA,CC1Fe,QACf,mBACA,kBACA,iBACA,UACA,UACA,YAAwB,gBAAmB,IAC3C,YACA,WAEA,CACA,iBAEA,2CAEA,IACA,IACA,qBACA,eAMA,6CAEA,WA3BA,GA4BA,iBA5BA,GA6BA,gBA9BA,OA+BA,wBAGA,gBACA,+BACA,gBACA,sBACA,cACA,YACA,sBACA,aACA,CACA,QACA,CACA,mBAEA,kBACA,YAAwB,gBAAmB,IAC3C,mCACA,2BAGA,mBAEA,QACA,YAAwB,aAAkB,IAC1C,aAGA,6CAEA,WA7DA,GA8DA,iBA9DA,GA+DA,gBAhEA,OAkEA,wBAGA,gBACA,+BACA,gBACA,sBACA,cACA,YACA,sBACA,aACA,CACA,CACA,CCjFe,QACf,uBACA,OACA,2BACA,gBAGA,WACA,sBAEA,4CACA,UACA,CAGA,MACA,4BACA,CACA,YACA,0CAEA,OADA,YACA,CACA,CACA,WACA,yBAEA,OADA,WACA,CACA,CACA,WACA,yBAEA,OADA,WACA,sBACA,CACA,aACA,sBAEA,OADA,oBAEA,CACA,aACA,0CAEA,OADA,YACA,CACA,CAEA,aACA,IACA,EADA,KAEA,EACA,0BAEA,kCAEU,GACV,QACA,CACA,YAEA,IACA,EADA,IAEA,GAEA,WADA,0BAEU,OACV,QACA,CACA,WACA,yBAwCA,OAvCA,WAEA,QAGA,EADA,aAEA,4BACA,2BACA,0BACA,2BACA,aAGA,QAGA,EADA,aAEA,4BACA,0BACA,2BACA,aAGA,QAGA,EADA,aACA,sDACA,aAGA,SAGA,EADA,YACA,mBACA,YAKA,CACA,CACA,CClGe,QACf,UAEA,OADA,gBAA0B,EAAQ,GAClC,GADkC,CAClC,0BACA,CACA,oBACA,4BAVA,IAWA,GACA,4BAEA,QACA,MAEA,OACA,wCAGA,UACA,KACA,uCACA,CAEA,QACA,yCAGA,OACA,yCAEA,QACA,QACA,+BACA,oCAGA,QACA,4BACA,4BAMA,OA5CA,IAyCA,GACA,2BAEA,CACA,CAGA,aACA,wBACA,cACA,OACA,QAEA,UAA+B,EAAS,GACxC,IADwC,EACjB,EAAU,GACjC,KADiC,aACjC,IACA,YAAwB,IAAW,IACnC,wBAEA,QACA,CAGA,aACA,wBACA,cACA,OACA,QAEA,eACA,YAAwB,IAAa,IACrC,SAAgC,EAAS,GAEzC,IAFyC,EAEzC,IAAuB,EAAU,GACjC,KADiC,aACjC,IACA,QACA,YAAwB,IAAW,IACnC,2BACA,OAEA,QACA,CAGA,eACA,OAAe,EAAM,mBACrB,CAGA,gBACA,wBACA,cACA,OACA,QAEA,UAA8B,EAAS,GACvC,IADuC,IACvC,KACA,YAAwB,OAAU,IAClC,SAA+B,EAAS,GAExC,UAAuB,EAAU,GACjC,KADiC,aACjC,IAEA,IADA,QACA,MACA,wBACA,+BACA,IACA,MACA,WACA,wBACA,MACA,KAEA,YAA4B,KAAU,IACtC,YAEA,MACA,CACA,QACA,CAGA,gBACA,wBACA,cACA,OACA,QAEA,eACA,YAAwB,IAAa,IACrC,SAA+B,EAAS,GAExC,iBACA,YAAwB,OAAU,IAClC,SAA+B,EAAS,GAExC,IAFwC,EAExC,IAAuB,EAAU,GACjC,KADiC,aACjC,IACA,QAEA,IADA,QACA,MACA,2BACA,OACA,+BACA,IACA,MACA,WACA,wBACA,MACA,KAEA,YAA4B,KAAU,IACtC,YAEA,MACA,CACA,QACA,CAGA,kBACA,uBACA,uBACA,YAAwB,YAAe,IACvC,kBAGA,SADA,cACA,CAD0C,WAG1C,OACA,wBACA,gBAEA,YAA4B,IAAS,IACrC,eAGA,gBAEA,gBAAmC,IAAS,KAC5C,UACA,aAEA,YACA,KACA,MAEA,gBAEA,gBAAmC,IAAS,KAC5C,UACA,aAEA,YACA,KACA,MAEA,oBAYA,cAVA,gBAAmC,IAAS,KAC5C,UACA,aAEA,aACA,KACA,CAMA,QACA,CAEA,YACA,UAA2B,EAAQ,WAEnC,aACA,YAAwB,WAAgB,IACxC,UAGA,gBAAkC,MAAS,IAC3C,MACA,WAGA,eAGA,YAAwB,MAAS,IACjC,OACA,eACA,QAGA,cAEA,kBACA,mBAEA,WACA,WACA,YAAwB,IAAO,IAC/B,mBAGA,eACA,YAAwB,IAAO,IAC/B,6BACA,+BAGA,wBACA,YAAwB,IAAO,IAC/B,YAA4B,OAAa,IACzC,iBAGA,QACA,CAGA,eACA,wBACA,YAAwB,IAAS,IACjC,kBAEA,QACA,CACA,CCnRA,kBACA,QACA,CADe,CACf,EACA,CADe,CACf,GAEA,cACA,CAD+B,IAC/B,MACA,mBAGA,GAFA,SACA,KACA,MACA,mBAEA,IADA,OACA,KACA,QAEA,CACA,GACA,CAEA,QAGA,IAFA,IACA,IACA,MACA,QACA,GACA,aACA,IACA,EAAU,aACV,UACA,QAEA,IACA,CACA,CCrBA,gBACA,WACA,WACA,IACA,YAAoB,IAAS,KAC7B,gBACA,GAEA,OACA,CACA,QACA,CACA,oBACA,8BACA,CACA,gBAIA,OAHA,SACA,2BAEA,CACA,CA4HO,SAAS,EAAM,GAEtB,UAFsB,MAItB,OACA,mBAMA,OACA,QACA,EANA,IAMA,KAKA,GATA,MAMA,kBAPA,IAWA,OA7CA,cACA,mBAEA,WACA,WACA,YAAoB,IAAO,IAC3B,mBAGA,eACA,YAAoB,IAAO,IAC3B,6BACA,eAGA,wBACA,YAAoB,IAAO,IAC3B,YAAwB,OAAa,IACrC,iBAGA,QACA,EAuBA,KAGA,KACA,QACA,QAtGA,YACA,mBACA,WACA,YAAoB,IAAU,IAC9B,kBAGA,WADA,cACA,EA+FA,GAGA,KACA,QACA,iBAxJA,KACA,oBACA,gBAEA,OACA,8BAEA,CACA,oBACA,oBACA,QAAmC,EAAQ,SAC3C,CAEA,UAAuB,EAAQ,GAC/B,GAD+B,CAC/B,aACA,cACA,OACA,QAEA,YAAoB,IAAO,IAC3B,kBAEA,aACA,EAiIA,KAGA,GAtBA,KAuBA,yBAEA,MA7BA,MA8BA,oBAGA,eAkJA,OAEA,mBACA,WACA,QACA,QACA,oBACA,gBACA,UAAuB,EAAQ,eAC/B,MAA2B,EAAQ,SACnC,CAEA,iBACA,cACA,SArDA,SAEA,YAAoB,MAAS,KAC7B,gBACA,gBACA,YAAwB,MAAS,IACjC,SAEA,CAEA,WAEA,YAAoB,MAAS,KAC7B,SACA,SAEA,QACA,YAAwB,MAAS,IACjC,OAGA,IACA,KAGA,sBACA,YACA,mBAIA,UAEA,UACA,YAAwB,MAAS,IACjC,0BAGA,EAeA,SAEA,iBACA,YAAoB,MAAS,IAE7B,eAGA,eACA,WACA,YAAoB,IAAO,IAC3B,oBACA,OAGA,wBACA,kBACA,YAAoB,IAAa,IACjC,YAAwB,IAAO,KAC/B,WAvXA,IAuXA,CAvXA,IAyXA,aACA,CADkC,CAClC,SACA,qCACA,eACA,MACA,CAMA,IADA,KACA,MACA,aArYA,IAqYA,CArYA,IAsYA,EApYA,cAIA,QACA,gBACA,IAGA,QACA,EA0XA,YACA,UACA,6CACA,mBACA,QACA,CACA,QACA,EAzMA,OASA,OANA,GACA,YA9IA,SACA,IAAoB,EAAQ,GAC5B,GAD4B,CAC5B,oBAEA,IACA,YAAoB,IAAS,KAC7B,WACA,SACA,oBACA,YAA4B,KAAU,IACtC,QAEA,MAEA,QAEA,CACA,QACA,EA4HA,UAEA,GACA,YAjHA,SACA,wBACA,IAEA,QACA,YAAwB,IAAS,IACjC,eAIA,QACA,QAAoB,IAAS,KAC7B,UACA,aAEA,YACA,KACA,MAGA,QACA,QAAoB,IAAS,KAC7B,UACA,aAEA,YACA,KACA,MAGA,SACA,QAAoB,IAAS,KAC7B,UACA,aAEA,aACA,KACA,CAEA,QACA,EAyEA,UAEA,CACA,EAhDA,IAAuB,EAAQ,GAC/B,EACA,CAiDA,cACA,iBACA,YAAoB,MAAS,IAC7B,OAEA,QACA,eACA,IACA,GACA,OACA,KACA,IACA,KAGA,kBACA,KACA,iBAGA,UACM,MACN,QACA,CAuBA,kBAEA,iBACA,cAvBA,gBAEA,YAAoB,MAAS,IAC7B,OAGA,WAEA,YAAoB,MAAS,IAC7B,QACA,qBAGA,QAEA,OACA,YAAoB,OAAU,IAC9B,gBAEA,EAKA,OAEA,cAEA,WACA,YAAoB,IAAO,IAC3B,oBAGA,wBACA,YAAoB,IAAY,KAChC,YAEA,EAFgC,CAEhC,CAhRA,KA+QA,KACA,CACA,CAD0B,CAC1B,KACA,0BACA,cACA,CAEA,QACA,CACA,gBAEA,QACA,YAAoB,MAAS,IAC7B,QAEA,iBACA,OAEA,QACA,aACA,KACA,IAGA,YAAoB,MAAS,IAC7B,QAEA,CEvSA,UAAkB,EAgDlB,WAhD2B,CAgD3B,IACA,WACA,iBACA,QAEA,QACA,gBEhGA,SAAS,EAAI,OACb,KACA,SAEA,KACA,WAAmB,YAAU,IAE7B,KACA,WAAmB,WAAS,GAE5B,iEACA,CETA,QAEA,cACA,cACA,aACA,CACA,CACA,QAGA,cACA,mBACA,YAAwB,iBAAoB,KAC5C,gBAEA,YACA,CACA,CACA,QAGA,cACA,kBACA,gBACA,CACA,CAgBA,WACA,EACA,EACA,EACA,GAGA,mBAFA,QAEA,GACA,CAsDA,OAAe,CACf,KACA,aACA,iBACA,WAhFA,gBACA,eACA,UAAkB,EAAkB,oCAEpC,iBACA,UAAkB,EAAkB,kCAEpC,WACA,QACA,EAwEA,cACA,kBA1DA,SACA,EACA,EACA,GACA,4BACA,EAsDA,IApDA,cACA,iBACA,EAmDA,cA3BA,SACA,EACA,EACA,EACA,GACA,gBAvBA,EACA,EACA,EACA,EACA,GAKA,GAFA,IAEY,CAFZ,UAEuB,CAJvB,OAEA,KD1EA,QC6EA,GAEA,OADA,kBAEU,EDhFV,ECgFqB,MAAW,CAEhC,IAFgC,GAEhC,CACA,EAOA,qBACA,EAsBA,YApBA,SACA,EACA,GAEA,KDjGA,ECiGY,MACZ,GACA,EAFuB,GAEvB,oBACU,EDpGV,ECoGqB,MAAW,CAEhC,IAFgC,GAEhC,CACA,CAWA,CAAC,CGhHD,CHgHE,QGhHF,MACA,MACA,UAAkB,EAAkB,mBAEpC,CCkHA,SACA,mBACA,eACA,sCACA,iBACA,qBAEA,MACA,mCAEA,OADA,kBACA,CACA,CACA,UACA,iBACA,CACA,aACA,uBAEA,WACA,qBACA,CACA,OAGA,OAFA,+BACA,kBACA,CACA,CACA,WAEA,OADA,kBACA,CACA,CACA,eAEA,OADA,iBACA,CACA,CACA,SACA,iDAEA,OADA,kBACA,CACA,CACA,YACA,0CAEA,iBEnKO,eACP,MAAW,cAAO,GAClB,CCHO,uBACP,CACO,mBACP,QACA,wCACA,SACA,4EAEA,YAA6B,EAAM,IAEnC,MACA,sCACA,iBACA,iBACA,oBAEA,iBAEA,QACA,4BCjBO,IAGA,qBAgBA,iBACP,IAEA,EAFA,IACA,OAuCA,OApCA,OACA,IACA,MAGA,OACA,mBACA,MAGA,OACA,EACA,WACA,UACA,OACA,MAGA,OACA,EACA,WACA,WACA,UACA,OACA,OAIA,EACA,WACA,WACA,WACA,UACA,UACA,MAEA,QAEO,iBACP,IAEA,EAFA,IACA,OA2FA,OAxFA,OACA,IACA,MAGA,OACA,sBACA,MAGA,OACA,EACA,WACA,UACA,OACA,MAGA,OACA,EACA,WACA,WACA,UACA,OACA,MAGA,OACA,EACA,UAhGO,YAiGP,YACA,WACA,UACA,QACA,MAGA,OACA,EACA,qBA1GO,YA2GP,YACA,WACA,UACA,QACA,MAGA,OACA,EACA,cACA,UACA,QAtHO,YAwHP,YACA,WACA,UACA,QACA,MAGA,OACA,EACA,YACA,WACA,UACA,QApIO,YAsIP,YACA,WACA,UACA,QACA,OAIA,EACA,UACA,YACA,WACA,UACA,QAnJO,YAqJP,YACA,WACA,UACA,QACA,MAEA,QAEO,yBACP,WAAY,WAAgB,OAC5B,OACA,KACA,iBACA,SACA,CACA,CACO,iBACP,qBACA,WAAkC,EAAW,EAC7C,0BACA,iBACA,kBACA,WACA,8BACA,cACA,CAAa,CACb,CACA,eAEA,CCnLO,cACP,OACA,iBACA,mDACA,0BACA,IACA,8BACA,KACA,oBACA,KACA,oBAMA,OALA,KAKA,CACA,OACA,QACA,eACA,eACA,OATA,EACA,2BACA,mBAQA,CAAiB,CACjB,OARA,KASA,CACA,CAAS,CACT,YACA,CACA,CAuEA,mBAEA,MADA,wBACA,wBACA,KACA,YAAoB,WAAgB,KACpC,uBAEA,QACA,CAyFA,eACA,SACA,YAAiB,WAAa,SAC9B,MACA,8BAA0C,GAAK,SAE/C,OAEA,QACA,CACO,eACP,kCA6IA,iBAEA,mBADA,EACA,OADA,EACA,qBACA,MAAkC,GAAS,KAE3C,CAF2C,EAE3C,GAA0C,GAAS,EADnD,IACmD,EACnD,KACA,SACA,eAGA,UAEA,SAAiC,GAAS,IAC1C,EAD0C,CAC1C,iBACA,IACA,MACA,UAEA,SAAkC,GAAS,IAC3C,EAD2C,CAC3C,SAEA,SAAiC,GAAS,EAD1C,IAC0C,CAC1C,OACA,IACA,MACA,UAEA,MAAoB,GAAS,KAC7B,CAD6B,CAC7B,KACA,QACA,SACA,YAAwB,IAAc,KACtC,MAAyB,GAAS,KAClC,CADkC,CAClC,WACA,QAEA,YACA,MAAqB,GAAS,KAC9B,CAD8B,CAC9B,KACA,eACA,aACA,eACA,QACA,SACA,YAAwB,IAAgB,KACxC,MAAwB,GAAS,KACjC,CADiC,EACjC,KACA,YACA,CACA,cACA,MACA,UAEA,IAAgB,kBAA6C,OAC7D,qBAEA,IAAgB,kBAA4C,KAD5D,IAEA,oBACA,GACA,MACA,UAEA,yBAEA,SAA6C,GAAS,EADtD,IACsD,CACtD,oBACA,IACA,MACA,UAEA,SAAkC,GAAS,IAC3C,EAD2C,CAC3C,SAEA,SAAkC,GAAS,EAD3C,IAC2C,CAC3C,YACA,IACA,MACA,UAEA,SAAkC,GAAS,IAC3C,EAD2C,CAC3C,SAEA,SAAgC,GAAS,EADzC,IACyC,CACzC,OACA,IACA,MACA,UAEA,SAAkC,GAAS,IAC3C,EAD2C,CAC3C,SAEA,SAAkC,GAAS,EAD3C,IAC2C,CAC3C,WACA,IACA,MACA,UAEA,SAAkC,GAAS,IAC3C,EAD2C,CAC3C,SACA,IACA,MAEA,+BAA2C,EAAQ,GAEnD,OACA,OACA,UACA,kBACA,YACA,CAAS,CACT,QACA,CACA,CACA,cACA,OACA,eACA,SAA0C,GAAS,KAEnD,CAFmD,EAEnD,GAA2C,GAAS,EADpD,IACoD,EACpD,KACA,SACA,YAA4B,IAAc,KAC1C,gCACA,4BAEA,OAAwB,YAA4B,KADpD,MAEA,IACA,YAA4B,UAAY,CACxC,CACA,OACA,OACA,UACA,OACA,UACA,CAAiB,CACjB,QACA,CACA,CAAS,CAET,CACA,cACA,OACA,eACA,SAA0C,GAAS,KAEnD,CAFmD,EAEnD,GAA2C,GAAS,EADpD,IACoD,EACpD,KACA,SACA,YAA4B,IAAc,KAC1C,SAAyC,GAAS,KAClD,CADkD,EAClD,EACA,qCACA,8BACA,2BACA,OAAwB,YAA4B,QACpD,IACA,YAA4B,UAAY,CACxC,CACA,OACA,OACA,UACA,OACA,UACA,CAAiB,CACjB,QACA,CACA,CAAS,CAET,CAwHO,eACP,OACA,wBACA,gBAhjBA,CAAa,OAlDb,UAEA,mBADA,EACA,8BACA,IACA,gBACA,GACA,MACA,OACA,QACA,OACA,OACA,WACA,QACA,UACA,OACA,IACA,MACA,yCAAyD,GAAG,kBAE5D,KACA,oBACA,GACA,cACA,qBACA,sBACA,wBACA,gBACA,YACA,IACA,MACA,6CAA6D,EAAE,GAG/D,SAAwC,GAAS,EADjD,IACiD,EAEjD,MAA6C,GAAS,EADtD,IACsD,EAEtD,MAA+C,GAAS,EADxD,IACwD,EAExD,OACA,OAFA,KAGA,OACA,mBACA,iBACA,YACA,cACA,mBACA,CAAa,CAEb,EACa,cAijBb,eA9iBA,CACA,eAGA,UADA,SADA,EACA,OADA,EACA,WADA,EACA,QACA,gBAEA,OACA,OAFA,KAGA,OACA,OACA,CAAiB,CAEjB,CAAS,CACT,WACA,EAiiBA,+BACA,wBACA,sBA7HA,CACA,eAIA,IAAoB,kBAlYpB,EACA,eAEA,mBADA,EACA,OADA,EACA,WADA,EACA,QACA,MAA0C,GAAS,KAEnD,MAA2C,GAAS,EADpD,IACoD,EACpD,KACA,SACA,YAA4B,IAAc,KAC1C,gCACA,4BAEA,GADA,KACA,UACA,UACA,UACA,UACA,UACA,SACA,QACA,MACA,qBACA,CAAqB,EACrB,UAEA,YACA,QACA,MACA,OACA,cACA,gBACA,gBACA,gBACA,gBAEA,CAAqB,EACrB,UAEA,aACA,IAA4B,kBAA2B,CApEvD,CACA,eACA,SAAuC,GAAS,KAChD,CADgD,EAChD,EACA,wBACA,KACA,SACA,IACA,IACA,KAAmB,WAAmB,IACtC,OACA,kBACA,OAMA,OAHA,KACA,kBAEA,CACA,OACA,OACA,MACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,EA0CuD,YACvD,YAAgC,eAAwB,EACxD,GACA,MAEA,2BAAmD,EAAI,EAEvD,CACA,OACA,OACA,UACA,WACA,MACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,EA0U8D,YAC9D,IACA,IAAoB,kBAAgD,iBACpE,IACA,IAAoB,kBAAyC,iBAE7D,OADA,IACA,CACA,OACA,yBACA,mBACA,iBACA,CAAiB,CACjB,QACA,CACA,CAAS,EA2GT,aA7SA,CACA,qBACA,EA4SA,yBA9XA,OA/CA,YA6BA,EA5BA,SAAyC,GAAS,KAClD,CADkD,EAClD,EACA,QAEA,SACA,SAAqC,GAAS,KAC9C,CAD8C,EAC9C,EACA,GACA,MACA,OAmaA,EAnaA,CACA,SAAqC,GAAS,KAC9C,CAD8C,EAC9C,EACA,GACA,MAEA,gCAEA,SAAwC,GAAS,KAEjD,CAFiD,EAEjD,GAA4C,GAAS,EADrD,IACqD,EACrD,KACA,SACA,YAAwB,IAAmB,KAC3C,SAAqC,GAAS,KAC9C,CAD8C,EAC9C,EACA,SACA,CAOA,OA2YA,GA/YA,IACA,0BACA,OAEA,CACA,OACA,gBACA,MACA,aACA,gBACA,YACA,YACA,CAAa,CACb,QACA,CACA,EAGA,qBA8XA,uBAlXA,mBA0CA,EAxCA,SAA2C,GAAS,KAEpD,CAFoD,EAEpD,GAA8C,GAAS,EADvD,IACuD,EAEvD,MAA6C,GAAS,EADtD,IACsD,EAEtD,MAA6C,GAAS,EADtD,IACsD,EACtD,KAGA,QACA,GAqWA,GArWA,GACA,SAAyC,GAAS,KAClD,CADkD,EAClD,EACA,GACA,MACA,OAgWA,EAhWA,CACA,SAAyC,GAAS,KAClD,CADkD,EAClD,EACA,GACA,MAEA,2DAIA,SAA4C,GAAS,KAErD,MAAgD,GAAS,EADzD,IACyD,EACzD,KACA,SACA,YAA4B,IAAmB,KAC/C,SAAyC,GAAS,KAClD,CADkD,EAClD,EACA,SACA,CACA,SAAiD,GAAS,KAS1D,CAT0D,MAC1D,KA2UA,GAvUA,IACA,0BACA,OAEA,CACA,OACA,MACA,YACA,aACA,gBACA,aACA,WACA,cACA,gBACA,iBACA,YACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,qBAoTA,sBApGA,aACA,mBA+BA,EA3BA,UAFA,SADA,EACA,OADA,EACA,WADA,EACA,QAEA,eAKA,MAA2C,GAAS,EAJpD,IAIoD,EAEpD,MAA8C,GAAS,EADvD,IACuD,EAEvD,MAAgD,GAAS,EADzD,IACyD,EAEzD,MAA6C,GAAS,EADtD,IACsD,EACtD,KACA,QACA,GAiFA,GAjFA,GACA,SAAyC,GAAS,KAClD,CADkD,CAClD,EACA,IACA,MACA,OA4EA,EA5EA,CACA,SAAyC,GAAS,KAClD,CADkD,CAClD,EACA,IACA,MAEA,wCAGA,GAmEA,EAnEA,GACA,SAAwC,GAAS,KACjD,CADiD,CACjD,EACA,IACA,CACA,SAA4C,GAAS,KAErD,CAFqD,EAErD,GAA+C,GAAS,EADxD,IACwD,EAExD,OACA,OACA,SACA,WACA,cACA,gBACA,YACA,eACA,WACA,gBACA,YACA,CAAiB,CACjB,OAbA,IAcA,CACA,CAAS,EA6CT,sBAxCA,mBAWA,EATA,mBADA,EACA,oBADA,EACA,QACA,MAA+C,GAAS,KACxD,CADwD,EACxD,EACA,SACA,YAA4B,IAAkB,KAC9C,SAA+C,GAAS,KACxD,CADwD,EACxD,EACA,SACA,CAMA,OAwBA,GA5BA,IACA,oBACA,MAEA,CACA,OACA,iBAAiD,OAAI,EAAO,CAC5D,eACA,WACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,qBAgBA,CACA,CCroBA,eACA,SACA,YAAoB,qBAAsC,IAC1D,6BAEA,QACA,CC8Ge,SACf,mBACA,iBACA,yBACA,iBACA,iBAGA,kBAEA,iBAAgB,GAAe,gCAC/B,EAA+B,GAAiB,GAChD,WADgD,CAChD,uBACA,mEACA,0CACA,MAA4B,GAAS,2DACrC,OAAqB,qBACrB,CACA,4CACA,MAA4B,GAAS,6DACrC,OAAqB,qBACrB,CAEA,UAAsB,EAAkB,0DAA2D,cAAmB,EAEtH,CAEA,kBACA,6BAEA,iBACA,mCACA,YAAwB,WAAmB,KAC3C,kCACA,QACA,oBAEA,QACA,CAEA,yBAEA,MADA,wBACA,IAGA,iCACA,6BACA,KAMA,OALA,cACA,iCACA,kBAEA,CAAS,EACT,CACA,CACA,6BAEA,MADA,uCACA,IAEA,2BAEA,8BACA,yCACA,IAAa,GAAmB,GAChC,aADgC,0BAGhC,gBACA,OAEA,kDACA,cACA,4CAEA,wBACA,uDACA,MACA,UAA0B,EAAkB,oEAO5C,OAEA,qBACA,oBACA,iCACA,iBACA,CACA,CACA,wBACA,0CACA,6CACA,oHAEA,4GACA,2BACA,UAA0B,EAAiB,uEAE3C,OACA,MACA,oBACA,iCACA,kBAEA,CAEA,CACA,gBACA,8BACA,CACA,sBACA,iBAAgB,GAAe,gCAC/B,8CACA,cACA,4CAEA,6BACA,wCAEA,QACA,oCACY,GAAmB,kBAC/B,6BACA,oDACA,sCACA,MACA,QAAwB,iBAAkB,EAC1C,EHtEW,KGsE+B,EHtE5B,WGsE4B,GHtE5B,oCGuEd,uBACA,qCACA,SACA,SACA,UAA8B,EAAkB,2CAA4C,0BAAoC,MAAM,EAAM,IAAI,EAAI,kBAAkB,EAAU,oBAAoB,EAAO,EAE3M,CACA,CAKA,oCACA,GACA,mBAAgC,GAAmB,iBACnD,4BACA,EACA,WAAyB,6BAAiC,CAC1D,gBACA,YACA,aACA,sBAKA,OAJA,aACA,GAA8B,8BAC9B,mBAEA,CACA,CAAiB,CACJ,EAEb,MACA,iCACA,MACA,UAA0B,EAAkB,wBAAyB,GAAgB,cAErF,2BACA,EACA,oCACA,YAAwB,WAAoB,KAC5C,IACA,MDpHe,YCoH0B,CDpH1B,eACf,IAwFA,EAtEA,EAIA,EACA,EACA,EA4DA,EACA,EACA,EACA,EAvFA,UAGA,UACA,IAAS,GAAmB,iBAC5B,uCAEA,yCACA,QACA,yBACA,UAEA,SACA,YACA,0BAEA,uBACA,cASA,GAPA,qBACA,gBAMQ,EAAgB,mBAIxB,EADA,aAEA,sBAEA,GADA,aACA,EAEA,cACA,UACA,WACA,IACA,YACA,iBACA,qBACA,cACA,GAEA,UAEY,EAAgB,eAC5B,GAAoB,EAAe,oBAGvB,EAAgB,uBAC5B,GAAoB,EAAe,8BAGnC,MACa,EAAgB,yBAC7B,gBAIA,cACA,OAEA,UAAkB,EAAkB,oBAEpC,SAEA,mBACA,WACA,YAAoB,IAAW,KAC/B,WACA,eACA,eACA,IACA,kBACA,eACA,MACA,WACA,OACA,mBACA,EACA,SA5LA,KACA,WACA,aAEA,WACA,iCAEA,WACA,oCAEA,WACA,mCAEA,WACA,mCAEA,WACA,oCAEA,WACA,kCAEA,WACA,YAEA,WACA,qCAEA,WACA,mDAEA,WACA,gBAtFA,GACA,gCAGA,EAFA,uBAEA,YADA,IAEA,WAEA,GADA,aACA,SACA,8BACA,YAAwB,IAAY,IACpC,eAGA,YACA,+BACA,YAAwB,IAAY,IACpC,eAGA,YACA,+BACA,YAAwB,IAAY,IACpC,eAGA,YACA,gCACA,YAAwB,IAAY,IACpC,SAEA,MACA,YACA,+BACA,YAAwB,IAAY,IACpC,eAGA,YACA,gCACA,YAAwB,IAAY,IACpC,eAGA,YACA,iCACA,YAAwB,IAAY,IACpC,eAIA,6BAAyC,EAAU,GAEnD,QACA,EAiCA,EAEA,WAAc,EAAkB,yBAA0B,EAAQ,EAClE,EAyJA,IACA,CAMA,GAAS,EAAe,sBAmCxB,GAAa,EAAgB,0BAC7B,OACA,WAEA,CACA,eACA,YAAwB,WAAkB,IAC1C,aAGA,GADA,4BACY,EAAgB,8BAC5B,WACA,YAA4B,WAAkB,IAC9C,YAEA,CACA,MAnDwB,CAExB,cAOA,GANA,GACA,GAnKA,oBACA,QACA,MACA,WACA,kBACA,WACA,mBACA,8BAEA,iBACA,SACA,YAA4B,eAAqB,IACjD,6BAEA,QACA,OACA,eACA,cAKA,CACA,CACA,YAAoB,IAAsB,KAC1C,mCACA,UAEA,GACA,qBACA,2BACA,kBACA,kBACA,kBACA,qBACA,kBACA,oBACA,kBACA,kBACA,kBACA,iBACA,CAAS,IACT,MACA,UAAsB,EAAkB,8BAA+B,EAAK,IAE5E,WAEA,GAA8B,kBAAqB,IACnD,GACA,aAGA,MADA,KAGA,EADA,IAGA,kBACA,KAEA,iBACA,YAEA,SACA,OAEA,WAA4B,wBAC5B,CACA,QACA,EA+FA,YAIA,IACA,EACA,aAAyB,UAAa,IACtC,iBACA,KAEA,iBACA,YAEA,SACA,OAUA,GANA,kBACA,gBAA4B,MAAe,EAAW,GAAG,EAAe,GAAG,mCAC3E,KAGA,UACY,EAAgB,8BAC5B,WACA,YAA4B,WAA0B,IACtD,YAEA,CACA,CAkBA,OACA,aACA,aACA,YACA,QACA,iBACA,cACA,WACA,YACA,eACA,mBACA,eACA,cACA,iBACA,gBACA,YACA,MACA,CACA,EC5CyC,qBACzC,UAAiC,EAAU,CAC3C,KACA,EAF2C,OAE3C,kBACA,8BACA,EACA,CACA,CAAiB,CACjB,CACA,SACA,gBAAiC,GAAsB,CACvD,kBADuD,yDAEvD,KACA,CAEA,OAEA,CAMA,YAAwB,WAAoB,MAC5C,WAGA,MACA,qBAAwB,GAAmB,CAC3C,aACA,MACA,MAtQA,kBACA,iBACA,6BACA,uBAEA,cACA,8BACA,uBAEA,QACA,wBACA,gCACA,qBAEA,YACA,6BAKA,uCACA,QACA,wBACA,gCACA,qBAEA,YACA,8BAKA,SAAwB,EAAS,YAEjC,QAA2B,EAAS,YACpC,UAA4B,EAAS,aAGrC,QAA2B,EAAS,YAEpC,UAA4B,EAAS,aAGrC,QAA2B,EAAS,cACpC,UAA4B,EAAS,eAErC,QAA2B,EAAS,cACpC,UAA4B,EAAS,eAErC,4BACA,EAlGA,gBAaA,eAZA,KACA,UACA,gCACA,uBACA,4BACA,MACA,UAA0B,EAAkB,gEAE5C,eACA,CACA,QACA,EACA,GACA,6BAEA,cADA,2CACA,iBACA,MACA,cACA,6BACA,UAA0B,EAAkB,iGAE5C,mBACA,CAAS,CAET,EA0EA,OAlEA,cAGA,kDAEA,OADA,qEACA,GACA,oBACA,kBACA,EA6DA,MAKA,yBACA,EA2MA,WAEA,CACA,CACA,QACA,CACA,oBAEA,yDACA,2CACA,IACA,uBACA,4CAGA,MADA,UACA,UAEA,uDACA,6BACA,GAAgB,GAAmB,kBACnC,8BACA,+BACA,CACA,kCACA,yBACA,OACA,8CACA,cACA,4CAEA,SAGA,gBACA,gCACA,OACA,IACA,GACA,KACA,uBACA,6BACA,QACA,EACA,QAEA,uBACA,8BACA,EACA,SACA,UAEA,0BACA,0BAEA,CAUA,aARA,iDACA,WACA,gBACA,0CACA,0EAEA,CAAiB,GAEjB,IAEA,QADA,0BACA,CACA,WACA,YACA,wBAAsD,WAAmB,GACzE,CACA,CACA,CACA,CACA,QACA,CACA,CAEA,sEACI,GAAW,KACf,CAAC,CCpZc,CDmZA,MCnZA,GACf,iBACA,kBACA,eACA,CACA,CCHe,iBAAwB,GACvC,MADgD,MAChD,KAEA,GADA,WACA,sBACA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,wCAAmB,EAE/D,CACA,gBAEA,OADyB,GAAO,8CAChC,uBAEA,CCZe,iBAAiC,GAChD,MADyD,MACzD,OACA,WACA,uBACA,CACA,gBAEA,UADA,mBACA,mBACA,uBACA,oBACA,YAAwB,IAAiB,KACzC,KACA,qBAEA,QACA,CAEA,kBACA,sCACA,qCACA,CAEA,gBACA,qCACA,sCACA,CACA,CACA,uDACI,GAAW,KACf,CAAC,CC5Bc,CD2BA,MC3BM,WAA2B,GAChD,MADyD,CACzD,SACA,EAFuC,CAEvC,gBAAgB,GAAiB,gBACjC,OACA,MACA,UAAsB,EAAkB,kCAAmC,EAAe,GAE1F,oCACA,iCACA,CACA,sBACA,gBACA,UAAgB,GAAW,gBAE3B,iBACA,iBACA,eACA,aACA,gBACA,UAA0B,GAAsB,uDAEhD,IACA,CAEA,OADA,mBACA,eACA,CACA,CCzBe,iBAA4B,GAC3C,MADoD,MACpD,KAEA,GADA,WACA,sBACA,sCAEA,0BACA,uCAGA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,4CAAmB,EAE/D,CACA,gBACA,mBAAgB,GAAiB,gBACjC,OACA,gCACA,qCACA,CACA,gBACA,SAAoC,GAAS,0BAE7C,OADA,gCACA,CACA,CACA,iBACA,oCACA,UAAsB,GAAsB,qEAE5C,mCAEA,CC/Be,iBAAyB,GACxC,MADiD,MACjD,KAEA,GADA,WACA,sBACA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,yCAAmB,EAE/D,CACA,gBACA,QACA,KAAsB,IAAP,GAAO,0BACtB,KAIA,MADA,CADyB,GAAO,2BAChC,QACA,uBAEA,CCXe,iBAA8B,GAC7C,MADsD,MACtD,KASA,GARA,WACA,cACA,iBACA,oBACA,8BACA,uBACA,kCACA,uBACA,wCACA,mBAAmC,eAAe,oDAElD,qBACA,kBACA,mBAGA,mCACA,yCAEA,CACA,gBAEA,sCACA,YAAwB,2BAA8B,IACtD,MACA,kCACA,yCAIA,4DACA,iBACA,cACA,4BACA,gCAEA,yCACA,CAAS,CACT,CACA,aACA,cACA,CADyB,GACzB,IACA,KACA,gCAHqE,KAGrE,WACA,4BACA,kBApDA,MACA,EAoDA,OACA,YACA,QACA,SACA,EACA,KACA,UAIA,GAFA,OAFyD,EAEzD,CADA,MAEA,KA3DA,EA0D0C,EA3D1C,aADA,GADA,EA+DA,GA9DA,kBACA,qBACA,gCA4DA,EACA,UAA8B,EAAkB,sBAEhD,gBACA,CAAa,CACb,CAAS,CACT,CACA,cACA,qGACA,4DACA,uDACA,oEACA,sCACA,yCACA,YAAwB,6BAAgC,KACxD,kDAEA,CACA,gBACA,oCACA,CAKA,wBACA,iCAEA,eACA,gBACA,IACA,IACA,YAAwB,0BAA6B,MACrD,oCACA,QACA,GAAoB,GAAO,SAC3B,GACA,EACA,6BACA,+CACA,qCAEA,YAAgC,qCAChC,0BAAiD,KACjD,IAEA,CACA,CACA,UAAkB,EAAkB,4BACpC,CACA,CCjHe,iBAA0B,GACzC,MADkD,MAClD,KAEA,GADA,WACA,sBACA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,0CAAmB,EAE/D,CACA,gBACA,IAIA,EACA,EALA,IACA,KAAe,GAAO,0BACtB,KAIA,SACA,oBACA,EAAgB,GAAO,6BAEvB,CACA,wBACA,MAAyB,GAAO,yBAChC,QACA,CACA,gCAEA,CCpBA,QACA,EAAO,GAEP,EAAO,GACP,EAAO,GACP,EAAO,GACP,EAAO,GACP,EAAO,GAHoB,CAEX,CAGT,EACP,EAIO,EAPW,IAED,GAKV,IATkB,CASlB,GACP,MAHA,GAGA,yBAHA,CAIA,MACA,UAAkB,EAAsB,qCAAsC,UAAqB,GAEnG,+BACA,CCxBA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UACA,SACA,SACA,UACA,SACA,UACA,eACA,eACA,SACA,UACA,eACA,SACA,SACA,SACA,SACA,eACA,UACA,eACA,QAGA,CA4Be,UACf,eACA,6BACA,sBACA,oBAEA,yCACA,+BACA,2CACA,wCACA,iCArCA,GACA,cACA,YAAoB,IAAO,KAC3B,YAsBA,OApBA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,CACA,EAWA,mBACA,6CACA,+BAMA,kBACA,4BACA,KAUA,QAVA,EACA,0BACA,MACA,sCAEA,MAAwB,GAAgB,eAExC,OADA,wBACA,CACA,CAIA,CAMA,eACA,gCAEA,yBACA,mCACA,eACA,iCAEA,MACA,YAEA,MACA,UAA8B,EAAkB,oBAAqB,GAAgB,yCAErF,EAAoB,GAAgB,KAEpC,QAFoC,iBAEpC,KACA,CACA,CACA,QACA,CACA,SACA,SAOA,OANA,+BACA,qBAGA,cACA,CAAS,EACT,CACA,CACA,CChIe,SACf,iBACA,YACA,mBACA,CACA,YACA,mDACA,CACA,kCAIA,IAHA,yBAGA,WACA,YAEA,iBAAgB,GAAe,gCAC/B,EAA+B,GAAiB,GAChD,WADgD,CAChD,iBACA,wCACA,UAAsB,EAAkB,wBAAyB,eAAmB,8BAEpF,MAAwB,GAAS,8DACjC,OACA,KACA,eACA,CACA,CACA,sBACA,6BACA,0CACA,CAGA,6BACA,6CACA,KAGA,WAAmB,GAA8B,gBACjD,CACA,UAFiD,CAEjD,GAGA,WAAmB,GAAS,SAC5B,CACA,kCd7CO,Ec8CP,iBAAgB,GAAe,gCAE/B,sBAAgB,0BADe,GAAiB,GAKhD,EAAwB,GADxB,oCACiC,UACjC,EdpDA,MADO,EcqDkC,SAAR,KAAQ,EdjDzC,CciDyC,MdjDzC,EAGA,WAGA,cAGA,EAFA,EAHA,EAHA,EAHA,EcqDA,EAAwB,GADxB,8DACiC,UAIjC,OAHA,+CACA,mGAAgK,EAAS,GAEzK,CACA,KACA,KACA,wBACA,gCACA,CACA,CACA,CACA,2DACA,WACA,YACI,GAAW,KACf,CAAC,CC1Cc,CDyCA,MCzCA,GACf,eAcA,GAbA,UAAoB,EAAI,2BACxB,0BACA,+CACA,cACA,oCACA,0BACA,EAIA,qBAAgC,MAAQ,CACxC,+BACS,EA3BT,WAEA,qBADA,8BACA,eACA,UACA,EAEA,CAFkB,IAElB,KACA,EAGA,CAHkB,EAGA,EAkBlB,EACA,gEAEA,CACA,UACA,0BACA,CAEA,sBACA,cAAgB,YAAoB,KAEpC,IADA,SADwD,CACxD,iBACA,MACA,0CACA,UAAsB,EAAsB,gBAAiB,IAAjB,UAAiB,EAAyB,gBAEtF,QACA,CAEA,qBACA,qCACA,MACA,UAAsB,EAAkB,+BAGxC,MADA,0BACA,QAEA,EADA,uBACA,eAGA,MADA,oBACA,kBAFA,IAEA,IAEA,OADA,cACe,SlBjFR,GACP,GkBgF8B,ClBhF9B,mBACA,KACA,gBACA,0BACA,GACA,QACA,eACA,eACA,qBACA,cACA,CACA,iBACA,kBACA,EAIA,CACA,MACA,QACA,CACA,CAAiB,CACjB,CAAa,CAEb,CACA,QACA,EkBsD8B,EAC9B,CACA,sBAEA,OADA,0BACA,YAEA,8BAKA,EAJA,iBAAgB,GAAe,2BAE/B,EAD+B,GAAiB,GAChD,WADgD,OAChD,WAGA,YAAwB,KAAsB,KAM9C,iCACA,0BAIA,UACA,iBACA,YAAgC,cAA6B,IAE7D,EADA,0BACA,kBAMA,oBAGA,QACA,CACA,0BACA,gCAIA,EAAgC,OAAK,QACrC,SACA,UAAsB,EAAkB,mBAAoB,EAAY,qBAAqB,EAAc,2BAA2B,EAAgB,EAEtJ,CAOA,uBACA,iBAAgB,GAAe,2BAC/B,EAA+B,GAAiB,GAChD,IACA,OAFgD,eAEhD,WACA,IAEA,QACA,uDAIA,UACA,iBACA,YAAoC,cAA6B,IAEjE,EADA,0BACA,kBAMA,oBAEA,IACA,CACA,CACA,SACA,GAEA,CACA,QACA,CACA,0BACA,WAAmB,GAAa,OAChC,CACA,EAFgC,IAEhC,mBACA,iBAAgB,GAAe,2BAE/B,iBAAgB,GADe,GAAiB,GAGhD,OAAe,GADf,CAFgD,KAEhD,8BACwB,aACxB,CACA,yCAEA,MAAqB,GADrB,MAC8B,GAD9B,oBAC8B,cAC9B,eACA,UAAsB,EAAkB,sCAAuC,GAAM,6BAA6B,QAAW,GAE7H,QACA,CACA,4BAEA,eACA,MAAwB,GAAK,GAI7B,OAHA,KAGA,CACA,CACA,eACA,OAAmB,EAAM,GAEzB,CAFyB,EAEzB,YACA,uBAA0D,kBAAgB,KAzL1E,gBACA,SACA,UAuL0E,GAtL1E,SACA,CAAS,CACJ,IAqLL,4CACA,CACA,eACA,wBAEA,OADY,SnBtCY,CAAU,KmBsCR,CnBtCQ,EAClC,MADkC,CAClC,SAEA,OADA,UAGA,kBAEA,UACA,gBACA,UAAkB,EAAkB,sBAAuB,EAAM,GAGjE,GADA,aACA,cA1KA,EA2KA,UAAkB,EAAkB,2BAEpC,iBACA,+BAEA,cACA,UAAkB,EAAkB,kCAAmC,GAAY,SAEnF,UACA,OACA,gBAlGA,EACA,GAEA,UAAkB,GAAQ,WAC1B,aACA,YAAoB,WAAiB,KACrC,SAAsB,GAAQ,eAE1B,CD1FG,SACP,CCyFe,CDxFf,EACA,GAEA,QACA,IACA,cACA,GACA,eACA,aAAgC,GAAQ,IAExC,CAFwC,CAExC,oBACA,iBACA,gBACA,0CAEA,YACQ,GAAQ,qCAEhB,KACA,WJ7BA,KI6ByC,EAEzC,0BACA,aACA,8CACA,cACA,eAEA,OACA,KACA,MAGA,oBAEM,OACN,KJ7CA,EI6Ce,IACf,ECoDe,CDrDO,CCqDP,KACX,SH/FJ,CG+FO,CH9FP,EACA,EACA,GACA,IAyBA,EAzBA,aACA,aACA,aACA,aACA,gBACA,OACA,YAAoB,IAAe,MACnC,UAAkC,GAAQ,MFhB1C,IEgB8D,CAAR,EACtD,IAAkC,EAD4B,CACpB,MFjB1C,IEiB8D,CAAR,EACtD,IAAkC,EAD4B,CACpB,MFlB1C,IEkB8D,CAAR,EACtD,IAAkC,EAD4B,CACpB,MFnB1C,IEmB8D,CAAR,EACtD,MAD8D,EAC9D,GACA,eACA,eACA,eACA,EAAgB,GAAQ,6BFxBxB,CEwBmE,GACnE,EAAgB,GAAQ,6BFzBxB,CEyBmE,GACnE,EAAgB,GAAQ,6BF1BxB,CE0BmE,GACnE,EAAgB,GAD2D,KACnD,wBF3BxB,CE2BmE,GACnE,EAAgB,GAAQ,iBACxB,EAAgB,GAAQ,iBACxB,EAAgB,GAAQ,iBACxB,EAAgB,GAAQ,gBACxB,CAGA,OAFA,iBAEA,KACA,OACA,KACA,QACA,MAAoB,GAAQ,MFvC5B,IEuCgD,CAAR,GACpB,2BFxCpB,CEwCiE,GACjE,KADyE,CACzE,GACA,KACA,QACA,MAAoB,GAAQ,MF5C5B,IE4CgD,CACpC,GAAQ,2BF7CpB,CE6CiE,GACjE,SACA,MAAoB,GAAQ,MF/C5B,IE+CgD,CAAR,GACpB,KAD4B,QAC5B,cFhDpB,CEgDiE,GACjE,KADyE,CACzE,GACA,KACA,QACA,MAAoB,GAAQ,MFpD5B,IEoDgD,CAAR,GACpB,KAD4B,QAC5B,cFrDpB,CEqDiE,GACjE,KADyE,CACzE,GACA,MAAoB,GAAQ,MFvD5B,IEuDgD,CAAR,GACpB,KAD4B,QAC5B,cFxDpB,CEwDiE,GACjE,KADyE,CACzE,GACA,MAAoB,GAAQ,MF1D5B,IE0DgD,CAAR,GACpB,KAD4B,QAC5B,cF3DpB,CE2DiE,GACjE,KADyE,CACzE,GACA,KACA,SACA,UAAsB,EAAkB,uDACxC,CACA,gBACA,EGkCO,QAEP,EAuFA,IACA,QACA,OAxFA,SACA,EACA,GACA,iBACA,YAAoB,WAAc,KAClC,SAAmB,GAAQ,WAE3B,iBACA,YAAoB,WAAiB,MACrC,gBACA,YAAwB,cAAoB,KAC5C,YAA6B,GAAQ,cAErC,CACI,CDrEG,SACP,CCoEe,CDnEf,EACA,GACA,QACA,cACA,GACA,QACA,IACA,aACA,aACA,UAAuB,GAAQ,YAE/B,GACA,kBACA,gBAAiC,GAAQ,IAEzC,CAFyC,CAEzC,uBACA,oBACA,mBACA,gDAEA,eACA,kBACA,cJvEA,EIuE+B,GAAO,CAEtC,eACA,aAAiC,GAAQ,eAE7B,GAAQ,8CAEpB,cACA,cJ/EA,KI+E0C,EAE1C,gCAEA,IADA,IACwB,CADxB,aJlFA,MIoFA,8CACA,cACA,eAEA,OACA,KACA,MAGA,oBAEU,OACV,8CACA,cACA,eAEA,OACA,KACA,MAGA,aAEA,EAAM,YACN,ECQe,OACX,SFlHJ,EACA,EACA,CEgHO,CF/GP,GACA,KALkC,CAKlC,cACA,aACA,aACA,aACA,aACA,OACA,IACA,IACA,MACA,MACA,IACA,IACA,IACA,IACA,KAAW,IAAW,qBACtB,iBAA4C,GAAQ,MHvBpD,IGuBwE,CAAR,EAChE,MADwE,EACxE,GAA4C,GAAQ,MHxBpD,IGwBwE,CAAR,EAChE,MADwE,EACxE,GAA4C,GAAQ,MHzBpD,IGyBwE,CAAR,EAChE,MADwE,EACxE,GAA4C,GAAQ,MH1BpD,IG0BwE,CAAR,EAChE,MADwE,EACxE,GACA,aACA,aACA,aACA,EAAgB,GAAQ,4BH/BxB,CG+BgE,GAChE,EAAgB,GADwD,KAChD,uBHhCxB,CGgCgE,GAChE,EAAgB,GADwD,KAChD,uBHjCxB,CGiCgE,GAChE,EAAgB,GADwD,KAChD,uBHlCxB,CGkCgE,GAChE,EAAgB,GADwD,KAChD,YACxB,EAAgB,GAAQ,iBACxB,EAAgB,GAAQ,iBACxB,EAAgB,GAAQ,iBACxB,IACA,IACA,IACA,GACA,CAEA,KAAW,IAAiB,MAC5B,iBAA4C,GAAQ,MH9CpD,IG8CwE,CAAR,EAChE,MADwE,EACxE,GACA,EAAgB,GAAQ,0BHhDxB,CGgDmE,GACnE,GACA,CACA,CAH2E,CEsEpE,QAEP,EAuEA,IACA,SACA,UAAsB,EAAkB,uBAAwB,EAAM,EACtE,CACA,EmBS0B,KAC1B,CAGA,CACA,kBACA,O1BnKW,E0BmKkC,QAE7C,K1BrKuB,C0BmKsB,OAE7C,EACA,O1BjKA,IAAe,IAAK,O0BiKyB,E1BjKzB,M0BmKpB,iBACA,O9BwCA,cAEA,I8B1C+C,E9B0C/C,cACA,WA/FA,GACA,OACA,SACA,EAGA,MADA,aACA,CACA,gDACA,MACA,CACA,mBACA,qBACA,0BACA,CAD6D,CAC7D,WACA,GA9FA,EA8FA,EACA,eACA,eAEA,CACA,YAAwB,IAAY,IACpC,OAEA,KAAe,MAAS,IACxB,QAEA,CACA,aACA,SACA,YACA,yBACA,YAAoB,IAAY,IAChC,qBAvFA,GACA,QAEA,EAFkB,CAElB,uBACA,sBACA,sBACA,YArCA,EAqCA,SACA,YArCoB,CAqCpB,OACA,UArCA,GAqCA,SACA,qBACA,WArCA,GAqCA,SACA,UArCA,IAqCA,SACA,uBACA,mBAWA,GAVA,aACA,cAEA,OADA,kBACA,EACA,YAEA,OADA,kBACA,EACA,YAEA,kBApDA,GAqDA,SACA,YAAwB,YAAe,IACvC,4BAKA,YAAwB,MAAS,IACjC,YAKA,GADA,mBACA,WA/DA,IA+DA,SACA,qBAIA,YAAwB,MAAS,IACjC,YAWA,OARA,mBA1EA,GA2EA,UACA,iBAEA,kBA7EA,GA8EA,UACA,gBAEA,CACA,EAgCA,GACA,+BACA,gCAGA,QACA,EA0DA,GACA,MACA,OAEA,eACA,sBAEA,WAhEA,GACA,QACA,qBACA,YAAoB,QAAa,IACjC,cAA4B,EAAS,YAErC,cACA,YAAoB,IAAO,IAC3B,aAA2B,EAAS,KAOpC,EAPoC,KAEpC,UAAoB,EAAS,GAC7B,IAD6B,CAC7B,KAAoB,EAAS,GAC7B,IAD6B,KAC7B,IACA,WAAwB,EAAS,cAEjC,CACA,EAgDA,GAEA,MAAmB,EAAU,GAC7B,KAD6B,aAC7B,IACA,wBAEA,GACA,OACA,QACA,QACA,IACA,IACA,IACA,MACA,SACA,KACA,EAEA,IACA,CADe,IACf,MACA,WAEA,GADA,SAlEA,aAEA,yCACA,gBACA,oBAEA,mBAEA,gCACA,gCACA,iCACA,iCACA,eACA,gBAEA,MAEA,eAEA,QACA,UACA,kCAEA,WAxKA,EAyKA,UACA,wBACA,aAGA,MACA,GADmB,IACnB,GACA,SACA,UACA,OACA,EAgCA,aACA,YACA,wBAEA,YAAoC,MAAS,IAC7C,oBAEA,SACA,MACA,QACA,CAEA,cACA,oBACA,YAGA,gCAKA,kBACA,CADsC,CACtC,SA/NA,OACA,gBAkBA,OAjBA,oCACA,CADiE,EACjE,gCACA,CADqE,CACrE,QACA,wCAEA,aACA,yCAIA,uBACA,WAEA,UACA,iBAEA,MACA,OACA,EA2MA,MACA,CAIA,OAHA,UACA,SAIA,SACA,QACA,IACA,WACA,SACA,QACA,SACA,WACA,aACA,cACA,SACA,IACA,GACA,CACA,CACA,UAEA,EArBA,SAEA,CACA,EAoBA,IAAuB,E8BxHwB,G1BjK/C,GJyR+B,M8BtH/B,cACA,O1BjKO,YAEP,G0B+J4C,C1B/J5C,EDyFO,SAAS,CAAM,MACtB,IADsB,EACtB,IAAkB,EAAQ,GAC1B,GAD0B,SAC1B,GACA,qBACA,eACA,WA/FA,SACA,SACA,aACA,gBACA,mBACA,QACA,OACA,OAKA,GAJA,GAEA,mBAzBA,GA2BA,MACA,sBAlBA,GAmBA,MA7BA,EA6BA,KAAiC,EDlE1B,MCkEkC,GDlElC,GACP,qBARA,YACA,QACA,eACA,YAEA,QACA,EAEA,IACA,IACA,eACA,WACA,YAEA,QACA,EC0D0D,uBAC1D,CACA,MACA,mBACA,cACA,aAA6B,EAAQ,YACrC,KACA,CACA,oBACA,eACA,uBAA0D,EAAW,GACrE,UADqE,EACxC,EAAQ,QACrC,CACA,CACA,QACA,EAkEA,SACA,WACA,WACA,IACA,aACA,SAEA,YAAoB,IAAY,IAChC,YAhEA,SACA,WAvDA,EAuDA,YAEA,IADA,qBAEA,GArDA,GAqDA,EAGA,OAFA,UACA,UACA,KAEA,OACA,SACA,gBACA,GAEA,OADA,OAnEA,EAmEA,aAEA,KAnEA,EAoEA,aApEA,EAoEA,YACA,KACA,MAvEA,EAwEA,aAxEA,EAwEA,cACA,KACA,MApEA,EAqEA,aArEA,EAqEA,cACA,KACA,MA3EA,EA4EA,WA5EA,EA4EA,cACA,OA5EA,EA4EA,WACA,gBACA,KACA,MA3EA,EA4EA,0BA5EA,EA4EA,YACA,KACA,MA7EA,EA8EA,wBA9EA,EA8EA,YACA,iBACA,eACA,KACA,MAjFA,GAkFA,gBACA,KACA,SACA,UAEA,CACA,iBACM,YACN,WACA,EAiBA,WAEA,QACA,ECzG2B,UAC3B,6DACA,E0B6J4C,QAG5C,UAAsB,EAAsB,GAAI,GAAmB,cAAvB,mBAAuB,EAEnE,CACA,yBACA,uCACA,iBACA,wBAEA,OADA,WACA,CACA,CACA,QACA,CACA,mBACA,iBAAgB,GAAe,2BAC/B,EAA+B,GAAiB,GAChD,WADgD,CAChD,oBACA,iBACA,2CACA,8BACA,iEACA,EACA,GACA,KACA,eACA,kBACA,SACA,EACA,SAEA,mEACA,iBAEA,wBACA,uEAGA,8BACA,QACA,iDAGA,kCACA,yBAEA,QACA,CACA,CExQA,iBACA,kBAEA,GADA,EACA,EACA,GAFA,EAEA,KAEA,EAJA,EAIA,OACA,QACA,OACA,iBACA,aACA,YACA,CAAK,CACL,CF4PA,sEACI,GAAW,KACf,CAAC,CE1Pc,CFyPA,MEzPA,GAQf,eACA,gBAA0B,EAAI,0BAC9B,CACA,uBAdA,EAeA,SACA,EAfA,MADA,EAgBA,iCAfA,gBAA+C,GAAK,KAgBpD,yBACA,eAjCA,YAA8B,EAkC9B,gBACA,UAAsB,EAAkB,iJAMxC,SACA,KACA,eACA,iBACA,WACA,+BAEA,SACA,8BACA,UAEA,UACA,8BACA,KACA,QACA,UAEA,kBAGA,UAA0B,EAAkB,4BAe5C,OAXA,GACA,8BAEA,cACA,QAGA,oCAEA,kDACA,CAAS,EACT,CACA,CACA,WAOA,OANA,kBACA,8CAEA,MADA,wBACA,CACA,EAAa,EAEb,iBAOA,qCACA,mCAaA,gCACA,iCACA,MACA,SAEA,UACA,cACA,wBACA,IACA,IAEA,MAIA,EACA,KACA,eACA,UACA,UAGA,QACA,CACA,CCnIe,SAiBf,eAWA,GAVA,UACA,QACA,IAAoB,GAAQ,CAC5B,IAD4B,EAC5B,QACA,gBACA,4BACA,oBACA,oCACA,qBACA,CAAiB,EACjB,uBAAmC,GAAQ,CAC3C,6CAEA,oBAQA,mCAAuD,EAIvD,GAHA,gCACA,oCACA,qCACA,mBAEA,UAAsB,EAAsB,2CAG5C,0CADA,EACA,KAEA,2EACA,qBACA,wBACA,uCACA,+BACA,kBACA,SACA,KACA,gBACA,iBACA,cACA,kCAEA,gBACA,OACA,SAEA,QACA,MACA,CACA,SACA,oCACA,OACA,SAEA,CAAa,EACb,SACA,gBACA,iBACA,cACA,kCAEA,SACA,QACA,qBArCA,GAqCA,kBACA,iDACA,iBACA,qGACA,SACA,CACA,CACA,2BACA,KACA,eACA,aAGA,IACA,sDACA,sDACA,SACA,KACA,gBACA,+CACA,IACA,mCACA,4CAEA,UACA,iBACA,SACA,gBACA,uBACA,iCAEA,gCACA,SAEA,CACA,QACA,CAAiB,EACjB,SACA,CACA,2BACA,aACA,mCACA,aACA,CACA,CACA,QACA,CACA,mBAAwB,2CAAyC,IAGjE,OAFA,oCACA,cACA,aACA,CAOA,+BACA,gDACA,CACA,gHGjJe,UACf,iBACA,cACA,aACA,CACA,WACA,4BAEA,YACA,mCACA,CACA,UACA,MACA,sEACA,CACA,YACA,kCAEA,YACA,yBAEA,aACA,+CACA,CACA,WACA,+CACA,CACA,cACA,iCAEA,cACA,sDACA,CACA,uBACA,qEACA,CACA,sBACA,4DAEA,eACA,wBACA,qDACA,MACA,CACA,4BACA,wBACA,GAAiB,qDAAqD,GAAG,gCAAgC,EACzG,MACA,CACA,gBACA,yBAEA,eACA,MACA,uEAEA,WACA,MACA,gGACA,mBAAoC,0BAA0B,iBAE9D,UACA,iCACA,CACA,YACA,ODmCO,kBACP,CCpCkC,GDoClC,KACA,KACA,MACA,IACA,MACA,SAEA,YACA,UACA,IACA,IACA,IACA,cACA,QAAqB,8BAA0B,IAgB/C,GAfA,MACA,oBACA,IACA,SACA,MAA4B,EAAO,GACnC,KAEA,aACA,MAA4B,EAAM,EAAE,EAAG,EACvC,KAEA,IACA,MACA,MAEA,SAEA,6BADA,cAEA,KACA,YACA,gBAEA,SACA,KACA,IACA,KAEA,SACA,KACA,IACA,KAEA,kBACA,KACA,GACA,OAAgC,EAAM,EAAE,GAAG,EAE3C,OACA,KAEA,kBACA,KACA,GACA,OAAgC,EAAM,EAAE,GAAG,EAE3C,cACA,KAEA,SACA,GACA,OAAgC,EAAM,EAAE,GAAG,EAE3C,IACA,KACA,KAEA,SACA,GACA,OAAgC,EAAM,EAAE,GAAG,EAE3C,MAA4B,EAAK,IAEjC,UACA,GACA,OAAgC,EAAM,EAAE,EAAG,GAE3C,MAA4B,EAAK,GACjC,UAKA,aAkBA,OAhBA,eACA,aACA,sBACA,aACA,MAAwB,EAAM,EAAE,EAAG,EACnC,KAEA,MACA,MAEA,QACA,OAAoB,EAAO,IAE3B,GACA,OAAoB,EAAM,EAAE,GAAG,EAE/B,CACA,EC7IkC,kGAClC,CACA,KACA,SAAkB,eAAe,GAAG,qBAAqB,EAEzD,OACA,uBACA,gBACA,WACA,UACA,YACA,WACA,eAEA,SAEA,CACA,WAEA,CACA,iBACA,ODxFO,gBACP,MACA,ECsFuC,IDtFvC,GAEA,sBACA,IACA,IACA,IACA,IACA,IACA,QAAiB,0CAAuC,IAaxD,GAZA,MACA,IACA,SACA,QACA,QACA,iBACA,QAAyB,EAAO,EAChC,QACA,EACA,KAEA,QACA,QACA,QACA,QACA,SACA,OACA,2BACA,uCACA,eACA,OAEA,WACA,QACA,QACA,iBACA,QAAyB,SAAY,EACrC,QACA,OAEA,WACA,QACA,YACA,SACA,QACA,QACA,OAEA,YACA,eACA,QACA,QACA,gBACA,SAA0B,EAAI,EAC9B,UACA,QACA,CACA,KACA,UAEA,QAEA,QACA,QACA,gBACA,SAJA,EAI8B,EAC9B,QALA,EAMA,QACA,EAEA,QACA,QACA,gBACA,SACA,QACA,QACA,EAEA,SAEA,SAEA,SAEA,SACA,KAcA,OATA,SACA,QACA,QACA,iBACA,QAAqB,EAAO,EAC5B,QACA,EACA,KAEA,YACA,ECbuC,iDACvC,CACA,aACA,OACA,iBACA,eACA,aACA,iBACA,mBACA,qCACA,iBACA,eACA,qBACA,aACA,aACA,uCACA,uBACA,uBACA,iDACA,kBACA,CACA,CACA,SACA,OACA,eACA,iBACA,eAEA,CACA,CACA,SAAW,cACX,SAAW,aACX,SAAW,iBC7GI,kBAA0B,yBAAsB,CAC/D,cACA,oBACA,kBACA,+BAAyC,UAAQ,EACjD,WACA,CAAS,EACT,+BAEA,qBACA,mCACA,+BACA,qBACA,MAAyB,GAAe,CACxC,WADwC,IACZ,mBAAY,MACxC,UAAuB,GAAS,CAChC,KADgC,MACJ,mBAAY,KACxC,CAAa,EACb,qCACA,mBACA,CAAS,EACT,uBACA,wCAEA,sCACA,MACA,iEAGA,OACA,OACA,iBAHA,6BAGA,YAEA,CACA,kBAOA,OANA,iBACA,+CAEA,MADA,uBACA,CACA,EAAa,EAEb,gBAEA,mBACA,SAAgB,GAAO,uBACvB,6BACA,CACA,sBACA,KACA,oBAAgB,GAAkB,uBAClC,mDACA,MACA,uBAUA,MARA,OAAgC,QAAc,GAC9C,aACA,UACA,QACA,MACA,eACA,CAAS,EACT,KAAkB,QAAO,MAEzB,2CACA,QACA,qBACA,eACA,kBAEA,OADA,aACA,EAEA,MADA,kCACA,YACA,CAAS,EACT,SACA,MACA,gBACA,wBAAwC,EAAQ,GAAG,eAAQ,MAAY,GAAG,eAAQ,KAAO,WAAW,eAAQ,YAAmB,8BAA8B,eAAQ,IAAO,GAE5K,QACA,CACA,kBACA,6BACA,CAAgB,QAAO,EACvB,8BACA,KACA,KACA,iBACA,wBACA,WACA,mCACA,MACA,cACA,OACA,MACA,CACA,CAIA,OAAuB,iCAHvB,EACA,wBACA,QAA6B,MAAQ,0EAA0G,CACxH,EAEvB,OADA,iBACA,CACA,YACA,KAEA,CACA,mBAOA,OANA,aACA,wCAEA,MADA,mBACA,CACA,EAAa,EAEb,YAEA,eACA,mBAAgB,UAA6B,MAC7C,MAAe,mBAAY,6CAC3B,CACA,qBACA,cAAgB,GAAY,oBAC5B,eACA,6CAEA,kBAEA,sBACA,wBACA,2BAEA,oBACA,qCAGA,CACA,eACA,QACA,4HACA,CACA,uBACA,sCAEA,iBACA,cAAgB,sCAAkD,MAClE,SAAgB,mCAAuC,EACvD,MAAe,uBAAgB,WAC/B,SAAoB,eAAkB,oBACtC,sBACA,eACA,kCACA,aACA,MACA,CACA,GACA,mCAEA,YAAkC,mBAAY,6DAClC,qBAAc,IAC1B,MAAkB,mBAAY,gCAC9B,MACA,gBAAwB,4CAAyD,MACjF,gBACA,GAAwB,SAAc,eAGtC,GACwB,SAAc,cACtC,4DACA,wBAGA,kBARA,SAWA,wCAAkE,WAAgB,GAClF,KAMA,cANA,CACA,kCACA,kCAA0D,WAAgB,KAC1E,SACA,CAIA,CACA,YACA,CAAa,CACb,CAAS,GACT,CACA,iBACA,uBACA,WAAmB,GAAuB,OAC1C,CACA,YAF0C,4BAE1C,KAGA,OACA,MAHA,gCAIA,eAHA,8BAIA,CACA,CACA,2BACA,SAAgB,GAAO,uBAQvB,MAPA,6BACA,YAAoB,iBAAsB,EAC1C,sBACA,kBACA,kCACA,EAAqB,aAAe,EAC3B,IACT,sCACA,CACA,cC9NA,WACA,MACA,mEAEA,GAEA,mBACA,oBACA,CAAK,CAGL,mBACA,oBACA,CAAK,CAGL,mBAEA,yBACA,oDAIA,YAAsB,WAAc,IACpC,oBACA,QACA,CAAK,CAGL,wBACA,aAA2B,IAAO,IAClC,sCACA,QACA,CAAK,CAGL,yBACA,qBAAyC,WAAkB,SAC3D,wBACA,QACA,CAAK,CAGL,yBACA,iBAAkC,cAAuB,KACzD,+BACA,QACA,CAAK,CAGL,uBACA,iBAAgC,WAAkB,IAClD,gCACA,+BAEA,iBACA,CAAK,CAGL,uBACA,iBAAkC,WAAgB,KAClD,mCACA,QACA,CAAK,CAGL,0BACA,iBAAmC,WAAkB,KAErD,QADA,4BACA,IAAwB,IAAO,IAC/B,oBACA,iCAEA,YAEA,iBACA,CAAK,CAGL,0BAEA,iCAEA,qBAA6C,WAC7C,QACA,MACA,iCACA,2BACA,gCAEA,QACA,CACA,CAEA,YACA,CAAC,qBC/FD,WACA,MAAc,EAAQ,KAAO,EAC7B,EAAa,QADQ,CACR,KAAuB,EACnB,EAAQ,KAAW,EACpC,EAAY,QADY,CACZ,IAGZ,gBAEA,sBAEA,EADA,yBACA,mBAEA,mBACA,KACA,kCACA,8CACA,iBAWA,QARA,oBACA,aACA,aACA,cACA,cACA,aAGA,IAAoB,WAAc,IAClC,kCACA,8BAIA,qBACA,sBAQA,QALA,QACA,QACA,QACA,QAEA,IAAoB,WAAc,OAElC,QACA,IACA,IACA,IAEA,kCACA,mCACA,kCACA,mCACA,iCACA,kCACA,mCACA,kCACA,iCACA,mCACA,+BACA,oCACA,kCACA,mCACA,oCACA,mCAEA,iCACA,kCACA,mCACA,mCACA,kCACA,iCACA,oCACA,mCACA,iCACA,mCACA,kCACA,kCACA,mCACA,iCACA,kCACA,oCAEA,8BACA,mCACA,mCACA,mCACA,kCACA,kCACA,kCACA,oCACA,kCACA,mCACA,mCACA,iCACA,kCACA,oCACA,mCACA,mCAEA,iCACA,kCACA,oCACA,kCACA,kCACA,mCACA,iCACA,mCACA,iCACA,mCACA,mCACA,mCACA,iCACA,oCACA,kCACA,mCAEA,UACA,UACA,UACA,SACA,CAEA,0BACA,CAGA,+BACA,6BACA,uBACA,EACA,8BACA,6BACA,uBACA,EACA,8BACA,0BACA,uBACA,EACA,8BACA,6BACA,uBACA,EAGA,gBACA,iBAEA,wBACA,WACA,mCAEA,6BACA,sBACA,iCACA,eACA,CAEA,CAAC,cClJD,cACA,2FACA,CANA,0BASA,EARA,uBASA,mBADA,EARA,GASA,0DATA,cACA,0BCqBA,qBAIA,uBACA,sDACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,gEACA,gEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,8DACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,8DACA,kEACA,kEACA,kEACA,kEACA,kEACA,kEACA,4CACA,EA8BA,OA7BA,WAIA,gBAIA,wBACA,YACA,EAD+B,IAM/B,uBACA,wBACA,EAMA,gCACA,aACA,yBAGA,CAEA,CAAC,cC/GD,OAEA,MAEA,0BACA,2DACA,CAAK,CAGL,0BACA,yDACA,CACA,CAAG,CAGH,KAEA,0BACA,iBAAkC,WAAgB,IAClD,4BACA,QACA,CAAK,CAGL,0BACA,iBAAgC,WAAkB,IAClD,kCACA,iBACA,CACA,CACA,EAEA,2DC/BA,OACA,8EACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,sFACA,wFACA,wFACA,CACA,gCACA,sBAUA,MARA,QAEA,oBAMe,CALf,MAKqB,EALrB,IAAwB,WAAwB,IAChD,wBAEA,WACA","sources":["webpack://_N_E/./node_modules/xz-decompress/dist/package/xz-decompress.js","webpack://_N_E/./node_modules/@gmod/cram/esm/seek-bzip/stream.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/constants.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/record.js","webpack://_N_E/./node_modules/@gmod/cram/esm/errors.js","webpack://_N_E/./node_modules/@gmod/cram/esm/seek-bzip/toHex.js","webpack://_N_E/./node_modules/@gmod/cram/esm/seek-bzip/bitreader.js","webpack://_N_E/./node_modules/@gmod/cram/esm/seek-bzip/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/arith_sh.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/byte_model.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/iostream.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/arith_gen.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/fqzcomp.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/rans4x16.js","webpack://_N_E/./node_modules/@gmod/cram/esm/util.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/tok3.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/io/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/constants.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/decoding.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/d04.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/d14.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/frequencies.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/sam.js","webpack://_N_E/./node_modules/@gmod/cram/esm/unzip.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/getBits.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/util.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/sectionParsers.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/slice/decodeRecord.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/slice/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/beta.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayLength.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayStop.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/external.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/gamma.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/huffman.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/subexp.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/container/compressionScheme.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/container/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/file.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/craiIndex.js","webpack://_N_E/./node_modules/@gmod/cram/esm/indexedCramFile.js","webpack://_N_E/./node_modules/@gmod/cram/esm/index.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/util.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramSlightlyLazyFeature.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramAdapter.js","webpack://_N_E/./node_modules/crypt/crypt.js","webpack://_N_E/./node_modules/md5/md5.js","webpack://_N_E/./node_modules/is-buffer/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/seek-bzip/crc32.js","webpack://_N_E/./node_modules/charenc/charenc.js","webpack://_N_E/./node_modules/crc/mjs/calculators/crc32.js"],"sourcesContent":["/*!\n * Based on xzwasm (c) Steve Sanderson. License: MIT - https://github.com/SteveSanderson/xzwasm\n * Contains xz-embedded by Lasse Collin and Igor Pavlov. License: Public domain - https://tukaani.org/xz/embedded.html\n * and walloc (c) 2020 Igalia, S.L. License: MIT - https://github.com/wingo/walloc\n */\n(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"stream/web\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"stream/web\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"xz-decompress\"] = factory(require(\"stream/web\"));\n\telse\n\t\troot[\"xz-decompress\"] = factory(root[\"stream/web\"]);\n})(this, (__WEBPACK_EXTERNAL_MODULE__2__) => {\nreturn /******/ (() => { // webpackBootstrap\n/******/ \t\"use strict\";\n/******/ \tvar __webpack_modules__ = ([\n/* 0 */,\n/* 1 */\n/***/ ((module) => {\n\nmodule.exports = \"data:application/wasm;base64,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\";\n\n/***/ }),\n/* 2 */\n/***/ ((module) => {\n\nmodule.exports = __WEBPACK_EXTERNAL_MODULE__2__;\n\n/***/ })\n/******/ \t]);\n/************************************************************************/\n/******/ \t// The module cache\n/******/ \tvar __webpack_module_cache__ = {};\n/******/ \t\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/ \t\t// Check if module is in cache\n/******/ \t\tvar cachedModule = __webpack_module_cache__[moduleId];\n/******/ \t\tif (cachedModule !== undefined) {\n/******/ \t\t\treturn cachedModule.exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = __webpack_module_cache__[moduleId] = {\n/******/ \t\t\t// no module.id needed\n/******/ \t\t\t// no module.loaded needed\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/ \t\n/******/ \t\t// Execute the module function\n/******/ \t\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n/******/ \t\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/ \t\n/************************************************************************/\n/******/ \t/* webpack/runtime/define property getters */\n/******/ \t(() => {\n/******/ \t\t// define getter functions for harmony exports\n/******/ \t\t__webpack_require__.d = (exports, definition) => {\n/******/ \t\t\tfor(var key in definition) {\n/******/ \t\t\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n/******/ \t\t\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n/******/ \t\t\t\t}\n/******/ \t\t\t}\n/******/ \t\t};\n/******/ \t})();\n/******/ \t\n/******/ \t/* webpack/runtime/hasOwnProperty shorthand */\n/******/ \t(() => {\n/******/ \t\t__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))\n/******/ \t})();\n/******/ \t\n/******/ \t/* webpack/runtime/make namespace object */\n/******/ \t(() => {\n/******/ \t\t// define __esModule on exports\n/******/ \t\t__webpack_require__.r = (exports) => {\n/******/ \t\t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n/******/ \t\t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n/******/ \t\t\t}\n/******/ \t\t\tObject.defineProperty(exports, '__esModule', { value: true });\n/******/ \t\t};\n/******/ \t})();\n/******/ \t\n/************************************************************************/\nvar __webpack_exports__ = {};\n// This entry need to be wrapped in an IIFE because it need to be isolated against other modules in the chunk.\n(() => {\n__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   XzReadableStream: () => (/* binding */ XzReadableStream)\n/* harmony export */ });\n/* harmony import */ var _dist_native_xz_decompress_wasm__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(1);\n\n\nconst ReadableStream = globalThis.ReadableStream\n    // Node < 18 support web streams, but it's not available as a global, so we need to require it.\n    // This won't be reached in modern browsers, and bundlers will ignore due to 'browser' field in package.json:\n    || (__webpack_require__(2).ReadableStream);\n\nconst XZ_OK = 0;\nconst XZ_STREAM_END = 1;\n\nclass XzContext {\n    constructor(moduleInstance) {\n        this.exports = moduleInstance.exports;\n        this.memory = this.exports.memory;\n        this.ptr = this.exports.create_context();\n        this._refresh();\n        this.bufSize = this.mem32[0];\n        this.inStart = this.mem32[1] - this.ptr;\n        this.inEnd = this.inStart + this.bufSize;\n        this.outStart = this.mem32[4] - this.ptr;\n    }\n\n    supplyInput(sourceDataUint8Array) {\n        this._refresh();\n        const inBuffer = this.mem8.subarray(this.inStart, this.inEnd);\n        inBuffer.set(sourceDataUint8Array, 0);\n        this.exports.supply_input(this.ptr, sourceDataUint8Array.byteLength);\n        this._refresh();\n    }\n\n    getNextOutput() {\n        const result = this.exports.get_next_output(this.ptr);\n        this._refresh();\n        if (result !== XZ_OK && result !== XZ_STREAM_END) {\n            throw new Error(`get_next_output failed with error code ${result}`);\n        }\n        const outChunk = this.mem8.slice(this.outStart, this.outStart + /* outPos */ this.mem32[5]);\n        return { outChunk, finished: result === XZ_STREAM_END };\n    }\n\n    needsMoreInput() {\n        return /* inPos */ this.mem32[2] === /* inSize */ this.mem32[3];\n    }\n\n    outputBufferIsFull() {\n        return /* outPos */ this.mem32[5] === this.bufSize;\n    }\n\n    resetOutputBuffer() {\n        this.outPos = this.mem32[5] = 0;\n    }\n\n    dispose() {\n        this.exports.destroy_context(this.ptr);\n        this.exports = null;\n    }\n\n    _refresh() {\n        if (this.memory.buffer !== this.mem8?.buffer) {\n            this.mem8 = new Uint8Array(this.memory.buffer, this.ptr);\n            this.mem32 = new Uint32Array(this.memory.buffer, this.ptr);\n        }\n    }\n}\n\nclass XzReadableStream extends ReadableStream {\n    static _moduleInstancePromise;\n    static _moduleInstance;\n    static async _getModuleInstance() {\n        const base64Wasm = _dist_native_xz_decompress_wasm__WEBPACK_IMPORTED_MODULE_0__.replace('data:application/wasm;base64,', '');\n        const wasmBytes = Uint8Array.from(atob(base64Wasm), c => c.charCodeAt(0)).buffer;\n        const wasmOptions = {};\n        const module = await WebAssembly.instantiate(wasmBytes, wasmOptions);\n        XzReadableStream._moduleInstance = module.instance;\n    }\n\n    constructor(compressedStream) {\n        let xzContext;\n        let unconsumedInput = null;\n        const compressedReader = compressedStream.getReader();\n\n        super({\n            async start(controller) {\n                if (!XzReadableStream._moduleInstance) {\n                    await (XzReadableStream._moduleInstancePromise || (XzReadableStream._moduleInstancePromise = XzReadableStream._getModuleInstance()));\n                }\n                xzContext = new XzContext(XzReadableStream._moduleInstance);\n            },\n\n            async pull(controller) {\n                if (xzContext.needsMoreInput()) {\n                    if (unconsumedInput === null || unconsumedInput.byteLength === 0) {\n                        const { done, value } = await compressedReader.read();\n                        if (!done) {\n                            unconsumedInput = value;\n                        }\n                    }\n                    const nextInputLength = Math.min(xzContext.bufSize, unconsumedInput.byteLength);\n                    xzContext.supplyInput(unconsumedInput.subarray(0, nextInputLength));\n                    unconsumedInput = unconsumedInput.subarray(nextInputLength);\n                }\n\n                const nextOutputResult = xzContext.getNextOutput();\n                controller.enqueue(nextOutputResult.outChunk);\n                xzContext.resetOutputBuffer();\n\n                if (nextOutputResult.finished) {\n                    xzContext.dispose(); // Not sure if this always happens\n                    controller.close();\n                }\n            },\n            cancel() {\n                xzContext.dispose(); // Not sure if this always happens\n                return compressedReader.cancel();\n            }\n        });\n    }\n}\n\n})();\n\n/******/ \treturn __webpack_exports__;\n/******/ })()\n;\n});","\"use strict\";\n// @ts-nocheck\n/// * very simple input/output stream interface */\nconst Stream = function () { };\n// input streams //////////////\n/** Returns the next byte, or -1 for EOF. */\nStream.prototype.readByte = function () {\n    throw new Error('abstract method readByte() not implemented');\n};\n/** Attempts to fill the buffer; returns number of bytes read, or\n *  -1 for EOF. */\nStream.prototype.read = function (buffer, bufOffset, length) {\n    let bytesRead = 0;\n    while (bytesRead < length) {\n        const c = this.readByte();\n        if (c < 0) {\n            // EOF\n            return bytesRead === 0 ? -1 : bytesRead;\n        }\n        buffer[bufOffset++] = c;\n        bytesRead++;\n    }\n    return bytesRead;\n};\nStream.prototype.seek = function (new_pos) {\n    throw new Error('abstract method seek() not implemented');\n};\n// output streams ///////////\nStream.prototype.writeByte = function (_byte) {\n    throw new Error('abstract method readByte() not implemented');\n};\nStream.prototype.write = function (buffer, bufOffset, length) {\n    let i;\n    for (i = 0; i < length; i++) {\n        this.writeByte(buffer[bufOffset++]);\n    }\n    return length;\n};\nStream.prototype.flush = function () { };\nmodule.exports = Stream;\n//# sourceMappingURL=stream.js.map","const Constants = {\n    CRAM_FLAG_PRESERVE_QUAL_SCORES: 1 << 0,\n    CRAM_FLAG_DETACHED: 1 << 1,\n    CRAM_FLAG_MATE_DOWNSTREAM: 1 << 2,\n    CRAM_FLAG_NO_SEQ: 1 << 3,\n    CRAM_FLAG_MASK: (1 << 4) - 1,\n    // mate read is reversed\n    CRAM_M_REVERSE: 1,\n    // mated read is unmapped\n    CRAM_M_UNMAP: 2,\n    //  the read is paired in sequencing, no matter whether it is mapped in a pair\n    BAM_FPAIRED: 1,\n    //  the read is mapped in a proper pair\n    BAM_FPROPER_PAIR: 2,\n    //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR\n    BAM_FUNMAP: 4,\n    //  the mate is unmapped\n    BAM_FMUNMAP: 8,\n    //  the read is mapped to the reverse strand\n    BAM_FREVERSE: 16,\n    //  the mate is mapped to the reverse strand\n    BAM_FMREVERSE: 32,\n    //  this is read1\n    BAM_FREAD1: 64,\n    //  this is read2\n    BAM_FREAD2: 128,\n    //  not primary alignment\n    BAM_FSECONDARY: 256,\n    //  QC failure\n    BAM_FQCFAIL: 512,\n    //  optical or PCR duplicate\n    BAM_FDUP: 1024,\n    //  supplementary alignment\n    BAM_FSUPPLEMENTARY: 2048,\n    BAM_CMATCH: 0,\n    BAM_CINS: 1,\n    BAM_CDEL: 2,\n    BAM_CREF_SKIP: 3,\n    BAM_CSOFT_CLIP: 4,\n    BAM_CHARD_CLIP: 5,\n    BAM_CPAD: 6,\n    BAM_CEQUAL: 7,\n    BAM_CDIFF: 8,\n    BAM_CBACK: 9,\n    BAM_CIGAR_STR: 'MIDNSHP:XB',\n    BAM_CIGAR_SHIFT: 4,\n    BAM_CIGAR_MASK: 0xf,\n    BAM_CIGAR_TYPE: 0x3c1a7,\n};\nexport default Constants;\n//# sourceMappingURL=constants.js.map","import Constants from './constants';\nfunction decodeReadSequence(cramRecord, refRegion) {\n    // if it has no length, it has no sequence\n    if (!cramRecord.lengthOnRef && !cramRecord.readLength) {\n        return null;\n    }\n    if (cramRecord.isUnknownBases()) {\n        return null;\n    }\n    // remember: all coordinates are 1-based closed\n    const regionSeqOffset = cramRecord.alignmentStart - refRegion.start;\n    if (!cramRecord.readFeatures) {\n        return refRegion.seq\n            .slice(regionSeqOffset, regionSeqOffset + (cramRecord.lengthOnRef || 0))\n            .toUpperCase();\n    }\n    let bases = '';\n    let regionPos = regionSeqOffset;\n    let currentReadFeature = 0;\n    while (bases.length < cramRecord.readLength) {\n        if (currentReadFeature < cramRecord.readFeatures.length) {\n            const feature = cramRecord.readFeatures[currentReadFeature];\n            if (feature.code === 'Q' || feature.code === 'q') {\n                currentReadFeature += 1;\n            }\n            else if (feature.pos === bases.length + 1) {\n                // process the read feature\n                currentReadFeature += 1;\n                if (feature.code === 'b') {\n                    // specify a base pair for some reason\n                    const added = feature.data;\n                    bases += added;\n                    regionPos += added.length;\n                }\n                else if (feature.code === 'B') {\n                    // base pair and associated quality\n                    // TODO: do we need to set the quality in the qual scores?\n                    bases += feature.data[0];\n                    regionPos += 1;\n                }\n                else if (feature.code === 'X') {\n                    // base substitution\n                    bases += feature.sub;\n                    regionPos += 1;\n                }\n                else if (feature.code === 'I') {\n                    // insertion\n                    bases += feature.data;\n                }\n                else if (feature.code === 'D') {\n                    // deletion\n                    regionPos += feature.data;\n                }\n                else if (feature.code === 'i') {\n                    // insert single base\n                    bases += feature.data;\n                }\n                else if (feature.code === 'N') {\n                    // reference skip. delete some bases\n                    // do nothing\n                    // seqBases.splice(feature.pos - 1, feature.data)\n                    regionPos += feature.data;\n                }\n                else if (feature.code === 'S') {\n                    // soft clipped bases that should be present in the read seq\n                    // seqBases.splice(feature.pos - 1, 0, ...feature.data.split(''))\n                    bases += feature.data;\n                }\n                else if (feature.code === 'P') {\n                    // padding, do nothing\n                }\n                else if (feature.code === 'H') {\n                    // hard clip, do nothing\n                }\n            }\n            else if (currentReadFeature < cramRecord.readFeatures.length) {\n                // put down a chunk of sequence up to the next read feature\n                const chunk = refRegion.seq.slice(regionPos, regionPos + feature.pos - bases.length - 1);\n                bases += chunk;\n                regionPos += chunk.length;\n            }\n        }\n        else {\n            // put down a chunk of reference up to the full read length\n            const chunk = refRegion.seq.slice(regionPos, regionPos + cramRecord.readLength - bases.length);\n            bases += chunk;\n            regionPos += chunk.length;\n        }\n    }\n    return bases.toUpperCase();\n}\nconst baseNumbers = {\n    a: 0,\n    A: 0,\n    c: 1,\n    C: 1,\n    g: 2,\n    G: 2,\n    t: 3,\n    T: 3,\n    n: 4,\n    N: 4,\n};\nfunction decodeBaseSubstitution(cramRecord, refRegion, compressionScheme, readFeature) {\n    // decode base substitution code using the substitution matrix\n    const refCoord = readFeature.refPos - refRegion.start;\n    const refBase = refRegion.seq.charAt(refCoord);\n    if (refBase) {\n        readFeature.ref = refBase;\n    }\n    let baseNumber = baseNumbers[refBase];\n    if (baseNumber === undefined) {\n        baseNumber = 4;\n    }\n    const substitutionScheme = compressionScheme.substitutionMatrix[baseNumber];\n    const base = substitutionScheme[readFeature.data];\n    if (base) {\n        readFeature.sub = base;\n    }\n}\nexport const BamFlags = [\n    [0x1, 'Paired'],\n    [0x2, 'ProperlyPaired'],\n    [0x4, 'SegmentUnmapped'],\n    [0x8, 'MateUnmapped'],\n    [0x10, 'ReverseComplemented'],\n    //  the mate is mapped to the reverse strand\n    [0x20, 'MateReverseComplemented'],\n    //  this is read1\n    [0x40, 'Read1'],\n    //  this is read2\n    [0x80, 'Read2'],\n    //  not primary alignment\n    [0x100, 'Secondary'],\n    //  QC failure\n    [0x200, 'FailedQc'],\n    //  optical or PCR duplicate\n    [0x400, 'Duplicate'],\n    //  supplementary alignment\n    [0x800, 'Supplementary'],\n];\nexport const CramFlags = [\n    [0x1, 'PreservingQualityScores'],\n    [0x2, 'Detached'],\n    [0x4, 'WithMateDownstream'],\n    [0x8, 'DecodeSequenceAsStar'],\n];\nexport const MateFlags = [\n    [0x1, 'OnNegativeStrand'],\n    [0x2, 'Unmapped'],\n];\nfunction makeFlagsHelper(x) {\n    const r = {};\n    for (const [code, name] of x) {\n        r[`is${name}`] = (flags) => !!(flags & code);\n        r[`set${name}`] = (flags) => flags | code;\n    }\n    return r;\n}\nexport const BamFlagsDecoder = makeFlagsHelper(BamFlags);\nexport const CramFlagsDecoder = makeFlagsHelper(CramFlags);\nexport const MateFlagsDecoder = makeFlagsHelper(MateFlags);\n/**\n * Class of each CRAM record returned by this API.\n */\nexport default class CramRecord {\n    constructor({ flags, cramFlags, readLength, mappingQuality, lengthOnRef, qualityScores, mateRecordNumber, readBases, readFeatures, mateToUse, readGroupId, readName, sequenceId, uniqueId, templateSize, alignmentStart, tags, }) {\n        this.flags = flags;\n        this.cramFlags = cramFlags;\n        this.readLength = readLength;\n        this.mappingQuality = mappingQuality;\n        this.lengthOnRef = lengthOnRef;\n        this.qualityScores = qualityScores;\n        if (readBases) {\n            this.readBases = readBases;\n        }\n        this.readGroupId = readGroupId;\n        this.readName = readName;\n        this.sequenceId = sequenceId;\n        this.uniqueId = uniqueId;\n        this.templateSize = templateSize;\n        this.alignmentStart = alignmentStart;\n        this.tags = tags;\n        // backwards compatibility\n        if (readFeatures) {\n            this.readFeatures = readFeatures;\n        }\n        if (mateToUse) {\n            this.mate = {\n                flags: mateToUse.mateFlags,\n                readName: mateToUse.mateReadName,\n                sequenceId: mateToUse.mateSequenceId,\n                alignmentStart: mateToUse.mateAlignmentStart,\n            };\n        }\n        if (mateRecordNumber) {\n            this.mateRecordNumber = mateRecordNumber;\n        }\n    }\n    /**\n     * @returns {boolean} true if the read is paired, regardless of whether both segments are mapped\n     */\n    isPaired() {\n        return !!(this.flags & Constants.BAM_FPAIRED);\n    }\n    /** @returns {boolean} true if the read is paired, and both segments are mapped */\n    isProperlyPaired() {\n        return !!(this.flags & Constants.BAM_FPROPER_PAIR);\n    }\n    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n    isSegmentUnmapped() {\n        return !!(this.flags & Constants.BAM_FUNMAP);\n    }\n    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n    isMateUnmapped() {\n        return !!(this.flags & Constants.BAM_FMUNMAP);\n    }\n    /** @returns {boolean} true if the read is mapped to the reverse strand */\n    isReverseComplemented() {\n        return !!(this.flags & Constants.BAM_FREVERSE);\n    }\n    /** @returns {boolean} true if the mate is mapped to the reverse strand */\n    isMateReverseComplemented() {\n        return !!(this.flags & Constants.BAM_FMREVERSE);\n    }\n    /** @returns {boolean} true if this is read number 1 in a pair */\n    isRead1() {\n        return !!(this.flags & Constants.BAM_FREAD1);\n    }\n    /** @returns {boolean} true if this is read number 2 in a pair */\n    isRead2() {\n        return !!(this.flags & Constants.BAM_FREAD2);\n    }\n    /** @returns {boolean} true if this is a secondary alignment */\n    isSecondary() {\n        return !!(this.flags & Constants.BAM_FSECONDARY);\n    }\n    /** @returns {boolean} true if this read has failed QC checks */\n    isFailedQc() {\n        return !!(this.flags & Constants.BAM_FQCFAIL);\n    }\n    /** @returns {boolean} true if the read is an optical or PCR duplicate */\n    isDuplicate() {\n        return !!(this.flags & Constants.BAM_FDUP);\n    }\n    /** @returns {boolean} true if this is a supplementary alignment */\n    isSupplementary() {\n        return !!(this.flags & Constants.BAM_FSUPPLEMENTARY);\n    }\n    /**\n     * @returns {boolean} true if the read is detached\n     */\n    isDetached() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_DETACHED);\n    }\n    /** @returns {boolean} true if the read has a mate in this same CRAM segment */\n    hasMateDownStream() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_MATE_DOWNSTREAM);\n    }\n    /** @returns {boolean} true if the read contains qual scores */\n    isPreservingQualityScores() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_PRESERVE_QUAL_SCORES);\n    }\n    /** @returns {boolean} true if the read has no sequence bases */\n    isUnknownBases() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_NO_SEQ);\n    }\n    /**\n     * Get the original sequence of this read.\n     * @returns {String} sequence basepairs\n     */\n    getReadBases() {\n        if (!this.readBases && this._refRegion) {\n            const decoded = decodeReadSequence(this, this._refRegion);\n            if (decoded) {\n                this.readBases = decoded;\n            }\n        }\n        return this.readBases;\n    }\n    /**\n     * Get the pair orientation of a paired read. Adapted from igv.js\n     * @returns {String} of paired orientatin\n     */\n    getPairOrientation() {\n        if (!this.isSegmentUnmapped() &&\n            this.isPaired() &&\n            !this.isMateUnmapped() &&\n            this.mate &&\n            this.sequenceId === this.mate.sequenceId) {\n            const s1 = this.isReverseComplemented() ? 'R' : 'F';\n            const s2 = this.isMateReverseComplemented() ? 'R' : 'F';\n            let o1 = ' ';\n            let o2 = ' ';\n            if (this.isRead1()) {\n                o1 = '1';\n                o2 = '2';\n            }\n            else if (this.isRead2()) {\n                o1 = '2';\n                o2 = '1';\n            }\n            const tmp = [];\n            let isize = this.templateLength || this.templateSize;\n            if (isize === undefined) {\n                throw new Error('One of templateSize and templateLength must be set');\n            }\n            if (this.alignmentStart > this.mate.alignmentStart && isize > 0) {\n                isize = -isize;\n            }\n            if (isize > 0) {\n                tmp[0] = s1;\n                tmp[1] = o1;\n                tmp[2] = s2;\n                tmp[3] = o2;\n            }\n            else {\n                tmp[2] = s1;\n                tmp[3] = o1;\n                tmp[0] = s2;\n                tmp[1] = o2;\n            }\n            return tmp.join('');\n        }\n        return null;\n    }\n    /**\n     * Annotates this feature with the given reference sequence basepair\n     * information. This will add a `sub` and a `ref` item to base\n     * substitution read features given the actual substituted and reference\n     * base pairs, and will make the `getReadSequence()` method work.\n     *\n     * @param {object} refRegion\n     * @param {number} refRegion.start\n     * @param {number} refRegion.end\n     * @param {string} refRegion.seq\n     * @param {CramContainerCompressionScheme} compressionScheme\n     * @returns {undefined} nothing\n     */\n    addReferenceSequence(refRegion, compressionScheme) {\n        if (this.readFeatures) {\n            // use the reference bases to decode the bases substituted in each base\n            // substitution\n            this.readFeatures.forEach(readFeature => {\n                if (readFeature.code === 'X') {\n                    decodeBaseSubstitution(this, refRegion, compressionScheme, readFeature);\n                }\n            });\n        }\n        // if this region completely covers this read,\n        // keep a reference to it\n        if (!this.readBases &&\n            refRegion.start <= this.alignmentStart &&\n            refRegion.end >=\n                this.alignmentStart + (this.lengthOnRef || this.readLength) - 1) {\n            this._refRegion = refRegion;\n        }\n    }\n    toJSON() {\n        const data = {};\n        Object.keys(this).forEach(k => {\n            if (k.startsWith('_')) {\n                return;\n            }\n            data[k] = this[k];\n        });\n        data.readBases = this.getReadBases();\n        return data;\n    }\n}\n//# sourceMappingURL=record.js.map","export class CramError extends Error {\n}\n/** Error caused by encountering a part of the CRAM spec that has not yet been implemented */\nexport class CramUnimplementedError extends Error {\n}\n/** An error caused by malformed data.  */\nexport class CramMalformedError extends CramError {\n}\n/**\n * An error caused by data being too big, exceeding a size limit.\n */\nexport class CramSizeLimitError extends CramError {\n}\n/**\n * An invalid argument was supplied to a cram-js method or object.\n */\nexport class CramArgumentError extends CramError {\n}\n//# sourceMappingURL=errors.js.map","// from https://www.xaymar.com/articles/2020/12/08/fastest-uint8array-to-hex-string-conversion-in-javascript/\n// Pre-Init\nconst LUT_HEX_4b = [\n    '0',\n    '1',\n    '2',\n    '3',\n    '4',\n    '5',\n    '6',\n    '7',\n    '8',\n    '9',\n    'A',\n    'B',\n    'C',\n    'D',\n    'E',\n    'F',\n];\nconst LUT_HEX_8b = new Array(0x100);\nfor (let n = 0; n < 0x100; n++) {\n    LUT_HEX_8b[n] = `${LUT_HEX_4b[(n >>> 4) & 0xf]}${LUT_HEX_4b[n & 0xf]}`;\n}\n// End Pre-Init\nexport function toHex(buffer) {\n    let out = '';\n    for (let idx = 0, edx = buffer.length; idx < edx; idx++) {\n        out += LUT_HEX_8b[buffer[idx]];\n    }\n    return out;\n}\n//# sourceMappingURL=toHex.js.map","/*\nnode-bzip - a pure-javascript Node.JS module for decoding bzip2 data\n\nCopyright (C) 2012 Eli Skeggs\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nAdapted from bzip2.js, copyright 2011 antimatter15 (antimatter15@gmail.com).\n\nBased on micro-bunzip by Rob Landley (rob@landley.net).\n\nBased on bzip2 decompression code by Julian R Seward (jseward@acm.org),\nwhich also acknowledges contributions by Mike Burrows, David Wheeler,\nPeter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,\nRobert Sedgewick, and Jon L. Bentley.\n*/\nimport { toHex } from './toHex';\nconst BITMASK = [0x00, 0x01, 0x03, 0x07, 0x0f, 0x1f, 0x3f, 0x7f, 0xff];\nexport default class BitReader {\n    constructor(stream) {\n        this.stream = stream;\n        this.bitOffset = 0;\n        this.curByte = 0;\n        this.hasByte = false;\n    }\n    _ensureByte() {\n        if (!this.hasByte) {\n            this.curByte = this.stream.readByte();\n            this.hasByte = true;\n        }\n    }\n    /**\n     * Reads bits from the buffer\n     * @param bits Number of bits to read\n     */\n    read(bits) {\n        let result = 0;\n        while (bits > 0) {\n            this._ensureByte();\n            const remaining = 8 - this.bitOffset;\n            // if we're in a byte\n            if (bits >= remaining) {\n                result <<= remaining;\n                result |= BITMASK[remaining] & this.curByte;\n                this.hasByte = false;\n                this.bitOffset = 0;\n                bits -= remaining;\n            }\n            else {\n                result <<= bits;\n                const shift = remaining - bits;\n                result |= (this.curByte & (BITMASK[bits] << shift)) >> shift;\n                this.bitOffset += bits;\n                bits = 0;\n            }\n        }\n        return result;\n    }\n    /**\n     * Seek to an arbitrary point in the buffer (expressed in bits)\n     * @param pos Position in bits\n     */\n    seek(pos) {\n        const n_bit = pos % 8;\n        const n_byte = (pos - n_bit) / 8;\n        this.bitOffset = n_bit;\n        this.stream.seek(n_byte);\n        this.hasByte = false;\n    }\n    /**\n     * Reads 6 bytes worth of data using the read method\n     */\n    pi() {\n        const buf = new Uint8Array(6);\n        for (let i = 0; i < buf.length; i++) {\n            buf[i] = this.read(8);\n        }\n        return toHex(buf);\n    }\n}\n//# sourceMappingURL=bitreader.js.map","// @ts-nocheck\n/*\nseek-bzip - a pure-javascript module for seeking within bzip2 data\n\nCopyright (C) 2013 C. Scott Ananian\nCopyright (C) 2012 Eli Skeggs\nCopyright (C) 2011 Kevin Kwok\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nAdapted from node-bzip, copyright 2012 Eli Skeggs.\nAdapted from bzip2.js, copyright 2011 Kevin Kwok (antimatter15@gmail.com).\n\nBased on micro-bunzip by Rob Landley (rob@landley.net).\n\nBased on bzip2 decompression code by Julian R Seward (jseward@acm.org),\nwhich also acknowledges contributions by Mike Burrows, David Wheeler,\nPeter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,\nRobert Sedgewick, and Jon L. Bentley.\n*/\nimport BitReader from './bitreader';\nimport CRC32 from './crc32';\nimport Stream from './stream';\nconst MAX_HUFCODE_BITS = 20;\nconst MAX_SYMBOLS = 258;\nconst SYMBOL_RUNA = 0;\nconst SYMBOL_RUNB = 1;\nconst MIN_GROUPS = 2;\nconst MAX_GROUPS = 6;\nconst GROUP_SIZE = 50;\nconst WHOLEPI = '314159265359';\nconst SQRTPI = '177245385090';\nconst mtf = function (array, index) {\n    const src = array[index];\n    for (let i = index; i > 0; i--) {\n        array[i] = array[i - 1];\n    }\n    array[0] = src;\n    return src;\n};\nconst Err = {\n    OK: 0,\n    LAST_BLOCK: -1,\n    NOT_BZIP_DATA: -2,\n    UNEXPECTED_INPUT_EOF: -3,\n    UNEXPECTED_OUTPUT_EOF: -4,\n    DATA_ERROR: -5,\n    OUT_OF_MEMORY: -6,\n    OBSOLETE_INPUT: -7,\n    END_OF_BLOCK: -8,\n};\nconst ErrorMessages = {};\nErrorMessages[Err.LAST_BLOCK] = 'Bad file checksum';\nErrorMessages[Err.NOT_BZIP_DATA] = 'Not bzip data';\nErrorMessages[Err.UNEXPECTED_INPUT_EOF] = 'Unexpected input EOF';\nErrorMessages[Err.UNEXPECTED_OUTPUT_EOF] = 'Unexpected output EOF';\nErrorMessages[Err.DATA_ERROR] = 'Data error';\nErrorMessages[Err.OUT_OF_MEMORY] = 'Out of memory';\nErrorMessages[Err.OBSOLETE_INPUT] =\n    'Obsolete (pre 0.9.5) bzip format not supported.';\nconst _throw = function (status, optDetail) {\n    let msg = ErrorMessages[status] || 'unknown error';\n    if (optDetail) {\n        msg += ': ' + optDetail;\n    }\n    const e = new TypeError(msg);\n    e.errorCode = status;\n    throw e;\n};\nclass Bunzip {\n    constructor(inputStream, outputStream) {\n        this.writePos = this.writeCurrent = this.writeCount = 0;\n        this._start_bunzip(inputStream, outputStream);\n    }\n    _init_block() {\n        const moreBlocks = this._get_next_block();\n        if (!moreBlocks) {\n            this.writeCount = -1;\n            return false; /* no more blocks */\n        }\n        this.blockCRC = new CRC32();\n        return true;\n    }\n    /* XXX micro-bunzip uses (inputStream, inputBuffer, len) as arguments */\n    _start_bunzip(inputStream, outputStream) {\n        /* Ensure that file starts with \"BZh['1'-'9'].\" */\n        const buf = new Uint8Array(4);\n        if (inputStream.read(buf, 0, 4) !== 4 ||\n            String.fromCharCode(buf[0], buf[1], buf[2]) !== 'BZh') {\n            _throw(Err.NOT_BZIP_DATA, 'bad magic');\n        }\n        const level = buf[3] - 0x30;\n        if (level < 1 || level > 9) {\n            _throw(Err.NOT_BZIP_DATA, 'level out of range');\n        }\n        this.reader = new BitReader(inputStream);\n        /* Fourth byte (ascii '1'-'9'), indicates block size in units of 100k of\n         uncompressed data.  Allocate intermediate buffer for block. */\n        this.dbufSize = 100000 * level;\n        this.nextoutput = 0;\n        this.outputStream = outputStream;\n        this.streamCRC = 0;\n    }\n    _get_next_block() {\n        let i, j, k;\n        const reader = this.reader;\n        // this is get_next_block() function from micro-bunzip:\n        /* Read in header signature and CRC, then validate signature.\n         (last block signature means CRC is for whole file, return now) */\n        const h = reader.pi();\n        if (h === SQRTPI) {\n            // last block\n            return false; /* no more blocks */\n        }\n        if (h !== WHOLEPI) {\n            _throw(Err.NOT_BZIP_DATA);\n        }\n        this.targetBlockCRC = reader.read(32) >>> 0; // (convert to unsigned)\n        this.streamCRC =\n            (this.targetBlockCRC ^\n                ((this.streamCRC << 1) | (this.streamCRC >>> 31))) >>>\n                0;\n        /* We can add support for blockRandomised if anybody complains.  There was\n         some code for this in busybox 1.0.0-pre3, but nobody ever noticed that\n         it didn't actually work. */\n        if (reader.read(1)) {\n            _throw(Err.OBSOLETE_INPUT);\n        }\n        const origPointer = reader.read(24);\n        if (origPointer > this.dbufSize) {\n            _throw(Err.DATA_ERROR, 'initial position out of bounds');\n        }\n        /* mapping table: if some byte values are never used (encoding things\n         like ascii text), the compression code removes the gaps to have fewer\n         symbols to deal with, and writes a sparse bitfield indicating which\n         values were present.  We make a translation table to convert the symbols\n         back to the corresponding bytes. */\n        let t = reader.read(16);\n        let symToByte = new Uint8Array(256), symTotal = 0;\n        for (i = 0; i < 16; i++) {\n            if (t & (1 << (0xf - i))) {\n                const o = i * 16;\n                k = reader.read(16);\n                for (j = 0; j < 16; j++) {\n                    if (k & (1 << (0xf - j))) {\n                        symToByte[symTotal++] = o + j;\n                    }\n                }\n            }\n        }\n        /* How many different huffman coding groups does this block use? */\n        const groupCount = reader.read(3);\n        if (groupCount < MIN_GROUPS || groupCount > MAX_GROUPS) {\n            _throw(Err.DATA_ERROR);\n        }\n        /* nSelectors: Every GROUP_SIZE many symbols we select a new huffman coding\n         group.  Read in the group selector list, which is stored as MTF encoded\n         bit runs.  (MTF=Move To Front, as each value is used it's moved to the\n         start of the list.) */\n        const nSelectors = reader.read(15);\n        if (nSelectors === 0) {\n            _throw(Err.DATA_ERROR);\n        }\n        const mtfSymbol = new Uint8Array(256);\n        for (i = 0; i < groupCount; i++) {\n            mtfSymbol[i] = i;\n        }\n        const selectors = new Uint8Array(nSelectors); // was 32768...\n        for (i = 0; i < nSelectors; i++) {\n            /* Get next value */\n            for (j = 0; reader.read(1); j++) {\n                if (j >= groupCount) {\n                    _throw(Err.DATA_ERROR);\n                }\n            }\n            /* Decode MTF to get the next selector */\n            selectors[i] = mtf(mtfSymbol, j);\n        }\n        /* Read the huffman coding tables for each group, which code for symTotal\n         literal symbols, plus two run symbols (RUNA, RUNB) */\n        let symCount = symTotal + 2;\n        let groups = [], hufGroup;\n        for (j = 0; j < groupCount; j++) {\n            const length = new Uint8Array(symCount), temp = new Uint16Array(MAX_HUFCODE_BITS + 1);\n            /* Read huffman code lengths for each symbol.  They're stored in\n             a way similar to mtf; record a starting value for the first symbol,\n             and an offset from the previous value for everys symbol after that. */\n            t = reader.read(5); // lengths\n            for (i = 0; i < symCount; i++) {\n                for (;;) {\n                    if (t < 1 || t > MAX_HUFCODE_BITS) {\n                        _throw(Err.DATA_ERROR);\n                    }\n                    /* If first bit is 0, stop.  Else second bit indicates whether\n                     to increment or decrement the value. */\n                    if (!reader.read(1)) {\n                        break;\n                    }\n                    if (!reader.read(1)) {\n                        t++;\n                    }\n                    else {\n                        t--;\n                    }\n                }\n                length[i] = t;\n            }\n            /* Find largest and smallest lengths in this group */\n            var minLen, maxLen;\n            minLen = maxLen = length[0];\n            for (i = 1; i < symCount; i++) {\n                if (length[i] > maxLen) {\n                    maxLen = length[i];\n                }\n                else if (length[i] < minLen) {\n                    minLen = length[i];\n                }\n            }\n            /* Calculate permute[], base[], and limit[] tables from length[].\n             *\n             * permute[] is the lookup table for converting huffman coded symbols\n             * into decoded symbols.  base[] is the amount to subtract from the\n             * value of a huffman symbol of a given length when using permute[].\n             *\n             * limit[] indicates the largest numerical value a symbol with a given\n             * number of bits can have.  This is how the huffman codes can vary in\n             * length: each code with a value>limit[length] needs another bit.\n             */\n            hufGroup = {};\n            groups.push(hufGroup);\n            hufGroup.permute = new Uint16Array(MAX_SYMBOLS);\n            hufGroup.limit = new Uint32Array(MAX_HUFCODE_BITS + 2);\n            hufGroup.base = new Uint32Array(MAX_HUFCODE_BITS + 1);\n            hufGroup.minLen = minLen;\n            hufGroup.maxLen = maxLen;\n            /* Calculate permute[].  Concurently, initialize temp[] and limit[]. */\n            let pp = 0;\n            for (i = minLen; i <= maxLen; i++) {\n                temp[i] = hufGroup.limit[i] = 0;\n                for (t = 0; t < symCount; t++) {\n                    if (length[t] === i) {\n                        hufGroup.permute[pp++] = t;\n                    }\n                }\n            }\n            /* Count symbols coded for at each bit length */\n            for (i = 0; i < symCount; i++) {\n                temp[length[i]]++;\n            }\n            /* Calculate limit[] (the largest symbol-coding value at each bit\n             * length, which is (previous limit<<1)+symbols at this level), and\n             * base[] (number of symbols to ignore at each bit length, which is\n             * limit minus the cumulative count of symbols coded for already). */\n            pp = t = 0;\n            for (i = minLen; i < maxLen; i++) {\n                pp += temp[i];\n                /* We read the largest possible symbol size and then unget bits\n                 after determining how many we need, and those extra bits could\n                 be set to anything.  (They're noise from future symbols.)  At\n                 each level we're really only interested in the first few bits,\n                 so here we set all the trailing to-be-ignored bits to 1 so they\n                 don't affect the value>limit[length] comparison. */\n                hufGroup.limit[i] = pp - 1;\n                pp <<= 1;\n                t += temp[i];\n                hufGroup.base[i + 1] = pp - t;\n            }\n            hufGroup.limit[maxLen + 1] =\n                Number.MAX_VALUE; /* Sentinal value for reading next sym. */\n            hufGroup.limit[maxLen] = pp + temp[maxLen] - 1;\n            hufGroup.base[minLen] = 0;\n        }\n        /* We've finished reading and digesting the block header.  Now read this\n         block's huffman coded symbols from the file and undo the huffman coding\n         and run length encoding, saving the result into dbuf[dbufCount++]=uc */\n        /* Initialize symbol occurrence counters and symbol Move To Front table */\n        const byteCount = new Uint32Array(256);\n        for (i = 0; i < 256; i++) {\n            mtfSymbol[i] = i;\n        }\n        /* Loop through compressed symbols. */\n        let runPos = 0, dbufCount = 0, selector = 0, uc;\n        const dbuf = (this.dbuf = new Uint32Array(this.dbufSize));\n        symCount = 0;\n        for (;;) {\n            /* Determine which huffman coding group to use. */\n            if (!symCount--) {\n                symCount = GROUP_SIZE - 1;\n                if (selector >= nSelectors) {\n                    _throw(Err.DATA_ERROR);\n                }\n                hufGroup = groups[selectors[selector++]];\n            }\n            /* Read next huffman-coded symbol. */\n            i = hufGroup.minLen;\n            j = reader.read(i);\n            for (;; i++) {\n                if (i > hufGroup.maxLen) {\n                    _throw(Err.DATA_ERROR);\n                }\n                if (j <= hufGroup.limit[i]) {\n                    break;\n                }\n                j = (j << 1) | reader.read(1);\n            }\n            /* Huffman decode value to get nextSym (with bounds checking) */\n            j -= hufGroup.base[i];\n            if (j < 0 || j >= MAX_SYMBOLS) {\n                _throw(Err.DATA_ERROR);\n            }\n            const nextSym = hufGroup.permute[j];\n            /* We have now decoded the symbol, which indicates either a new literal\n             byte, or a repeated run of the most recent literal byte.  First,\n             check if nextSym indicates a repeated run, and if so loop collecting\n             how many times to repeat the last literal. */\n            if (nextSym === SYMBOL_RUNA || nextSym === SYMBOL_RUNB) {\n                /* If this is the start of a new run, zero out counter */\n                if (!runPos) {\n                    runPos = 1;\n                    t = 0;\n                }\n                /* Neat trick that saves 1 symbol: instead of or-ing 0 or 1 at\n                 each bit position, add 1 or 2 instead.  For example,\n                 1011 is 1<<0 + 1<<1 + 2<<2.  1010 is 2<<0 + 2<<1 + 1<<2.\n                 You can make any bit pattern that way using 1 less symbol than\n                 the basic or 0/1 method (except all bits 0, which would use no\n                 symbols, but a run of length 0 doesn't mean anything in this\n                 context).  Thus space is saved. */\n                t += nextSym === SYMBOL_RUNA ? runPos : 2 * runPos;\n                runPos <<= 1;\n                continue;\n            }\n            /* When we hit the first non-run symbol after a run, we now know\n             how many times to repeat the last literal, so append that many\n             copies to our buffer of decoded symbols (dbuf) now.  (The last\n             literal used is the one at the head of the mtfSymbol array.) */\n            if (runPos) {\n                runPos = 0;\n                if (dbufCount + t > this.dbufSize) {\n                    _throw(Err.DATA_ERROR);\n                }\n                uc = symToByte[mtfSymbol[0]];\n                byteCount[uc] += t;\n                while (t--) {\n                    dbuf[dbufCount++] = uc;\n                }\n            }\n            /* Is this the terminating symbol? */\n            if (nextSym > symTotal) {\n                break;\n            }\n            /* At this point, nextSym indicates a new literal character.  Subtract\n             one to get the position in the MTF array at which this literal is\n             currently to be found.  (Note that the result can't be -1 or 0,\n             because 0 and 1 are RUNA and RUNB.  But another instance of the\n             first symbol in the mtf array, position 0, would have been handled\n             as part of a run above.  Therefore 1 unused mtf position minus\n             2 non-literal nextSym values equals -1.) */\n            if (dbufCount >= this.dbufSize) {\n                _throw(Err.DATA_ERROR);\n            }\n            i = nextSym - 1;\n            uc = mtf(mtfSymbol, i);\n            uc = symToByte[uc];\n            /* We have our literal byte.  Save it into dbuf. */\n            byteCount[uc]++;\n            dbuf[dbufCount++] = uc;\n        }\n        /* At this point, we've read all the huffman-coded symbols (and repeated\n         runs) for this block from the input stream, and decoded them into the\n         intermediate buffer.  There are dbufCount many decoded bytes in dbuf[].\n         Now undo the Burrows-Wheeler transform on dbuf.\n         See http://dogma.net/markn/articles/bwt/bwt.htm\n      */\n        if (origPointer < 0 || origPointer >= dbufCount) {\n            _throw(Err.DATA_ERROR);\n        }\n        /* Turn byteCount into cumulative occurrence counts of 0 to n-1. */\n        j = 0;\n        for (i = 0; i < 256; i++) {\n            k = j + byteCount[i];\n            byteCount[i] = j;\n            j = k;\n        }\n        /* Figure out what order dbuf would be in if we sorted it. */\n        for (i = 0; i < dbufCount; i++) {\n            uc = dbuf[i] & 0xff;\n            dbuf[byteCount[uc]] |= i << 8;\n            byteCount[uc]++;\n        }\n        /* Decode first byte by hand to initialize \"previous\" byte.  Note that it\n         doesn't get output, and if the first three characters are identical\n         it doesn't qualify as a run (hence writeRunCountdown=5). */\n        let pos = 0, current = 0, run = 0;\n        if (dbufCount) {\n            pos = dbuf[origPointer];\n            current = pos & 0xff;\n            pos >>= 8;\n            run = -1;\n        }\n        this.writePos = pos;\n        this.writeCurrent = current;\n        this.writeCount = dbufCount;\n        this.writeRun = run;\n        return true; /* more blocks to come */\n    }\n    /* Undo burrows-wheeler transform on intermediate buffer to produce output.\n     If start_bunzip was initialized with out_fd=-1, then up to len bytes of\n     data are written to outbuf.  Return value is number of bytes written or\n     error (all errors are negative numbers).  If out_fd!=-1, outbuf and len\n     are ignored, data is written to out_fd and return is RETVAL_OK or error.\n  */\n    _read_bunzip(outputBuffer, len) {\n        let copies, previous, outbyte;\n        /* james@jamestaylor.org: writeCount goes to -1 when the buffer is fully\n           decoded, which results in this returning RETVAL_LAST_BLOCK, also\n           equal to -1... Confusing, I'm returning 0 here to indicate no\n           bytes written into the buffer */\n        if (this.writeCount < 0) {\n            return 0;\n        }\n        const gotcount = 0;\n        let dbuf = this.dbuf, pos = this.writePos, current = this.writeCurrent;\n        let dbufCount = this.writeCount, outputsize = this.outputsize;\n        let run = this.writeRun;\n        while (dbufCount) {\n            dbufCount--;\n            previous = current;\n            pos = dbuf[pos];\n            current = pos & 0xff;\n            pos >>= 8;\n            if (run++ === 3) {\n                copies = current;\n                outbyte = previous;\n                current = -1;\n            }\n            else {\n                copies = 1;\n                outbyte = current;\n            }\n            this.blockCRC.updateCRCRun(outbyte, copies);\n            while (copies--) {\n                this.outputStream.writeByte(outbyte);\n                this.nextoutput++;\n            }\n            if (current != previous) {\n                run = 0;\n            }\n        }\n        this.writeCount = dbufCount;\n        // check CRC\n        if (this.blockCRC.getCRC() !== this.targetBlockCRC) {\n            _throw(Err.DATA_ERROR, 'Bad block CRC ' +\n                '(got ' +\n                this.blockCRC.getCRC().toString(16) +\n                ' expected ' +\n                this.targetBlockCRC.toString(16) +\n                ')');\n        }\n        return this.nextoutput;\n    }\n}\nconst coerceInputStream = function (input) {\n    if ('readByte' in input) {\n        return input;\n    }\n    const inputStream = new Stream();\n    inputStream.pos = 0;\n    inputStream.readByte = function () {\n        return input[this.pos++];\n    };\n    inputStream.seek = function (pos) {\n        this.pos = pos;\n    };\n    inputStream.eof = function () {\n        return this.pos >= input.length;\n    };\n    return inputStream;\n};\nconst coerceOutputStream = function (output) {\n    const outputStream = new Stream();\n    let resizeOk = true;\n    if (output) {\n        if (typeof output === 'number') {\n            outputStream.buffer = new Uint8Array(output);\n            resizeOk = false;\n        }\n        else if ('writeByte' in output) {\n            return output;\n        }\n        else {\n            outputStream.buffer = output;\n            resizeOk = false;\n        }\n    }\n    else {\n        outputStream.buffer = new Uint8Array(16384);\n    }\n    outputStream.pos = 0;\n    outputStream.writeByte = function (_byte) {\n        if (resizeOk && this.pos >= this.buffer.length) {\n            const newBuffer = new Uint8Array(this.buffer.length * 2);\n            newBuffer.set(this.buffer);\n            this.buffer = newBuffer;\n        }\n        this.buffer[this.pos++] = _byte;\n    };\n    outputStream.getBuffer = function () {\n        // trim buffer\n        if (this.pos !== this.buffer.length) {\n            if (!resizeOk) {\n                throw new TypeError('outputsize does not match decoded input');\n            }\n            const newBuffer = new Uint8Array(this.pos);\n            newBuffer.set(this.buffer.slice(0, this.pos));\n            this.buffer = newBuffer;\n        }\n        return this.buffer;\n    };\n    outputStream._coerced = true;\n    return outputStream;\n};\n/* Static helper functions */\n// 'input' can be a stream or a buffer\n// 'output' can be a stream or a buffer or a number (buffer size)\nexport function decode(input, output, multistream) {\n    // make a stream from a buffer, if necessary\n    const inputStream = coerceInputStream(input);\n    const outputStream = coerceOutputStream(output);\n    const bz = new Bunzip(inputStream, outputStream);\n    while (true) {\n        if ('eof' in inputStream && inputStream.eof()) {\n            break;\n        }\n        if (bz._init_block()) {\n            bz._read_bunzip();\n        }\n        else {\n            const targetStreamCRC = bz.reader.read(32) >>> 0; // (convert to unsigned)\n            if (targetStreamCRC !== bz.streamCRC) {\n                _throw(Err.DATA_ERROR, 'Bad stream CRC ' +\n                    '(got ' +\n                    bz.streamCRC.toString(16) +\n                    ' expected ' +\n                    targetStreamCRC.toString(16) +\n                    ')');\n            }\n            if (multistream && 'eof' in inputStream && !inputStream.eof()) {\n                // note that start_bunzip will also resync the bit reader to next byte\n                bz._start_bunzip(inputStream, outputStream);\n            }\n            else {\n                break;\n            }\n        }\n    }\n    if ('getBuffer' in outputStream) {\n        return outputStream.getBuffer();\n    }\n}\nexport default Bunzip;\n//# sourceMappingURL=index.js.map","// @ts-nocheck\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// An arithmetic coder, based on Eugene Shelwien's reimplementation of\n// Michael Schindler range coder.\n//\n// Order-0 byte stream of ~/scratch/data/q40b\n// C:              3.1s decode  (approx same vs 32-bit and 64-bit)\n// Arith_sh.js     6.7s decode  (32-bit with carries)\n// Arith.js      317.0s decode  (64-bit no carries); int64 crippling it.\n// ----------------------------------------------------------------------\n// Arithmetic (range) coder\nexport default class RangeCoder {\n    constructor(src) {\n        this.low = 0;\n        this.range = 0xffffffff;\n        this.code = 0;\n        this.FFnum = 0;\n        this.carry = 0;\n        this.cache = 0;\n    }\n    RangeStartDecode(src) {\n        for (let i = 0; i < 5; i++) {\n            this.code = (this.code << 8) + src.ReadByte();\n        }\n        this.code &= 0xffffffff;\n        this.code >>>= 0; // force to be +ve int\n    }\n    RangeGetFrequency(tot_freq) {\n        this.range = Math.floor(this.range / tot_freq);\n        // return this.code / this.range;\n        return Math.floor(this.code / this.range);\n        // Conceptual scenario; return freq only and don't modify range yet\n        // return Math.floor(this.code / (Math.floor(this.range / tot_freq)));\n    }\n    RangeDecode(src, sym_low, sym_freq, tot_freq) {\n        // Conceptually we divide range here, but in practice we cached it earlier\n        // this.range = Math.floor(this.range / tot_freq);\n        this.code -= sym_low * this.range;\n        this.range *= sym_freq;\n        while (this.range < 1 << 24) {\n            this.range *= 256;\n            this.code = this.code * 256 + src.ReadByte();\n        }\n    }\n    RangeShiftLow(dst) {\n        // We know range is < (1<<24) as we got here.  We already have a\n        // cached copy of 8 bits from low.  Is this correct, or does it need\n        // fixing?  Possible scenarios.\n        // 1. Low < 0xff000000 thus low+range < 0xffffffff and cache\n        //    cannot possibly change.  Output cache and as many ffs as needed.\n        // 2. We already detected an overflow in RangeEncode, setting carry.\n        //    In this case output cached byte + 1 and any 00s needed.\n        // 3. Neither case - range is low but we haven't yet detected if we're\n        //    XXffffff or XY000000 scenario.  Increase counter for ff/00s.\n        if ((this.low < 0xff000000) | this.carry) {\n            // cached byte if no overflow, byte+1 otherwise\n            dst.WriteByte(this.cache + this.carry);\n            // Flush any tracked FFs (no carry) or 00s (carry).\n            while (this.FFnum) {\n                dst.WriteByte(this.carry - 1);\n                this.FFnum--;\n            }\n            // Take a copy of top byte ready for next flush\n            this.cache = this.low >>> 24;\n            this.carry = 0;\n        }\n        else {\n            this.FFnum++; // keep track of number of trailing ff/00 bytes to write\n        }\n        this.low <<= 8;\n        this.low >>>= 0; // force to be +ve int\n    }\n    RangeEncode(dst, sym_low, sym_freq, tot_freq) {\n        const old_low = this.low;\n        this.range = Math.floor(this.range / tot_freq);\n        this.low += sym_low * this.range;\n        this.low >>>= 0; // Truncate to +ve int so we can spot overflow\n        this.range *= sym_freq;\n        // \"low + sym*range < old_low\" means we overflow; set carry.\n        // NB: can this.low < old_low occur twice before range < (1<<24)?\n        // We claim not, but prove it!\n        if (this.low < old_low) {\n            if (this.carry != 0) {\n                console.log('ERROR: Multiple carry');\n            }\n            this.carry = 1;\n        }\n        // Renormalise if range gets too small\n        while (this.range < 1 << 24) {\n            this.range *= 256;\n            this.RangeShiftLow(dst);\n        }\n    }\n    RangeFinishEncode(dst) {\n        for (let i = 0; i < 5; i++) {\n            this.RangeShiftLow(dst);\n        }\n    }\n}\n//# sourceMappingURL=arith_sh.js.map","/* eslint-disable no-var */\n// @ts-nocheck\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// An adaptive probability model for encoding and decoding of symbols\n// within a given alphabet, using the range coder to get/put the\n// compressed data.\nconst MAX_FREQ = (1 << 16) - 17;\nconst STEP = 16;\nexport default class ByteModel {\n    constructor(max_sym = 256) {\n        this.total_freq = max_sym;\n        this.max_sym = max_sym - 1;\n        this.S = [];\n        this.F = [];\n        for (let i = 0; i <= this.max_sym; i++) {\n            this.S[i] = i;\n            this.F[i] = 1;\n        }\n    }\n    ModelDecode(src, rc) {\n        // Find symbol\n        const freq = rc.RangeGetFrequency(this.total_freq);\n        // Linear scan to find cumulative frequency 'freq'\n        let acc = 0;\n        let x = 0;\n        while (acc + this.F[x] <= freq) {\n            acc += this.F[x++];\n        }\n        //\tfor (var acc = 0; (acc += this.F[x]) <= freq; x++)\n        //\t    ;\n        //\tacc -= this.F[x];\n        // Update range coder\n        rc.RangeDecode(src, acc, this.F[x], this.total_freq);\n        // Update model\n        this.F[x] += STEP;\n        this.total_freq += STEP;\n        if (this.total_freq > MAX_FREQ) {\n            this.ModelRenormalise();\n        }\n        // Keep symbols approximately frequency sorted\n        const sym = this.S[x];\n        if (x > 0 && this.F[x] > this.F[x - 1]) {\n            let tmp = this.F[x];\n            this.F[x] = this.F[x - 1];\n            this.F[x - 1] = tmp;\n            tmp = this.S[x];\n            this.S[x] = this.S[x - 1];\n            this.S[x - 1] = tmp;\n        }\n        return sym;\n    }\n    ModelRenormalise() {\n        // Halve all the frequencies, being careful not to hit zero\n        this.total_freq = 0;\n        for (let i = 0; i <= this.max_sym; i++) {\n            this.F[i] -= Math.floor(this.F[i] / 2);\n            this.total_freq += this.F[i];\n        }\n    }\n    ModelEncode(dst, rc, sym) {\n        // Find cumulative frequency\n        let acc = 0;\n        for (var x = 0; this.S[x] != sym; x++) {\n            acc += this.F[x];\n        }\n        // Encode\n        rc.RangeEncode(dst, acc, this.F[x], this.total_freq);\n        // Update model\n        this.F[x] += STEP;\n        this.total_freq += STEP;\n        if (this.total_freq > MAX_FREQ) {\n            // FIXME x2\n            this.ModelRenormalise();\n        }\n        // Keep symbols approximately frequency sorted\n        var sym = this.S[x];\n        if (x > 0 && this.F[x] > this.F[x - 1]) {\n            let tmp = this.F[x];\n            this.F[x] = this.F[x - 1];\n            this.F[x - 1] = tmp;\n            tmp = this.S[x];\n            this.S[x] = this.S[x - 1];\n            this.S[x - 1] = tmp;\n        }\n    }\n}\n//# sourceMappingURL=byte_model.js.map","// @ts-nocheck\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// Turn a buffer into a fake stream with get / put commands.\n// This enables up to closely match the published pseudocode.\nexport default class IOStream {\n    constructor(buf, start_pos = 0, size = 0) {\n        if (size !== 0) {\n            this.buf = new Uint8Array(size);\n            this.length = size;\n        }\n        else {\n            this.buf = buf;\n            this.length = buf.length;\n        }\n        this.dataView = new DataView(this.buf.buffer);\n        this.pos = start_pos;\n    }\n    // ----------\n    // Reading\n    EOF() {\n        return this.pos >= this.length;\n    }\n    ReadData(len) {\n        const A = this.buf.slice(this.pos, this.pos + len);\n        this.pos += len;\n        return A;\n    }\n    ReadByte() {\n        const b = this.buf[this.pos];\n        this.pos++;\n        return b;\n    }\n    ReadChar() {\n        const b = this.buf[this.pos];\n        this.pos++;\n        return String.fromCharCode(b);\n    }\n    ReadUint16() {\n        let i = this.ReadByte();\n        i |= this.ReadByte() << 8;\n        return i;\n    }\n    ReadUint32() {\n        const i = this.dataView.getInt32(this.pos, true);\n        this.pos += 4;\n        return i;\n    }\n    // nul terminated string\n    ReadString() {\n        let s = '';\n        let b;\n        do {\n            b = this.buf[this.pos++];\n            if (b) {\n                s += String.fromCharCode(b);\n            }\n        } while (b);\n        return s;\n    }\n    ReadUint7() {\n        // Variable sized unsigned integers\n        let i = 0;\n        let c;\n        do {\n            c = this.ReadByte();\n            i = (i << 7) | (c & 0x7f);\n        } while (c & 0x80);\n        return i;\n    }\n    ReadITF8() {\n        let i = this.buf[this.pos];\n        this.pos++;\n        // process.stderr.write(\"i=\"+i+\"\\n\");\n        if (i >= 0xf0) {\n            // 1111xxxx => +4 bytes\n            i = (i & 0x0f) << 28;\n            i +=\n                (this.buf[this.pos + 0] << 20) +\n                    (this.buf[this.pos + 1] << 12) +\n                    (this.buf[this.pos + 2] << 4) +\n                    (this.buf[this.pos + 3] >> 4);\n            this.pos += 4;\n            // process.stderr.write(\"  4i=\"+i+\"\\n\");\n        }\n        else if (i >= 0xe0) {\n            // 1110xxxx => +3 bytes\n            i = (i & 0x0f) << 24;\n            i +=\n                (this.buf[this.pos + 0] << 16) +\n                    (this.buf[this.pos + 1] << 8) +\n                    (this.buf[this.pos + 2] << 0);\n            this.pos += 3;\n            // process.stderr.write(\"  3i=\"+i+\"\\n\");\n        }\n        else if (i >= 0xc0) {\n            // 110xxxxx => +2 bytes\n            i = (i & 0x1f) << 16;\n            i += (this.buf[this.pos + 0] << 8) + (this.buf[this.pos + 1] << 0);\n            this.pos += 2;\n            // process.stderr.write(\"  2i=\"+i+\"\\n\");\n        }\n        else if (i >= 0x80) {\n            // 10xxxxxx => +1 bytes\n            i = (i & 0x3f) << 8;\n            i += this.buf[this.pos];\n            this.pos++;\n        }\n        else {\n            // 0xxxxxxx => +0 bytes\n        }\n        return i;\n    }\n}\n//# sourceMappingURL=iostream.js.map","/* eslint-disable no-var */\n// @ts-nocheck\n/*\n * Copyright (c) 2019,2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nimport { decode } from '../seek-bzip';\nimport RangeCoder from './arith_sh';\nimport ByteModel from './byte_model';\nimport IOStream from './iostream';\nconst ARITH_ORDER = 1;\nconst ARITH_EXT = 4;\nconst ARITH_STRIPE = 8;\nconst ARITH_NOSIZE = 16;\nconst ARITH_CAT = 32;\nconst ARITH_RLE = 64;\nconst ARITH_PACK = 128;\nexport default class RangeCoderGen {\n    decode(src) {\n        this.stream = new IOStream(src);\n        return this.decodeStream(this.stream);\n    }\n    decodeStream(stream, n_out = 0) {\n        const flags = this.stream.ReadByte();\n        if (!(flags & ARITH_NOSIZE)) {\n            n_out = this.stream.ReadUint7();\n        }\n        let e_len = n_out;\n        const order = flags & ARITH_ORDER;\n        // 4-way recursion\n        if (flags & ARITH_STRIPE) {\n            return this.decodeStripe(this.stream, n_out);\n        }\n        // Meta data\n        if (flags & ARITH_PACK) {\n            var P;\n            [P, e_len] = this.decodePackMeta(this.stream);\n        }\n        // NOP, useful for tiny blocks\n        if (flags & ARITH_CAT) {\n            var data = this.decodeCat(this.stream, e_len);\n        }\n        // Entropy decode\n        else if (flags & ARITH_EXT) {\n            var data = this.decodeExt(this.stream, e_len);\n        }\n        else if (flags & ARITH_RLE) {\n            var data = order\n                ? this.decodeRLE1(this.stream, e_len)\n                : this.decodeRLE0(this.stream, e_len);\n        }\n        else {\n            var data = order\n                ? this.decode1(this.stream, e_len)\n                : this.decode0(this.stream, e_len);\n        }\n        // Transforms\n        if (flags & ARITH_PACK) {\n            data = this.decodePack(data, P, n_out);\n        }\n        return data;\n    }\n    // ----------------------------------------------------------------------\n    // Order-0 codec\n    decode0(stream, n_out) {\n        const output = new Uint8Array(n_out);\n        let max_sym = stream.ReadByte();\n        if (max_sym == 0) {\n            max_sym = 256;\n        }\n        const byte_model = new ByteModel(max_sym);\n        const rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        for (let i = 0; i < n_out; i++) {\n            output[i] = byte_model.ModelDecode(stream, rc);\n        }\n        return output;\n    }\n    // ----------------------------------------------------------------------\n    // Order-1 codec\n    decode1(stream, n_out) {\n        const output = new Uint8Array(n_out);\n        let max_sym = stream.ReadByte();\n        if (max_sym == 0) {\n            max_sym = 256;\n        }\n        const byte_model = new Array(max_sym);\n        for (var i = 0; i < max_sym; i++) {\n            byte_model[i] = new ByteModel(max_sym);\n        }\n        const rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        let last = 0;\n        for (var i = 0; i < n_out; i++) {\n            output[i] = byte_model[last].ModelDecode(stream, rc);\n            last = output[i];\n        }\n        return output;\n    }\n    // ----------------------------------------------------------------------\n    // External codec\n    decodeExt(stream, n_out) {\n        return decode(stream.buf.slice(stream.pos));\n    }\n    // ----------------------------------------------------------------------\n    // Order-0 RLE codec\n    decodeRLE0(stream, n_out) {\n        const output = new Uint8Array(n_out);\n        let max_sym = stream.ReadByte();\n        if (max_sym == 0) {\n            max_sym = 256;\n        }\n        const model_lit = new ByteModel(max_sym);\n        const model_run = new Array(258);\n        for (var i = 0; i <= 257; i++) {\n            model_run[i] = new ByteModel(4);\n        }\n        const rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        var i = 0;\n        while (i < n_out) {\n            output[i] = model_lit.ModelDecode(stream, rc);\n            let part = model_run[output[i]].ModelDecode(stream, rc);\n            let run = part;\n            let rctx = 256;\n            while (part == 3) {\n                part = model_run[rctx].ModelDecode(stream, rc);\n                rctx = 257;\n                run += part;\n            }\n            for (let j = 1; j <= run; j++) {\n                output[i + j] = output[i];\n            }\n            i += run + 1;\n        }\n        return output;\n    }\n    // ----------------------------------------------------------------------\n    // Order-1 RLE codec\n    decodeRLE1(stream, n_out) {\n        const output = new Uint8Array(n_out);\n        let max_sym = stream.ReadByte();\n        if (max_sym == 0) {\n            max_sym = 256;\n        }\n        const model_lit = new Array(max_sym);\n        for (var i = 0; i < max_sym; i++) {\n            model_lit[i] = new ByteModel(max_sym);\n        }\n        const model_run = new Array(258);\n        for (var i = 0; i <= 257; i++) {\n            model_run[i] = new ByteModel(4);\n        }\n        const rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        let last = 0;\n        var i = 0;\n        while (i < n_out) {\n            output[i] = model_lit[last].ModelDecode(stream, rc);\n            last = output[i];\n            let part = model_run[output[i]].ModelDecode(stream, rc);\n            let run = part;\n            let rctx = 256;\n            while (part == 3) {\n                part = model_run[rctx].ModelDecode(stream, rc);\n                rctx = 257;\n                run += part;\n            }\n            for (let j = 1; j <= run; j++) {\n                output[i + j] = output[i];\n            }\n            i += run + 1;\n        }\n        return output;\n    }\n    // ----------------------------------------------------------------------\n    // Pack method\n    decodePackMeta(stream) {\n        this.nsym = stream.ReadByte();\n        const M = new Array(this.nsym);\n        for (let i = 0; i < this.nsym; i++) {\n            M[i] = stream.ReadByte();\n        }\n        const e_len = stream.ReadUint7(); // Could be derived data from nsym and n_out\n        return [M, e_len];\n    }\n    decodePack(data, M, len) {\n        const out = new Uint8Array(len);\n        if (this.nsym <= 1) {\n            // Constant value\n            for (var i = 0; i < len; i++) {\n                out[i] = M[0];\n            }\n        }\n        else if (this.nsym <= 2) {\n            // 1 bit per value\n            for (var i = 0, j = 0; i < len; i++) {\n                if (i % 8 == 0) {\n                    var v = data[j++];\n                }\n                out[i] = M[v & 1];\n                v >>= 1;\n            }\n        }\n        else if (this.nsym <= 4) {\n            // 2 bits per value\n            for (var i = 0, j = 0; i < len; i++) {\n                if (i % 4 == 0) {\n                    var v = data[j++];\n                }\n                out[i] = M[v & 3];\n                v >>= 2;\n            }\n        }\n        else if (this.nsym <= 16) {\n            // 4 bits per value\n            for (var i = 0, j = 0; i < len; i++) {\n                if (i % 2 == 0) {\n                    var v = data[j++];\n                }\n                out[i] = M[v & 15];\n                v >>= 4;\n            }\n        }\n        else {\n            // 8 bits per value: NOP\n            return data;\n        }\n        return out;\n    }\n    // Compute M array and return meta-data stream\n    packMeta(src) {\n        const stream = new IOStream('', 0, 1024);\n        // Count symbols\n        const M = new Array(256);\n        for (var i = 0; i < src.length; i++) {\n            M[src[i]] = 1;\n        }\n        // Write Map\n        for (var nsym = 0, i = 0; i < 256; i++) {\n            if (M[i]) {\n                M[i] = ++nsym;\n            }\n        } // map to 1..N\n        stream.WriteByte(nsym);\n        // FIXME: add check for nsym > 16?\n        // Or just accept it as an inefficient waste of time.\n        for (var i = 0; i < 256; i++) {\n            if (M[i]) {\n                stream.WriteByte(i); // adjust to 0..N-1\n                M[i]--;\n            }\n        }\n        return [stream, M, nsym];\n    }\n    decodeStripe(stream, len) {\n        const N = stream.ReadByte();\n        // Retrieve lengths\n        const clen = new Array(N);\n        const ulen = new Array(N);\n        for (var j = 0; j < N; j++) {\n            clen[j] = stream.ReadUint7();\n        }\n        // Decode streams\n        const T = new Array(N);\n        for (var j = 0; j < N; j++) {\n            ulen[j] = Math.floor(len / N) + (len % N > j);\n            T[j] = this.decodeStream(stream, ulen[j]);\n        }\n        // Transpose\n        const out = new Uint8Array(len);\n        for (var j = 0; j < N; j++) {\n            for (let i = 0; i < ulen[j]; i++) {\n                out[i * N + j] = T[j][i];\n            }\n        }\n        return out;\n    }\n    // ----------------------------------------------------------------------\n    // Cat method\n    decodeCat(stream, len) {\n        const out = new Uint8Array(len);\n        for (let i = 0; i < len; i++) {\n            out[i] = stream.ReadByte();\n        }\n        return out;\n    }\n}\n//# sourceMappingURL=arith_gen.js.map","/* eslint-disable no-var */\n// @ts-nocheck\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nimport RangeCoder from './arith_sh';\nimport ByteModel from './byte_model';\nimport IOStream from './iostream';\n// ----------------------------------------------------------------------\n// Main arithmetic entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nfunction read_array(src, tab, size) {\n    let j = 0; // array value\n    let z = 0; // array index: tab[j]\n    let last = -1;\n    // Remove first level of run-length encoding\n    const R = new Array(1024); // runs\n    while (z < size) {\n        const run = src.ReadByte();\n        R[j++] = run;\n        z += run;\n        if (run == last) {\n            let copy = src.ReadByte();\n            z += run * copy;\n            while (copy--) {\n                R[j++] = run;\n            }\n        }\n        last = run;\n    }\n    // Now expand runs in R to tab, noting 255 is max run\n    let i = 0;\n    j = 0;\n    z = 0;\n    while (z < size) {\n        let run_len = 0;\n        do {\n            var part = R[j++];\n            run_len += part;\n        } while (part == 255);\n        while (run_len--) {\n            tab[z++] = i;\n        }\n        i++;\n    }\n}\nconst QMAX = 256;\nconst FLAG_DEDUP = 2;\nconst FLAG_FLEN = 4;\nconst FLAG_SEL = 8; // whether selector is used in context\nconst FLAG_QMAP = 16;\nconst FLAG_PTAB = 32;\nconst FLAG_DTAB = 64;\nconst FLAG_QTAB = 128;\nconst GFLAG_MULTI_PARAM = 1;\nconst GFLAG_HAVE_STAB = 2;\nconst GFLAG_DO_REV = 4;\n// Compute a new context from our current state and qual q\nfunction fqz_update_ctx(params, state, q) {\n    let last = params.context;\n    state.qctx = (state.qctx << params.qshift) + params.qtab[q]; // >>> 0\n    last += (state.qctx & ((1 << params.qbits) - 1)) << params.qloc; // >>> 0\n    if (params.do_pos) {\n        last += params.ptab[Math.min(state.p, 1023)] << params.ploc;\n    }\n    if (params.do_delta) {\n        last += params.dtab[Math.min(state.delta, 255)] << params.dloc;\n        // Is it better to use q here or qtab[q]?\n        // If qtab[q] we can map eg [a-z0-9A-Z]->0 ,->1 and have\n        // delta being a token number count into comma separated lists?\n        state.delta += state.prevq != q ? 1 : 0;\n        state.prevq = q;\n    }\n    if (params.do_sel) {\n        last += state.s << params.sloc;\n    }\n    state.p--;\n    return last & 0xffff;\n}\nfunction decode_fqz_single_param(src) {\n    const p = {}; // params\n    // Load FQZ parameters\n    p.context = src.ReadUint16();\n    p.pflags = src.ReadByte();\n    p.do_dedup = p.pflags & FLAG_DEDUP;\n    p.fixed_len = p.pflags & FLAG_FLEN;\n    p.do_sel = p.pflags & FLAG_SEL;\n    p.do_qmap = p.pflags & FLAG_QMAP;\n    p.do_pos = p.pflags & FLAG_PTAB;\n    p.do_delta = p.pflags & FLAG_DTAB;\n    p.do_qtab = p.pflags & FLAG_QTAB;\n    p.max_sym = src.ReadByte();\n    let x = src.ReadByte();\n    p.qbits = x >> 4;\n    p.qshift = x & 15;\n    x = src.ReadByte();\n    p.qloc = x >> 4;\n    p.sloc = x & 15;\n    x = src.ReadByte();\n    p.ploc = x >> 4;\n    p.dloc = x & 15;\n    // Qual map, eg to \"unbin\" Illumina qualities\n    p.qmap = new Array(256);\n    if (p.pflags & FLAG_QMAP) {\n        for (var i = 0; i < p.max_sym; i++) {\n            p.qmap[i] = src.ReadByte();\n        }\n    }\n    else {\n        // Useful optimisation to speed up main loop\n        for (var i = 0; i < 256; i++) {\n            p.qmap[i] = i;\n        } // NOP\n    }\n    // Read tables\n    p.qtab = new Array(1024);\n    if (p.qbits > 0 && p.pflags & FLAG_QTAB) {\n        read_array(src, p.qtab, 256);\n    }\n    else {\n        // Useful optimisation to speed up main loop\n        for (var i = 0; i < 256; i++) {\n            p.qtab[i] = i;\n        } // NOP\n    }\n    p.ptab = new Array(1024);\n    if (p.pflags & FLAG_PTAB) {\n        read_array(src, p.ptab, 1024);\n    }\n    p.dtab = new Array(256);\n    if (p.pflags & FLAG_DTAB) {\n        read_array(src, p.dtab, 256);\n    }\n    return p;\n}\nfunction decode_fqz_params(src) {\n    const gparams = {\n        max_sym: 0,\n    };\n    // Check fqz format version\n    const vers = src.ReadByte();\n    if (vers != 5) {\n        console.error('Invalid FQZComp version number');\n        return;\n    }\n    const gflags = src.ReadByte();\n    const nparam = gflags & GFLAG_MULTI_PARAM ? src.ReadByte() : 1;\n    let max_sel = gflags.nparam > 1 ? gflags.nparam - 1 : 0; // Note max_sel, not num_sel\n    const stab = new Array(256);\n    if (gflags & GFLAG_HAVE_STAB) {\n        max_sel = src.ReadByte();\n        read_array(src, stab, 256);\n    }\n    else {\n        for (var i = 0; i < nparam; i++) {\n            stab[i] = i;\n        }\n        for (; i < 256; i++) {\n            stab[i] = nparam - 1;\n        }\n    }\n    gparams.do_rev = gflags & GFLAG_DO_REV;\n    gparams.stab = stab;\n    gparams.max_sel = max_sel;\n    gparams.params = new Array(gparams.nparam);\n    for (let p = 0; p < nparam; p++) {\n        gparams.params[p] = decode_fqz_single_param(src);\n        if (gparams.max_sym < gparams.params[p].max_sym) {\n            gparams.max_sym = gparams.params[p].max_sym;\n        }\n    }\n    return gparams;\n}\nfunction fqz_create_models(gparams) {\n    const model = {};\n    model.qual = new Array(1 << 16);\n    for (var i = 0; i < 1 << 16; i++) {\n        model.qual[i] = new ByteModel(gparams.max_sym + 1);\n    } // +1 as max value not num. values\n    model.len = new Array(4);\n    for (var i = 0; i < 4; i++) {\n        model.len[i] = new ByteModel(256);\n    }\n    model.rev = new ByteModel(2);\n    model.dup = new ByteModel(2);\n    if (gparams.max_sel > 0) {\n        model.sel = new ByteModel(gparams.max_sel + 1);\n    } // +1 as max value not num. values\n    return model;\n}\n// Initialise a new record, updating state.\n// Returns 1 if dup, otherwise 0\nfunction decode_fqz_new_record(src, rc, gparams, model, state, rev) {\n    // Parameter selector\n    state.s = gparams.max_sel > 0 ? model.sel.ModelDecode(src, rc) : 0;\n    state.x = gparams.stab[state.s];\n    const params = gparams.params[state.x];\n    // Reset contexts at the start of each new record\n    if (params.fixed_len >= 0) {\n        // Not fixed or fixed but first record\n        var len = model.len[0].ModelDecode(src, rc);\n        len |= model.len[1].ModelDecode(src, rc) << 8;\n        len |= model.len[2].ModelDecode(src, rc) << 16;\n        len |= model.len[3].ModelDecode(src, rc) << 24;\n        if (params.fixed_len > 0) {\n            params.fixed_len = -len;\n        }\n    }\n    else {\n        len = -params.fixed_len;\n    }\n    state.len = len;\n    if (gparams.do_rev) {\n        rev[state.rec] = model.rev.ModelDecode(src, rc);\n    }\n    state.is_dup = 0;\n    if (params.pflags & FLAG_DEDUP) {\n        if (model.dup.ModelDecode(src, rc)) {\n            state.is_dup = 1;\n        }\n    }\n    state.p = len; // number of remaining bytes in this record\n    state.delta = 0;\n    state.qctx = 0;\n    state.prevq = 0;\n    state.rec++;\n}\nfunction decode_fqz(src, q_lens) {\n    // Decode parameter block\n    const n_out = src.ReadUint7();\n    const gparams = decode_fqz_params(src);\n    if (!gparams) {\n        return;\n    }\n    var params = gparams.params;\n    const rev = new Array(q_lens.length);\n    // Create initial models\n    const model = fqz_create_models(gparams);\n    // Create our entropy encoder and output buffers\n    const rc = new RangeCoder(src);\n    rc.RangeStartDecode(src);\n    const output = new Uint8Array(n_out);\n    // Internal FQZ state\n    const state = {\n        qctx: 0, // Qual-only sub-context\n        prevq: 0, // Previous quality value\n        delta: 0, // Running delta (q vs prevq)\n        p: 0, // Number of bases left in current record\n        s: 0, // Current parameter selector value (0 if unused)\n        x: 0, // \"stab\" tabulated copy of s\n        len: 0, // Length of current string\n        is_dup: 0, // This string is a duplicate of last\n        rec: 0, // Record number\n    };\n    // The main decode loop itself\n    let i = 0; // position in output buffer\n    while (i < n_out) {\n        if (state.p == 0) {\n            decode_fqz_new_record(src, rc, gparams, model, state, rev);\n            if (state.is_dup > 0) {\n                if (model.dup.ModelDecode(src, rc)) {\n                    // Duplicate of last line\n                    for (let x = 0; x < len; x++) {\n                        output[i + x] = output[i + x - state.len];\n                    }\n                    i += state.len;\n                    state.p = 0;\n                    continue;\n                }\n            }\n            q_lens.push(state.len);\n            var params = gparams.params[state.x];\n            var last = params.context;\n        }\n        // Decode the current quality (possibly mapped via qmap)\n        const Q = model.qual[last].ModelDecode(src, rc);\n        // if (params.do_qmap)\n        //    output[i++] = params.qmap[Q];\n        // else\n        //    output[i++] = Q\n        output[i++] = params.qmap[Q]; // optimised version of above\n        last = fqz_update_ctx(params, state, Q);\n    }\n    if (gparams.do_rev) {\n        reverse_qualities(output, n_out, rev, q_lens);\n    }\n    return output;\n}\nfunction reverse_qualities(qual, qual_len, rev, len) {\n    let rec = 0;\n    let i = 0;\n    while (i < qual_len) {\n        if (rev[rec]) {\n            let j = 0;\n            let k = len[rec] - 1;\n            while (j < k) {\n                const tmp = qual[i + j];\n                qual[i + j] = qual[i + k];\n                qual[i + k] = tmp;\n                j++;\n                k--;\n            }\n        }\n        i += len[rec++];\n    }\n}\nexport function decode(src, q_lens) {\n    const stream = new IOStream(src);\n    return decode_fqz(stream, q_lens);\n}\n//# sourceMappingURL=fqzcomp.js.map","/* eslint-disable no-var */\n// @ts-nocheck\n/*\n * Copyright (c) 2019,2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nimport IOStream from './iostream';\n// ----------------------------------------------------------------------\n// rANS primitives itself\n//\n// RansGet* is decoder side\nfunction RansGetCumulativeFreq(R, bits) {\n    return R & ((1 << bits) - 1);\n}\nfunction RansGetSymbolFromFreq(C, f) {\n    // NOTE: Inefficient.\n    // In practice we would implement this via a precomputed\n    // lookup table C2S[f]; see RansBuildC2S below.\n    let s = 0;\n    while (f >= C[s + 1]) {\n        s++;\n    }\n    // console.error(f, C, s)\n    return s;\n}\nfunction RansBuildC2S(C, bits) {\n    const max = 1 << bits;\n    const C2S = new Array(max);\n    let s = 0;\n    for (let f = 0; f < max; f++) {\n        while (f >= C[s + 1]) {\n            s++;\n        }\n        C2S[f] = s;\n    }\n    return C2S;\n}\nfunction RansAdvanceStep(R, c, f, bits) {\n    return f * (R >> bits) + (R & ((1 << bits) - 1)) - c;\n}\nfunction RansRenorm(src, R) {\n    if (R < 1 << 15) {\n        R = (R << 16) + src.ReadUint16();\n    }\n    return R;\n}\nfunction DecodeRLEMeta(src, N) {\n    const u_meta_len = src.ReadUint7();\n    const rle_len = src.ReadUint7();\n    // Decode RLE lengths\n    if (u_meta_len & 1) {\n        var rle_meta = src.ReadData((u_meta_len - 1) / 2);\n    }\n    else {\n        const comp_meta_len = src.ReadUint7();\n        var rle_meta = src.ReadData(comp_meta_len);\n        rle_meta = RansDecode0(new IOStream(rle_meta), u_meta_len / 2, N);\n    }\n    // Decode list of symbols for which RLE lengths are applied\n    var rle_meta = new IOStream(rle_meta);\n    const L = new Array(256);\n    let n = rle_meta.ReadByte();\n    if (n == 0) {\n        n = 256;\n    }\n    for (let i = 0; i < n; i++) {\n        L[rle_meta.ReadByte()] = 1;\n    }\n    return [L, rle_meta, rle_len];\n}\nfunction DecodeRLE(buf, L, rle_meta, len) {\n    const src = new IOStream(buf);\n    const out = new Uint8Array(len);\n    // Expand up buf+meta to out; i = buf index, j = out index\n    let j = 0;\n    for (let i = 0; j < len; i++) {\n        const sym = buf[i];\n        if (L[sym]) {\n            const run = rle_meta.ReadUint7();\n            for (let r = 0; r <= run; r++) {\n                out[j++] = sym;\n            }\n        }\n        else {\n            out[j++] = sym;\n        }\n    }\n    return out;\n}\n// Pack meta data is the number and value of distinct symbols plus\n// the length of the packed byte stream.\nfunction DecodePackMeta(src) {\n    const nsym = src.ReadByte();\n    const P = new Array(nsym);\n    for (let i = 0; i < nsym; i++) {\n        P[i] = src.ReadByte();\n    }\n    const len = src.ReadUint7();\n    return [P, nsym, len];\n}\n// Extract bits from src producing output of length len.\n// Nsym is number of distinct symbols used.\nfunction DecodePack(data, P, nsym, len) {\n    const out = new Uint8Array(len);\n    let j = 0;\n    // Constant value\n    if (nsym <= 1) {\n        for (var i = 0; i < len; i++) {\n            out[i] = P[0];\n        }\n    }\n    // 1 bit per value\n    else if (nsym <= 2) {\n        for (i = 0; i < len; i++) {\n            if (i % 8 == 0) {\n                var v = data[j++];\n            }\n            out[i] = P[v & 1];\n            v >>= 1;\n        }\n    }\n    // 2 bits per value\n    else if (nsym <= 4) {\n        for (i = 0; i < len; i++) {\n            if (i % 4 == 0) {\n                var v = data[j++];\n            }\n            out[i] = P[v & 3];\n            v >>= 2;\n        }\n    }\n    // 4 bits per value\n    else if (nsym <= 16) {\n        for (i = 0; i < len; i++) {\n            if (i % 2 == 0) {\n                var v = data[j++];\n            }\n            out[i] = P[v & 15];\n            v >>= 4;\n        }\n    }\n    return out;\n}\nfunction RansDecodeStripe(src, len) {\n    const N = src.ReadByte();\n    // Retrieve lengths\n    const clen = new Array(N);\n    const ulen = new Array(N);\n    for (var j = 0; j < N; j++) {\n        clen[j] = src.ReadUint7();\n    }\n    // Decode streams\n    const T = new Array(N);\n    for (var j = 0; j < N; j++) {\n        ulen[j] = Math.floor(len / N) + (len % N > j);\n        T[j] = RansDecodeStream(src, ulen[j]);\n    }\n    // Transpose\n    const out = new Uint8Array(len);\n    for (var j = 0; j < N; j++) {\n        for (let i = 0; i < ulen[j]; i++) {\n            out[i * N + j] = T[j][i];\n        }\n    }\n    return out;\n}\n// ----------------------------------------------------------------------\n// Main rANS entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nexport function decode(src) {\n    const stream = new IOStream(src);\n    return RansDecodeStream(stream, 0);\n}\nfunction RansDecodeStream(stream, n_out) {\n    const format = stream.ReadByte();\n    const order = format & 1;\n    const x32 = format & 4;\n    const stripe = format & 8;\n    const nosz = format & 16;\n    const cat = format & 32;\n    const rle = format & 64;\n    const pack = format & 128;\n    const Nway = x32 ? 32 : 4;\n    if (!nosz) {\n        n_out = stream.ReadUint7();\n    }\n    // N-way interleaving\n    if (stripe) {\n        return RansDecodeStripe(stream, n_out);\n    }\n    // Bit packing\n    if (pack) {\n        var pack_len = n_out;\n        var [P, nsym, n_out] = DecodePackMeta(stream);\n    }\n    // Run length encoding\n    if (rle) {\n        var rle_len = n_out;\n        var [L, rle_meta, n_out] = DecodeRLEMeta(stream, Nway);\n    }\n    // Uncompress data (all, packed or run literals)\n    if (cat) {\n        var buf = stream.ReadData(n_out);\n    }\n    else if (order == 0) {\n        var buf = RansDecode0(stream, n_out, Nway);\n    }\n    else {\n        var buf = RansDecode1(stream, n_out, Nway);\n    }\n    // Apply expansion transforms\n    if (rle) {\n        buf = DecodeRLE(buf, L, rle_meta, rle_len);\n    }\n    if (pack) {\n        buf = DecodePack(buf, P, nsym, pack_len);\n    }\n    return buf;\n}\n// ----------------------------------------------------------------------\n// Order-0 decoder\nfunction ReadAlphabet(src) {\n    const A = new Array(256);\n    for (let i = 0; i < 256; i++) {\n        A[i] = 0;\n    }\n    let rle = 0;\n    let sym = src.ReadByte();\n    let last_sym = sym;\n    do {\n        A[sym] = 1;\n        if (rle > 0) {\n            rle--;\n            sym++;\n        }\n        else {\n            sym = src.ReadByte();\n            if (sym == last_sym + 1) {\n                rle = src.ReadByte();\n            }\n        }\n        last_sym = sym;\n    } while (sym != 0);\n    return A;\n}\n// Decode a single table of order-0 frequences,\n// filling out the F and C arrays.\nfunction ReadFrequencies0(src, F, C) {\n    // Initialise; not in the specification - implicit?\n    for (var i = 0; i < 256; i++) {\n        F[i] = 0;\n    }\n    // Fetch alphabet\n    const A = ReadAlphabet(src);\n    // Fetch frequencies for the symbols listed in our alphabet\n    for (var i = 0; i < 256; i++) {\n        if (A[i] > 0) {\n            F[i] = src.ReadUint7();\n        }\n    }\n    NormaliseFrequencies0_Shift(F, 12);\n    // Compute C[] from F[]\n    C[0] = 0;\n    for (var i = 0; i <= 255; i++) {\n        C[i + 1] = C[i] + F[i];\n    }\n}\nfunction RansDecode0(src, nbytes, N) {\n    // Decode frequencies\n    const F = new Array(256);\n    const C = new Array(256);\n    ReadFrequencies0(src, F, C);\n    // Fast lookup to avoid slow RansGetSymbolFromFreq\n    const C2S = RansBuildC2S(C, 12);\n    // Initialise rANS state\n    const R = new Array(N);\n    for (var i = 0; i < N; i++) {\n        R[i] = src.ReadUint32();\n    }\n    // Main decode loop\n    const output = new Uint8Array(nbytes);\n    for (var i = 0; i < nbytes; i++) {\n        const ix = i & (N - 1); // equiv to i%N as N is power of 2\n        const f = RansGetCumulativeFreq(R[ix], 12);\n        const s = C2S[f]; // Equiv to RansGetSymbolFromFreq(C, f);\n        output[i] = s;\n        R[ix] = RansAdvanceStep(R[ix], C[s], F[s], 12);\n        R[ix] = RansRenorm(src, R[ix]);\n    }\n    // Main decode loop\n    return output;\n}\nfunction NormaliseFrequencies0_Shift(F, bits) {\n    // Compute total and number of bits to shift by\n    let tot = 0;\n    for (var i = 0; i < 256; i++) {\n        tot += F[i];\n    }\n    if (tot == 0 || tot == 1 << bits) {\n        return;\n    }\n    let shift = 0;\n    while (tot < 1 << bits) {\n        tot *= 2;\n        shift++;\n    }\n    // Scale total of frequencies to (1<<bits)\n    for (var i = 0; i < 256; i++) {\n        F[i] <<= shift;\n    }\n}\n// ----------------------------------------------------------------------\n// Order-1 decoder\n// Decode a table of order-1 frequences,\n// filling out the F and C arrays.\nfunction ReadFrequencies1(src, F, C, shift) {\n    // Initialise; not in the specification - implicit?\n    for (var i = 0; i < 256; i++) {\n        F[i] = new Array(256);\n        C[i] = new Array(256);\n        for (var j = 0; j < 256; j++) {\n            F[i][j] = 0;\n        }\n    }\n    // Fetch alphabet\n    const A = ReadAlphabet(src);\n    // Read F[]\n    for (var i = 0; i < 256; i++) {\n        if (!A[i]) {\n            continue;\n        }\n        let run = 0;\n        for (var j = 0; j < 256; j++) {\n            if (!A[j]) {\n                continue;\n            }\n            if (run > 0) {\n                run--;\n            }\n            else {\n                F[i][j] = src.ReadUint7();\n                if (F[i][j] == 0) {\n                    run = src.ReadByte();\n                }\n            }\n        }\n        NormaliseFrequencies0_Shift(F[i], shift);\n        // Compute C[] from F[]\n        C[i][0] = 0;\n        for (var j = 0; j < 256; j++) {\n            C[i][j + 1] = C[i][j] + F[i][j];\n        }\n    }\n}\nfunction RansDecode1(src, nbytes, N) {\n    // FIXME: this bit is missing from the RansDecode0 pseudocode.\n    var comp = src.ReadByte();\n    const shift = comp >> 4;\n    var freq_src = src;\n    if (comp & 1) {\n        const ulen = src.ReadUint7();\n        const clen = src.ReadUint7();\n        var comp = new IOStream(src.ReadData(clen));\n        var freq_src = new IOStream(RansDecode0(comp, ulen, 4));\n    }\n    // Decode frequencies\n    const F = new Array(256);\n    const C = new Array(256);\n    ReadFrequencies1(freq_src, F, C, shift);\n    // Fast lookup to avoid slow RansGetSymbolFromFreq\n    const C2S = new Array(256);\n    for (var i = 0; i < 256; i++ // Could do only for symbols in alphabet?\n    ) {\n        C2S[i] = RansBuildC2S(C[i], shift);\n    }\n    // Initialise rANS state\n    const R = new Array(N);\n    const L = new Array(N);\n    for (var j = 0; j < N; j++) {\n        R[j] = src.ReadUint32();\n        L[j] = 0;\n    }\n    // Main decode loop\n    const output = new Uint8Array(nbytes);\n    const nbytesx = Math.floor(nbytes / N);\n    for (var i = 0; i < nbytesx; i++) {\n        for (var j = 0; j < N; j++) {\n            var f = RansGetCumulativeFreq(R[j], shift);\n            // var s = RansGetSymbolFromFreq(C[L[j]], f);\n            var s = C2S[L[j]][f]; // Precomputed version of above\n            output[i + j * nbytesx] = s;\n            R[j] = RansAdvanceStep(R[j], C[L[j]][s], F[L[j]][s], shift);\n            R[j] = RansRenorm(src, R[j]);\n            L[j] = s;\n        }\n    }\n    // Now deal with the remainder if buffer size is not a multiple of N,\n    // using the last rANS state exclusively.  (It'd have been nice to have\n    // designed this to just act as if we kept going with a bail out.)\n    i = N * i;\n    while (i < nbytes) {\n        var f = RansGetCumulativeFreq(R[N - 1], shift);\n        var s = RansGetSymbolFromFreq(C[L[N - 1]], f);\n        output[i++] = s;\n        R[N - 1] = RansAdvanceStep(R[N - 1], C[L[N - 1]][s], F[L[N - 1]][s], shift);\n        R[N - 1] = RansRenorm(src, R[N - 1]);\n        L[N - 1] = s;\n    }\n    return output;\n}\n//# sourceMappingURL=rans4x16.js.map","function sum(array) {\n    let sum = 0;\n    for (const entry of array) {\n        sum += entry.length;\n    }\n    return sum;\n}\nexport function concatUint8Array(args) {\n    const mergedArray = new Uint8Array(sum(args));\n    let offset = 0;\n    for (const entry of args) {\n        mergedArray.set(entry, offset);\n        offset += entry.length;\n    }\n    return mergedArray;\n}\n//# sourceMappingURL=util.js.map","/* eslint-disable no-var */\n// @ts-nocheck\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// Name tokeniser\n//\n// This is a reference implementation designed to match the\n// written specification as closely as possible.  It is *NOT*\n// an efficient implementation, but see comments below.\nimport { concatUint8Array } from '../util';\nimport arith_gen from './arith_gen';\nimport IOStream from './iostream';\nimport * as rans from './rans4x16';\nconst arith = new arith_gen();\nconst TOK_TYPE = 0;\nconst TOK_STRING = 1;\nconst TOK_CHAR = 2;\nconst TOK_DIGITS0 = 3;\nconst TOK_DZLEN = 4;\nconst TOK_DUP = 5;\nconst TOK_DIFF = 6;\nconst TOK_DIGITS = 7;\nconst TOK_DELTA = 8;\nconst TOK_DELTA0 = 9;\nconst TOK_MATCH = 10;\nconst TOK_NOP = 11;\nconst TOK_END = 12;\n// ----------------------------------------------------------------------\n// Token byte streams\nfunction DecodeTokenByteStreams(src, in_size, use_arith, nnames) {\n    let t = -1;\n    const B = new Array(256);\n    while (!src.EOF()) {\n        const ttype = src.ReadByte();\n        const tok_new = ttype & 128;\n        const tok_dup = ttype & 64;\n        const type = ttype & 63;\n        if (tok_new) {\n            t++;\n            B[t] = new Array(13);\n        }\n        if (type != TOK_TYPE && tok_new) {\n            const M = new Array(nnames - 1).fill(TOK_MATCH);\n            B[t][TOK_TYPE] = new IOStream(concatUint8Array([new Uint8Array(type), M]));\n        }\n        if (tok_dup) {\n            const dup_pos = src.ReadByte();\n            const dup_type = src.ReadByte();\n            B[t][type] = new IOStream(B[dup_pos][dup_type].buf);\n        }\n        else {\n            const clen = src.ReadUint7();\n            const data = src.ReadData(clen);\n            B[t][type] = use_arith ? arith.decode(data) : rans.decode(data);\n            B[t][type] = new IOStream(B[t][type]);\n        }\n    }\n    return B;\n}\n// ----------------------------------------------------------------------\n// Token decode\nfunction LeftPadNumber(val, len) {\n    let str = val + '';\n    while (str.length < len) {\n        str = '0' + str;\n    }\n    return str;\n}\nfunction DecodeSingleName(B, N, T, n) {\n    let type = B[0][TOK_TYPE].ReadByte();\n    const dist = B[0][type].ReadUint32();\n    const m = n - dist;\n    if (type == TOK_DUP) {\n        N[n] = N[m];\n        T[n] = T[m];\n        return N[n];\n    }\n    let t = 1;\n    N[n] = '';\n    T[n] = new Array(256);\n    do {\n        type = B[t][TOK_TYPE].ReadByte();\n        switch (type) {\n            case TOK_CHAR:\n                T[n][t] = B[t][TOK_CHAR].ReadChar();\n                break;\n            case TOK_STRING:\n                T[n][t] = B[t][TOK_STRING].ReadString();\n                break;\n            case TOK_DIGITS:\n                T[n][t] = B[t][TOK_DIGITS].ReadUint32();\n                break;\n            case TOK_DIGITS0:\n                var d = B[t][TOK_DIGITS0].ReadUint32();\n                var l = B[t][TOK_DZLEN].ReadByte();\n                T[n][t] = LeftPadNumber(d, l);\n                break;\n            case TOK_DELTA:\n                T[n][t] = (T[m][t] >> 0) + B[t][TOK_DELTA].ReadByte();\n                break;\n            case TOK_DELTA0:\n                var d = (T[m][t] >> 0) + B[t][TOK_DELTA0].ReadByte();\n                var l = T[m][t].length;\n                T[n][t] = LeftPadNumber(d, l);\n                break;\n            case TOK_MATCH:\n                T[n][t] = T[m][t];\n                break;\n            default:\n                T[n][t] = '';\n                break;\n        }\n        N[n] += T[n][t++];\n    } while (type != TOK_END);\n    return N[n];\n}\n// ----------------------------------------------------------------------\n// Main tokeniser decode entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nexport function decode(src, len, separator) {\n    var src = new IOStream(src);\n    const ulen = src.ReadUint32();\n    const nnames = src.ReadUint32();\n    const use_arith = src.ReadByte();\n    const B = DecodeTokenByteStreams(src, len, use_arith, nnames);\n    const N = new Array(nnames);\n    const T = new Array(nnames);\n    let str = '';\n    if (separator === undefined) {\n        separator = '\\n';\n    }\n    for (let i = 0; i < nnames; i++) {\n        str += DecodeSingleName(B, N, T, i) + separator;\n    }\n    return str;\n}\n//# sourceMappingURL=tok3.js.map","// @ts-nocheck\n//\n/*\n * Copyright (c) 2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// This is an interface to the htscodecs reference implementation of\n// the CRAM 3.1 codecs.\n// This JavaScript file is not part of the reference implementation\n// and is simply and interface to get a consistent interface for cram-js.\nimport arith from './arith_gen';\nimport * as fqzcomp from './fqzcomp';\nimport * as r4x8 from './rans';\nimport * as r4x16 from './rans4x16';\nimport * as tok3 from './tok3';\nexport function r4x8_uncompress(inputBuffer) {\n    return r4x8.decode(inputBuffer);\n}\nexport function r4x16_uncompress(inputBuffer) {\n    return r4x16.decode(inputBuffer);\n}\nexport function arith_uncompress(inputBuffer) {\n    // fix by @cmdcolin for CRAM 3.1\n    // xref https://github.com/jkbonfield/htscodecs/pull/1/files\n    return new arith().decode(inputBuffer);\n}\nexport function fqzcomp_uncompress(inputBuffer) {\n    const q_lens = [];\n    return fqzcomp.decode(inputBuffer, q_lens);\n}\nexport function tok3_uncompress(inputBuffer) {\n    // Returns in string form instead of buffer\n    const out = tok3.decode(inputBuffer, 0, '\\0');\n    return Uint8Array.from(Array.from(out).map(letter => letter.charCodeAt(0)));\n}\n//# sourceMappingURL=index.js.map","import { LocalFile, RemoteFile } from 'generic-filehandle2';\nfunction open(maybeUrl, maybePath, maybeFilehandle) {\n    if (maybeFilehandle) {\n        return maybeFilehandle;\n    }\n    if (maybeUrl) {\n        return new RemoteFile(maybeUrl);\n    }\n    if (maybePath) {\n        return new LocalFile(maybePath);\n    }\n    throw new Error('no url, path, or filehandle provided, cannot open');\n}\nexport { open };\nexport { LocalFile, RemoteFile } from 'generic-filehandle2';\n//# sourceMappingURL=index.js.map","const TF_SHIFT = 12;\nconst TOTFREQ = 1 << TF_SHIFT;\nconst RANS_BYTE_L = 1 << 23;\nexport { RANS_BYTE_L, TF_SHIFT, TOTFREQ };\n//# sourceMappingURL=constants.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport { RANS_BYTE_L } from './constants';\nclass FC {\n    // int F, C;\n    constructor() {\n        this.F = undefined;\n        this.C = undefined;\n    }\n}\nclass AriDecoder {\n    // final FC[] fc = new FC[256];\n    // byte[] R;\n    constructor() {\n        this.fc = new Array(256);\n        for (let i = 0; i < this.fc.length; i += 1) {\n            this.fc[i] = new FC();\n        }\n        this.R = null;\n    }\n}\nclass DecodingSymbol {\n    // int start; // Start of range.\n    // int freq; // Symbol frequency.\n    constructor() {\n        this.start = undefined;\n        this.freq = undefined;\n    }\n}\n// Initialize a decoder symbol to start \"start\" and frequency \"freq\"\nfunction symbolInit(sym, start, freq) {\n    if (!(start <= 1 << 16)) {\n        throw new CramMalformedError('assertion failed: start <= 1<<16');\n    }\n    if (!(freq <= (1 << 16) - start)) {\n        throw new CramMalformedError('assertion failed: freq <= 1<<16');\n    }\n    sym.start = start;\n    sym.freq = freq;\n}\n// Advances in the bit stream by \"popping\" a single symbol with range start\n// \"start\" and frequency \"freq\". All frequencies are assumed to sum to\n// \"1 << scaleBits\".\n// No renormalization or output happens.\n/* private static int */ function advanceStep(\n/* final int */ r, \n/* final int */ start, \n/* final int */ freq, \n/* final int */ scaleBits) {\n    /* final int */ const mask = (1 << scaleBits) - 1;\n    // s, x = D(x)\n    return freq * (r >> scaleBits) + (r & mask) - start;\n}\n// Equivalent to RansDecAdvanceStep that takes a symbol.\n/* static int  */ function advanceSymbolStep(\n/* final int */ r, \n/* final RansDecSymbol */ sym, \n/* final int */ scaleBits) {\n    return advanceStep(r, sym.start, sym.freq, scaleBits);\n}\n// Returns the current cumulative frequency (map it to a symbol yourself!)\n/* static int */ function get(/* final int */ r, /* final int */ scaleBits) {\n    return r & ((1 << scaleBits) - 1);\n}\n// Advances in the bit stream by \"popping\" a single symbol with range start\n// \"start\" and frequency \"freq\". All frequencies are assumed to sum to\n// \"1 << scaleBits\",\n// and the resulting bytes get written to ptr (which is updated).\n/* private static int */ function advance(\n/* int */ r, \n/* final ByteBuffer */ pptr, \n/* final int */ start, \n/* final int */ freq, \n/* final int */ scaleBits) {\n    /* final int */ const mask = (1 << scaleBits) - 1;\n    // s, x = D(x)\n    r = freq * (r >> scaleBits) + (r & mask) - start;\n    // re-normalize\n    if (r < RANS_BYTE_L) {\n        do {\n            /* final int */ const b = 0xff & pptr.get();\n            r = (r << 8) | b;\n        } while (r < RANS_BYTE_L);\n    }\n    return r;\n}\n// Equivalent to RansDecAdvance that takes a symbol.\n/*  static int */ function advanceSymbol(\n/* final int */ r, \n/* final ByteBuffer */ pptr, \n/* final RansDecSymbol */ sym, \n/* final int */ scaleBits) {\n    return advance(r, pptr, sym.start, sym.freq, scaleBits);\n}\n// Re-normalize.\n/*  static int */ function renormalize(\n/* int */ r, \n/* final ByteBuffer */ pptr) {\n    // re-normalize\n    if (r < RANS_BYTE_L) {\n        do {\n            r = (r << 8) | (0xff & pptr.get());\n        } while (r < RANS_BYTE_L);\n    }\n    return r;\n}\nexport default {\n    FC,\n    AriDecoder,\n    DecodingSymbol,\n    symbolInit,\n    advanceStep,\n    advanceSymbolStep,\n    get,\n    advanceSymbol,\n    renormalize,\n};\n//# sourceMappingURL=decoding.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport { TF_SHIFT } from './constants';\nimport Decoding from './decoding';\nexport default function uncompress(\n/* ByteBuffer */ input, \n/* Decoding.AriDecoder */ D, \n/* Decoding.Symbol[] */ syms, \n/* ByteBuffer */ out) {\n    let rans0 = input.getInt();\n    let rans1 = input.getInt();\n    let rans2 = input.getInt();\n    let rans3 = input.getInt();\n    const /* int */ outputSize = out.remaining();\n    const /* int */ outputEnd = outputSize & ~3;\n    for (let i = 0; i < outputEnd; i += 4) {\n        const /* byte */ c0 = D.R[Decoding.get(rans0, TF_SHIFT)];\n        const /* byte */ c1 = D.R[Decoding.get(rans1, TF_SHIFT)];\n        const /* byte */ c2 = D.R[Decoding.get(rans2, TF_SHIFT)];\n        const /* byte */ c3 = D.R[Decoding.get(rans3, TF_SHIFT)];\n        out.putAt(i, c0);\n        out.putAt(i + 1, c1);\n        out.putAt(i + 2, c2);\n        out.putAt(i + 3, c3);\n        rans0 = Decoding.advanceSymbolStep(rans0, syms[0xff & c0], TF_SHIFT);\n        rans1 = Decoding.advanceSymbolStep(rans1, syms[0xff & c1], TF_SHIFT);\n        rans2 = Decoding.advanceSymbolStep(rans2, syms[0xff & c2], TF_SHIFT);\n        rans3 = Decoding.advanceSymbolStep(rans3, syms[0xff & c3], TF_SHIFT);\n        rans0 = Decoding.renormalize(rans0, input);\n        rans1 = Decoding.renormalize(rans1, input);\n        rans2 = Decoding.renormalize(rans2, input);\n        rans3 = Decoding.renormalize(rans3, input);\n    }\n    out.setPosition(outputEnd);\n    let /* byte */ c;\n    switch (outputSize & 3) {\n        case 0:\n            break;\n        case 1:\n            c = D.R[Decoding.get(rans0, TF_SHIFT)];\n            Decoding.advanceSymbol(rans0, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            break;\n        case 2:\n            c = D.R[Decoding.get(rans0, TF_SHIFT)];\n            Decoding.advanceSymbol(rans0, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            c = D.R[Decoding.get(rans1, TF_SHIFT)];\n            Decoding.advanceSymbol(rans1, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            break;\n        case 3:\n            c = D.R[Decoding.get(rans0, TF_SHIFT)];\n            Decoding.advanceSymbol(rans0, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            c = D.R[Decoding.get(rans1, TF_SHIFT)];\n            Decoding.advanceSymbol(rans1, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            c = D.R[Decoding.get(rans2, TF_SHIFT)];\n            Decoding.advanceSymbol(rans2, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            break;\n        default:\n            throw new CramMalformedError('invalid output size encountered during rANS decoding');\n    }\n    out.setPosition(0);\n}\n//# sourceMappingURL=d04.js.map","// @ts-nocheck\nimport { TF_SHIFT } from './constants';\nimport Decoding from './decoding';\nexport default function uncompress(\n/* ByteBuffer */ input, \n/* ByteBuffer */ output, \n/* Decoding.AriDecoder[] */ D, \n/* Decoding.Symbol[][] */ syms) {\n    const /* int */ outputSize = output.remaining();\n    let rans0 = input.getInt();\n    let rans1 = input.getInt();\n    let rans2 = input.getInt();\n    let rans7 = input.getInt();\n    const /* int */ isz4 = outputSize >> 2;\n    let /* int */ i0 = 0;\n    let /* int */ i1 = isz4;\n    let /* int */ i2 = 2 * isz4;\n    let /* int */ i7 = 3 * isz4;\n    let /* int */ l0 = 0;\n    let /* int */ l1 = 0;\n    let /* int */ l2 = 0;\n    let /* int */ l7 = 0;\n    for (; i0 < isz4; i0 += 1, i1 += 1, i2 += 1, i7 += 1) {\n        const /* int */ c0 = 0xff & D[l0].R[Decoding.get(rans0, TF_SHIFT)];\n        const /* int */ c1 = 0xff & D[l1].R[Decoding.get(rans1, TF_SHIFT)];\n        const /* int */ c2 = 0xff & D[l2].R[Decoding.get(rans2, TF_SHIFT)];\n        const /* int */ c7 = 0xff & D[l7].R[Decoding.get(rans7, TF_SHIFT)];\n        output.putAt(i0, c0);\n        output.putAt(i1, c1);\n        output.putAt(i2, c2);\n        output.putAt(i7, c7);\n        rans0 = Decoding.advanceSymbolStep(rans0, syms[l0][c0], TF_SHIFT);\n        rans1 = Decoding.advanceSymbolStep(rans1, syms[l1][c1], TF_SHIFT);\n        rans2 = Decoding.advanceSymbolStep(rans2, syms[l2][c2], TF_SHIFT);\n        rans7 = Decoding.advanceSymbolStep(rans7, syms[l7][c7], TF_SHIFT);\n        rans0 = Decoding.renormalize(rans0, input);\n        rans1 = Decoding.renormalize(rans1, input);\n        rans2 = Decoding.renormalize(rans2, input);\n        rans7 = Decoding.renormalize(rans7, input);\n        l0 = c0;\n        l1 = c1;\n        l2 = c2;\n        l7 = c7;\n    }\n    // Remainder\n    for (; i7 < outputSize; i7 += 1) {\n        const /* int */ c7 = 0xff & D[l7].R[Decoding.get(rans7, TF_SHIFT)];\n        output.putAt(i7, c7);\n        rans7 = Decoding.advanceSymbol(rans7, input, syms[l7][c7], TF_SHIFT);\n        l7 = c7;\n    }\n}\n//# sourceMappingURL=d14.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport { TOTFREQ } from './constants';\nimport Decoding from './decoding';\nfunction assert(result) {\n    if (!result) {\n        throw new CramMalformedError('assertion failed');\n    }\n}\nexport function readStatsO0(\n/* ByteBuffer */ cp, \n/* Decoding.AriDecoder */ decoder, \n/* Decoding.RansDecSymbol[] */ syms) {\n    // Pre-compute reverse lookup of frequency.\n    let rle = 0;\n    let x = 0;\n    let j = cp.get() & 0xff;\n    do {\n        if (decoder.fc[j] == null) {\n            decoder.fc[j] = new Decoding.FC();\n        }\n        decoder.fc[j].F = cp.get() & 0xff;\n        if (decoder.fc[j].F >= 128) {\n            decoder.fc[j].F &= ~128;\n            decoder.fc[j].F = ((decoder.fc[j].F & 127) << 8) | (cp.get() & 0xff);\n        }\n        decoder.fc[j].C = x;\n        Decoding.symbolInit(syms[j], decoder.fc[j].C, decoder.fc[j].F);\n        /* Build reverse lookup table */\n        if (!decoder.R) {\n            decoder.R = new Array(TOTFREQ);\n        }\n        decoder.R.fill(j, x, x + decoder.fc[j].F);\n        x += decoder.fc[j].F;\n        if (rle === 0 && j + 1 === (0xff & cp.getByteAt(cp.position()))) {\n            j = cp.get() & 0xff;\n            rle = cp.get() & 0xff;\n        }\n        else if (rle !== 0) {\n            rle -= 1;\n            j += 1;\n        }\n        else {\n            j = cp.get() & 0xff;\n        }\n    } while (j !== 0);\n    assert(x < TOTFREQ);\n}\nexport function readStatsO1(\n/* ByteBuffer */ cp, \n/*  Decoding.AriDecoder[] */ D, \n/* Decoding.RansDecSymbol[][] */ syms) {\n    let rlei = 0;\n    let i = 0xff & cp.get();\n    do {\n        let rlej = 0;\n        let x = 0;\n        let j = 0xff & cp.get();\n        if (D[i] == null) {\n            D[i] = new Decoding.AriDecoder();\n        }\n        do {\n            if (D[i].fc[j] == null) {\n                D[i].fc[j] = new Decoding.FC();\n            }\n            D[i].fc[j].F = 0xff & cp.get();\n            if (D[i].fc[j].F >= 128) {\n                D[i].fc[j].F &= ~128;\n                D[i].fc[j].F = ((D[i].fc[j].F & 127) << 8) | (0xff & cp.get());\n            }\n            D[i].fc[j].C = x;\n            if (D[i].fc[j].F === 0) {\n                D[i].fc[j].F = TOTFREQ;\n            }\n            if (syms[i][j] == null) {\n                syms[i][j] = new Decoding.RansDecSymbol();\n            }\n            Decoding.symbolInit(syms[i][j], D[i].fc[j].C, D[i].fc[j].F);\n            /* Build reverse lookup table */\n            if (D[i].R == null) {\n                D[i].R = new Array(TOTFREQ);\n            }\n            D[i].R.fill(j, x, x + D[i].fc[j].F);\n            x += D[i].fc[j].F;\n            assert(x <= TOTFREQ);\n            if (rlej === 0 && j + 1 === (0xff & cp.getByteAt(cp.position()))) {\n                j = 0xff & cp.get();\n                rlej = 0xff & cp.get();\n            }\n            else if (rlej !== 0) {\n                rlej -= 1;\n                j += 1;\n            }\n            else {\n                j = 0xff & cp.get();\n            }\n        } while (j !== 0);\n        if (rlei === 0 && i + 1 === (0xff & cp.getByteAt(cp.position()))) {\n            i = 0xff & cp.get();\n            rlei = 0xff & cp.get();\n        }\n        else if (rlei !== 0) {\n            rlei -= 1;\n            i += 1;\n        }\n        else {\n            i = 0xff & cp.get();\n        }\n    } while (i !== 0);\n}\n//# sourceMappingURL=frequencies.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport D04 from './d04';\nimport D14 from './d14';\nimport Decoding from './decoding';\nimport { readStatsO0, readStatsO1 } from './frequencies';\n// const /* int */ ORDER_BYTE_LENGTH = 1\n// const /* int */ COMPRESSED_BYTE_LENGTH = 4\nconst /* int */ RAW_BYTE_LENGTH = 4;\n// const /* int */ PREFIX_BYTE_LENGTH =\n//   ORDER_BYTE_LENGTH + COMPRESSED_BYTE_LENGTH + RAW_BYTE_LENGTH\n// enum ORDER {\n//     ZERO, ONE;\n//     static ORDER fromInt(const /* int */ value) {\n//         try {\n//             return ORDER.values()[value];\n//         } catch (const ArrayIndexOutOfBoundsException e) {\n//             throw new RuntimeException(\"Unknown rANS order: \" + value);\n//         }\n//     }\n// }\n// static ByteBuffer compress(const ByteBuffer input, const ORDER order, const ByteBuffer out) {\n//     if (input.remaining() == 0)\n//         return EMPTY_BUFFER;\n//     if (input.remaining() < 4)\n//         return encode_order0_way4(input, out);\n//     switch (order) {\n//         case ZERO:\n//             return encode_order0_way4(input, out);\n//         case ONE:\n//             return encode_order1_way4(input, out);\n//         default:\n//             throw new RuntimeException(\"Unknown rANS order: \" + order);\n//     }\n// }\n// static /* ByteBuffer */ allocateIfNeeded(/* const int */ in_size,\n//                                            /* const ByteBuffer */ out_buf) {\n//     const /* int */ compressedSize = (/* int */) (1.05 * in_size + 257 * 257 * 3 + 4);\n//     if (out_buf == null)\n//         return ByteBuffer.allocate(compressedSize);\n//     if (out_buf.remaining() < compressedSize)\n//         throw new RuntimeException(\"Insufficient buffer size.\");\n//     out_buf.order(ByteOrder.LITTLE_ENDIAN);\n//     return out_buf;\n// }\n// static ByteBuffer encode_order0_way4(const ByteBuffer input,\n//                                              ByteBuffer out_buf) {\n//     const /* int */ in_size = input.remaining();\n//     out_buf = allocateIfNeeded(in_size, out_buf);\n//     const /* int */ freqTableStart = PREFIX_BYTE_LENGTH;\n//     out_buf.position(freqTableStart);\n//     const /* int */[] F = Frequencies.calcFrequencies_o0(in);\n//     const RansEncSymbol[] syms = Frequencies.buildSyms_o0(F);\n//     const ByteBuffer cp = out_buf.slice();\n//     const /* int */ frequencyTable_size = Frequencies.writeFrequencies_o0(cp, F);\n//     input.rewind();\n//     const /* int */ compressedBlob_size = E04.compress(input, syms, cp);\n//     finalizeCompressed(0, out_buf, in_size, frequencyTable_size,\n//             compressedBlob_size);\n//     return out_buf;\n// }\n// static ByteBuffer encode_order1_way4(const ByteBuffer input,\n//                                              ByteBuffer out_buf) {\n//     const /* int */ in_size = input.remaining();\n//     out_buf = allocateIfNeeded(in_size, out_buf);\n//     const /* int */ freqTableStart = PREFIX_BYTE_LENGTH;\n//     out_buf.position(freqTableStart);\n//     const /* int */[][] F = Frequencies.calcFrequencies_o1(in);\n//     const RansEncSymbol[][] syms = Frequencies.buildSyms_o1(F);\n//     const ByteBuffer cp = out_buf.slice();\n//     const /* int */ frequencyTable_size = Frequencies.writeFrequencies_o1(cp, F);\n//     input.rewind();\n//     const /* int */ compressedBlob_size = E14.compress(input, syms, cp);\n//     finalizeCompressed(1, out_buf, in_size, frequencyTable_size,\n//             compressedBlob_size);\n//     return out_buf;\n// }\n// static void finalizeCompressed(const /* int */ order, const ByteBuffer out_buf,\n//                                        const /* int */ in_size, const /* int */ frequencyTable_size, const /* int */ compressedBlob_size) {\n//     out_buf.limit(PREFIX_BYTE_LENGTH + frequencyTable_size\n//             + compressedBlob_size);\n//     out_buf.put(0, (byte) order);\n//     out_buf.order(ByteOrder.LITTLE_ENDIAN);\n//     const /* int */ compressedSizeOffset = ORDER_BYTE_LENGTH;\n//     out_buf.putInt(compressedSizeOffset, frequencyTable_size\n//             + compressedBlob_size);\n//     const /* int */ rawSizeOffset = ORDER_BYTE_LENGTH + COMPRESSED_BYTE_LENGTH;\n//     out_buf.putInt(rawSizeOffset, in_size);\n//     out_buf.rewind();\n// }\nfunction uncompressOrder0Way4(\n/* const ByteBuffer  */ input, \n/* const ByteBuffer  */ out) {\n    // input.order(ByteOrder.LITTLE_ENDIAN);\n    const D = new Decoding.AriDecoder();\n    const syms = new Array(256);\n    for (let i = 0; i < syms.length; i += 1) {\n        syms[i] = new Decoding.DecodingSymbol();\n    }\n    readStatsO0(input, D, syms);\n    D04(input, D, syms, out);\n    return out;\n}\nfunction uncompressOrder1Way4(\n/* const ByteBuffer */ input, \n/* const ByteBuffer */ output) {\n    const D = new Array(256);\n    for (let i = 0; i < D.length; i += 1) {\n        D[i] = new Decoding.AriDecoder();\n    }\n    const /* Decoding.RansDecSymbol[][]  */ syms = new Array(256);\n    for (let i = 0; i < syms.length; i += 1) {\n        syms[i] = new Array(256);\n        for (let j = 0; j < syms[i].length; j += 1) {\n            syms[i][j] = new Decoding.DecodingSymbol();\n        }\n    }\n    readStatsO1(input, D, syms);\n    D14(input, output, D, syms);\n    return output;\n}\n/* compat layer to make a node buffer act like a java ByteBuffer */\nclass ByteBuffer {\n    constructor(nodeBuffer, initialInputPosition = 0) {\n        this._buffer = nodeBuffer;\n        this._dataView = new DataView(nodeBuffer.buffer);\n        this._position = initialInputPosition;\n        this.length = nodeBuffer.length;\n    }\n    get() {\n        const b = this._buffer[this._position];\n        this._position += 1;\n        return b;\n    }\n    getByte() {\n        return this.get();\n    }\n    getByteAt(position) {\n        return this._buffer[position];\n    }\n    position() {\n        return this._position;\n    }\n    put(val) {\n        this._buffer[this._position] = val;\n        this._position += 1;\n        return val;\n    }\n    putAt(position, val) {\n        this._buffer[position] = val;\n        return val;\n    }\n    setPosition(pos) {\n        this._position = pos;\n        return pos;\n    }\n    getInt() {\n        const i = this._dataView.getInt32(this._position, true);\n        this._position += 4;\n        return i;\n    }\n    remaining() {\n        return this._buffer.length - this._position;\n    }\n}\n// static /* const */ ByteBuffer EMPTY_BUFFER = ByteBuffer.allocate(0);\nexport default function uncompress(inputBuffer, outputBuffer, initialInputPosition = 0) {\n    if (inputBuffer.length === 0) {\n        outputBuffer.fill(0);\n        return outputBuffer;\n    }\n    const input = new ByteBuffer(inputBuffer, initialInputPosition);\n    // input.order(ByteOrder.LITTLE_ENDIAN);\n    const order = input.get();\n    if (order !== 0 && order !== 1) {\n        throw new CramMalformedError(`Invalid rANS order ${order}`);\n    }\n    const /* int */ inputSize = input.getInt();\n    if (inputSize !== input.remaining() - RAW_BYTE_LENGTH) {\n        throw new CramMalformedError('Incorrect input length.');\n    }\n    const /* int */ outputSize = input.getInt();\n    const output = new ByteBuffer(outputBuffer || new Uint8Array(outputSize));\n    // TODO output.limit(outputSize)\n    if (output.length < outputSize) {\n        throw new CramMalformedError(`Output buffer too small to fit ${outputSize} bytes.`);\n    }\n    switch (order) {\n        case 0:\n            return uncompressOrder0Way4(input, output);\n        case 1:\n            return uncompressOrder1Way4(input, output);\n        default:\n            throw new CramMalformedError(`Invalid rANS order: ${order}`);\n    }\n}\n//# sourceMappingURL=index.js.map","export function parseHeaderText(text) {\n    const lines = text.split(/\\r?\\n/);\n    const data = [];\n    for (const line of lines) {\n        const [tag, ...fields] = line.split(/\\t/);\n        if (tag) {\n            data.push({\n                tag: tag.slice(1),\n                data: fields.map(f => {\n                    const r = f.indexOf(':');\n                    return r !== -1\n                        ? {\n                            tag: f.slice(0, r),\n                            value: f.slice(r + 1),\n                        }\n                        : // @CO lines are not comma separated.\n                            // See \"samtools view -H c2\\#pad.3.0.cram\"\n                            // so, just store value tag and value itself\n                            {\n                                tag: f,\n                                value: '',\n                            };\n                }),\n            });\n        }\n    }\n    return data;\n}\n//# sourceMappingURL=sam.js.map","import { inflate } from 'pako';\nexport function unzip(input) {\n    return inflate(input);\n}\n//# sourceMappingURL=unzip.js.map","export class CramBufferOverrunError extends Error {\n}\nexport function getBits(data, cursor, numBits) {\n    let val = 0;\n    if (cursor.bytePosition + (7 - cursor.bitPosition + numBits) / 8 >\n        data.length) {\n        throw new CramBufferOverrunError('read error during decoding. the file seems to be truncated.');\n    }\n    for (let dlen = numBits; dlen; dlen--) {\n        // get the next `dlen` bits in the input, put them in val\n        val <<= 1;\n        val |= (data[cursor.bytePosition] >> cursor.bitPosition) & 1;\n        cursor.bitPosition -= 1;\n        if (cursor.bitPosition < 0) {\n            cursor.bytePosition += 1;\n        }\n        cursor.bitPosition &= 7;\n    }\n    return val;\n}\n//# sourceMappingURL=getBits.js.map","import md5 from 'md5';\nexport const TWO_PWR_16_DBL = 1 << 16;\nexport const TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;\nexport const TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;\nexport const TWO_PWR_24_DBL = 1 << 24;\nexport const TWO_PWR_56_DBL = TWO_PWR_24_DBL * TWO_PWR_32_DBL;\nexport function itf8Size(v) {\n    if (!(v & ~0x7f)) {\n        return 1;\n    }\n    if (!(v & ~0x3fff)) {\n        return 2;\n    }\n    if (!(v & ~0x1fffff)) {\n        return 3;\n    }\n    if (!(v & ~0xfffffff)) {\n        return 4;\n    }\n    return 5;\n}\nexport function parseItf8(buffer, initialOffset) {\n    let offset = initialOffset;\n    const countFlags = buffer[offset];\n    let result;\n    // Single byte value (0xxxxxxx)\n    if (countFlags < 0x80) {\n        result = countFlags;\n        offset += 1;\n    }\n    // Two byte value (10xxxxxx)\n    else if (countFlags < 0xc0) {\n        result = ((countFlags & 0x3f) << 8) | buffer[offset + 1];\n        offset += 2;\n    }\n    // Three byte value (110xxxxx)\n    else if (countFlags < 0xe0) {\n        result =\n            ((countFlags & 0x1f) << 16) |\n                (buffer[offset + 1] << 8) |\n                buffer[offset + 2];\n        offset += 3;\n    }\n    // Four byte value (1110xxxx)\n    else if (countFlags < 0xf0) {\n        result =\n            ((countFlags & 0x0f) << 24) |\n                (buffer[offset + 1] << 16) |\n                (buffer[offset + 2] << 8) |\n                buffer[offset + 3];\n        offset += 4;\n    }\n    // Five byte value (11110xxx)\n    else {\n        result =\n            ((countFlags & 0x0f) << 28) |\n                (buffer[offset + 1] << 20) |\n                (buffer[offset + 2] << 12) |\n                (buffer[offset + 3] << 4) |\n                (buffer[offset + 4] & 0x0f);\n        offset += 5;\n    }\n    return [result, offset - initialOffset];\n}\nexport function parseLtf8(buffer, initialOffset) {\n    let offset = initialOffset;\n    const countFlags = buffer[offset];\n    let value;\n    // Single byte value < 0x80\n    if (countFlags < 0x80) {\n        value = countFlags;\n        offset += 1;\n    }\n    // Two byte value < 0xC0\n    else if (countFlags < 0xc0) {\n        value = ((countFlags << 8) | buffer[offset + 1]) & 0x3fff;\n        offset += 2;\n    }\n    // Three byte value < 0xE0\n    else if (countFlags < 0xe0) {\n        value =\n            ((countFlags & 0x3f) << 16) |\n                (buffer[offset + 1] << 8) |\n                buffer[offset + 2];\n        offset += 3;\n    }\n    // Four byte value < 0xF0\n    else if (countFlags < 0xf0) {\n        value =\n            ((countFlags & 0x1f) << 24) |\n                (buffer[offset + 1] << 16) |\n                (buffer[offset + 2] << 8) |\n                buffer[offset + 3];\n        offset += 4;\n    }\n    // Five byte value < 0xF8\n    else if (countFlags < 0xf8) {\n        value =\n            (buffer[offset] & 0x0f) * TWO_PWR_32_DBL +\n                ((buffer[offset + 1] << 24) |\n                    (buffer[offset + 2] << 16) |\n                    (buffer[offset + 3] << 8) |\n                    buffer[offset + 4]);\n        offset += 5;\n    }\n    // Six byte value < 0xFC\n    else if (countFlags < 0xfc) {\n        value =\n            (((buffer[offset] & 0x07) << 8) | buffer[offset + 1]) * TWO_PWR_32_DBL +\n                ((buffer[offset + 2] << 24) |\n                    (buffer[offset + 3] << 16) |\n                    (buffer[offset + 4] << 8) |\n                    buffer[offset + 5]);\n        offset += 6;\n    }\n    // Seven byte value < 0xFE\n    else if (countFlags < 0xfe) {\n        value =\n            (((buffer[offset] & 0x03) << 16) |\n                (buffer[offset + 1] << 8) |\n                buffer[offset + 2]) *\n                TWO_PWR_32_DBL +\n                ((buffer[offset + 3] << 24) |\n                    (buffer[offset + 4] << 16) |\n                    (buffer[offset + 5] << 8) |\n                    buffer[offset + 6]);\n        offset += 7;\n    }\n    // Eight byte value < 0xFF\n    else if (countFlags < 0xff) {\n        value =\n            ((buffer[offset + 1] << 24) |\n                (buffer[offset + 2] << 16) |\n                (buffer[offset + 3] << 8) |\n                buffer[offset + 4]) *\n                TWO_PWR_32_DBL +\n                ((buffer[offset + 5] << 24) |\n                    (buffer[offset + 6] << 16) |\n                    (buffer[offset + 7] << 8) |\n                    buffer[offset + 8]);\n        offset += 8;\n    }\n    // Nine byte value\n    else {\n        value =\n            buffer[offset + 1] * TWO_PWR_56_DBL +\n                ((buffer[offset + 2] << 24) |\n                    (buffer[offset + 3] << 16) |\n                    (buffer[offset + 4] << 8) |\n                    buffer[offset + 5]) *\n                    TWO_PWR_32_DBL +\n                ((buffer[offset + 6] << 24) |\n                    (buffer[offset + 7] << 16) |\n                    (buffer[offset + 8] << 8) |\n                    buffer[offset + 9]);\n        offset += 9;\n    }\n    return [value, offset - initialOffset];\n}\nexport function parseItem(buffer, parser, startBufferPosition = 0, startFilePosition = 0) {\n    const { offset, value } = parser(buffer, startBufferPosition);\n    return {\n        ...value,\n        _endPosition: offset + startFilePosition,\n        _size: offset - startBufferPosition,\n    };\n}\nexport function tinyMemoize(_class, methodName) {\n    const method = _class.prototype[methodName];\n    const memoAttrName = `_memo_${methodName}`;\n    _class.prototype[methodName] = function _tinyMemoized() {\n        if (!(memoAttrName in this)) {\n            const res = method.call(this);\n            this[memoAttrName] = res;\n            Promise.resolve(res).catch(() => {\n                delete this[memoAttrName];\n            });\n        }\n        return this[memoAttrName];\n    };\n}\nexport function sequenceMD5(seq) {\n    return md5(seq.toUpperCase().replaceAll(/[^\\u0021-\\u007e]/g, ''));\n}\n//# sourceMappingURL=util.js.map","import { parseItf8, parseLtf8 } from './util';\nexport function cramFileDefinition() {\n    return {\n        parser: (b, _startOffset = 0) => {\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const decoder = new TextDecoder('utf8');\n            let offset = 0;\n            const magic = decoder.decode(b.subarray(offset, offset + 4));\n            offset += 4;\n            const majorVersion = dataView.getUint8(offset);\n            offset += 1;\n            const minorVersion = dataView.getUint8(offset);\n            offset += 1;\n            const fileId = decoder\n                .decode(b.subarray(offset, offset + 20))\n                .replaceAll('\\0', '');\n            offset += 20;\n            return {\n                value: {\n                    magic,\n                    majorVersion,\n                    minorVersion,\n                    fileId,\n                },\n                offset,\n            };\n        },\n        maxLength: 26,\n    };\n}\nexport function cramBlockHeader() {\n    const parser = (buffer, _startOffset = 0) => {\n        const b = buffer;\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        const d = dataView.getUint8(offset);\n        const compressionMethod = [\n            'raw',\n            'gzip',\n            'bzip2',\n            'lzma',\n            'rans',\n            'rans4x16',\n            'arith',\n            'fqzcomp',\n            'tok3',\n        ][d];\n        if (!compressionMethod) {\n            throw new Error(`compression method number ${d} not implemented`);\n        }\n        offset += 1;\n        const c = dataView.getUint8(offset);\n        const contentType = [\n            'FILE_HEADER',\n            'COMPRESSION_HEADER',\n            'MAPPED_SLICE_HEADER',\n            'UNMAPPED_SLICE_HEADER', // < only used in cram v1\n            'EXTERNAL_DATA',\n            'CORE_DATA',\n        ][c];\n        if (!contentType) {\n            throw new Error(`invalid block content type id ${c}`);\n        }\n        offset += 1;\n        const [contentId, newOffset1] = parseItf8(buffer, offset);\n        offset += newOffset1;\n        const [compressedSize, newOffset2] = parseItf8(buffer, offset);\n        offset += newOffset2;\n        const [uncompressedSize, newOffset3] = parseItf8(buffer, offset);\n        offset += newOffset3;\n        return {\n            offset,\n            value: {\n                uncompressedSize,\n                compressedSize,\n                contentId,\n                contentType: contentType,\n                compressionMethod: compressionMethod,\n            },\n        };\n    };\n    return { parser, maxLength: 17 };\n}\nexport function cramBlockCrc32() {\n    return {\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const crc32 = dataView.getUint32(offset, true);\n            offset += 4;\n            return {\n                offset,\n                value: {\n                    crc32,\n                },\n            };\n        },\n        maxLength: 4,\n    };\n}\nfunction makeTagSet(buffer, stringStart, stringEnd) {\n    const decoder = new TextDecoder('utf8');\n    const str = decoder.decode(buffer.subarray(stringStart, stringEnd));\n    const tags = [];\n    for (let i = 0; i < str.length; i += 3) {\n        tags.push(str.slice(i, i + 3));\n    }\n    return tags;\n}\nexport function cramTagDictionary() {\n    return {\n        parser: (buffer, offset) => {\n            const [size, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const subbuf = buffer.subarray(offset, offset + size);\n            offset += size;\n            const tagSets = [];\n            let stringStart = 0;\n            let i = 0;\n            for (; i < subbuf.length; i++) {\n                if (!subbuf[i]) {\n                    tagSets.push(makeTagSet(subbuf, stringStart, i));\n                    stringStart = i + 1;\n                }\n            }\n            if (i > stringStart) {\n                tagSets.push(makeTagSet(subbuf, stringStart, i));\n            }\n            return {\n                value: {\n                    size,\n                    ents: tagSets,\n                },\n                offset,\n            };\n        },\n    };\n}\nexport function cramPreservationMap() {\n    return {\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const [mapSize, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [mapCount, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const ents = [];\n            for (let i = 0; i < mapCount; i++) {\n                const key = String.fromCharCode(buffer[offset]) +\n                    String.fromCharCode(buffer[offset + 1]);\n                offset += 2;\n                if (key === 'MI' ||\n                    key === 'UI' ||\n                    key === 'PI' ||\n                    key === 'RN' ||\n                    key === 'AP' ||\n                    key === 'RR') {\n                    ents.push({\n                        key,\n                        value: !!dataView.getUint8(offset),\n                    });\n                    offset += 1;\n                }\n                else if (key === 'SM') {\n                    ents.push({\n                        key,\n                        value: [\n                            dataView.getUint8(offset),\n                            dataView.getUint8(offset + 1),\n                            dataView.getUint8(offset + 2),\n                            dataView.getUint8(offset + 3),\n                            dataView.getUint8(offset + 4),\n                        ],\n                    });\n                    offset += 5;\n                }\n                else if (key === 'TD') {\n                    const { offset: offsetRet, value } = cramTagDictionary().parser(buffer, offset);\n                    ents.push({ key, value: value.ents });\n                    offset = offsetRet;\n                }\n                else {\n                    throw new Error(`unknown key ${key}`);\n                }\n            }\n            return {\n                value: {\n                    mapSize,\n                    mapCount,\n                    ents,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction formatMap(data) {\n    const map = {};\n    for (const { key, value } of data.ents) {\n        if (map[key]) {\n            console.warn(`duplicate key ${key} in map`);\n        }\n        map[key] = value;\n    }\n    return map;\n}\nexport function isMappedSliceHeader(header) {\n    return typeof header.refSeqId === 'number';\n}\n// assemble a section parser for the unmapped slice header, with slight\n// variations depending on the major version of the cram file\nfunction cramUnmappedSliceHeader(majorVersion) {\n    let maxLength = 0;\n    maxLength += 5;\n    maxLength += 9;\n    maxLength += 5 * 2;\n    maxLength += 16;\n    const parser = (buffer, offset) => {\n        const [numRecords, newOffset1] = parseItf8(buffer, offset);\n        offset += newOffset1;\n        let recordCounter = 0;\n        // recordCounter is itf8 in a CRAM v2 file, absent in CRAM v1\n        if (majorVersion >= 3) {\n            const [rc, newOffset2] = parseLtf8(buffer, offset);\n            offset += newOffset2;\n            recordCounter = rc;\n        }\n        else if (majorVersion === 2) {\n            const [rc, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            recordCounter = rc;\n        }\n        else {\n            console.warn('recordCounter=0');\n        }\n        const [numBlocks, newOffset3] = parseItf8(buffer, offset);\n        offset += newOffset3;\n        const [numContentIds, newOffset4] = parseItf8(buffer, offset);\n        offset += newOffset4;\n        const contentIds = [];\n        for (let i = 0; i < numContentIds; i++) {\n            const [id, newOffset5] = parseItf8(buffer, offset);\n            offset += newOffset5;\n            contentIds.push(id);\n        }\n        // the md5 sum is missing in cram v1\n        let md5;\n        if (majorVersion >= 2) {\n            md5 = [...buffer.subarray(offset, offset + 16)];\n            offset += 16;\n        }\n        return {\n            value: {\n                recordCounter,\n                md5,\n                contentIds,\n                numContentIds,\n                numBlocks,\n                numRecords,\n            },\n            offset,\n        };\n    };\n    return {\n        parser,\n        maxLength: (numContentIds) => maxLength + numContentIds * 5,\n    };\n}\n// assembles a section parser for the unmapped slice header, with slight\n// variations depending on the major version of the cram file\nfunction cramMappedSliceHeader(majorVersion) {\n    let maxLength = 0;\n    maxLength += 5 * 4; // EL0\n    maxLength += 9; // EL1\n    maxLength += 5 * 3; // EL2 ITF8s\n    maxLength += 16; // MD5\n    return {\n        parser: (buffer, offset) => {\n            // L0\n            const [refSeqId, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [refSeqStart, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const [refSeqSpan, newOffset3] = parseItf8(buffer, offset);\n            offset += newOffset3;\n            const [numRecords, newOffset4] = parseItf8(buffer, offset);\n            offset += newOffset4;\n            // EL0\n            // L1\n            let recordCounter = 0;\n            if (majorVersion >= 3) {\n                const [rc, newOffset5] = parseLtf8(buffer, offset);\n                offset += newOffset5;\n                recordCounter = rc;\n            }\n            else if (majorVersion === 2) {\n                const [rc, newOffset5] = parseItf8(buffer, offset);\n                offset += newOffset5;\n                recordCounter = rc;\n            }\n            else {\n                console.warn('majorVersion is <2, recordCounter set to 0');\n            }\n            // EL1\n            // L2\n            const [numBlocks, newOffset6] = parseItf8(buffer, offset);\n            offset += newOffset6;\n            const [numContentIds, newOffset7] = parseItf8(buffer, offset);\n            offset += newOffset7;\n            const contentIds = [];\n            for (let i = 0; i < numContentIds; i++) {\n                const [id, newOffset5] = parseItf8(buffer, offset);\n                offset += newOffset5;\n                contentIds.push(id);\n            }\n            const [refBaseBlockId, newOffset8] = parseItf8(buffer, offset);\n            offset += newOffset8;\n            // EL2\n            // the md5 sum is missing in cram v1\n            let md5;\n            if (majorVersion >= 2) {\n                md5 = [...buffer.subarray(offset, offset + 16)];\n                offset += 16;\n            }\n            return {\n                value: {\n                    md5,\n                    numBlocks,\n                    numRecords,\n                    numContentIds,\n                    refSeqSpan,\n                    refSeqId,\n                    refSeqStart,\n                    recordCounter,\n                    refBaseBlockId,\n                    contentIds,\n                },\n                offset,\n            };\n        },\n        maxLength: (numContentIds) => maxLength + numContentIds * 5,\n    };\n}\nfunction cramEncoding() {\n    return {\n        parser: (buffer, offset) => cramEncodingSub(buffer, offset),\n    };\n}\nfunction cramEncodingSub(buffer, offset) {\n    const b = buffer;\n    const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n    const [codecId, newOffset1] = parseItf8(buffer, offset);\n    offset += newOffset1;\n    const [parametersBytes, newOffset2] = parseItf8(buffer, offset);\n    offset += newOffset2;\n    const parameters = {};\n    if (codecId === 0) {\n        // NULL\n    }\n    else if (codecId === 1) {\n        // EXTERNAL\n        const [bc, newOffset3] = parseItf8(buffer, offset);\n        parameters.blockContentId = bc;\n        offset += newOffset3;\n    }\n    else if (codecId === 2) {\n        // GOLUMB\n        const [off, newOffset3] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset3;\n        const [M2, newOffset4] = parseItf8(buffer, offset);\n        parameters.M = M2;\n        offset += newOffset4;\n    }\n    else if (codecId === 3) {\n        // HUFFMAN_INT\n        const val = parseItf8(buffer, offset);\n        const numCodes = val[0];\n        offset += val[1];\n        const symbols = [];\n        for (let i = 0; i < numCodes; i++) {\n            const code = parseItf8(buffer, offset);\n            symbols.push(code[0]);\n            offset += code[1];\n        }\n        parameters.symbols = symbols;\n        const val2 = parseItf8(buffer, offset);\n        const numLengths = val[0];\n        parameters.numLengths = numLengths;\n        parameters.numCodes = numCodes;\n        parameters.numLengths = numLengths;\n        offset += val2[1];\n        const bitLengths = [];\n        for (let i = 0; i < numLengths; i++) {\n            const len = parseItf8(buffer, offset);\n            offset += len[1];\n            bitLengths.push(len[0]);\n        }\n        parameters.bitLengths = bitLengths;\n    }\n    else if (codecId === 4) {\n        // BYTE_ARRAY_LEN\n        const { value: lengthsEncoding, offset: newOffset1 } = cramEncodingSub(buffer, offset);\n        parameters.lengthsEncoding = lengthsEncoding;\n        offset = newOffset1;\n        const { value: valuesEncoding, offset: newOffset2 } = cramEncodingSub(buffer, offset);\n        parameters.valuesEncoding = valuesEncoding;\n        offset = newOffset2;\n    }\n    else if (codecId === 5) {\n        // BYTE_ARRAY_STOP\n        parameters.stopByte = dataView.getUint8(offset);\n        offset += 1;\n        const [blockContentId, newOffset1] = parseItf8(buffer, offset);\n        parameters.blockContentId = blockContentId;\n        offset += newOffset1;\n    }\n    else if (codecId === 6) {\n        // BETA\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n        const [len, newOffset2] = parseItf8(buffer, offset);\n        parameters.length = len;\n        offset += newOffset2;\n    }\n    else if (codecId === 7) {\n        // SUBEXP\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n        const [K, newOffset2] = parseItf8(buffer, offset);\n        parameters.K = K;\n        offset += newOffset2;\n    }\n    else if (codecId === 8) {\n        // GOLOMB_RICE\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n        const [l2m, newOffset2] = parseItf8(buffer, offset);\n        parameters.log2m = l2m;\n        offset += newOffset2;\n    }\n    else if (codecId === 9) {\n        // GAMMA\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n    }\n    else {\n        throw new Error(`unknown codecId ${codecId}`);\n    }\n    return {\n        value: {\n            codecId,\n            parametersBytes,\n            parameters,\n        },\n        offset,\n    };\n}\nfunction cramDataSeriesEncodingMap() {\n    return {\n        parser: (buffer, offset) => {\n            const [mapSize, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [mapCount, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const ents = [];\n            for (let i = 0; i < mapCount; i++) {\n                const key = String.fromCharCode(buffer[offset]) +\n                    String.fromCharCode(buffer[offset + 1]);\n                offset += 2;\n                const { value, offset: newOffset4 } = cramEncodingSub(buffer, offset);\n                offset = newOffset4;\n                ents.push({ key, value });\n            }\n            return {\n                value: {\n                    mapSize,\n                    ents,\n                    mapCount,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramTagEncodingMap() {\n    return {\n        parser: (buffer, offset) => {\n            const [mapSize, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [mapCount, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const ents = [];\n            for (let i = 0; i < mapCount; i++) {\n                const [k0, newOffset3] = parseItf8(buffer, offset);\n                offset += newOffset3;\n                const key = String.fromCharCode((k0 >> 16) & 0xff) +\n                    String.fromCharCode((k0 >> 8) & 0xff) +\n                    String.fromCharCode(k0 & 0xff);\n                const { value, offset: newOffset4 } = cramEncodingSub(buffer, offset);\n                offset = newOffset4;\n                ents.push({ key, value });\n            }\n            return {\n                value: {\n                    mapSize,\n                    ents,\n                    mapCount,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramCompressionHeader() {\n    return {\n        parser: (buffer, offset) => {\n            // TODO: if we want to support CRAM v1, we will need to refactor\n            // compression header into 2 parts to parse the landmarks, like the\n            // container header\n            const { value: preservation, offset: newOffset1 } = cramPreservationMap().parser(buffer, offset);\n            offset = newOffset1;\n            const { value: dataSeriesEncoding, offset: newOffset2 } = cramDataSeriesEncodingMap().parser(buffer, offset);\n            offset = newOffset2;\n            const { value: tagEncoding, offset: newOffset3 } = cramTagEncodingMap().parser(buffer, offset);\n            offset = newOffset3;\n            return {\n                value: {\n                    dataSeriesEncoding: formatMap(dataSeriesEncoding),\n                    preservation: formatMap(preservation),\n                    tagEncoding: formatMap(tagEncoding),\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramContainerHeader1(majorVersion) {\n    let maxLength = 4;\n    maxLength += 5 * 4;\n    maxLength += 9;\n    maxLength += 9;\n    maxLength += 5 + 5;\n    return {\n        maxLength,\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            // byte size of the container data (blocks)\n            const length = dataView.getInt32(offset, true);\n            offset += 4;\n            // reference sequence identifier:\n            // -1 for unmapped reads,\n            // -2 for multiple reference sequences\n            const [refSeqId, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [refSeqStart, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const [alignmentSpan, newOffset3] = parseItf8(buffer, offset);\n            offset += newOffset3;\n            const [numRecords, newOffset4] = parseItf8(buffer, offset);\n            offset += newOffset4;\n            let recordCounter = 0;\n            if (majorVersion >= 3) {\n                const [rc, newOffset5] = parseLtf8(buffer, offset);\n                recordCounter = rc;\n                offset += newOffset5;\n            }\n            else if (majorVersion === 2) {\n                const [rc, newOffset5] = parseItf8(buffer, offset);\n                recordCounter = rc;\n                offset += newOffset5;\n            }\n            else {\n                console.warn('setting recordCounter=0');\n            }\n            let numBases;\n            if (majorVersion > 1) {\n                const [n, newOffset5] = parseLtf8(buffer, offset);\n                numBases = n;\n                offset += newOffset5;\n            }\n            const [numBlocks, newOffset6] = parseItf8(buffer, offset);\n            offset += newOffset6;\n            const [numLandmarks, newOffset7] = parseItf8(buffer, offset);\n            offset += newOffset7;\n            return {\n                value: {\n                    length,\n                    refSeqId,\n                    refSeqStart,\n                    alignmentSpan,\n                    numBlocks,\n                    numLandmarks,\n                    numBases,\n                    recordCounter,\n                    numRecords,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramContainerHeader2(majorVersion) {\n    return {\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const [numLandmarks, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const landmarks = [];\n            for (let i = 0; i < numLandmarks; i++) {\n                const [landmark, newOffset2] = parseItf8(buffer, offset);\n                offset += newOffset2;\n                landmarks.push(landmark);\n            }\n            let crc32;\n            if (majorVersion >= 3) {\n                crc32 = dataView.getUint32(offset, true);\n                offset += 4;\n            }\n            return {\n                value: {\n                    ...(crc32 === undefined ? {} : { crc32 }),\n                    numLandmarks,\n                    landmarks,\n                },\n                offset,\n            };\n        },\n        maxLength: (numLandmarks) => 5 + 5 * numLandmarks + 4,\n    };\n}\nexport function getSectionParsers(majorVersion) {\n    return {\n        cramFileDefinition: cramFileDefinition(),\n        cramBlockHeader: cramBlockHeader(),\n        cramBlockCrc32: cramBlockCrc32(),\n        cramDataSeriesEncodingMap: cramDataSeriesEncodingMap(),\n        cramTagEncodingMap: cramTagEncodingMap(),\n        cramCompressionHeader: cramCompressionHeader(),\n        cramEncoding: cramEncoding(),\n        cramUnmappedSliceHeader: cramUnmappedSliceHeader(majorVersion),\n        cramMappedSliceHeader: cramMappedSliceHeader(majorVersion),\n        cramContainerHeader1: cramContainerHeader1(majorVersion),\n        cramContainerHeader2: cramContainerHeader2(majorVersion),\n    };\n}\n//# sourceMappingURL=sectionParsers.js.map","import { CramMalformedError } from '../../errors';\nimport { BamFlagsDecoder, CramFlagsDecoder, MateFlagsDecoder, } from '../record';\nimport { isMappedSliceHeader } from '../sectionParsers';\n/**\n * given a Buffer, read a string up to the first null character\n * @private\n */\nfunction readNullTerminatedString(buffer) {\n    let r = '';\n    for (let i = 0; i < buffer.length && buffer[i] !== 0; i++) {\n        r += String.fromCharCode(buffer[i]);\n    }\n    return r;\n}\n/**\n * parse a BAM tag's array value from a binary buffer\n * @private\n */\nfunction parseTagValueArray(buffer) {\n    const arrayType = String.fromCharCode(buffer[0]);\n    const dataView = new DataView(buffer.buffer);\n    const littleEndian = true;\n    const length = dataView.getUint32(1, littleEndian);\n    const array = new Array(length);\n    buffer = buffer.slice(5);\n    if (arrayType === 'c') {\n        const arr = new Int8Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'C') {\n        const arr = new Uint8Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 's') {\n        const arr = new Int16Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'S') {\n        const arr = new Uint16Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'i') {\n        const arr = new Int32Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'I') {\n        const arr = new Uint32Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'f') {\n        const arr = new Float32Array(buffer.buffer);\n        for (let i = 0; i < length; i++) {\n            array[i] = arr[i];\n        }\n    }\n    else {\n        throw new Error(`unknown type: ${arrayType}`);\n    }\n    return array;\n}\nfunction parseTagData(tagType, buffer) {\n    if (tagType === 'Z') {\n        return readNullTerminatedString(buffer);\n    }\n    if (tagType === 'A') {\n        return String.fromCharCode(buffer[0]);\n    }\n    if (tagType === 'I') {\n        return new Uint32Array(buffer.buffer)[0];\n    }\n    if (tagType === 'i') {\n        return new Int32Array(buffer.buffer)[0];\n    }\n    if (tagType === 's') {\n        return new Int16Array(buffer.buffer)[0];\n    }\n    if (tagType === 'S') {\n        return new Uint16Array(buffer.buffer)[0];\n    }\n    if (tagType === 'c') {\n        return new Int8Array(buffer.buffer)[0];\n    }\n    if (tagType === 'C') {\n        return buffer[0];\n    }\n    if (tagType === 'f') {\n        return new Float32Array(buffer.buffer)[0];\n    }\n    if (tagType === 'H') {\n        return Number.parseInt(readNullTerminatedString(buffer).replace(/^0x/, ''), 16);\n    }\n    if (tagType === 'B') {\n        return parseTagValueArray(buffer);\n    }\n    throw new CramMalformedError(`Unrecognized tag type ${tagType}`);\n}\nfunction decodeReadFeatures(alignmentStart, readFeatureCount, decodeDataSeries, compressionScheme, majorVersion) {\n    let currentReadPos = 0;\n    let currentRefPos = alignmentStart - 1;\n    const readFeatures = new Array(readFeatureCount);\n    function decodeRFData([type, dataSeriesName]) {\n        const data = decodeDataSeries(dataSeriesName);\n        if (type === 'character') {\n            return String.fromCharCode(data);\n        }\n        else if (type === 'string') {\n            let r = '';\n            for (let i = 0; i < data.byteLength; i++) {\n                r += String.fromCharCode(data[i]);\n            }\n            return r;\n        }\n        else if (type === 'numArray') {\n            return Array.from(data);\n        }\n        // else if (type === 'number') {\n        //   return data[0]\n        // }\n        return data;\n    }\n    for (let i = 0; i < readFeatureCount; i++) {\n        const code = String.fromCharCode(decodeDataSeries('FC'));\n        const readPosDelta = decodeDataSeries('FP');\n        // map of operator name -> data series name\n        const data1Schema = {\n            B: ['character', 'BA'],\n            S: ['string', majorVersion > 1 ? 'SC' : 'IN'], // IN if cram v1, SC otherwise\n            X: ['number', 'BS'],\n            D: ['number', 'DL'],\n            I: ['string', 'IN'],\n            i: ['character', 'BA'],\n            b: ['string', 'BB'],\n            q: ['numArray', 'QQ'],\n            Q: ['number', 'QS'],\n            H: ['number', 'HC'],\n            P: ['number', 'PD'],\n            N: ['number', 'RS'],\n        }[code];\n        if (!data1Schema) {\n            throw new CramMalformedError(`invalid read feature code \"${code}\"`);\n        }\n        let data = decodeRFData(data1Schema);\n        // if this is a tag with two data items, make the data an array and add the second item\n        const data2Schema = { B: ['number', 'QS'] }[code];\n        if (data2Schema) {\n            data = [data, decodeRFData(data2Schema)];\n        }\n        currentReadPos += readPosDelta;\n        const pos = currentReadPos;\n        currentRefPos += readPosDelta;\n        const refPos = currentRefPos;\n        // for gapping features, adjust the reference position for read features that follow\n        if (code === 'D' || code === 'N') {\n            currentRefPos += data;\n        }\n        else if (code === 'I' || code === 'S') {\n            currentRefPos -= data.length;\n        }\n        else if (code === 'i') {\n            currentRefPos -= 1;\n        }\n        readFeatures[i] = { code, pos, refPos, data };\n    }\n    return readFeatures;\n}\nexport default function decodeRecord(slice, decodeDataSeries, compressionScheme, sliceHeader, coreDataBlock, blocksByContentId, cursors, majorVersion, recordNumber) {\n    let flags = decodeDataSeries('BF');\n    // note: the C data type of compressionFlags is byte in cram v1 and int32 in\n    // cram v2+, but that does not matter for us here in javascript land.\n    const cramFlags = decodeDataSeries('CF');\n    if (!isMappedSliceHeader(sliceHeader.parsedContent)) {\n        throw new Error('slice header not mapped');\n    }\n    const sequenceId = majorVersion > 1 && sliceHeader.parsedContent.refSeqId === -2\n        ? decodeDataSeries('RI')\n        : sliceHeader.parsedContent.refSeqId;\n    const readLength = decodeDataSeries('RL');\n    // if APDelta, will calculate the true start in a second pass\n    let alignmentStart = decodeDataSeries('AP');\n    if (compressionScheme.APdelta) {\n        alignmentStart = alignmentStart + cursors.lastAlignmentStart;\n    }\n    cursors.lastAlignmentStart = alignmentStart;\n    const readGroupId = decodeDataSeries('RG');\n    let readName;\n    if (compressionScheme.readNamesIncluded) {\n        readName = readNullTerminatedString(decodeDataSeries('RN'));\n    }\n    let mateToUse;\n    let templateSize;\n    let mateRecordNumber;\n    // mate record\n    if (CramFlagsDecoder.isDetached(cramFlags)) {\n        // note: the MF is a byte in 1.0, int32 in 2+, but once again this doesn't\n        // matter for javascript\n        const mateFlags = decodeDataSeries('MF');\n        let mateReadName;\n        if (!compressionScheme.readNamesIncluded) {\n            mateReadName = readNullTerminatedString(decodeDataSeries('RN'));\n            readName = mateReadName;\n        }\n        const mateSequenceId = decodeDataSeries('NS');\n        const mateAlignmentStart = decodeDataSeries('NP');\n        if (mateFlags || mateSequenceId > -1) {\n            mateToUse = {\n                mateFlags,\n                mateSequenceId,\n                mateAlignmentStart,\n                mateReadName,\n            };\n        }\n        templateSize = decodeDataSeries('TS');\n        // set mate unmapped if needed\n        if (MateFlagsDecoder.isUnmapped(mateFlags)) {\n            flags = BamFlagsDecoder.setMateUnmapped(flags);\n        }\n        // set mate reversed if needed\n        if (MateFlagsDecoder.isOnNegativeStrand(mateFlags)) {\n            flags = BamFlagsDecoder.setMateReverseComplemented(flags);\n        }\n        // detachedCount++\n    }\n    else if (CramFlagsDecoder.isWithMateDownstream(cramFlags)) {\n        mateRecordNumber = decodeDataSeries('NF') + recordNumber + 1;\n    }\n    // TODO: the aux tag parsing will have to be refactored if we want to support\n    // cram v1\n    const TLindex = decodeDataSeries('TL');\n    if (TLindex < 0) {\n        /* TODO: check nTL: TLindex >= compressionHeader.tagEncoding.size */\n        throw new CramMalformedError('invalid TL index');\n    }\n    const tags = {};\n    // TN = tag names\n    const TN = compressionScheme.getTagNames(TLindex);\n    const ntags = TN.length;\n    for (let i = 0; i < ntags; i++) {\n        const tagId = TN[i];\n        const tagName = tagId.slice(0, 2);\n        const tagType = tagId.slice(2, 3);\n        const tagData = compressionScheme\n            .getCodecForTag(tagId)\n            .decode(slice, coreDataBlock, blocksByContentId, cursors);\n        tags[tagName] =\n            tagData === undefined\n                ? undefined\n                : typeof tagData === 'number'\n                    ? tagData\n                    : parseTagData(tagType, tagData);\n    }\n    let readFeatures;\n    let lengthOnRef;\n    let mappingQuality;\n    let qualityScores;\n    let readBases = undefined;\n    if (!BamFlagsDecoder.isSegmentUnmapped(flags)) {\n        // reading read features\n        const readFeatureCount = decodeDataSeries('FN');\n        if (readFeatureCount) {\n            readFeatures = decodeReadFeatures(alignmentStart, readFeatureCount, decodeDataSeries, compressionScheme, majorVersion);\n        }\n        // compute the read's true span on the reference sequence, and the end\n        // coordinate of the alignment on the reference\n        lengthOnRef = readLength;\n        if (readFeatures) {\n            for (const { code, data } of readFeatures) {\n                if (code === 'D' || code === 'N') {\n                    lengthOnRef += data;\n                }\n                else if (code === 'I' || code === 'S') {\n                    lengthOnRef = lengthOnRef - data.length;\n                }\n                else if (code === 'i') {\n                    lengthOnRef = lengthOnRef - 1;\n                }\n            }\n        }\n        if (Number.isNaN(lengthOnRef)) {\n            console.warn(`${readName || `${sequenceId}:${alignmentStart}`} record has invalid read features`);\n            lengthOnRef = readLength;\n        }\n        // mapping quality\n        mappingQuality = decodeDataSeries('MQ');\n        if (CramFlagsDecoder.isPreservingQualityScores(cramFlags)) {\n            qualityScores = new Array(readLength);\n            for (let i = 0; i < qualityScores.length; i++) {\n                qualityScores[i] = decodeDataSeries('QS');\n            }\n        }\n    }\n    else if (CramFlagsDecoder.isDecodeSequenceAsStar(cramFlags)) {\n        readBases = null;\n        qualityScores = null;\n    }\n    else {\n        const bases = new Array(readLength);\n        for (let i = 0; i < bases.length; i++) {\n            bases[i] = decodeDataSeries('BA');\n        }\n        readBases = String.fromCharCode(...bases);\n        if (CramFlagsDecoder.isPreservingQualityScores(cramFlags)) {\n            qualityScores = new Array(readLength);\n            for (let i = 0; i < bases.length; i++) {\n                qualityScores[i] = decodeDataSeries('QS');\n            }\n        }\n    }\n    return {\n        readLength,\n        sequenceId,\n        cramFlags,\n        flags,\n        alignmentStart,\n        readGroupId,\n        readName,\n        mateToUse,\n        templateSize,\n        mateRecordNumber,\n        readFeatures,\n        lengthOnRef,\n        mappingQuality,\n        qualityScores,\n        readBases,\n        tags,\n    };\n}\n//# sourceMappingURL=decodeRecord.js.map","import { CramArgumentError, CramMalformedError } from '../../errors';\nimport { CramBufferOverrunError } from '../codecs/getBits';\nimport Constants from '../constants';\nimport decodeRecord from './decodeRecord';\nimport CramRecord from '../record';\nimport { getSectionParsers, isMappedSliceHeader, } from '../sectionParsers';\nimport { parseItem, sequenceMD5, tinyMemoize } from '../util';\n/**\n * @private\n * Try to estimate the template length from a bunch of interrelated multi-segment reads.\n * @param {Array[CramRecord]} allRecords\n * @param {number} currentRecordNumber\n * @param {CramRecord} thisRecord\n */\nfunction calculateMultiSegmentMatedTemplateLength(allRecords, currentRecordNumber, thisRecord) {\n    function getAllMatedRecords(startRecord) {\n        const records = [startRecord];\n        if (startRecord.mateRecordNumber !== undefined &&\n            startRecord.mateRecordNumber >= 0) {\n            const mateRecord = allRecords[startRecord.mateRecordNumber];\n            if (!mateRecord) {\n                throw new CramMalformedError('intra-slice mate record not found, this file seems malformed');\n            }\n            records.push(...getAllMatedRecords(mateRecord));\n        }\n        return records;\n    }\n    const matedRecords = getAllMatedRecords(thisRecord);\n    const starts = matedRecords.map(r => r.alignmentStart);\n    const ends = matedRecords.map(r => r.alignmentStart + r.readLength - 1);\n    const estimatedTemplateLength = Math.max(...ends) - Math.min(...starts) + 1;\n    if (estimatedTemplateLength >= 0) {\n        matedRecords.forEach(r => {\n            if (r.templateLength !== undefined) {\n                throw new CramMalformedError('mate pair group has some members that have template lengths already, this file seems malformed');\n            }\n            r.templateLength = estimatedTemplateLength;\n        });\n    }\n}\n/**\n * @private\n * Attempt to calculate the `templateLength` for a pair of intra-slice paired reads.\n * Ported from htslib. Algorithm is imperfect.\n * @param {CramRecord} thisRecord\n * @param {CramRecord} mateRecord\n */\nfunction calculateIntraSliceMatePairTemplateLength(thisRecord, mateRecord) {\n    // this just estimates the template length by using the simple (non-gapped) end coordinate of each\n    // read, because gapping in the alignment doesn't mean the template is longer or shorter\n    const start = Math.min(thisRecord.alignmentStart, mateRecord.alignmentStart);\n    const end = Math.max(thisRecord.alignmentStart + thisRecord.readLength - 1, mateRecord.alignmentStart + mateRecord.readLength - 1);\n    const lengthEstimate = end - start + 1;\n    thisRecord.templateLength = lengthEstimate;\n    mateRecord.templateLength = lengthEstimate;\n}\n/**\n * @private establishes a mate-pair relationship between two records in the\n * same slice. CRAM compresses mate-pair relationships between records in the\n * same slice down into just one record having the index in the slice of its\n * mate\n */\nfunction associateIntraSliceMate(allRecords, currentRecordNumber, thisRecord, mateRecord) {\n    const complicatedMultiSegment = !!(mateRecord.mate ||\n        (mateRecord.mateRecordNumber !== undefined &&\n            mateRecord.mateRecordNumber !== currentRecordNumber));\n    // Deal with lossy read names\n    if (!thisRecord.readName) {\n        thisRecord.readName = String(thisRecord.uniqueId);\n        mateRecord.readName = thisRecord.readName;\n    }\n    thisRecord.mate = {\n        sequenceId: mateRecord.sequenceId,\n        alignmentStart: mateRecord.alignmentStart,\n        uniqueId: mateRecord.uniqueId,\n    };\n    if (mateRecord.readName) {\n        thisRecord.mate.readName = mateRecord.readName;\n    }\n    // the mate record might have its own mate pointer, if this is some kind of\n    // multi-segment (more than paired) scheme, so only relate that one back to this one\n    // if it does not have any other relationship\n    if (!mateRecord.mate && mateRecord.mateRecordNumber === undefined) {\n        mateRecord.mate = {\n            sequenceId: thisRecord.sequenceId,\n            alignmentStart: thisRecord.alignmentStart,\n            uniqueId: thisRecord.uniqueId,\n        };\n        if (thisRecord.readName) {\n            mateRecord.mate.readName = thisRecord.readName;\n        }\n    }\n    // make sure the proper flags and cramFlags are set on both records\n    // paired\n    thisRecord.flags |= Constants.BAM_FPAIRED;\n    // set mate unmapped if needed\n    if (mateRecord.flags & Constants.BAM_FUNMAP) {\n        thisRecord.flags |= Constants.BAM_FMUNMAP;\n        // thisRecord.templateLength = 0\n    }\n    if (thisRecord.flags & Constants.BAM_FUNMAP) {\n        // thisRecord.templateLength = 0\n        mateRecord.flags |= Constants.BAM_FMUNMAP;\n    }\n    // set mate reversed if needed\n    if (mateRecord.flags & Constants.BAM_FREVERSE) {\n        thisRecord.flags |= Constants.BAM_FMREVERSE;\n    }\n    if (thisRecord.flags & Constants.BAM_FREVERSE) {\n        mateRecord.flags |= Constants.BAM_FMREVERSE;\n    }\n    if (thisRecord.templateLength === undefined) {\n        if (complicatedMultiSegment) {\n            calculateMultiSegmentMatedTemplateLength(allRecords, currentRecordNumber, thisRecord);\n        }\n        else {\n            calculateIntraSliceMatePairTemplateLength(thisRecord, mateRecord);\n        }\n    }\n    // delete this last because it's used by the\n    // complicated template length estimation\n    thisRecord.mateRecordNumber = undefined;\n}\nexport default class CramSlice {\n    constructor(container, containerPosition, sliceSize) {\n        this.container = container;\n        this.containerPosition = containerPosition;\n        this.sliceSize = sliceSize;\n        this.file = container.file;\n    }\n    // memoize\n    async getHeader() {\n        // fetch and parse the slice header\n        const { majorVersion } = await this.file.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const containerHeader = await this.container.getHeader();\n        const header = await this.file.readBlock(containerHeader._endPosition + this.containerPosition);\n        if (header.contentType === 'MAPPED_SLICE_HEADER') {\n            const content = parseItem(header.content, sectionParsers.cramMappedSliceHeader.parser, 0, containerHeader._endPosition);\n            return { ...header, parsedContent: content };\n        }\n        else if (header.contentType === 'UNMAPPED_SLICE_HEADER') {\n            const content = parseItem(header.content, sectionParsers.cramUnmappedSliceHeader.parser, 0, containerHeader._endPosition);\n            return { ...header, parsedContent: content };\n        }\n        else {\n            throw new CramMalformedError(`error reading slice header block, invalid content type ${header.contentType}`);\n        }\n    }\n    // memoize\n    async getBlocks() {\n        const header = await this.getHeader();\n        // read all the blocks into memory and store them\n        let blockPosition = header._endPosition;\n        const blocks = new Array(header.parsedContent.numBlocks);\n        for (let i = 0; i < blocks.length; i++) {\n            const block = await this.file.readBlock(blockPosition);\n            blocks[i] = block;\n            blockPosition = blocks[i]._endPosition;\n        }\n        return blocks;\n    }\n    // no memoize\n    async getCoreDataBlock() {\n        const blocks = await this.getBlocks();\n        return blocks[0];\n    }\n    // memoize\n    async _getBlocksContentIdIndex() {\n        const blocks = await this.getBlocks();\n        const blocksByContentId = {};\n        blocks.forEach(block => {\n            if (block.contentType === 'EXTERNAL_DATA') {\n                blocksByContentId[block.contentId] = block;\n            }\n        });\n        return blocksByContentId;\n    }\n    async getBlockByContentId(id) {\n        const blocksByContentId = await this._getBlocksContentIdIndex();\n        return blocksByContentId[id];\n    }\n    async getReferenceRegion() {\n        // read the slice header\n        const decoder = new TextDecoder('utf8');\n        const sliceHeader = (await this.getHeader()).parsedContent;\n        if (!isMappedSliceHeader(sliceHeader)) {\n            throw new Error('slice header not mapped');\n        }\n        if (sliceHeader.refSeqId < 0) {\n            return undefined;\n        }\n        const compressionScheme = await this.container.getCompressionScheme();\n        if (compressionScheme === undefined) {\n            throw new Error('compression scheme undefined');\n        }\n        if (sliceHeader.refBaseBlockId >= 0) {\n            const refBlock = await this.getBlockByContentId(sliceHeader.refBaseBlockId);\n            if (!refBlock) {\n                throw new CramMalformedError('embedded reference specified, but reference block does not exist');\n            }\n            // TODO: we do not read anything named 'span'\n            // if (sliceHeader.span > refBlock.uncompressedSize) {\n            //   throw new CramMalformedError('Embedded reference is too small')\n            // }\n            // TODO verify\n            return {\n                // @ts-expect-error\n                seq: decoder.decode(refBlock.data),\n                start: sliceHeader.refSeqStart,\n                end: sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1,\n                span: sliceHeader.refSeqSpan,\n            };\n        }\n        if (compressionScheme.referenceRequired ||\n            this.file.fetchReferenceSequenceCallback) {\n            if (!this.file.fetchReferenceSequenceCallback) {\n                throw new Error('reference sequence not embedded, and seqFetch callback not provided, cannot fetch reference sequence');\n            }\n            const seq = await this.file.fetchReferenceSequenceCallback(sliceHeader.refSeqId, sliceHeader.refSeqStart, sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1);\n            if (seq.length !== sliceHeader.refSeqSpan) {\n                throw new CramArgumentError('seqFetch callback returned a reference sequence of the wrong length');\n            }\n            return {\n                seq,\n                start: sliceHeader.refSeqStart,\n                end: sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1,\n                span: sliceHeader.refSeqSpan,\n            };\n        }\n        return undefined;\n    }\n    getAllRecords() {\n        return this.getRecords(() => true);\n    }\n    async _fetchRecords() {\n        const { majorVersion } = await this.file.getDefinition();\n        const compressionScheme = await this.container.getCompressionScheme();\n        if (compressionScheme === undefined) {\n            throw new Error('compression scheme undefined');\n        }\n        const sliceHeader = await this.getHeader();\n        const blocksByContentId = await this._getBlocksContentIdIndex();\n        // check MD5 of reference if available\n        if (majorVersion > 1 &&\n            this.file.options.checkSequenceMD5 &&\n            isMappedSliceHeader(sliceHeader.parsedContent) &&\n            sliceHeader.parsedContent.refSeqId >= 0 &&\n            sliceHeader.parsedContent.md5?.join('') !== '0000000000000000') {\n            const refRegion = await this.getReferenceRegion();\n            if (refRegion) {\n                const { seq, start, end } = refRegion;\n                const seqMd5 = sequenceMD5(seq);\n                const storedMd5 = sliceHeader.parsedContent.md5\n                    ?.map(byte => (byte < 16 ? '0' : '') + byte.toString(16))\n                    .join('');\n                if (seqMd5 !== storedMd5) {\n                    throw new CramMalformedError(`MD5 checksum reference mismatch for ref ${sliceHeader.parsedContent.refSeqId} pos ${start}..${end}. recorded MD5: ${storedMd5}, calculated MD5: ${seqMd5}`);\n                }\n            }\n        }\n        // tracks the read position within the block. codec.decode() methods\n        // advance the byte and bit positions in the cursor as they decode\n        // data note that we are only decoding a single block here, the core\n        // data block\n        const coreDataBlock = await this.getCoreDataBlock();\n        const cursors = {\n            lastAlignmentStart: isMappedSliceHeader(sliceHeader.parsedContent)\n                ? sliceHeader.parsedContent.refSeqStart\n                : 0,\n            coreBlock: { bitPosition: 7, bytePosition: 0 },\n            externalBlocks: {\n                map: new Map(),\n                getCursor(contentId) {\n                    let r = this.map.get(contentId);\n                    if (r === undefined) {\n                        r = { bitPosition: 7, bytePosition: 0 };\n                        this.map.set(contentId, r);\n                    }\n                    return r;\n                },\n            },\n        };\n        const decodeDataSeries = (dataSeriesName) => {\n            const codec = compressionScheme.getCodecForDataSeries(dataSeriesName);\n            if (!codec) {\n                throw new CramMalformedError(`no codec defined for ${dataSeriesName} data series`);\n            }\n            return codec.decode(this, coreDataBlock, blocksByContentId, cursors);\n        };\n        const records = new Array(sliceHeader.parsedContent.numRecords);\n        for (let i = 0; i < records.length; i += 1) {\n            try {\n                const init = decodeRecord(this, decodeDataSeries, compressionScheme, sliceHeader, coreDataBlock, blocksByContentId, cursors, majorVersion, i);\n                records[i] = new CramRecord({\n                    ...init,\n                    uniqueId: sliceHeader.contentPosition +\n                        sliceHeader.parsedContent.recordCounter +\n                        i +\n                        1,\n                });\n            }\n            catch (e) {\n                if (e instanceof CramBufferOverrunError) {\n                    console.warn('read attempted beyond end of buffer, file seems truncated.');\n                    break;\n                }\n                else {\n                    throw e;\n                }\n            }\n        }\n        // interpret `recordsToNextFragment` attributes to make standard `mate`\n        // objects\n        //\n        // Resolve mate pair cross-references between records in this slice\n        for (let i = 0; i < records.length; i += 1) {\n            const r = records[i];\n            // check for !!r added after removal  of \"stat\" file size check: found\n            // some undefined entries\n            if (r) {\n                const { mateRecordNumber } = r;\n                if (mateRecordNumber !== undefined &&\n                    mateRecordNumber >= 0 &&\n                    records[mateRecordNumber]) {\n                    associateIntraSliceMate(records, i, r, records[mateRecordNumber]);\n                }\n            }\n        }\n        return records;\n    }\n    async getRecords(filterFunction) {\n        // fetch the features if necessary, using the file-level feature cache\n        const cacheKey = this.container.filePosition + this.containerPosition;\n        let recordsPromise = this.file.featureCache.get(cacheKey.toString());\n        if (!recordsPromise) {\n            recordsPromise = this._fetchRecords();\n            this.file.featureCache.set(cacheKey.toString(), recordsPromise);\n        }\n        const unfiltered = await recordsPromise;\n        const records = unfiltered.filter(filterFunction);\n        // if we can fetch reference sequence, add the reference sequence to the records\n        if (records.length && this.file.fetchReferenceSequenceCallback) {\n            const sliceHeader = await this.getHeader();\n            if (isMappedSliceHeader(sliceHeader.parsedContent) &&\n                (sliceHeader.parsedContent.refSeqId >= 0 || // single-ref slice\n                    sliceHeader.parsedContent.refSeqId === -2) // multi-ref slice\n            ) {\n                const singleRefId = sliceHeader.parsedContent.refSeqId >= 0\n                    ? sliceHeader.parsedContent.refSeqId\n                    : undefined;\n                const compressionScheme = await this.container.getCompressionScheme();\n                if (compressionScheme === undefined) {\n                    throw new Error('compression scheme undefined');\n                }\n                const refRegions = {};\n                // iterate over the records to find the spans of the reference\n                // sequences we need to fetch\n                for (const record of records) {\n                    const seqId = singleRefId !== undefined ? singleRefId : record.sequenceId;\n                    let refRegion = refRegions[seqId];\n                    if (!refRegion) {\n                        refRegion = {\n                            id: seqId,\n                            start: record.alignmentStart,\n                            end: Number.NEGATIVE_INFINITY,\n                            seq: null,\n                        };\n                        refRegions[seqId] = refRegion;\n                    }\n                    const end = record.alignmentStart +\n                        (record.lengthOnRef || record.readLength) -\n                        1;\n                    if (end > refRegion.end) {\n                        refRegion.end = end;\n                    }\n                    if (record.alignmentStart < refRegion.start) {\n                        refRegion.start = record.alignmentStart;\n                    }\n                }\n                // fetch the `seq` for all of the ref regions\n                await Promise.all(Object.values(refRegions).map(async (refRegion) => {\n                    if (refRegion.id !== -1 &&\n                        refRegion.start <= refRegion.end &&\n                        this.file.fetchReferenceSequenceCallback) {\n                        refRegion.seq = await this.file.fetchReferenceSequenceCallback(refRegion.id, refRegion.start, refRegion.end);\n                    }\n                }));\n                // now decorate all the records with them\n                for (const record of records) {\n                    const seqId = singleRefId !== undefined ? singleRefId : record.sequenceId;\n                    const refRegion = refRegions[seqId];\n                    if (refRegion?.seq) {\n                        const seq = refRegion.seq;\n                        record.addReferenceSequence({ ...refRegion, seq }, compressionScheme);\n                    }\n                }\n            }\n        }\n        return records;\n    }\n}\n// memoize several methods in the class for performance\n'getHeader getBlocks _getBlocksContentIdIndex'.split(' ').forEach(method => {\n    tinyMemoize(CramSlice, method);\n});\n//# sourceMappingURL=index.js.map","// codec base class\nexport default class CramCodec {\n    constructor(parameters, dataType) {\n        this.parameters = parameters;\n        this.dataType = dataType;\n    }\n}\n//# sourceMappingURL=_base.js.map","import CramCodec from './_base';\nimport { getBits } from './getBits';\nimport { CramUnimplementedError } from '../../errors';\nexport default class BetaCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType !== 'int') {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by BETA codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const fromBits = getBits(coreDataBlock.content, cursors.coreBlock, this.parameters.length);\n        return fromBits - this.parameters.offset;\n    }\n}\n//# sourceMappingURL=beta.js.map","import CramCodec from './_base';\nimport { tinyMemoize } from '../util';\nexport default class ByteArrayStopCodec extends CramCodec {\n    constructor(parameters, dataType, instantiateCodec) {\n        super(parameters, dataType);\n        this.instantiateCodec = instantiateCodec;\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const lengthCodec = this._getLengthCodec();\n        const arrayLength = lengthCodec.decode(slice, coreDataBlock, blocksByContentId, cursors) || 0;\n        const dataCodec = this._getDataCodec();\n        const data = new Uint8Array(arrayLength);\n        for (let i = 0; i < arrayLength; i += 1) {\n            data[i] =\n                dataCodec.decode(slice, coreDataBlock, blocksByContentId, cursors) || 0;\n        }\n        return data;\n    }\n    // memoize\n    _getLengthCodec() {\n        const encodingParams = this.parameters.lengthsEncoding;\n        return this.instantiateCodec(encodingParams, 'int');\n    }\n    // memoize\n    _getDataCodec() {\n        const encodingParams = this.parameters.valuesEncoding;\n        return this.instantiateCodec(encodingParams, 'byte');\n    }\n}\n'_getLengthCodec _getDataCodec'.split(' ').forEach(method => {\n    tinyMemoize(ByteArrayStopCodec, method);\n});\n//# sourceMappingURL=byteArrayLength.js.map","import CramCodec from './_base';\nimport { CramMalformedError } from '../../errors';\nimport { CramBufferOverrunError } from './getBits';\nexport default class ByteArrayStopCodec extends CramCodec {\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const { blockContentId } = this.parameters;\n        const contentBlock = blocksByContentId[blockContentId];\n        if (!contentBlock) {\n            throw new CramMalformedError(`no block found with content ID ${blockContentId}`);\n        }\n        const cursor = cursors.externalBlocks.getCursor(blockContentId);\n        return this._decodeByteArray(contentBlock, cursor);\n    }\n    _decodeByteArray(contentBlock, cursor) {\n        const dataBuffer = contentBlock.content;\n        const { stopByte } = this.parameters;\n        // scan to the next stop byte\n        const startPosition = cursor.bytePosition;\n        let stopPosition = cursor.bytePosition;\n        while (dataBuffer[stopPosition] !== stopByte &&\n            stopPosition < dataBuffer.length) {\n            if (stopPosition === dataBuffer.length) {\n                throw new CramBufferOverrunError('byteArrayStop reading beyond length of data buffer?');\n            }\n            stopPosition = stopPosition + 1;\n        }\n        cursor.bytePosition = stopPosition + 1;\n        return dataBuffer.subarray(startPosition, stopPosition);\n    }\n}\n//# sourceMappingURL=byteArrayStop.js.map","import CramCodec from './_base';\nimport { CramUnimplementedError } from '../../errors';\nimport { parseItf8 } from '../util';\nimport { CramBufferOverrunError } from './getBits';\nexport default class ExternalCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType === 'int') {\n            this._decodeData = this._decodeInt;\n        }\n        else if (this.dataType === 'byte') {\n            this._decodeData = this._decodeByte;\n        }\n        else {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by EXTERNAL codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const { blockContentId } = this.parameters;\n        const contentBlock = blocksByContentId[blockContentId];\n        const cursor = cursors.externalBlocks.getCursor(blockContentId);\n        return contentBlock ? this._decodeData(contentBlock, cursor) : undefined;\n    }\n    _decodeInt(contentBlock, cursor) {\n        const [result, bytesRead] = parseItf8(contentBlock.content, cursor.bytePosition);\n        cursor.bytePosition = cursor.bytePosition + bytesRead;\n        return result;\n    }\n    _decodeByte(contentBlock, cursor) {\n        if (cursor.bytePosition >= contentBlock.content.length) {\n            throw new CramBufferOverrunError('attempted to read beyond end of block. this file seems truncated.');\n        }\n        return contentBlock.content[cursor.bytePosition++];\n    }\n}\n//# sourceMappingURL=external.js.map","import CramCodec from './_base';\nimport { getBits } from './getBits';\nimport { CramUnimplementedError } from '../../errors';\nexport default class GammaCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType !== 'int') {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by GAMMA codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        let length = 1;\n        while (getBits(coreDataBlock.content, cursors.coreBlock, 1) === 0) {\n            length = length + 1;\n        }\n        const readBits = getBits(coreDataBlock.content, cursors.coreBlock, length - 1);\n        const value = readBits | (1 << (length - 1));\n        return value - this.parameters.offset;\n    }\n}\n//# sourceMappingURL=gamma.js.map","import CramCodec from './_base';\nimport { getBits } from './getBits';\nimport { CramMalformedError } from '../../errors';\nfunction numberOfSetBits(ii) {\n    let i = (ii - (ii >> 1)) & 0x55555555;\n    i = (i & 0x33333333) + ((i >> 2) & 0x33333333);\n    return (((i + (i >> 4)) & 0x0f0f0f0f) * 0x01010101) >> 24;\n}\nexport default class HuffmanIntCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        this.codes = {};\n        this.codeBook = {};\n        this.sortedCodes = [];\n        this.sortedValuesByBitCode = [];\n        this.sortedBitCodes = [];\n        this.sortedBitLengthsByBitCode = [];\n        this.bitCodeToValue = [];\n        if (!['byte', 'int'].includes(this.dataType)) {\n            throw new TypeError(`${this.dataType} decoding not yet implemented by HUFFMAN_INT codec`);\n        }\n        this.buildCodeBook();\n        this.buildCodes();\n        this.buildCaches();\n        // if this is a degenerate zero-length huffman code, special-case the\n        // decoding\n        if (this.sortedCodes[0].bitLength === 0) {\n            this._decode = this._decodeZeroLengthCode;\n        }\n    }\n    buildCodeBook() {\n        // parse the parameters together into a `codes` data structure\n        let codes = new Array(this.parameters.numCodes);\n        for (let i = 0; i < this.parameters.numCodes; i++) {\n            codes[i] = {\n                symbol: this.parameters.symbols[i],\n                bitLength: this.parameters.bitLengths[i],\n            };\n        }\n        // sort the codes by bit length and symbol value\n        codes = codes.sort((a, b) => a.bitLength - b.bitLength || a.symbol - b.symbol);\n        this.codeBook = {};\n        codes.forEach(code => {\n            if (!this.codeBook[code.bitLength]) {\n                this.codeBook[code.bitLength] = [];\n            }\n            this.codeBook[code.bitLength].push(code.symbol);\n        });\n    }\n    buildCodes() {\n        this.codes = {}; /*  new TreeMap<Integer, HuffmanBitCode>(); */\n        let codeLength = 0;\n        let codeValue = -1;\n        Object.entries(this.codeBook).forEach(([bitLength, symbols]) => {\n            const bitLengthInt = Number.parseInt(bitLength, 10);\n            symbols.forEach(symbol => {\n                const code = {\n                    bitLength: bitLengthInt,\n                    value: symbol,\n                    bitCode: 0,\n                };\n                codeValue = codeValue + 1;\n                const delta = bitLengthInt - codeLength; // new length?\n                codeValue = codeValue << delta; // pad with 0's\n                code.bitCode = codeValue; // calculated: huffman code\n                codeLength = codeLength + delta; // adjust current code length\n                if (numberOfSetBits(codeValue) > bitLengthInt) {\n                    throw new CramMalformedError('Symbol out of range');\n                }\n                this.codes[symbol] = code;\n            });\n        });\n    }\n    buildCaches() {\n        this.sortedCodes = Object.values(this.codes).sort((a, b) => a.bitLength - b.bitLength || a.bitCode - b.bitCode);\n        this.sortedValuesByBitCode = this.sortedCodes.map(c => c.value);\n        this.sortedBitCodes = this.sortedCodes.map(c => c.bitCode);\n        this.sortedBitLengthsByBitCode = this.sortedCodes.map(c => c.bitLength);\n        const maxBitCode = Math.max(...this.sortedBitCodes);\n        this.bitCodeToValue = new Array(maxBitCode + 1).fill(-1);\n        for (let i = 0; i < this.sortedBitCodes.length; i += 1) {\n            this.bitCodeToValue[this.sortedCodes[i].bitCode] = i;\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        return this._decode(slice, coreDataBlock, cursors.coreBlock);\n    }\n    // _decodeNull() {\n    //   return -1\n    // }\n    // the special case for zero-length codes\n    _decodeZeroLengthCode() {\n        return this.sortedCodes[0].value;\n    }\n    _decode(slice, coreDataBlock, coreCursor) {\n        const input = coreDataBlock.content;\n        let prevLen = 0;\n        let bits = 0;\n        for (let i = 0; i < this.sortedCodes.length; i += 1) {\n            const length = this.sortedCodes[i].bitLength;\n            bits <<= length - prevLen;\n            bits |= getBits(input, coreCursor, length - prevLen);\n            prevLen = length;\n            {\n                const index = this.bitCodeToValue[bits];\n                if (index > -1 && this.sortedBitLengthsByBitCode[index] === length) {\n                    return this.sortedValuesByBitCode[index];\n                }\n                for (let j = i; this.sortedCodes[j + 1].bitLength === length &&\n                    j < this.sortedCodes.length; j += 1) {\n                    i += 1;\n                }\n            }\n        }\n        throw new CramMalformedError('Huffman symbol not found.');\n    }\n}\n//# sourceMappingURL=huffman.js.map","import CramCodec from './_base';\nimport { getBits } from './getBits';\nimport { CramUnimplementedError } from '../../errors';\nexport default class SubexpCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType !== 'int') {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by SUBEXP codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        let numLeadingOnes = 0;\n        while (getBits(coreDataBlock.content, cursors.coreBlock, 1)) {\n            numLeadingOnes = numLeadingOnes + 1;\n        }\n        let b;\n        let n;\n        if (numLeadingOnes === 0) {\n            b = this.parameters.K;\n            n = getBits(coreDataBlock.content, cursors.coreBlock, b);\n        }\n        else {\n            b = numLeadingOnes + this.parameters.K - 1;\n            const bits = getBits(coreDataBlock.content, cursors.coreBlock, b);\n            n = (1 << b) | bits;\n        }\n        return n - this.parameters.offset;\n    }\n}\n//# sourceMappingURL=subexp.js.map","import BetaCodec from './beta';\nimport ByteArrayLengthCodec from './byteArrayLength';\nimport ByteArrayStopCodec from './byteArrayStop';\nimport ExternalCodec from './external';\nimport GammaCodec from './gamma';\nimport HuffmanIntCodec from './huffman';\nimport SubexpCodec from './subexp';\nimport { CramUnimplementedError } from '../../errors';\nconst codecClasses = {\n    1: ExternalCodec,\n    // 2: GolombCodec,\n    3: HuffmanIntCodec,\n    4: ByteArrayLengthCodec,\n    5: ByteArrayStopCodec,\n    6: BetaCodec,\n    7: SubexpCodec,\n    // 8: GolombRiceCodec,\n    9: GammaCodec,\n};\nfunction getCodecClassWithId(id) {\n    return codecClasses[id];\n}\nexport function instantiateCodec(encodingData, dataType) {\n    const CodecClass = getCodecClassWithId(dataType === 'ignore' ? 0 : encodingData.codecId);\n    if (!CodecClass) {\n        throw new CramUnimplementedError(`no codec implemented for codec ID ${encodingData.codecId}`);\n    }\n    return new CodecClass(encodingData.parameters, dataType, instantiateCodec);\n}\n//# sourceMappingURL=index.js.map","import { CramMalformedError } from '../../errors';\nimport { instantiateCodec } from '../codecs';\n// the hardcoded data type to be decoded for each core\n// data field\nconst dataSeriesTypes = {\n    BF: 'int',\n    CF: 'int',\n    RI: 'int',\n    RL: 'int',\n    AP: 'int',\n    RG: 'int',\n    MF: 'int',\n    NS: 'int',\n    NP: 'int',\n    TS: 'int',\n    NF: 'int',\n    TC: 'byte',\n    TN: 'int',\n    FN: 'int',\n    FC: 'byte',\n    FP: 'int',\n    BS: 'byte',\n    IN: 'byteArray',\n    SC: 'byteArray',\n    DL: 'int',\n    BA: 'byte',\n    BB: 'byteArray',\n    RS: 'int',\n    PD: 'int',\n    HC: 'int',\n    MQ: 'int',\n    RN: 'byteArray',\n    QS: 'byte',\n    QQ: 'byteArray',\n    TL: 'int',\n    // TM: 'ignore',\n    // TV: 'ignore',\n};\nfunction parseSubstitutionMatrix(byteArray) {\n    const matrix = new Array(5);\n    for (let i = 0; i < 5; i += 1) {\n        matrix[i] = new Array(4);\n    }\n    matrix[0][(byteArray[0] >> 6) & 3] = 'C';\n    matrix[0][(byteArray[0] >> 4) & 3] = 'G';\n    matrix[0][(byteArray[0] >> 2) & 3] = 'T';\n    matrix[0][(byteArray[0] >> 0) & 3] = 'N';\n    matrix[1][(byteArray[1] >> 6) & 3] = 'A';\n    matrix[1][(byteArray[1] >> 4) & 3] = 'G';\n    matrix[1][(byteArray[1] >> 2) & 3] = 'T';\n    matrix[1][(byteArray[1] >> 0) & 3] = 'N';\n    matrix[2][(byteArray[2] >> 6) & 3] = 'A';\n    matrix[2][(byteArray[2] >> 4) & 3] = 'C';\n    matrix[2][(byteArray[2] >> 2) & 3] = 'T';\n    matrix[2][(byteArray[2] >> 0) & 3] = 'N';\n    matrix[3][(byteArray[3] >> 6) & 3] = 'A';\n    matrix[3][(byteArray[3] >> 4) & 3] = 'C';\n    matrix[3][(byteArray[3] >> 2) & 3] = 'G';\n    matrix[3][(byteArray[3] >> 0) & 3] = 'N';\n    matrix[4][(byteArray[4] >> 6) & 3] = 'A';\n    matrix[4][(byteArray[4] >> 4) & 3] = 'C';\n    matrix[4][(byteArray[4] >> 2) & 3] = 'G';\n    matrix[4][(byteArray[4] >> 0) & 3] = 'T';\n    return matrix;\n}\nexport default class CramContainerCompressionScheme {\n    constructor(content) {\n        this.dataSeriesCodecCache = {};\n        this.tagCodecCache = {};\n        this.tagEncoding = {};\n        // interpret some of the preservation map tags for convenient use\n        this.readNamesIncluded = content.preservation.RN;\n        this.APdelta = content.preservation.AP;\n        this.referenceRequired = !!content.preservation.RR;\n        this.tagIdsDictionary = content.preservation.TD;\n        this.substitutionMatrix = parseSubstitutionMatrix(content.preservation.SM);\n        this.dataSeriesEncoding = content.dataSeriesEncoding;\n        this.tagEncoding = content.tagEncoding;\n    }\n    /**\n     * @param {string} tagName three-character tag name\n     * @private\n     */\n    getCodecForTag(tagName) {\n        const test = this.tagCodecCache[tagName];\n        if (!test) {\n            const encodingData = this.tagEncoding[tagName];\n            if (!encodingData) {\n                throw new Error('Error, no tag encoding');\n            }\n            const ret = instantiateCodec(encodingData, 'byteArray');\n            this.tagCodecCache[tagName] = ret;\n            return ret;\n        }\n        else {\n            return test;\n        }\n    }\n    /**\n     *\n     * @param {number} tagListId ID of the tag list to fetch from the tag dictionary\n     * @private\n     */\n    getTagNames(tagListId) {\n        return this.tagIdsDictionary[tagListId];\n    }\n    getCodecForDataSeries(dataSeriesName) {\n        let r = this.dataSeriesCodecCache[dataSeriesName];\n        if (r === undefined) {\n            const encodingData = this.dataSeriesEncoding[dataSeriesName];\n            // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n            if (encodingData) {\n                const dataType = dataSeriesTypes[dataSeriesName];\n                // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n                if (!dataType) {\n                    throw new CramMalformedError(`data series name ${dataSeriesName} not defined in file compression header`);\n                }\n                r = instantiateCodec(encodingData, dataType);\n                // didn't find a way to make TS understand this\n                this.dataSeriesCodecCache[dataSeriesName] = r;\n            }\n        }\n        return r;\n    }\n    toJSON() {\n        const data = {};\n        Object.keys(this).forEach(k => {\n            if (k.endsWith('Cache')) {\n                return;\n            }\n            data[k] = this[k];\n        });\n        return data;\n    }\n}\n//# sourceMappingURL=compressionScheme.js.map","import { CramMalformedError } from '../../errors';\n// locals\nimport CramSlice from '../slice';\nimport { itf8Size, parseItem, tinyMemoize } from '../util';\nimport CramContainerCompressionScheme from './compressionScheme';\nimport { getSectionParsers } from '../sectionParsers';\nexport default class CramContainer {\n    constructor(file, filePosition) {\n        this.file = file;\n        this.filePosition = filePosition;\n    }\n    getHeader() {\n        return this._readContainerHeader(this.filePosition);\n    }\n    async getCompressionHeaderBlock() {\n        const containerHeader = await this.getHeader();\n        // if there are no records in the container, there will be no compression\n        // header\n        if (!containerHeader.numRecords) {\n            return null;\n        }\n        const { majorVersion } = await this.file.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const block = await this.getFirstBlock();\n        if (block.contentType !== 'COMPRESSION_HEADER') {\n            throw new CramMalformedError(`invalid content type ${block.contentType} in compression header block`);\n        }\n        const content = parseItem(block.content, sectionParsers.cramCompressionHeader.parser, 0, block.contentPosition);\n        return {\n            ...block,\n            parsedContent: content,\n        };\n    }\n    async getFirstBlock() {\n        const containerHeader = await this.getHeader();\n        return this.file.readBlock(containerHeader._endPosition);\n    }\n    // parses the compression header data into a CramContainerCompressionScheme\n    // object\n    async getCompressionScheme() {\n        const header = await this.getCompressionHeaderBlock();\n        if (!header) {\n            return undefined;\n        }\n        return new CramContainerCompressionScheme(header.parsedContent);\n    }\n    getSlice(slicePosition, sliceSize) {\n        // note: slicePosition is relative to the end of the container header\n        // TODO: perhaps we should cache slices?\n        return new CramSlice(this, slicePosition, sliceSize);\n    }\n    async _readContainerHeader(position) {\n        const { majorVersion } = await this.file.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const { cramContainerHeader1, cramContainerHeader2 } = sectionParsers;\n        // parse the container header. do it in 2 pieces because you cannot tell\n        // how much to buffer until you read numLandmarks\n        const bytes1 = await this.file.read(cramContainerHeader1.maxLength, position);\n        const header1 = parseItem(bytes1, cramContainerHeader1.parser);\n        const numLandmarksSize = itf8Size(header1.numLandmarks);\n        const bytes2 = await this.file.read(cramContainerHeader2.maxLength(header1.numLandmarks), position + header1._size - numLandmarksSize);\n        const header2 = parseItem(bytes2, cramContainerHeader2.parser);\n        if (this.file.validateChecksums && header2.crc32 !== undefined) {\n            await this.file.checkCrc32(position, header1._size + header2._size - numLandmarksSize - 4, header2.crc32, `container header beginning at position ${position}`);\n        }\n        return {\n            ...header1,\n            ...header2,\n            _size: header1._size + header2._size - numLandmarksSize,\n            _endPosition: header1._size + header2._size - numLandmarksSize + position,\n        };\n    }\n}\n'getHeader getCompressionHeaderBlock getCompressionScheme'\n    .split(' ')\n    .forEach(method => {\n    tinyMemoize(CramContainer, method);\n});\n//# sourceMappingURL=index.js.map","import crc32 from 'crc/calculators/crc32';\nimport QuickLRU from 'quick-lru';\nimport { XzReadableStream } from 'xz-decompress';\nimport { CramMalformedError, CramUnimplementedError } from '../errors';\nimport * as htscodecs from '../htscodecs';\nimport { open } from '../io';\nimport ransuncompress from '../rans';\nimport { parseHeaderText } from '../sam';\nimport { decode } from '../seek-bzip';\nimport { unzip } from '../unzip';\nimport CramContainer from './container';\nimport { cramFileDefinition, getSectionParsers, } from './sectionParsers';\nimport { parseItem, tinyMemoize } from './util';\nfunction bufferToStream(buf) {\n    return new ReadableStream({\n        start(controller) {\n            controller.enqueue(buf);\n            controller.close();\n        },\n    });\n}\n// source: https://abdulapopoola.com/2019/01/20/check-endianness-with-javascript/\nfunction getEndianness() {\n    const uInt32 = new Uint32Array([0x11223344]);\n    const uInt8 = new Uint8Array(uInt32.buffer);\n    if (uInt8[0] === 0x44) {\n        return 0; // little-endian\n    }\n    else if (uInt8[0] === 0x11) {\n        return 1; // big-endian\n    }\n    else {\n        return 2; // mixed-endian?\n    }\n}\nexport default class CramFile {\n    constructor(args) {\n        this.file = open(args.url, args.path, args.filehandle);\n        this.validateChecksums = true;\n        this.fetchReferenceSequenceCallback = args.seqFetch;\n        this.options = {\n            checkSequenceMD5: args.checkSequenceMD5,\n            cacheSize: args.cacheSize ?? 20000,\n        };\n        // cache of features in a slice, keyed by the slice offset. caches all of\n        // the features in a slice, or none. the cache is actually used by the\n        // slice object, it's just kept here at the level of the file\n        this.featureCache = new QuickLRU({\n            maxSize: this.options.cacheSize,\n        });\n        if (getEndianness() > 0) {\n            throw new Error('Detected big-endian machine, may be unable to run');\n        }\n    }\n    read(length, position) {\n        return this.file.read(length, position);\n    }\n    // memoized\n    async getDefinition() {\n        const { maxLength, parser } = cramFileDefinition();\n        const headbytes = await this.file.read(maxLength, 0);\n        const definition = parser(headbytes).value;\n        if (definition.majorVersion !== 2 && definition.majorVersion !== 3) {\n            throw new CramUnimplementedError(`CRAM version ${definition.majorVersion} not supported`);\n        }\n        return definition;\n    }\n    // memoize\n    async getSamHeader() {\n        const firstContainer = await this.getContainerById(0);\n        if (!firstContainer) {\n            throw new CramMalformedError('file contains no containers');\n        }\n        const firstBlock = await firstContainer.getFirstBlock();\n        const content = firstBlock.content;\n        const dataView = new DataView(content.buffer);\n        const headerLength = dataView.getInt32(0, true);\n        const textStart = 4;\n        const decoder = new TextDecoder('utf8');\n        const text = decoder.decode(content.subarray(textStart, textStart + headerLength));\n        this.header = text;\n        return parseHeaderText(text);\n    }\n    async getHeaderText() {\n        await this.getSamHeader();\n        return this.header;\n    }\n    async getContainerById(containerNumber) {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        let position = sectionParsers.cramFileDefinition.maxLength;\n        // skip with a series of reads to the proper container\n        let currentContainer;\n        for (let i = 0; i <= containerNumber; i++) {\n            // if we are about to go off the end of the file\n            // and have not found that container, it does not exist\n            // if (position + cramContainerHeader1.maxLength + 8 >= fileSize) {\n            //   return undefined\n            // }\n            currentContainer = this.getContainerAtPosition(position);\n            const currentHeader = await currentContainer.getHeader();\n            // if this is the first container, read all the blocks in the container\n            // to determine its length, because we cannot trust the container\n            // header's given length due to a bug somewhere in htslib\n            if (i === 0) {\n                position = currentHeader._endPosition;\n                for (let j = 0; j < currentHeader.numBlocks; j++) {\n                    const block = await this.readBlock(position);\n                    position = block._endPosition;\n                }\n            }\n            else {\n                // otherwise, just traverse to the next container using the container's\n                // length\n                position += currentHeader._size + currentHeader.length;\n            }\n        }\n        return currentContainer;\n    }\n    async checkCrc32(position, length, recordedCrc32, description) {\n        const b = await this.file.read(length, position);\n        // this shift >>> 0 is equivalent to crc32(b).unsigned but uses the\n        // internal calculator of crc32 to avoid accidentally importing buffer\n        // https://github.com/alexgorbatchev/crc/blob/31fc3853e417b5fb5ec83335428805842575f699/src/define_crc.ts#L5\n        const calculatedCrc32 = crc32(b) >>> 0;\n        if (calculatedCrc32 !== recordedCrc32) {\n            throw new CramMalformedError(`crc mismatch in ${description}: recorded CRC32 = ${recordedCrc32}, but calculated CRC32 = ${calculatedCrc32}`);\n        }\n    }\n    /**\n     * @returns {Promise[number]} the number of containers in the file\n     *\n     * note: this is currently used only in unit tests, and after removing file\n     * length check, relies on a try catch to read return an error to break\n     */\n    async containerCount() {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        let containerCount = 0;\n        let position = sectionParsers.cramFileDefinition.maxLength;\n        try {\n            // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n            while (true) {\n                const currentHeader = await this.getContainerAtPosition(position).getHeader();\n                // if this is the first container, read all the blocks in the container,\n                // because we cannot trust the container header's given length due to a\n                // bug somewhere in htslib\n                if (containerCount === 0) {\n                    position = currentHeader._endPosition;\n                    for (let j = 0; j < currentHeader.numBlocks; j++) {\n                        const block = await this.readBlock(position);\n                        position = block._endPosition;\n                    }\n                }\n                else {\n                    // otherwise, just traverse to the next container using the container's\n                    // length\n                    position += currentHeader._size + currentHeader.length;\n                }\n                containerCount += 1;\n            }\n        }\n        catch (e) {\n            containerCount--;\n            /* do nothing */\n        }\n        return containerCount;\n    }\n    getContainerAtPosition(position) {\n        return new CramContainer(this, position);\n    }\n    async readBlockHeader(position) {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const { cramBlockHeader } = sectionParsers;\n        const buffer = await this.file.read(cramBlockHeader.maxLength, position);\n        return parseItem(buffer, cramBlockHeader.parser, 0, position);\n    }\n    async _parseSection(section, position, size = section.maxLength, preReadBuffer) {\n        const buffer = preReadBuffer ?? (await this.file.read(size, position));\n        const data = parseItem(buffer, section.parser, 0, position);\n        if (data._size !== size) {\n            throw new CramMalformedError(`section read error: requested size ${size} does not equal parsed size ${data._size}`);\n        }\n        return data;\n    }\n    async _uncompressPre(compressionMethod, inputBuffer, uncompressedSize) {\n        // console.log({ compressionMethod })\n        if (compressionMethod === 'gzip') {\n            const ret = unzip(inputBuffer);\n            if (ret[0] === 24) {\n                // console.log(ret.slice(0, 500).join(','))\n            }\n            return ret;\n        }\n        else if (compressionMethod === 'bzip2') {\n            return decode(inputBuffer);\n        }\n        else if (compressionMethod === 'lzma') {\n            const decompressedResponse = new Response(new XzReadableStream(bufferToStream(inputBuffer)));\n            return new Uint8Array(await decompressedResponse.arrayBuffer());\n        }\n        else if (compressionMethod === 'rans') {\n            const outputBuffer = new Uint8Array(uncompressedSize);\n            ransuncompress(inputBuffer, outputBuffer);\n            return outputBuffer;\n            // htscodecs r4x8 is slower, but compatible.\n            // htscodecs.r4x8_uncompress(inputBuffer, outputBuffer);\n        }\n        else if (compressionMethod === 'rans4x16') {\n            return htscodecs.r4x16_uncompress(inputBuffer);\n        }\n        else if (compressionMethod === 'arith') {\n            return htscodecs.arith_uncompress(inputBuffer);\n        }\n        else if (compressionMethod === 'fqzcomp') {\n            return htscodecs.fqzcomp_uncompress(inputBuffer);\n        }\n        else if (compressionMethod === 'tok3') {\n            return htscodecs.tok3_uncompress(inputBuffer);\n        }\n        else {\n            throw new CramUnimplementedError(`${compressionMethod} decompression not yet implemented`);\n        }\n    }\n    async _uncompress(compressionMethod, inputBuffer, uncompressedSize) {\n        const buf = await this._uncompressPre(compressionMethod, inputBuffer, uncompressedSize);\n        if (buf.length !== uncompressedSize) {\n            const ret = new Uint8Array(uncompressedSize);\n            ret.set(buf, 0);\n            return ret;\n        }\n        return buf;\n    }\n    async readBlock(position) {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const blockHeader = await this.readBlockHeader(position);\n        const blockContentPosition = blockHeader._endPosition;\n        const d = await this.file.read(blockHeader.compressedSize, blockContentPosition);\n        const uncompressedData = blockHeader.compressionMethod !== 'raw'\n            ? await this._uncompress(blockHeader.compressionMethod, d, blockHeader.uncompressedSize)\n            : d;\n        const block = {\n            ...blockHeader,\n            _endPosition: blockContentPosition,\n            contentPosition: blockContentPosition,\n            content: uncompressedData,\n        };\n        if (majorVersion >= 3) {\n            // parse the crc32\n            const crc = await this._parseSection(sectionParsers.cramBlockCrc32, blockContentPosition + blockHeader.compressedSize);\n            block.crc32 = crc.crc32;\n            // check the block data crc32\n            if (this.validateChecksums) {\n                await this.checkCrc32(position, blockHeader._size + blockHeader.compressedSize, crc.crc32, 'block data');\n            }\n            // make the endposition and size reflect the whole block\n            block._endPosition = crc._endPosition;\n            block._size =\n                block.compressedSize + sectionParsers.cramBlockCrc32.maxLength;\n        }\n        else {\n            block._endPosition = blockContentPosition + block.compressedSize;\n            block._size = block.compressedSize;\n        }\n        return block;\n    }\n}\n'getDefinition getSectionParsers getSamHeader'.split(' ').forEach(method => {\n    tinyMemoize(CramFile, method);\n});\n//# sourceMappingURL=file.js.map","export { default as CramRecord } from './record';\nexport { default } from './file';\n//# sourceMappingURL=index.js.map","import { CramMalformedError } from './errors';\nimport { open } from './io';\nimport { unzip } from './unzip';\nconst BAI_MAGIC = 21_578_050; // BAI\\1\nfunction addRecordToIndex(index, record) {\n    const [seqId, start, span, containerStart, sliceStart, sliceBytes] = record;\n    const s = seqId;\n    if (!index[s]) {\n        index[s] = [];\n    }\n    index[s].push({\n        start: start,\n        span: span,\n        containerStart: containerStart,\n        sliceStart: sliceStart,\n        sliceBytes: sliceBytes,\n    });\n}\nfunction maybeUnzip(data) {\n    return data[0] === 31 && data[1] === 139 ? unzip(data) : data;\n}\nexport default class CraiIndex {\n    /**\n     *\n     * @param {object} args\n     * @param {string} [args.path]\n     * @param {string} [args.url]\n     * @param {FileHandle} [args.filehandle]\n     */\n    constructor(args) {\n        this.filehandle = open(args.url, args.path, args.filehandle);\n    }\n    async parseIndex() {\n        const index = {};\n        const uncompressedBuffer = maybeUnzip(await this.filehandle.readFile());\n        const dataView = new DataView(uncompressedBuffer.buffer);\n        if (uncompressedBuffer.length > 4 &&\n            dataView.getUint32(0, true) === BAI_MAGIC) {\n            throw new CramMalformedError('invalid .crai index file. note: file appears to be a .bai index. this is technically legal but please open a github issue if you need support');\n        }\n        // interpret the text as regular ascii, since it is supposed to be only\n        // digits and whitespace characters this is written in a deliberately\n        // low-level fashion for performance, because some .crai files can be\n        // pretty large.\n        let currentRecord = [];\n        let currentString = '';\n        for (const charCode of uncompressedBuffer) {\n            if ((charCode >= 48 && charCode <= 57) /* 0-9 */ ||\n                (!currentString && charCode === 45) /* leading - */) {\n                currentString += String.fromCharCode(charCode);\n            }\n            else if (charCode === 9 /* \\t */) {\n                currentRecord.push(Number.parseInt(currentString, 10));\n                currentString = '';\n            }\n            else if (charCode === 10 /* \\n */) {\n                currentRecord.push(Number.parseInt(currentString, 10));\n                currentString = '';\n                addRecordToIndex(index, currentRecord);\n                currentRecord = [];\n            }\n            else if (charCode !== 13 /* \\r */ && charCode !== 32 /* space */) {\n                // if there are other characters in the file besides\n                // space and \\r, something is wrong.\n                throw new CramMalformedError('invalid .crai index file');\n            }\n        }\n        // if the file ends without a \\n, we need to flush our buffers\n        if (currentString) {\n            currentRecord.push(Number.parseInt(currentString, 10));\n        }\n        if (currentRecord.length === 6) {\n            addRecordToIndex(index, currentRecord);\n        }\n        // sort each of them by start\n        Object.entries(index).forEach(([seqId, ent]) => {\n            const e2 = ent;\n            index[seqId] = e2.sort((a, b) => a.start - b.start || a.span - b.span);\n        });\n        return index;\n    }\n    getIndex() {\n        if (!this.parseIndexP) {\n            this.parseIndexP = this.parseIndex().catch((e) => {\n                this.parseIndexP = undefined;\n                throw e;\n            });\n        }\n        return this.parseIndexP;\n    }\n    /**\n     * @param {number} seqId\n     * @returns {Promise} true if the index contains entries for\n     * the given reference sequence ID, false otherwise\n     */\n    async hasDataForReferenceSequence(seqId) {\n        return !!(await this.getIndex())[seqId];\n    }\n    /**\n     * fetch index entries for the given range\n     *\n     * @param {number} seqId\n     * @param {number} queryStart\n     * @param {number} queryEnd\n     *\n     * @returns {Promise} promise for\n     * an array of objects of the form\n     * `{start, span, containerStart, sliceStart, sliceBytes }`\n     */\n    async getEntriesForRange(seqId, queryStart, queryEnd) {\n        const seqEntries = (await this.getIndex())[seqId];\n        if (!seqEntries) {\n            return [];\n        }\n        const compare = (entry) => {\n            const entryStart = entry.start;\n            const entryEnd = entry.start + entry.span;\n            if (entryStart > queryEnd) {\n                return -1;\n            } // entry is ahead of query\n            if (entryEnd <= queryStart) {\n                return 1;\n            } // entry is behind query\n            return 0; // entry overlaps query\n        };\n        const bins = [];\n        for (const entry of seqEntries) {\n            if (compare(entry) === 0) {\n                bins.push(entry);\n            }\n        }\n        return bins;\n    }\n}\n//# sourceMappingURL=craiIndex.js.map","import CramFile from './cramFile';\nimport { CramUnimplementedError } from './errors';\nexport default class IndexedCramFile {\n    /**\n     *\n     * @param {object} args\n     * @param {CramFile} args.cram\n     *\n     * @param {Index-like} args.index object that supports\n     * getEntriesForRange(seqId,start,end) -> Promise[Array[index entries]]\n     *\n     * @param {number} [args.cacheSize] optional maximum number of CRAM records\n     * to cache.  default 20,000\n     *\n     * @param {boolean} [args.checkSequenceMD5] - default true. if false,\n     * disables verifying the MD5 checksum of the reference sequence underlying a\n     * slice. In some applications, this check can cause an inconvenient amount\n     * (many megabases) of sequences to be fetched.\n     */\n    constructor(args) {\n        this.cram =\n            args.cram ??\n                new CramFile({\n                    url: args.cramUrl,\n                    path: args.cramPath,\n                    filehandle: args.cramFilehandle,\n                    seqFetch: args.seqFetch,\n                    checkSequenceMD5: args.checkSequenceMD5,\n                    cacheSize: args.cacheSize,\n                });\n        if (!(this.cram instanceof CramFile)) {\n            throw new Error('invalid arguments: no cramfile');\n        }\n        this.index = args.index;\n    }\n    /**\n     *\n     * @param seq numeric ID of the reference sequence\n     * @param start start of the range of interest. 1-based closed coordinates.\n     * @param end end of the range of interest. 1-based closed coordinates.\n     */\n    async getRecordsForRange(seq, start, end, opts = {}) {\n        opts.viewAsPairs = opts.viewAsPairs || false;\n        opts.pairAcrossChr = opts.pairAcrossChr || false;\n        opts.maxInsertSize = opts.maxInsertSize || 200000;\n        if (typeof seq === 'string') {\n            // TODO: support string reference sequence names somehow\n            throw new CramUnimplementedError('string sequence names not yet supported');\n        }\n        const seqId = seq;\n        const slices = await this.index.getEntriesForRange(seqId, start, end);\n        // fetch all the slices and parse the feature data\n        const sliceResults = await Promise.all(slices.map(slice => this.getRecordsInSlice(slice, feature => feature.sequenceId === seq &&\n            feature.alignmentStart <= end &&\n            feature.lengthOnRef !== undefined &&\n            feature.alignmentStart + feature.lengthOnRef - 1 >= start)));\n        let ret = Array.prototype.concat(...sliceResults);\n        if (opts.viewAsPairs) {\n            const readNames = {};\n            const readIds = {};\n            for (const read of ret) {\n                const name = read.readName;\n                if (name === undefined) {\n                    throw new Error('readName undefined');\n                }\n                const id = read.uniqueId;\n                if (!readNames[name]) {\n                    readNames[name] = 0;\n                }\n                readNames[name] += 1;\n                readIds[id] = 1;\n            }\n            const unmatedPairs = {};\n            Object.entries(readNames).forEach(([k, v]) => {\n                if (v === 1) {\n                    unmatedPairs[k] = true;\n                }\n            });\n            const matePromises = [];\n            for (const cramRecord of ret) {\n                const name = cramRecord.readName;\n                if (name === undefined) {\n                    throw new Error('readName undefined');\n                }\n                if (unmatedPairs[name] &&\n                    cramRecord.mate &&\n                    (cramRecord.mate.sequenceId === seqId || opts.pairAcrossChr) &&\n                    Math.abs(cramRecord.alignmentStart - cramRecord.mate.alignmentStart) <\n                        opts.maxInsertSize) {\n                    const mateSlices = this.index.getEntriesForRange(cramRecord.mate.sequenceId, cramRecord.mate.alignmentStart, cramRecord.mate.alignmentStart + 1);\n                    matePromises.push(mateSlices);\n                }\n            }\n            const mateBlocks = await Promise.all(matePromises);\n            let mateChunks = [];\n            for (const block of mateBlocks) {\n                mateChunks.push(...block);\n            }\n            // filter out duplicates\n            mateChunks = mateChunks\n                .sort((a, b) => a.toString().localeCompare(b.toString()))\n                .filter((item, pos, ary) => !pos || item.toString() !== ary[pos - 1].toString());\n            const mateRecordPromises = [];\n            const mateFeatPromises = [];\n            for (const c of mateChunks) {\n                let recordPromise = this.cram.featureCache.get(c.toString());\n                if (!recordPromise) {\n                    recordPromise = this.getRecordsInSlice(c, () => true);\n                    this.cram.featureCache.set(c.toString(), recordPromise);\n                }\n                mateRecordPromises.push(recordPromise);\n                const featPromise = recordPromise.then(feats => {\n                    const mateRecs = [];\n                    for (const feature of feats) {\n                        if (feature.readName === undefined) {\n                            throw new Error('readName undefined');\n                        }\n                        if (unmatedPairs[feature.readName] && !readIds[feature.uniqueId]) {\n                            mateRecs.push(feature);\n                        }\n                    }\n                    return mateRecs;\n                });\n                mateFeatPromises.push(featPromise);\n            }\n            const newMateFeats = await Promise.all(mateFeatPromises);\n            if (newMateFeats.length) {\n                const newMates = newMateFeats.reduce((result, current) => result.concat(current));\n                ret = ret.concat(newMates);\n            }\n        }\n        return ret;\n    }\n    getRecordsInSlice({ containerStart, sliceStart, sliceBytes, }, filterFunction) {\n        const container = this.cram.getContainerAtPosition(containerStart);\n        const slice = container.getSlice(sliceStart, sliceBytes);\n        return slice.getRecords(filterFunction);\n    }\n    /**\n     *\n     * @param {number} seqId\n     * @returns {Promise} true if the CRAM file contains data for the given\n     * reference sequence numerical ID\n     */\n    hasDataForReferenceSequence(seqId) {\n        return this.index.hasDataForReferenceSequence(seqId);\n    }\n}\n//# sourceMappingURL=indexedCramFile.js.map","export { CramRecord, default as CramFile } from './cramFile';\nexport { default as CraiIndex } from './craiIndex';\nexport { default as IndexedCramFile } from './indexedCramFile';\n//# sourceMappingURL=index.js.map","export function readFeaturesToMismatches(readFeatures, start, qual) {\n    if (!readFeatures) {\n        return [];\n    }\n    const mismatches = new Array(readFeatures.length);\n    let j = 0;\n    let insLen = 0;\n    let refPos = 0;\n    let sublen = 0;\n    let lastPos = start;\n    for (const { refPos: p, code, pos, data, sub, ref } of readFeatures) {\n        sublen = refPos - lastPos;\n        lastPos = refPos;\n        if (sublen && insLen > 0) {\n            mismatches[j++] = {\n                start: refPos,\n                type: 'insertion',\n                base: `${insLen}`,\n                length: 0,\n            };\n            insLen = 0;\n        }\n        refPos = p - 1 - start;\n        if (code === 'X') {\n            mismatches[j++] = {\n                start: refPos,\n                length: 1,\n                base: sub,\n                qual: qual === null || qual === void 0 ? void 0 : qual[pos - 1],\n                altbase: ref === null || ref === void 0 ? void 0 : ref.toUpperCase(),\n                type: 'mismatch',\n            };\n        }\n        else if (code === 'I') {\n            mismatches[j++] = {\n                start: refPos,\n                type: 'insertion',\n                base: `${data.length}`,\n                length: 0,\n            };\n        }\n        else if (code === 'N') {\n            mismatches[j++] = {\n                type: 'skip',\n                length: data,\n                start: refPos,\n                base: 'N',\n            };\n        }\n        else if (code === 'S') {\n            const len = data.length;\n            mismatches[j++] = {\n                start: refPos,\n                type: 'softclip',\n                base: `S${len}`,\n                cliplen: len,\n                length: 1,\n            };\n        }\n        else if (code === 'P') {\n        }\n        else if (code === 'H') {\n            const len = data;\n            mismatches[j++] = {\n                start: refPos,\n                type: 'hardclip',\n                base: `H${len}`,\n                cliplen: len,\n                length: 1,\n            };\n        }\n        else if (code === 'D') {\n            mismatches[j++] = {\n                type: 'deletion',\n                length: data,\n                start: refPos,\n                base: '*',\n            };\n        }\n        else if (code === 'b') {\n        }\n        else if (code === 'q') {\n        }\n        else if (code === 'B') {\n        }\n        else if (code === 'i') {\n            insLen++;\n        }\n        else if (code === 'Q') {\n        }\n    }\n    if (sublen && insLen > 0) {\n        mismatches[j++] = {\n            start: refPos,\n            type: 'insertion',\n            base: `${insLen}`,\n            length: 0,\n        };\n        insLen = 0;\n    }\n    return mismatches.slice(0, j);\n}\nexport function readFeaturesToCIGAR(readFeatures, alignmentStart, readLen, refRegion) {\n    let seq = '';\n    let cigar = '';\n    let op = 'M';\n    let oplen = 0;\n    if (!refRegion) {\n        return '';\n    }\n    const ref = refRegion.seq;\n    const refStart = refRegion.start;\n    let lastPos = alignmentStart;\n    let sublen = 0;\n    let insLen = 0;\n    if (readFeatures !== undefined) {\n        for (const { code, refPos, sub, data } of readFeatures) {\n            sublen = refPos - lastPos;\n            seq += ref.slice(lastPos - refStart, refPos - refStart);\n            lastPos = refPos;\n            if (insLen > 0 && sublen) {\n                cigar += `${insLen}I`;\n                insLen = 0;\n            }\n            if (oplen && op !== 'M') {\n                cigar += `${oplen}${op}`;\n                oplen = 0;\n            }\n            if (sublen) {\n                op = 'M';\n                oplen += sublen;\n            }\n            if (code === 'b') {\n                const ret = data.split(',');\n                const added = String.fromCharCode(...ret);\n                seq += added;\n                lastPos += added.length;\n                oplen += added.length;\n            }\n            else if (code === 'B') {\n                seq += sub;\n                lastPos++;\n                oplen++;\n            }\n            else if (code === 'X') {\n                seq += sub;\n                lastPos++;\n                oplen++;\n            }\n            else if (code === 'D' || code === 'N') {\n                lastPos += data;\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += data + code;\n                oplen = 0;\n            }\n            else if (code === 'I' || code === 'S') {\n                seq += data;\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += data.length + code;\n                oplen = 0;\n            }\n            else if (code === 'i') {\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                insLen++;\n                seq += data;\n                oplen = 0;\n            }\n            else if (code === 'P') {\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += `${data}P`;\n            }\n            else if (code === 'H') {\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += `${data}H`;\n                oplen = 0;\n            }\n        }\n    }\n    else {\n        sublen = readLen - seq.length;\n    }\n    if (seq.length !== readLen) {\n        sublen = readLen - seq.length;\n        seq += ref.slice(lastPos - refStart, lastPos - refStart + sublen);\n        if (oplen && op !== 'M') {\n            cigar += `${oplen}${op}`;\n            oplen = 0;\n        }\n        op = 'M';\n        oplen += sublen;\n    }\n    if (sublen && insLen > 0) {\n        cigar += `${insLen}I`;\n    }\n    if (oplen) {\n        cigar += `${oplen}${op}`;\n    }\n    return cigar;\n}\n","import { readFeaturesToCIGAR, readFeaturesToMismatches } from './util';\nimport { cacheGetter } from '../shared/util';\nexport default class CramSlightlyLazyFeature {\n    constructor(record, _store) {\n        this.record = record;\n        this._store = _store;\n    }\n    get name() {\n        return this.record.readName;\n    }\n    get start() {\n        return this.record.alignmentStart - 1;\n    }\n    get end() {\n        var _a;\n        return this.start + ((_a = this.record.lengthOnRef) !== null && _a !== void 0 ? _a : 1);\n    }\n    get score() {\n        return this.record.mappingQuality;\n    }\n    get flags() {\n        return this.record.flags;\n    }\n    get strand() {\n        return this.record.isReverseComplemented() ? -1 : 1;\n    }\n    get qual() {\n        return (this.record.qualityScores || []).join(' ');\n    }\n    get qualRaw() {\n        return this.record.qualityScores;\n    }\n    get refName() {\n        return this._store.refIdToName(this.record.sequenceId);\n    }\n    get pair_orientation() {\n        return this.record.isPaired() ? this.record.getPairOrientation() : undefined;\n    }\n    get template_length() {\n        return this.record.templateLength || this.record.templateSize;\n    }\n    get next_ref() {\n        return this.record.mate\n            ? this._store.refIdToName(this.record.mate.sequenceId)\n            : undefined;\n    }\n    get next_segment_position() {\n        return this.record.mate\n            ? `${this._store.refIdToName(this.record.mate.sequenceId)}:${this.record.mate.alignmentStart}`\n            : undefined;\n    }\n    get is_paired() {\n        return !!this.record.mate;\n    }\n    get next_pos() {\n        var _a;\n        return (_a = this.record.mate) === null || _a === void 0 ? void 0 : _a.alignmentStart;\n    }\n    get tags() {\n        var _a;\n        const RG = (_a = this._store.samHeader.readGroups) === null || _a === void 0 ? void 0 : _a[this.record.readGroupId];\n        return RG !== undefined ? { ...this.record.tags, RG } : this.record.tags;\n    }\n    get seq() {\n        return this.record.getReadBases();\n    }\n    get CIGAR() {\n        return readFeaturesToCIGAR(this.record.readFeatures, this.record.alignmentStart, this.record.readLength, this.record._refRegion);\n    }\n    id() {\n        return `${this._store.id}-${this.record.uniqueId}`;\n    }\n    get(field) {\n        return field === 'mismatches'\n            ? this.mismatches\n            : field === 'qual'\n                ? this.qual\n                : field === 'CIGAR'\n                    ? this.CIGAR\n                    : this.fields[field];\n    }\n    parent() {\n        return undefined;\n    }\n    children() {\n        return undefined;\n    }\n    get mismatches() {\n        return readFeaturesToMismatches(this.record.readFeatures, this.start, this.qualRaw);\n    }\n    get fields() {\n        return {\n            start: this.start,\n            name: this.name,\n            end: this.end,\n            score: this.score,\n            strand: this.strand,\n            template_length: this.template_length,\n            flags: this.flags,\n            tags: this.tags,\n            refName: this.refName,\n            seq: this.seq,\n            type: 'match',\n            pair_orientation: this.pair_orientation,\n            next_ref: this.next_ref,\n            next_pos: this.next_pos,\n            next_segment_position: this.next_segment_position,\n            uniqueId: this.id(),\n        };\n    }\n    toJSON() {\n        return {\n            ...this.fields,\n            CIGAR: this.CIGAR,\n            qual: this.qual,\n        };\n    }\n}\ncacheGetter(CramSlightlyLazyFeature, 'fields');\ncacheGetter(CramSlightlyLazyFeature, 'CIGAR');\ncacheGetter(CramSlightlyLazyFeature, 'mismatches');\n","import { CraiIndex, IndexedCramFile } from '@gmod/cram';\nimport { BaseFeatureDataAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { toLocale, updateStatus } from '@jbrowse/core/util';\nimport QuickLRU from '@jbrowse/core/util/QuickLRU';\nimport { openLocation } from '@jbrowse/core/util/io';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport { checkStopToken } from '@jbrowse/core/util/stopToken';\nimport { firstValueFrom } from 'rxjs';\nimport { toArray } from 'rxjs/operators';\nimport CramSlightlyLazyFeature from './CramSlightlyLazyFeature';\nimport { filterReadFlag, filterTagValue } from '../shared/util';\nexport default class CramAdapter extends BaseFeatureDataAdapter {\n    constructor() {\n        super(...arguments);\n        this.samHeader = {};\n        this.ultraLongFeatureCache = new QuickLRU({\n            maxSize: 500,\n        });\n        this.seqIdToOriginalRefName = [];\n    }\n    async configurePre() {\n        const cramLocation = this.getConf('cramLocation');\n        const craiLocation = this.getConf('craiLocation');\n        const pm = this.pluginManager;\n        const cram = new IndexedCramFile({\n            cramFilehandle: openLocation(cramLocation, pm),\n            index: new CraiIndex({\n                filehandle: openLocation(craiLocation, pm),\n            }),\n            seqFetch: (...args) => this.seqFetch(...args),\n            checkSequenceMD5: false,\n        });\n        if (!this.getSubAdapter) {\n            throw new Error('Error getting subadapter');\n        }\n        const seqConf = this.getConf('sequenceAdapter');\n        if (!seqConf) {\n            throw new Error('no sequenceAdapter supplied to CramAdapter config');\n        }\n        const subadapter = await this.getSubAdapter(seqConf);\n        return {\n            cram,\n            sequenceAdapter: subadapter.dataAdapter,\n        };\n    }\n    async configure() {\n        if (!this.configureP) {\n            this.configureP = this.configurePre().catch((e) => {\n                this.configureP = undefined;\n                throw e;\n            });\n        }\n        return this.configureP;\n    }\n    async getHeader(_opts) {\n        const { cram } = await this.configure();\n        return cram.cram.getHeaderText();\n    }\n    async seqFetch(seqId, start, end) {\n        start -= 1;\n        const { sequenceAdapter } = await this.configure();\n        const refName = this.refIdToOriginalName(seqId) || this.refIdToName(seqId);\n        if (!refName) {\n            throw new Error('unknown');\n        }\n        const seqChunks = await firstValueFrom(sequenceAdapter\n            .getFeatures({\n            refName,\n            start,\n            end,\n            assemblyName: '',\n        })\n            .pipe(toArray()));\n        const sequence = seqChunks\n            .sort((a, b) => a.get('start') - b.get('start'))\n            .map(chunk => {\n            const chunkStart = chunk.get('start');\n            const chunkEnd = chunk.get('end');\n            const trimStart = Math.max(start - chunkStart, 0);\n            const trimEnd = Math.min(end - chunkStart, chunkEnd - chunkStart);\n            const trimLength = trimEnd - trimStart;\n            const chunkSeq = chunk.get('seq') || chunk.get('residues');\n            return chunkSeq.slice(trimStart, trimStart + trimLength);\n        })\n            .join('');\n        const qlen = end - start;\n        if (sequence.length !== qlen) {\n            throw new Error(`fetching ${refName}:${toLocale(start - 1)}-${toLocale(end)} returned ${toLocale(sequence.length)} bases, should have returned ${toLocale(qlen)}`);\n        }\n        return sequence;\n    }\n    async setupPre(_opts) {\n        const conf = await this.configure();\n        const { cram } = conf;\n        const samHeader = await cram.cram.getSamHeader();\n        const idToName = [];\n        const nameToId = {};\n        for (const [refId, sqLine] of samHeader\n            .filter(l => l.tag === 'SQ')\n            .entries()) {\n            const SN = sqLine.data.find(item => item.tag === 'SN');\n            if (SN) {\n                const refName = SN.value;\n                nameToId[refName] = refId;\n                idToName[refId] = refName;\n            }\n        }\n        const readGroups = samHeader\n            .filter(l => l.tag === 'RG')\n            .map(rgLine => { var _a; return (_a = rgLine.data.find(item => item.tag === 'ID')) === null || _a === void 0 ? void 0 : _a.value; });\n        const data = { idToName, nameToId, readGroups };\n        this.samHeader = data;\n        return {\n            samHeader: data,\n            ...conf,\n        };\n    }\n    async setupPre2(opts) {\n        if (!this.setupP) {\n            this.setupP = this.setupPre(opts).catch((e) => {\n                this.setupP = undefined;\n                throw e;\n            });\n        }\n        return this.setupP;\n    }\n    async setup(opts) {\n        const { statusCallback = () => { } } = opts || {};\n        return updateStatus('Downloading index', statusCallback, () => this.setupPre2(opts));\n    }\n    async getRefNames(opts) {\n        const { samHeader } = await this.setup(opts);\n        if (!samHeader.idToName) {\n            throw new Error('CRAM file has no header lines');\n        }\n        return samHeader.idToName;\n    }\n    refNameToId(refName) {\n        if (this.samHeader.nameToId) {\n            return this.samHeader.nameToId[refName];\n        }\n        if (this.seqIdToRefName) {\n            return this.seqIdToRefName.indexOf(refName);\n        }\n        return undefined;\n    }\n    refIdToName(refId) {\n        var _a, _b;\n        return ((_a = this.samHeader.idToName) === null || _a === void 0 ? void 0 : _a[refId]) || ((_b = this.seqIdToRefName) === null || _b === void 0 ? void 0 : _b[refId]);\n    }\n    refIdToOriginalName(refId) {\n        return this.seqIdToOriginalRefName[refId];\n    }\n    getFeatures(region, opts) {\n        const { stopToken, filterBy, statusCallback = () => { } } = opts || {};\n        const { refName, start, end, originalRefName } = region;\n        return ObservableCreate(async (observer) => {\n            const { cram, samHeader } = await this.setup(opts);\n            const refId = this.refNameToId(refName);\n            if (refId === undefined) {\n                console.warn('Unknown refName', refName);\n                observer.complete();\n                return;\n            }\n            if (originalRefName) {\n                this.seqIdToOriginalRefName[refId] = originalRefName;\n            }\n            const records = await updateStatus('Downloading alignments', statusCallback, () => cram.getRecordsForRange(refId, start, end));\n            checkStopToken(stopToken);\n            await updateStatus('Processing alignments', statusCallback, () => {\n                var _a;\n                const { flagInclude = 0, flagExclude = 0, tagFilter, readName, } = filterBy || {};\n                for (const record of records) {\n                    if (filterReadFlag(record.flags, flagInclude, flagExclude)) {\n                        continue;\n                    }\n                    if (tagFilter &&\n                        filterTagValue(tagFilter.tag === 'RG'\n                            ? (_a = samHeader.readGroups) === null || _a === void 0 ? void 0 : _a[record.readGroupId]\n                            : record.tags[tagFilter.tag], tagFilter.value)) {\n                        continue;\n                    }\n                    if (readName && record.readName !== readName) {\n                        continue;\n                    }\n                    const ret = this.ultraLongFeatureCache.get(`${record.uniqueId}`);\n                    if (!ret) {\n                        const elt = this.cramRecordToFeature(record);\n                        this.ultraLongFeatureCache.set(`${record.uniqueId}`, elt);\n                        observer.next(elt);\n                    }\n                    else {\n                        observer.next(ret);\n                    }\n                }\n                observer.complete();\n            });\n        }, stopToken);\n    }\n    freeResources() { }\n    cramRecordToFeature(record) {\n        return new CramSlightlyLazyFeature(record, this);\n    }\n    async getMultiRegionFeatureDensityStats(regions, opts) {\n        const bytes = await this.bytesForRegions(regions, opts);\n        const fetchSizeLimit = this.getConf('fetchSizeLimit');\n        return {\n            bytes,\n            fetchSizeLimit,\n        };\n    }\n    async bytesForRegions(regions, _opts) {\n        const { cram } = await this.configure();\n        const blockResults = await Promise.all(regions.map(region => {\n            const { refName, start, end } = region;\n            const chrId = this.refNameToId(refName);\n            return chrId !== undefined\n                ? cram.index.getEntriesForRange(chrId, start, end)\n                : [{ sliceBytes: 0 }];\n        }));\n        return blockResults.flat().reduce((a, b) => a + b.sliceBytes, 0);\n    }\n}\n","(function() {\n  var base64map\n      = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',\n\n  crypt = {\n    // Bit-wise rotation left\n    rotl: function(n, b) {\n      return (n << b) | (n >>> (32 - b));\n    },\n\n    // Bit-wise rotation right\n    rotr: function(n, b) {\n      return (n << (32 - b)) | (n >>> b);\n    },\n\n    // Swap big-endian to little-endian and vice versa\n    endian: function(n) {\n      // If number given, swap endian\n      if (n.constructor == Number) {\n        return crypt.rotl(n, 8) & 0x00FF00FF | crypt.rotl(n, 24) & 0xFF00FF00;\n      }\n\n      // Else, assume array and swap all items\n      for (var i = 0; i < n.length; i++)\n        n[i] = crypt.endian(n[i]);\n      return n;\n    },\n\n    // Generate an array of any length of random bytes\n    randomBytes: function(n) {\n      for (var bytes = []; n > 0; n--)\n        bytes.push(Math.floor(Math.random() * 256));\n      return bytes;\n    },\n\n    // Convert a byte array to big-endian 32-bit words\n    bytesToWords: function(bytes) {\n      for (var words = [], i = 0, b = 0; i < bytes.length; i++, b += 8)\n        words[b >>> 5] |= bytes[i] << (24 - b % 32);\n      return words;\n    },\n\n    // Convert big-endian 32-bit words to a byte array\n    wordsToBytes: function(words) {\n      for (var bytes = [], b = 0; b < words.length * 32; b += 8)\n        bytes.push((words[b >>> 5] >>> (24 - b % 32)) & 0xFF);\n      return bytes;\n    },\n\n    // Convert a byte array to a hex string\n    bytesToHex: function(bytes) {\n      for (var hex = [], i = 0; i < bytes.length; i++) {\n        hex.push((bytes[i] >>> 4).toString(16));\n        hex.push((bytes[i] & 0xF).toString(16));\n      }\n      return hex.join('');\n    },\n\n    // Convert a hex string to a byte array\n    hexToBytes: function(hex) {\n      for (var bytes = [], c = 0; c < hex.length; c += 2)\n        bytes.push(parseInt(hex.substr(c, 2), 16));\n      return bytes;\n    },\n\n    // Convert a byte array to a base-64 string\n    bytesToBase64: function(bytes) {\n      for (var base64 = [], i = 0; i < bytes.length; i += 3) {\n        var triplet = (bytes[i] << 16) | (bytes[i + 1] << 8) | bytes[i + 2];\n        for (var j = 0; j < 4; j++)\n          if (i * 8 + j * 6 <= bytes.length * 8)\n            base64.push(base64map.charAt((triplet >>> 6 * (3 - j)) & 0x3F));\n          else\n            base64.push('=');\n      }\n      return base64.join('');\n    },\n\n    // Convert a base-64 string to a byte array\n    base64ToBytes: function(base64) {\n      // Remove non-base-64 characters\n      base64 = base64.replace(/[^A-Z0-9+\\/]/ig, '');\n\n      for (var bytes = [], i = 0, imod4 = 0; i < base64.length;\n          imod4 = ++i % 4) {\n        if (imod4 == 0) continue;\n        bytes.push(((base64map.indexOf(base64.charAt(i - 1))\n            & (Math.pow(2, -2 * imod4 + 8) - 1)) << (imod4 * 2))\n            | (base64map.indexOf(base64.charAt(i)) >>> (6 - imod4 * 2)));\n      }\n      return bytes;\n    }\n  };\n\n  module.exports = crypt;\n})();\n","(function(){\r\n  var crypt = require('crypt'),\r\n      utf8 = require('charenc').utf8,\r\n      isBuffer = require('is-buffer'),\r\n      bin = require('charenc').bin,\r\n\r\n  // The core\r\n  md5 = function (message, options) {\r\n    // Convert to byte array\r\n    if (message.constructor == String)\r\n      if (options && options.encoding === 'binary')\r\n        message = bin.stringToBytes(message);\r\n      else\r\n        message = utf8.stringToBytes(message);\r\n    else if (isBuffer(message))\r\n      message = Array.prototype.slice.call(message, 0);\r\n    else if (!Array.isArray(message) && message.constructor !== Uint8Array)\r\n      message = message.toString();\r\n    // else, assume byte array already\r\n\r\n    var m = crypt.bytesToWords(message),\r\n        l = message.length * 8,\r\n        a =  1732584193,\r\n        b = -271733879,\r\n        c = -1732584194,\r\n        d =  271733878;\r\n\r\n    // Swap endian\r\n    for (var i = 0; i < m.length; i++) {\r\n      m[i] = ((m[i] <<  8) | (m[i] >>> 24)) & 0x00FF00FF |\r\n             ((m[i] << 24) | (m[i] >>>  8)) & 0xFF00FF00;\r\n    }\r\n\r\n    // Padding\r\n    m[l >>> 5] |= 0x80 << (l % 32);\r\n    m[(((l + 64) >>> 9) << 4) + 14] = l;\r\n\r\n    // Method shortcuts\r\n    var FF = md5._ff,\r\n        GG = md5._gg,\r\n        HH = md5._hh,\r\n        II = md5._ii;\r\n\r\n    for (var i = 0; i < m.length; i += 16) {\r\n\r\n      var aa = a,\r\n          bb = b,\r\n          cc = c,\r\n          dd = d;\r\n\r\n      a = FF(a, b, c, d, m[i+ 0],  7, -680876936);\r\n      d = FF(d, a, b, c, m[i+ 1], 12, -389564586);\r\n      c = FF(c, d, a, b, m[i+ 2], 17,  606105819);\r\n      b = FF(b, c, d, a, m[i+ 3], 22, -1044525330);\r\n      a = FF(a, b, c, d, m[i+ 4],  7, -176418897);\r\n      d = FF(d, a, b, c, m[i+ 5], 12,  1200080426);\r\n      c = FF(c, d, a, b, m[i+ 6], 17, -1473231341);\r\n      b = FF(b, c, d, a, m[i+ 7], 22, -45705983);\r\n      a = FF(a, b, c, d, m[i+ 8],  7,  1770035416);\r\n      d = FF(d, a, b, c, m[i+ 9], 12, -1958414417);\r\n      c = FF(c, d, a, b, m[i+10], 17, -42063);\r\n      b = FF(b, c, d, a, m[i+11], 22, -1990404162);\r\n      a = FF(a, b, c, d, m[i+12],  7,  1804603682);\r\n      d = FF(d, a, b, c, m[i+13], 12, -40341101);\r\n      c = FF(c, d, a, b, m[i+14], 17, -1502002290);\r\n      b = FF(b, c, d, a, m[i+15], 22,  1236535329);\r\n\r\n      a = GG(a, b, c, d, m[i+ 1],  5, -165796510);\r\n      d = GG(d, a, b, c, m[i+ 6],  9, -1069501632);\r\n      c = GG(c, d, a, b, m[i+11], 14,  643717713);\r\n      b = GG(b, c, d, a, m[i+ 0], 20, -373897302);\r\n      a = GG(a, b, c, d, m[i+ 5],  5, -701558691);\r\n      d = GG(d, a, b, c, m[i+10],  9,  38016083);\r\n      c = GG(c, d, a, b, m[i+15], 14, -660478335);\r\n      b = GG(b, c, d, a, m[i+ 4], 20, -405537848);\r\n      a = GG(a, b, c, d, m[i+ 9],  5,  568446438);\r\n      d = GG(d, a, b, c, m[i+14],  9, -1019803690);\r\n      c = GG(c, d, a, b, m[i+ 3], 14, -187363961);\r\n      b = GG(b, c, d, a, m[i+ 8], 20,  1163531501);\r\n      a = GG(a, b, c, d, m[i+13],  5, -1444681467);\r\n      d = GG(d, a, b, c, m[i+ 2],  9, -51403784);\r\n      c = GG(c, d, a, b, m[i+ 7], 14,  1735328473);\r\n      b = GG(b, c, d, a, m[i+12], 20, -1926607734);\r\n\r\n      a = HH(a, b, c, d, m[i+ 5],  4, -378558);\r\n      d = HH(d, a, b, c, m[i+ 8], 11, -2022574463);\r\n      c = HH(c, d, a, b, m[i+11], 16,  1839030562);\r\n      b = HH(b, c, d, a, m[i+14], 23, -35309556);\r\n      a = HH(a, b, c, d, m[i+ 1],  4, -1530992060);\r\n      d = HH(d, a, b, c, m[i+ 4], 11,  1272893353);\r\n      c = HH(c, d, a, b, m[i+ 7], 16, -155497632);\r\n      b = HH(b, c, d, a, m[i+10], 23, -1094730640);\r\n      a = HH(a, b, c, d, m[i+13],  4,  681279174);\r\n      d = HH(d, a, b, c, m[i+ 0], 11, -358537222);\r\n      c = HH(c, d, a, b, m[i+ 3], 16, -722521979);\r\n      b = HH(b, c, d, a, m[i+ 6], 23,  76029189);\r\n      a = HH(a, b, c, d, m[i+ 9],  4, -640364487);\r\n      d = HH(d, a, b, c, m[i+12], 11, -421815835);\r\n      c = HH(c, d, a, b, m[i+15], 16,  530742520);\r\n      b = HH(b, c, d, a, m[i+ 2], 23, -995338651);\r\n\r\n      a = II(a, b, c, d, m[i+ 0],  6, -198630844);\r\n      d = II(d, a, b, c, m[i+ 7], 10,  1126891415);\r\n      c = II(c, d, a, b, m[i+14], 15, -1416354905);\r\n      b = II(b, c, d, a, m[i+ 5], 21, -57434055);\r\n      a = II(a, b, c, d, m[i+12],  6,  1700485571);\r\n      d = II(d, a, b, c, m[i+ 3], 10, -1894986606);\r\n      c = II(c, d, a, b, m[i+10], 15, -1051523);\r\n      b = II(b, c, d, a, m[i+ 1], 21, -2054922799);\r\n      a = II(a, b, c, d, m[i+ 8],  6,  1873313359);\r\n      d = II(d, a, b, c, m[i+15], 10, -30611744);\r\n      c = II(c, d, a, b, m[i+ 6], 15, -1560198380);\r\n      b = II(b, c, d, a, m[i+13], 21,  1309151649);\r\n      a = II(a, b, c, d, m[i+ 4],  6, -145523070);\r\n      d = II(d, a, b, c, m[i+11], 10, -1120210379);\r\n      c = II(c, d, a, b, m[i+ 2], 15,  718787259);\r\n      b = II(b, c, d, a, m[i+ 9], 21, -343485551);\r\n\r\n      a = (a + aa) >>> 0;\r\n      b = (b + bb) >>> 0;\r\n      c = (c + cc) >>> 0;\r\n      d = (d + dd) >>> 0;\r\n    }\r\n\r\n    return crypt.endian([a, b, c, d]);\r\n  };\r\n\r\n  // Auxiliary functions\r\n  md5._ff  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (b & c | ~b & d) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n  md5._gg  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (b & d | c & ~d) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n  md5._hh  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (b ^ c ^ d) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n  md5._ii  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (c ^ (b | ~d)) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n\r\n  // Package private blocksize\r\n  md5._blocksize = 16;\r\n  md5._digestsize = 16;\r\n\r\n  module.exports = function (message, options) {\r\n    if (message === undefined || message === null)\r\n      throw new Error('Illegal argument ' + message);\r\n\r\n    var digestbytes = crypt.wordsToBytes(md5(message, options));\r\n    return options && options.asBytes ? digestbytes :\r\n        options && options.asString ? bin.bytesToString(digestbytes) :\r\n        crypt.bytesToHex(digestbytes);\r\n  };\r\n\r\n})();\r\n","/*!\n * Determine if an object is a Buffer\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n\n// The _isBuffer check is for Safari 5-7 support, because it's missing\n// Object.prototype.constructor. Remove this eventually\nmodule.exports = function (obj) {\n  return obj != null && (isBuffer(obj) || isSlowBuffer(obj) || !!obj._isBuffer)\n}\n\nfunction isBuffer (obj) {\n  return !!obj.constructor && typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)\n}\n\n// For Node v0.10 support. Remove this eventually.\nfunction isSlowBuffer (obj) {\n  return typeof obj.readFloatLE === 'function' && typeof obj.slice === 'function' && isBuffer(obj.slice(0, 0))\n}\n","\"use strict\";\n// @ts-nocheck\n/* CRC32, used in Bzip2 implementation.\n * This is a port of CRC32.java from the jbzip2 implementation at\n *   https://code.google.com/p/jbzip2\n * which is:\n *   Copyright (c) 2011 Matthew Francis\n *\n *   Permission is hereby granted, free of charge, to any person\n *   obtaining a copy of this software and associated documentation\n *   files (the \"Software\"), to deal in the Software without\n *   restriction, including without limitation the rights to use,\n *   copy, modify, merge, publish, distribute, sublicense, and/or sell\n *   copies of the Software, and to permit persons to whom the\n *   Software is furnished to do so, subject to the following\n *   conditions:\n *\n *   The above copyright notice and this permission notice shall be\n *   included in all copies or substantial portions of the Software.\n *\n *   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n *   EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n *   OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n *   NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n *   HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n *   WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n *   FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n *   OTHER DEALINGS IN THE SOFTWARE.\n * This JavaScript implementation is:\n *   Copyright (c) 2013 C. Scott Ananian\n * with the same licensing terms as Matthew Francis' original implementation.\n */\nmodule.exports = (function () {\n    /**\n     * A static CRC lookup table\n     */\n    const crc32Lookup = new Uint32Array([\n        0x00000000, 0x04c11db7, 0x09823b6e, 0x0d4326d9, 0x130476dc, 0x17c56b6b,\n        0x1a864db2, 0x1e475005, 0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61,\n        0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd, 0x4c11db70, 0x48d0c6c7,\n        0x4593e01e, 0x4152fda9, 0x5f15adac, 0x5bd4b01b, 0x569796c2, 0x52568b75,\n        0x6a1936c8, 0x6ed82b7f, 0x639b0da6, 0x675a1011, 0x791d4014, 0x7ddc5da3,\n        0x709f7b7a, 0x745e66cd, 0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039,\n        0x8b27c03c, 0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5, 0xbe2b5b58, 0xbaea46ef,\n        0xb7a96036, 0xb3687d81, 0xad2f2d84, 0xa9ee3033, 0xa4ad16ea, 0xa06c0b5d,\n        0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49, 0xc7361b4c, 0xc3f706fb,\n        0xceb42022, 0xca753d95, 0xf23a8028, 0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1,\n        0xe13ef6f4, 0xe5ffeb43, 0xe8bccd9a, 0xec7dd02d, 0x34867077, 0x30476dc0,\n        0x3d044b19, 0x39c556ae, 0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072,\n        0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16, 0x018aeb13, 0x054bf6a4,\n        0x0808d07d, 0x0cc9cdca, 0x7897ab07, 0x7c56b6b0, 0x71159069, 0x75d48dde,\n        0x6b93dddb, 0x6f52c06c, 0x6211e6b5, 0x66d0fb02, 0x5e9f46bf, 0x5a5e5b08,\n        0x571d7dd1, 0x53dc6066, 0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba,\n        0xaca5c697, 0xa864db20, 0xa527fdf9, 0xa1e6e04e, 0xbfa1b04b, 0xbb60adfc,\n        0xb6238b25, 0xb2e29692, 0x8aad2b2f, 0x8e6c3698, 0x832f1041, 0x87ee0df6,\n        0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a, 0xe0b41de7, 0xe4750050,\n        0xe9362689, 0xedf73b3e, 0xf3b06b3b, 0xf771768c, 0xfa325055, 0xfef34de2,\n        0xc6bcf05f, 0xc27dede8, 0xcf3ecb31, 0xcbffd686, 0xd5b88683, 0xd1799b34,\n        0xdc3abded, 0xd8fba05a, 0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637,\n        0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb, 0x4f040d56, 0x4bc510e1,\n        0x46863638, 0x42472b8f, 0x5c007b8a, 0x58c1663d, 0x558240e4, 0x51435d53,\n        0x251d3b9e, 0x21dc2629, 0x2c9f00f0, 0x285e1d47, 0x36194d42, 0x32d850f5,\n        0x3f9b762c, 0x3b5a6b9b, 0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff,\n        0x1011a0fa, 0x14d0bd4d, 0x19939b94, 0x1d528623, 0xf12f560e, 0xf5ee4bb9,\n        0xf8ad6d60, 0xfc6c70d7, 0xe22b20d2, 0xe6ea3d65, 0xeba91bbc, 0xef68060b,\n        0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f, 0xc423cd6a, 0xc0e2d0dd,\n        0xcda1f604, 0xc960ebb3, 0xbd3e8d7e, 0xb9ff90c9, 0xb4bcb610, 0xb07daba7,\n        0xae3afba2, 0xaafbe615, 0xa7b8c0cc, 0xa379dd7b, 0x9b3660c6, 0x9ff77d71,\n        0x92b45ba8, 0x9675461f, 0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3,\n        0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640, 0x4e8ee645, 0x4a4ffbf2,\n        0x470cdd2b, 0x43cdc09c, 0x7b827d21, 0x7f436096, 0x7200464f, 0x76c15bf8,\n        0x68860bfd, 0x6c47164a, 0x61043093, 0x65c52d24, 0x119b4be9, 0x155a565e,\n        0x18197087, 0x1cd86d30, 0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec,\n        0x3793a651, 0x3352bbe6, 0x3e119d3f, 0x3ad08088, 0x2497d08d, 0x2056cd3a,\n        0x2d15ebe3, 0x29d4f654, 0xc5a92679, 0xc1683bce, 0xcc2b1d17, 0xc8ea00a0,\n        0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c, 0xe3a1cbc1, 0xe760d676,\n        0xea23f0af, 0xeee2ed18, 0xf0a5bd1d, 0xf464a0aa, 0xf9278673, 0xfde69bc4,\n        0x89b8fd09, 0x8d79e0be, 0x803ac667, 0x84fbdbd0, 0x9abc8bd5, 0x9e7d9662,\n        0x933eb0bb, 0x97ffad0c, 0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668,\n        0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4,\n    ]);\n    const CRC32 = function () {\n        /**\n         * The current CRC\n         */\n        let crc = 0xffffffff;\n        /**\n         * @return The current CRC\n         */\n        this.getCRC = function () {\n            return ~crc >>> 0; // return an unsigned value\n        };\n        /**\n         * Update the CRC with a single byte\n         * @param value The value to update the CRC with\n         */\n        this.updateCRC = function (value) {\n            crc = (crc << 8) ^ crc32Lookup[((crc >>> 24) ^ value) & 0xff];\n        };\n        /**\n         * Update the CRC with a sequence of identical bytes\n         * @param value The value to update the CRC with\n         * @param count The number of bytes\n         */\n        this.updateCRCRun = function (value, count) {\n            while (count-- > 0) {\n                crc = (crc << 8) ^ crc32Lookup[((crc >>> 24) ^ value) & 0xff];\n            }\n        };\n    };\n    return CRC32;\n})();\n//# sourceMappingURL=crc32.js.map","var charenc = {\n  // UTF-8 encoding\n  utf8: {\n    // Convert a string to a byte array\n    stringToBytes: function(str) {\n      return charenc.bin.stringToBytes(unescape(encodeURIComponent(str)));\n    },\n\n    // Convert a byte array to a string\n    bytesToString: function(bytes) {\n      return decodeURIComponent(escape(charenc.bin.bytesToString(bytes)));\n    }\n  },\n\n  // Binary encoding\n  bin: {\n    // Convert a string to a byte array\n    stringToBytes: function(str) {\n      for (var bytes = [], i = 0; i < str.length; i++)\n        bytes.push(str.charCodeAt(i) & 0xFF);\n      return bytes;\n    },\n\n    // Convert a byte array to a string\n    bytesToString: function(bytes) {\n      for (var str = [], i = 0; i < bytes.length; i++)\n        str.push(String.fromCharCode(bytes[i]));\n      return str.join('');\n    }\n  }\n};\n\nmodule.exports = charenc;\n","// Generated by `./pycrc.py --algorithm=table-driven --model=crc-32 --generate=c`\nlet TABLE = [\n    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f, 0xe963a535, 0x9e6495a3,\n    0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91,\n    0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,\n    0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5,\n    0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n    0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,\n    0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599, 0xb8bda50f,\n    0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924, 0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d,\n    0x76dc4190, 0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,\n    0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n    0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457,\n    0x65b0d9c6, 0x12b7e950, 0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,\n    0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb,\n    0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9,\n    0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad,\n    0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683,\n    0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,\n    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7,\n    0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n    0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,\n    0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79,\n    0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236, 0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f,\n    0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,\n    0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n    0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21,\n    0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,\n    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45,\n    0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db,\n    0xaed16a4a, 0xd9d65adc, 0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf,\n    0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d,\n];\nif (typeof Int32Array !== 'undefined') {\n    TABLE = new Int32Array(TABLE);\n}\nconst crc32 = (current, previous) => {\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    let crc = previous === 0 ? 0 : ~~previous ^ -1;\n    for (let index = 0; index < current.length; index++) {\n        crc = TABLE[(crc ^ current[index]) & 0xff] ^ (crc >>> 8);\n    }\n    return crc ^ -1;\n};\nexport default crc32;\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55]}