{"version":3,"file":"static/chunks/8951.06ade98dbb3e8e6a.js","mappings":"0HCae,SACf,QACA,OACA,uBACA,UACA,eACA,cACA,iBACA,CACA,kBACA,SAGA,EAFA,YAEA,kBACA,6BACA,MACA,SAEA,QAAc,YAAc,EAC5B,KAEA,MADA,oBACA,UAEA,UACA,SAGA,IACA,6BACA,YACA,eACA,KACA,gBACA,sBACA,iBACA,QACA,OAIA,uBACA,OAEA,GACA,SAEA,CACA,oBACA,yBACA,oCACA,CAAa,EAGb,0CACA,6BAlEA,MAkEA,KAEA,iBACA,cACA,KACA,CACA,EDlEO,YACP,8BARO,GACP,QACA,eACA,YAEA,QACA,EAEA,IACA,IACA,eACA,WACA,YAEA,QACA,EC0DyC,OACzC,GAzEA,KA0EA,MAGA,0CACA,cACA,KACA,CACA,CAEA,OA9EA,cACA,cACA,oBACA,WACA,yBACA,CAAK,CACL,GAwEA,mCACA,CACA,kBAKA,MAJA,8BACA,gBACA,MACS,EAET,YACA,eACA,QACA,eA3FA,GA+FA,OAHA,aAEA,gBADA,WACA,IACA,CACS,CACT,CACA,sBACA,QACA,QAEA,cADA,yBAEA,oBACA,IACA,IACA,WAIA,UACA,UAIA,OACA,OAFA,8BAGA,KACA,CACA,CACA,gDCvHA,cACA,IACA,4BACA,CACA,SACA,QACA,CACA,CACA,qBACA,iCACA,mBACA,EACA,6BACA,6CACA,8BACA,CACe,gBAAoC,aAAW,CAC9D,mBACA,aACA,MAA2B,oBAAc,iBACzC,EAA4B,oBAAc,kBAC1C,MACA,mCAEA,MACA,mCAEA,iBAA0B,EAAK,EAAD,CAAC,eAAY,MAA8B,kBAAY,WACrF,CACA,qBACA,kCACA,eAEA,EADA,8BAEA,2DACA,cACA,wCACA,0BACA,sBACA,IACA,wBACA,0CACA,OACA,OACA,uBACA,SACA,uCAEA,GAAqB,GAAO,GAAG,EAAQ,GADvC,EAEA,WAAuB,IAAU,EACjC,YACA,QACA,gBACA,8CACA,SACA,CAAa,CACb,CAAS,EACT,6BACA,sEACA,CACA,CACA,iBACA","sources":["webpack://_N_E/./node_modules/@gmod/trix/esm/util.js","webpack://_N_E/./node_modules/@gmod/trix/esm/index.js","webpack://_N_E/./node_modules/@jbrowse/plugin-trix/esm/TrixTextSearchAdapter/TrixTextSearchAdapter.js"],"sourcesContent":["export function sum(array) {\n    let sum = 0;\n    for (const entry of array) {\n        sum += entry.length;\n    }\n    return sum;\n}\nexport function concatUint8Array(args) {\n    const mergedArray = new Uint8Array(sum(args));\n    let offset = 0;\n    for (const entry of args) {\n        mergedArray.set(entry, offset);\n        offset += entry.length;\n    }\n    return mergedArray;\n}\n//# sourceMappingURL=util.js.map","import { concatUint8Array } from './util';\nconst CHUNK_SIZE = 65536;\n// this is the number of hex characters to use for the address in ixixx, see\n// https://github.com/GMOD/ixixx-js/blob/master/src/index.ts#L182\nconst ADDRESS_SIZE = 10;\n// https://stackoverflow.com/a/9229821/2129219\nfunction uniqBy(a, key) {\n    const seen = new Set();\n    return a.filter(item => {\n        const k = key(item);\n        return seen.has(k) ? false : seen.add(k);\n    });\n}\nexport default class Trix {\n    ixxFile;\n    ixFile;\n    maxResults;\n    constructor(ixxFile, ixFile, maxResults = 20) {\n        this.ixxFile = ixxFile;\n        this.ixFile = ixFile;\n        this.maxResults = maxResults;\n    }\n    async search(searchString, opts) {\n        let resultArr = [];\n        const searchWords = searchString.split(' ');\n        // we only search one word at a time\n        const searchWord = searchWords[0].toLowerCase();\n        const res = await this._getBuffer(searchWord, opts);\n        if (!res) {\n            return [];\n        }\n        let { end, buffer } = res;\n        let done = false;\n        const decoder = new TextDecoder('utf8');\n        const str = decoder.decode(buffer);\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        while (!done) {\n            let foundSomething = false;\n            // slice to lastIndexOf('\\n') to make sure we get complete records\n            // since the buffer fetch could get halfway into a record\n            const lines = str\n                .slice(0, str.lastIndexOf('\\n'))\n                .split('\\n')\n                .filter(f => !!f);\n            const hits2 = [];\n            for (const line of lines) {\n                const word = line.split(' ')[0];\n                const match = word.startsWith(searchWord);\n                if (!foundSomething && match) {\n                    foundSomething = true;\n                }\n                // we are done scanning if we are lexicographically greater than the\n                // search string\n                if (word.slice(0, searchWord.length) > searchWord) {\n                    done = true;\n                }\n                if (match) {\n                    hits2.push(line);\n                }\n            }\n            const hits = hits2.flatMap(line => {\n                const [term, ...parts] = line.split(' ');\n                return parts.map(elt => [term, elt.split(',')[0]]);\n            });\n            // if we are not done, and we haven't filled up maxResults with hits yet,\n            // then refetch\n            if (resultArr.length + hits.length < this.maxResults && !done) {\n                const res2 = await this.ixFile.read(CHUNK_SIZE, end, opts);\n                // early break if empty response\n                if (res2.length === 0) {\n                    resultArr = resultArr.concat(hits);\n                    break;\n                }\n                buffer = concatUint8Array([buffer, res2]);\n                end += CHUNK_SIZE;\n            }\n            // if we have filled up the hits, or we are detected to be done via the\n            // filtering, then return\n            else if (resultArr.length + hits.length >= this.maxResults || done) {\n                resultArr = resultArr.concat(hits);\n                break;\n            }\n        }\n        // deduplicate results based on the detail column (resultArr[1])\n        return uniqBy(resultArr, elt => elt[1]).slice(0, this.maxResults);\n    }\n    async getIndex(opts) {\n        const file = await this.ixxFile.readFile({\n            encoding: 'utf8',\n            ...opts,\n        });\n        return file\n            .split('\\n')\n            .filter(f => !!f)\n            .map(line => {\n            const p = line.length - ADDRESS_SIZE;\n            const prefix = line.slice(0, p);\n            const posStr = line.slice(p);\n            const pos = Number.parseInt(posStr, 16);\n            return [prefix, pos];\n        });\n    }\n    async _getBuffer(searchWord, opts) {\n        let start = 0;\n        let end = 65536;\n        const indexes = await this.getIndex(opts);\n        for (const [key, value] of indexes) {\n            const trimmedKey = key.slice(0, searchWord.length);\n            if (trimmedKey < searchWord) {\n                start = value;\n                end = value + 65536;\n            }\n        }\n        // Return the buffer and its end position in the file.\n        const len = end - start;\n        if (len < 0) {\n            return undefined;\n        }\n        const buffer = await this.ixFile.read(len, start, opts);\n        return {\n            buffer,\n            end,\n        };\n    }\n}\n//# sourceMappingURL=index.js.map","import Trix from '@gmod/trix';\nimport BaseResult from '@jbrowse/core/TextSearch/BaseResults';\nimport { readConfObject } from '@jbrowse/core/configuration';\nimport { BaseAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { openLocation } from '@jbrowse/core/util/io';\nfunction decodeURIComponentNoThrow(uri) {\n    try {\n        return decodeURIComponent(uri);\n    }\n    catch (e) {\n        return uri;\n    }\n}\nfunction shorten(str, term, w = 15) {\n    const tidx = str.toLowerCase().indexOf(term);\n    return str.length < 40\n        ? str\n        : (Math.max(0, tidx - w) > 0 ? '...' : '') +\n            str.slice(Math.max(0, tidx - w), tidx + term.length + w).trim() +\n            (tidx + term.length < str.length ? '...' : '');\n}\nexport default class TrixTextSearchAdapter extends BaseAdapter {\n    constructor(config, getSubAdapter, pluginManager) {\n        super(config, getSubAdapter, pluginManager);\n        const ixFilePath = readConfObject(config, 'ixFilePath');\n        const ixxFilePath = readConfObject(config, 'ixxFilePath');\n        if (!ixFilePath) {\n            throw new Error('must provide out.ix');\n        }\n        if (!ixxFilePath) {\n            throw new Error('must provide out.ixx');\n        }\n        this.trixJs = new Trix(openLocation(ixxFilePath, pluginManager), openLocation(ixFilePath, pluginManager), 1500);\n    }\n    async searchIndex(args) {\n        const query = args.queryString.toLowerCase();\n        const strs = query.split(' ');\n        const results = await this.trixJs.search(query);\n        const formatted = results\n            .filter(([, data]) => strs.every(r => decodeURIComponentNoThrow(data).toLowerCase().includes(r)))\n            .map(([term, data]) => {\n            const result = JSON.parse(data.replaceAll('|', ','));\n            const [loc, trackId, ...rest] = result.map(record => decodeURIComponentNoThrow(record));\n            const labelFieldIdx = rest.findIndex(elt => !!elt);\n            const contextIdx = rest\n                .map(elt => elt.toLowerCase())\n                .findIndex(f => f.includes(term.toLowerCase()));\n            const labelField = rest[labelFieldIdx];\n            const contextField = rest[contextIdx];\n            const context = contextIdx !== -1 ? shorten(contextField, term) : undefined;\n            const label = shorten(labelField, term);\n            const displayString = !context || label.toLowerCase() === context.toLowerCase()\n                ? label\n                : `${label} (${context})`;\n            return new BaseResult({\n                locString: loc,\n                label: labelField,\n                displayString,\n                matchedObject: result.map(record => decodeURIComponent(record)),\n                trackId,\n            });\n        });\n        return args.searchType === 'exact'\n            ? formatted.filter(r => r.getLabel().toLowerCase() === args.queryString.toLowerCase())\n            : formatted;\n    }\n    freeResources() { }\n}\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2]}