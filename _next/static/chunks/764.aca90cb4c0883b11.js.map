{"version":3,"file":"static/chunks/764.aca90cb4c0883b11.js","mappings":"sHAAe,SACf,aACA,aACA,kBACA,qBACA,aAD4C,IAC5C,EACA,CACA,WACA,CAH0C,KAG1C,GAAkB,mBAAmB,GAAG,kBAAkB,EAE1D,aACA,4EAEA,qBACA,EACA,QACA,KAAe,GAAM,KACrB,OAEA,KAAe,WAAiB,KAChC,qBACA,SAGA,QACA,CACA,CACO,uBACP,KACA,+DAEA,kCACA,mBACA,iBACA,aACA,WACA,sBACA,CCpCe,QACf,KACA,KACA,IACA,aACA,mBACA,SACA,YACA,YACA,WACA,mBACA,CACA,iBACA,SAAkB,qBAAqB,IAAI,sBAAsB,OAAO,SAAS,gBAAgB,mBAAmB,GAEpH,WACA,4BACA,CACA,aACA,oCACA,6BACA,cACA,CACA,qBACA,2BACA,kBAEA,sDAEA,CEoBO,oBAEP,EADA,SAEA,gBACA,SAMA,aAJA,eACA,gDACA,sDACA,CAAK,EACL,GACA,8BACA,cACA,UACA,QAEA,KAvBO,KAwBP,IAvBA,8CACA,+CAuBA,4BACA,iBAIA,UACA,IAEA,EAGA,QACA,CACO,gBACP,OACA,UDjFO,gBACP,OCgF0C,CDhF1C,GACA,UACA,WACA,WAKA,QAJA,OACA,UACA,WACA,cACA,GAVO,YAUP,OACA,ECuE0C,IAC1C,CACA,CACO,gBACP,SACA,iBACA,EACA,EACA,CACA,CC5Fe,QACf,WACA,yBAKA,YAAkB,sBAAsC,EACxD,kBACA,mBACA,CACA,CCWe,gBAAkB,EACjC,OAD0C,MAE1C,eACA,0BACA,wCACA,CAEA,oBAYA,EAXA,uCACA,yBAEA,GA7BA,UAA4B,EA6B5B,kBACA,8BAEA,uBAIA,IAEA,WACA,YAAwB,IAAc,SAGtC,EADA,uBAEA,KACA,SACA,YAA4B,IAAc,MAC1C,wBAEA,GADA,KACA,UACA,KACA,EAA4B,EAAc,QAC1C,IAD0C,OAG1C,WACA,oEAEA,CACA,uBACA,KACA,eACA,YAAoC,IAAgB,KACpD,MAAkC,EAAS,KAE3C,EAF2C,EAEA,EAD3C,KAC2C,CAC3C,KACA,EAAwC,EAAa,KACrD,MADqD,GACb,EAAK,MAC7C,CACA,MACA,CACA,CACA,uBACA,KAIA,eACA,YAA4B,IAAiB,KAC7C,MAA+B,EAAS,KACxC,EADwC,CACxC,EACA,EAAgC,EAAa,KAC7C,MAD6C,CAG7C,eAA2B,wBAC3B,CACA,OACA,OACA,gBACA,mBACA,UACA,UACA,CACA,CACA,yBAA+C,EAE/C,IAEA,EADA,sBACA,WAEA,MACA,SAEA,gBAAgB,cAA0B,EAC1C,gBACA,SAEA,8BAZA,MAYA,EArGA,EAyFA,YAaA,iBAzGA,EA4FA,MAcA,EAbA,WAcA,YAfA,OAgBA,kBACA,8BACA,kBAlBA,MAmBA,sDAEA,UArBA,MAqBA,eACA,YAtBA,MAsBA,IAAmC,IAtBnC,MAsB8C,QAC9C,MACA,6BACA,MAzBA,MAyBA,EACA,IA1BA,MA0BA,EA1BA,KA2BA,EACA,uBAEA,kBACA,KACA,iCACA,EAAS,CACT,CACA,+BAAmD,MA1HnD,QA0JA,EA/BA,KACA,MAEA,0BAEA,MACA,SAEA,mBAEA,MACA,SAGA,MAvIA,CACA,MACA,KAJA,EAyIA,IArIA,OAHA,GAwIA,EAxIA,IAGA,KACA,sBACA,wBACA,0BACA,4BACA,CAiIA,KAEA,iBACA,YAAkC,KAAY,IAE9C,iBAEA,aADA,cAEA,WAAwC,EAAK,kBAO7C,2BAEA,sBACA,sBACA,YAA6B,KAAa,KAC1C,uBAEA,2BACA,KAEA,CACA,OAAe,EAAc,IAC7B,CACA,OAF6B,KAE7B,IAAyB,EAOzB,OANA,aACA,sCAEA,MADA,mBACA,CACA,EAAa,EAEb,YAEA,sBAAoC,EACpC,0BACA,8BACA,CACA,qECpLA,gBACA,yBACA,CACe,gBAAkB,EACjC,OAD0C,MAC1C,EACA,QACA,UACA,cACA,eACA,0BACA,wCACA,CACA,iBACA,SAEA,kBACA,6BACA,oBAEA,GAAyB,4BAAkC,OAC3D,MACA,iDAAiE,EAAY,GAE7E,OACA,uBACA,yBACA,uBACA,EACA,sBACA,8BACA,sBACA,sBACA,OACA,gBACA,eAhBA,gDAiBA,YACA,WACA,YACA,SACA,cACA,GAAe,SH2CR,KG3CsB,EH2CtB,GACP,QACA,IACA,KACA,KACA,YAAoB,WAAuB,KAC3C,UACA,QACA,SACA,YAA4C,IAAO,IACnD,6BAEA,OACA,OACA,MACA,CACA,MACA,IACA,CAEA,mBAAa,gBACb,EGhE6B,2CAE7B,CAEA,oBAIA,EAoBA,EAvBA,wCACA,QAA4B,WAAK,IACjC,yBAEA,oBACA,aAvD6B,EAuD7B,EACA,SAEA,aAzD6B,EAyD7B,EACA,SAGA,8BAA8C,EAAM,EAGpD,gCACA,4BACA,8CACA,wBACA,uCACA,sBAEA,SAEA,WACA,YAAwB,IAAc,SAKtC,EAHA,KAGuB,CAHvB,iBACA,KACA,SAEA,YAA4B,IAAc,KAC1C,wBAEA,GADA,KACA,oBACA,EAA4B,EAAc,QAC1C,IAD0C,MAG1C,CACA,EAAoC,EAAa,EAAgB,EAAS,MAC1E,CADiD,EACjD,EACA,uBACA,KACA,eACA,YAAoC,IAAgB,MACpD,MAAkC,EAAS,KAE3C,EAF2C,EAEA,EAD3C,KAC2C,CAC3C,KACA,EAAwC,EAAa,KACrD,MADqD,GACb,EAAK,MAC7C,CACA,MACA,CACA,CACA,MAA2B,mBAC3B,CACA,OACA,aACA,gBACA,UACA,WACA,OACA,mBACA,KAEA,CACA,+BAAmD,EACnD,KACA,MAGA,MADA,sBACA,WAEA,MACA,SAEA,yBACA,gBACA,SAEA,SAEA,iBACA,YAAkC,KAAY,IAE9C,iBAEA,aADA,cAEA,UAKA,OAAe,EAAc,MAAa,EAAa,IAA1B,CAC7B,CAKA,KANuD,IAMvD,SApJA,EAqJA,OACA,CADkB,EAElB,MAEA,mBACA,gBAEA,KACA,QACA,IACA,6BACA,KACA,KAAe,cAAiB,SAjKhC,EAiKgC,MAhKhC,MAgKgC,MAChC,eACA,WACA,kCACA,qBAAyC,EAAI,GAAG,GAAK,iDAAiD,cAAc,UAAU,WAAW,2DAEzI,aACA,CACA,QACA,CACA,gBAAyB,EAOzB,OANA,aACA,sCAEA,MADA,mBACA,CACA,EAAa,EAEb,YAEA,sBAAoC,EACpC,0BACA,8BACA,CACA,CC/LA,MAAe,CAEf,cAEA,mBAEA,aAEA,cAEA,gBAEA,iBAEA,cAEA,eAEA,mBAEA,gBAEA,cAEA,uBACA,CAAC,CCxBD,CDwBE,CCxBF,6BACA,8BACe,SACf,WACA,OACA,cACA,GACA,mBACA,6BACA,iDACA,CACA,gBACA,2BACA,CACA,YACA,+DACA,CACA,aACA,8CACA,CACA,YACA,8CACA,CACA,UACA,qCAEA,SACA,uBAEA,SACA,gCACA,uBACA,CACA,YACA,eAEA,WACA,4BACA,OAEA,cACA,sBACA,qBACA,mBACA,mDACA,CACA,aACA,wCACA,CACA,SACA,0BACA,CACA,WACA,SACA,YAAwB,0BAA+B,IACvD,kDAEA,QACA,CACA,WACA,cACA,sBACA,qBACA,mBACA,gBACA,iBACA,KACA,WACA,iEACA,2CAEA,GADA,KACA,QACA,4CACA,UAEA,WACA,4BACA,UAEA,WACA,6BACA,UAEA,WACA,wBACA,UAEA,WACA,yBACA,UAEA,WACA,4BACA,UAEA,WACA,6BACA,UAEA,WACA,8BACA,UAEA,qBACA,SACA,YACA,0BACA,SACA,oCAGA,KAEA,CACA,eACA,MACA,YAEA,0BADA,qBAEA,yBAEA,GADA,KACA,SACA,aACA,SACA,YAAwC,IAAW,KACnD,6BACA,OACA,UACA,YACA,IACA,CACA,eACA,KACA,CACA,SACA,YAAwC,IAAW,IACnD,+BACA,IAEA,OACA,OAEA,YACA,aACA,SACA,YAAwC,IAAW,KACnD,8BACA,OACA,UACA,YACA,IACA,CACA,eACA,KACA,CACA,SACA,YAAwC,IAAW,IACnD,gCACA,IAEA,OACA,OAEA,YACA,SACA,YAAoC,IAAW,IAC/C,+BACA,IAEA,OACA,MACA,YACA,SACA,YAAoC,IAAW,IAC/C,gCACA,IAEA,OACA,MACA,YACA,SACA,YAAoC,IAAW,IAC/C,2BACA,IAEA,OACA,MACA,YACA,SACA,YAAoC,IAAW,IAC/C,4BACA,IAEA,OACA,MACA,YACA,SACA,YAAoC,IAAW,IAC/C,iCACA,IAEA,OACA,CACA,KACA,CACA,wCACA,KACA,CACA,CACA,QACA,CAKA,WACA,oBAA+B,EAAS,YACxC,CAEA,mBACA,oBAA+B,EAAS,iBACxC,CAEA,oBACA,oBAA+B,EAAS,WACxC,CAEA,iBACA,oBAA+B,EAAS,YACxC,CAEA,wBACA,oBAA+B,EAAS,aACxC,CAEA,4BACA,oBAA+B,EAAS,cACxC,CAEA,UACA,oBAA+B,EAAS,WACxC,CAEA,UACA,oBAA+B,EAAS,WACxC,CAEA,cACA,oBAA+B,EAAS,eACxC,CAEA,aACA,oBAA+B,EAAS,YACxC,CAEA,cACA,oBAA+B,EAAS,SACxC,CAEA,kBACA,oBAA+B,EAAS,mBACxC,CACA,qBACA,4BACA,OACA,gBACA,QACA,EAEA,yBACA,gCACA,KAGA,yBACA,OACA,UACA,gCAUA,OAPA,KAEA,EADA,4BACA,EAEA,MADA,aAEA,qCAEA,CACA,mBACA,eACA,CAEA,EACA,QACA,YAA4B,IAAiB,IAE7C,EADA,4BACA,EACA,UACA,YAGA,2BACA,OAEA,KAEA,OACA,iBACA,eACA,CACA,CACA,CACA,oBACA,yCAEA,YACA,iCAEA,oBACA,0BAEA,uBACA,0BAEA,oBACA,2BACA,CACA,UACA,cAAgB,GAAY,WAC5B,qDACA,qBACA,kBACA,KACA,IACA,YAAwB,IAAc,KACtC,aACA,wBAEA,MACA,gBACA,IAEA,CACA,iBACA,CAEA,uBACA,8BACA,wBACA,+BACA,2CACA,2CACA,MACA,MACA,gBACA,MACA,OAEA,iBACA,MACA,OAEA,SAcA,OAbA,qBACA,GACA,OACA,OACA,OACA,SAGA,OACA,OACA,OACA,QAEA,UACA,CAEA,CACA,gBACA,+CACA,CACA,cACA,+CACA,CACA,iBACA,+CACA,CACA,iBACA,+CACA,CACA,eACA,+CACA,CACA,sBACA,+CACA,CACA,SACA,SACA,+BACA,gCAIA,eAEA,QACA,CACA,CACA,gBACA,qDACA,MACA,6CAGA,YACA,MACA,mCAEA,qCACA,MACA,mBAEA,OADA,8BAAgD,QAAY,EAC5D,CACA,CAAS,CACJ,CACL,CC5aO,cACP,uBACA,KACA,gBACA,0BACA,GACA,QACA,eACA,eACA,qBAGA,OAA6B,IAF7B,aAE6B,MAD7B,YAC6B,CAC7B,CAAiB,CACjB,CAAa,CAEb,CACA,QACA,CCLA,oBACA,SACA,qBACA,cAEA,QACA,CF0ZA,YACA,sBACA,WACA,WE5ZA,SACA,OACA,2BACA,CACA,OACA,2BACA,CACA,WACA,2BACA,CACA,QACA,2BACA,CACA,CACe,QACf,aACA,IACA,MACA,YACA,WACA,gBACA,MACA,UACA,QACA,iBAAuB,GAAqB,EAC5C,SAAmB,MAAQ,CAC3B,UACA,CAAS,EACT,kBACA,UAAoB,UAAc,EAClC,MAAoB,6BAA+B,uBACnD,QACA,MAAwB,cAAiB,CAC5B,EACb,oCACA,CAAS,CACJ,cACL,eAAkB,+IAAwJ,EAE1K,GADA,oBACA,EACA,gBAEA,KACA,aAA2B,WAAS,SAEpC,KACA,aAA2B,YAAU,SAErC,KACA,eACA,oBAGA,wCAEA,KACA,eAA6B,EAAG,YAAG,EAA2B,OAE9D,KACA,eAA6B,EAAG,YAAG,IAAgB,WAAS,IAAW,OAEvE,KACA,eAA6B,EAAG,YAAG,IAAgB,YAAU,IAAU,OAEvE,KACA,eAA6B,EAAG,YAAG,EAA2B,OAE9D,KACA,eAA6B,EAAG,YAAG,IAAgB,WAAS,IAAW,OAEvE,KACA,eAA6B,EAAG,YAAG,IAAgB,YAAU,IAAU,OAEvE,KACA,eAA6B,EAAG,YAAG,IAAgB,WAAS,IAAI,EAAQ,OAAQ,OAEhF,KACA,eAA6B,EAAG,CAAG,eAAgB,YAAU,IAAI,EAAO,OAAQ,OAEhF,KACA,oBAGA,2CAEA,uBACA,CACA,0BASA,EARA,MP7DO,QO6DsB,CP7DtB,IAA0B,EACjC,qBAAgC,UAAc,CAC9C,EO2D6B,GAC7B,eACA,OAEA,gCACA,kBACA,oCACA,OAIA,EAFA,EAEA,oBADA,EA1GA,MA2GA,GAGA,2BAEA,YAA4B,WAAK,IACjC,yBACA,gCACA,8BAEA,uBACA,yBACA,yCACA,eAAgB,gBAAyB,qCAGzC,OAFA,kBACA,kBACe,EAAe,YAC9B,CAD8B,UAE9B,GAOA,OANA,cACA,6CAEA,MADA,oBACA,CACA,EAAa,EAEb,aAEA,wBAAiC,EAEjC,OADA,wBACA,YAIA,0BACA,OACA,kCAGA,iCACA,QAA4B,WAAK,IACjC,yBACA,mBACA,MACA,KACA,KACA,0BACA,YAAwB,IAAU,MAClC,uBACA,uDACA,uBAIA,GAHA,OACA,gBAA8B,WAAuB,EACrD,UACA,SAEA,OADA,qDAAqE,GAAa,SAClF,0BAEA,CACA,kBAAiB,eACjB,CACA,kCACA,6CACA,CACA,sCACA,wBACA,2BACA,0BAGA,CACA,gDACA,0CACA,MALA,QAOA,uCAAiE,EACjE,gBAAgB,GAAc,EAC9B,KACA,KACA,gBACA,gDAA4E,eAAa,WACzF,KACA,eACA,iBACA,eAEA,KACA,KACA,CACA,UAEA,SAEA,CAIA,GAFA,UACA,QACA,EACA,KAEA,CACQ,CP3MD,YACP,MAGA,WAEA,qCACA,sBAGA,OADA,qBACA,CACA,CAEA,8CAEA,EACA,EO2LwB,UACxB,GACA,8BAEA,CACA,wBACA,kBAAgB,uBAAwC,EACxD,KACA,KACA,UACA,SACA,gBACA,aACA,OACA,MACA,SAEA,OACA,MACA,CACA,iCACA,OACA,SAGA,CAAS,EACT,SACA,UACA,gBACA,aACA,UACA,aACA,eACA,YACA,MACA,IACA,yBACA,4CAEA,CACA,CAAS,EAGT,cAEA,YADA,uBACA,OACA,qBACA,sBAgBA,MAbA,iDACA,SAAoB,qCAAsC,uBAC1D,QACA,MACA,CAAa,EACb,KACA,kDACA,qBACA,UAGA,QACA,CAAS,IACT,MACA,CACA,0BAA+C,EAC/C,2BACA,CACA,kBAAuB,eAAa,EACpC,qEACA,CAAgB,oCAAwC,MAAQ,qBAAe,MAC/E,YAAiB,oCACjB,CACA,+BACA,QACA,KACA,IACA,cACA,yBACA,oBACA,uBACA,UAGA,MACA,qCACA,GACA,CAEA,eACA,UAAoC,EAAU,CAC9C,MAD8C,CAE9C,YACA,QACA,KACA,CAAqB,CAqBrB,sBACA,SACA,SACA,oBACA,EAI4B,OAAK,qBACjC,CAAiB,EACjB,UACA,2DACA,MPzVA,OOyViC,KPzVjC,gBOyViC,IACjC,cAEA,CACA,KACA,CACA,QACA,CACA,mBACA,2BACA,2CACA,CACA,mBACA,2BACA,uDACA,CACA,sBACA,eACA,eAEA,mBACA,2BACA,+CACA,CACA,8BACA,eACA,eAEA,mBACA,2BACA,kBACA,GACA,kCACA,CACA,CCzXA,sBACA,wCACA,IAAgB,iBAAe,EAC/B,0BAGA,qBACA,SACA,uCAGA,sBADA,sBAEA,CACA,CAGA,YAAoB,QAAmB,EACvC,iBACA,KACA,SAA2B,mBAA2B,CACzC,EACb,SACA,oBAAwC,UAAY,WAAW,EAAI,IAAI,eAAiB,GAExF,4CACA,CACA,CAAK,GACL,OR2FO,YACP,qBARO,YACP,QACA,eACA,YAEA,QACA,EAEA,IACA,IACA,eACA,WACA,YAEA,QACA,EQnG2B,2BAAkC,WAAK,MAClE,CACe,gBAAyB,EACxC,KAD+C,EAC/C,CACA,oBACA,GACA,OAAgB,UAAc,EAC9B,uBACA,uBAEA,sCACA,SAAwB,aAAa,GAAG,aAAa,EACrD,KAAuB,EAAK,iBAAiB,EAAI,SAAS,EAAI,OAAO,EAAI,aACzE,uBACA,cACA,YAEA,CACA,qBAA8C,KAAS,EACvD,SACA,oBAAwC,UAAe,WAAW,EAAI,IAAI,eAAoB,GAE9F,qBACA,mCACA,iCAEA,CACA,SACA,oBACA,MACA,cACA,EAEA,mBACA,GAAkC,EAAI,GAAG,EAAI,GAAG,EAAI,EAEpD,gBACA,EAEA,MACA,eACA,gBACA,eACA,CAAqB,CACrB,MACA,qCACA,gBACA,eACA,CAAqB,CACrB,aACA,GAAkC,EAAI,GAAG,EAAI,GAAG,EAAI,EAEnC,CACjB,SACA,CACA,CAEA,kBAAuB,QAAO,EAC9B,aACA,+CAEA,OACA,cACA,cACA,cACA,OACA,CACA,CACA,oBAA6B,EAC7B,SAAuB,aAAa,GAAG,aAAa,gCACpD,mBACA,SACA,oBAAoC,UAAe,WAAW,EAAI,IAAI,eAAoB,GAE1F,qBACA,2BACA,yBACA,gCACA,MAD2C,MAC3C,GADoD,eAGpD,uBAGA,EAA0B,EAF1B,aAEyC,GAFzC,QACA,2BAIA,KACA,KAEA,eADA,0BACA,WACA,SACA,IACA,oBACA,aACA,UAEA,cACA,YAGA,QACA,cAAgC,WAChC,CAGA,OAFA,kBACA,kBACA,CACA,CACA,6KExIe,SACf,mBACA,cACA,eACA,UACA,CACA,KACA,SAAkB,gBAAgB,GAAG,eAAe,EAEpD,iBACA,MAAe,QAAa,iFAC5B,CACA,WACA,MACA,iEACA,CACA,OACA,uBACA,gBACA,WACA,UACA,cACA,CACA,SAEA,CACA,WAEA,CACA,aACA,kBACA,eACA,eACA,OACA,cACA,YACA,UACA,cACA,gBACA,kCACA,cACA,YACA,gCACA,cACA,UACA,aACA,oCACA,8CACA,6BACA,wBACA,GAAqB,4BAA4B,GAAG,aAAe,EACnE,OACA,kBACA,CACA,CACA,SACA,OACA,eACA,eAEA,CACA,CACA,QAAW,aACX,QAAW,gBCtDI,iBAAyB,wBAAsB,CAC9D,cACA,oBACA,+BAAyC,SAAQ,EACjD,WACA,CAAS,CACT,CACA,qBACA,kCACA,qCACA,sCACA,qBACA,YACA,MAAwB,IAAO,EAC/B,cAA2B,kBAAY,MACvC,gBAAiC,kBAAY,aAC7C,gBAA8C,OAAZ,kBAAY,MAC9C,yCACS,EACT,kCACA,0BACA,gBAAoB,GAAc,4BAClC,OACA,MACA,iBACA,CACA,CACA,WAAiB,EACjB,CACA,kBAOA,OANA,iBACA,+CAEA,MADA,uBACA,CACA,EAAa,EAEb,gBAEA,mBACA,QAAgB,GAAM,uBACtB,wBACA,CACA,kBACA,mBAAgB,UAA6B,MAC7C,KAAgB,GAAM,uBAetB,OAdA,qBAA+B,kBAAY,iCAC3C,0BACA,KACA,KASA,OARA,mDACA,mCACA,MACA,cACA,OACA,MACA,CACA,CAAa,EACb,UAAqB,aACrB,CAAS,EACT,eAEA,eAOA,OANA,aACA,wCAEA,MADA,mBACA,CACA,EAAa,EAEb,YAEA,qBACA,aAAgB,GAAW,oBAC3B,QACA,CACA,sBACA,oBAAgB,GAAkB,uBAElC,IADA,GAIA,GAFA,OAKA,MAPA,EAOA,aACA,UACA,QACA,MACA,eACA,CAAS,EACT,QAAgC,OAAc,QAAe,OAAO,KACpE,KAYA,GAXA,EACA,2CACA,YACA,qBACA,eACA,kBAEA,OADA,aACA,EACA,kCACA,iBACA,CAAS,EACT,eACA,+CAA+D,EAAQ,GAAG,uBAA6B,GAAG,oBAAsB,WAAW,2BAAkC,kCAAkC,uBAA+B,GAE9O,QACA,CACA,iBACA,YAAgB,mCAAuC,EACvD,CAAgB,gDAAkD,MAClE,MAAe,sBAAgB,WAC/B,QAAoB,GAAM,sBAC1B,qBACY,oBAAc,IAC1B,YAAkC,kBAAY,6DAClC,oBAAc,IAC1B,MAAkB,kBAAY,qCAC9B,gBAAwB,4CAAyD,MACjF,oBACA,EAIA,GAHA,WACA,4CAEwB,QAAc,eAGtC,GACwB,QAAc,yBAGtC,cANA,SASA,wCAAkE,KAAU,GAC5E,KAMA,cANA,CACA,UAAwC,EAAsB,UAC9D,UAD8D,gBAC9D,QAA0D,KAAU,KACpE,SACA,CAIA,CACA,YACA,CAAa,CACb,CAAS,CACT,CACA,6CACA,QAAgB,GAAM,8BACtB,QAGA,CAAqB,MAFrB,MAAgC,qBAAe,MAE1B,eADrB,8BACqB,EAErB,4CACA,CACA,iBACA,eACA,MACA,kEAEA,oCC3KA,OACA,8EACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,sFACA,wFACA,wFACA,CACA,gCACA,sBAUA,MARA,QAEA,oBAMe,CALf,MAKqB,EALrB,IAAwB,WAAwB,IAChD,wBAEA,WACA","sources":["webpack://_N_E/./node_modules/@gmod/bam/esm/virtualOffset.js","webpack://_N_E/./node_modules/@gmod/bam/esm/chunk.js","webpack://_N_E/./node_modules/@gmod/bam/esm/long.js","webpack://_N_E/./node_modules/@gmod/bam/esm/util.js","webpack://_N_E/./node_modules/@gmod/bam/esm/indexFile.js","webpack://_N_E/./node_modules/@gmod/bam/esm/bai.js","webpack://_N_E/./node_modules/@gmod/bam/esm/csi.js","webpack://_N_E/./node_modules/@gmod/bam/esm/constants.js","webpack://_N_E/./node_modules/@gmod/bam/esm/record.js","webpack://_N_E/./node_modules/@gmod/bam/esm/sam.js","webpack://_N_E/./node_modules/@gmod/bam/esm/bamFile.js","webpack://_N_E/./node_modules/@gmod/bam/esm/htsget.js","webpack://_N_E/./node_modules/@gmod/bam/esm/index.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/BamAdapter/BamSlightlyLazyFeature.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/BamAdapter/BamAdapter.js","webpack://_N_E/./node_modules/crc/mjs/calculators/crc32.js"],"sourcesContent":["export default class VirtualOffset {\n    blockPosition;\n    dataPosition;\n    constructor(blockPosition, dataPosition) {\n        this.blockPosition = blockPosition; // < offset of the compressed data block\n        this.dataPosition = dataPosition; // < offset into the uncompressed data\n    }\n    toString() {\n        return `${this.blockPosition}:${this.dataPosition}`;\n    }\n    compareTo(b) {\n        return (this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition);\n    }\n    static min(...args) {\n        let min;\n        let i = 0;\n        for (; !min; i += 1) {\n            min = args[i];\n        }\n        for (; i < args.length; i += 1) {\n            if (min.compareTo(args[i]) > 0) {\n                min = args[i];\n            }\n        }\n        return min;\n    }\n}\nexport function fromBytes(bytes, offset = 0, bigendian = false) {\n    if (bigendian) {\n        throw new Error('big-endian virtual file offsets not implemented');\n    }\n    return new VirtualOffset(bytes[offset + 7] * 0x10000000000 +\n        bytes[offset + 6] * 0x100000000 +\n        bytes[offset + 5] * 0x1000000 +\n        bytes[offset + 4] * 0x10000 +\n        bytes[offset + 3] * 0x100 +\n        bytes[offset + 2], (bytes[offset + 1] << 8) | bytes[offset]);\n}\n//# sourceMappingURL=virtualOffset.js.map","// little class representing a chunk in the index\nexport default class Chunk {\n    minv;\n    maxv;\n    bin;\n    _fetchedSize;\n    buffer;\n    constructor(minv, maxv, bin, _fetchedSize) {\n        this.minv = minv;\n        this.maxv = maxv;\n        this.bin = bin;\n        this._fetchedSize = _fetchedSize;\n    }\n    toUniqueString() {\n        return `${this.minv.toString()}..${this.maxv.toString()} (bin ${this.bin}, fetchedSize ${this.fetchedSize()})`;\n    }\n    toString() {\n        return this.toUniqueString();\n    }\n    compareTo(b) {\n        return (this.minv.compareTo(b.minv) ||\n            this.maxv.compareTo(b.maxv) ||\n            this.bin - b.bin);\n    }\n    fetchedSize() {\n        if (this._fetchedSize !== undefined) {\n            return this._fetchedSize;\n        }\n        return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition;\n    }\n}\n//# sourceMappingURL=chunk.js.map","export const TWO_PWR_16_DBL = 1 << 16;\nexport const TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;\nexport function longFromBytesToUnsigned(source, i = 0) {\n    const low = source[i] |\n        (source[i + 1] << 8) |\n        (source[i + 2] << 16) |\n        (source[i + 3] << 24);\n    const high = source[i + 4] |\n        (source[i + 5] << 8) |\n        (source[i + 6] << 16) |\n        (source[i + 7] << 24);\n    return (high >>> 0) * TWO_PWR_32_DBL + (low >>> 0);\n}\n//# sourceMappingURL=long.js.map","import { longFromBytesToUnsigned } from './long';\nexport function timeout(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n}\n/**\n * Properly check if the given AbortSignal is aborted.\n *\n * Per the standard, if the signal reads as aborted, this function throws\n * either a DOMException AbortError, or a regular error with a `code` attribute\n * set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal) {\n    if (!signal) {\n        return;\n    }\n    if (signal.aborted) {\n        // console.log('bam aborted!')\n        if (typeof DOMException === 'undefined') {\n            const e = new Error('aborted');\n            //@ts-ignore\n            e.code = 'ERR_ABORTED';\n            throw e;\n        }\n        else {\n            throw new DOMException('aborted', 'AbortError');\n        }\n    }\n}\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal) {\n    await Promise.resolve();\n    checkAbortSignal(signal);\n}\nexport function canMergeBlocks(chunk1, chunk2) {\n    return (chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n        chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000);\n}\nexport function makeOpts(obj = {}) {\n    return 'aborted' in obj ? { signal: obj } : obj;\n}\nexport function optimizeChunks(chunks, lowest) {\n    const mergedChunks = [];\n    let lastChunk;\n    if (chunks.length === 0) {\n        return chunks;\n    }\n    chunks.sort((c0, c1) => {\n        const dif = c0.minv.blockPosition - c1.minv.blockPosition;\n        return dif === 0 ? c0.minv.dataPosition - c1.minv.dataPosition : dif;\n    });\n    for (const chunk of chunks) {\n        if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n            if (lastChunk === undefined) {\n                mergedChunks.push(chunk);\n                lastChunk = chunk;\n            }\n            else {\n                if (canMergeBlocks(lastChunk, chunk)) {\n                    if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n                        lastChunk.maxv = chunk.maxv;\n                    }\n                }\n                else {\n                    mergedChunks.push(chunk);\n                    lastChunk = chunk;\n                }\n            }\n        }\n    }\n    return mergedChunks;\n}\nexport function parsePseudoBin(bytes, offset) {\n    return {\n        lineCount: longFromBytesToUnsigned(bytes, offset),\n    };\n}\nexport function findFirstData(firstDataLine, virtualOffset) {\n    return firstDataLine\n        ? firstDataLine.compareTo(virtualOffset) > 0\n            ? virtualOffset\n            : firstDataLine\n        : virtualOffset;\n}\nexport function parseNameBytes(namesBytes, renameRefSeq = s => s) {\n    let currRefId = 0;\n    let currNameStart = 0;\n    const refIdToName = [];\n    const refNameToId = {};\n    for (let i = 0; i < namesBytes.length; i += 1) {\n        if (!namesBytes[i]) {\n            if (currNameStart < i) {\n                let refName = '';\n                for (let j = currNameStart; j < i; j++) {\n                    refName += String.fromCharCode(namesBytes[j]);\n                }\n                refName = renameRefSeq(refName);\n                refIdToName[currRefId] = refName;\n                refNameToId[refName] = currRefId;\n            }\n            currNameStart = i + 1;\n            currRefId += 1;\n        }\n    }\n    return { refNameToId, refIdToName };\n}\nexport function sum(array) {\n    let sum = 0;\n    for (const entry of array) {\n        sum += entry.length;\n    }\n    return sum;\n}\nexport function concatUint8Array(args) {\n    const mergedArray = new Uint8Array(sum(args));\n    let offset = 0;\n    for (const entry of args) {\n        mergedArray.set(entry, offset);\n        offset += entry.length;\n    }\n    return mergedArray;\n}\n//# sourceMappingURL=util.js.map","export default class IndexFile {\n    filehandle;\n    renameRefSeq;\n    /**\n     * @param {filehandle} filehandle\n     * @param {function} [renameRefSeqs]\n     */\n    constructor({ filehandle, renameRefSeq = (n) => n, }) {\n        this.filehandle = filehandle;\n        this.renameRefSeq = renameRefSeq;\n    }\n}\n//# sourceMappingURL=indexFile.js.map","import { fromBytes } from './virtualOffset';\nimport Chunk from './chunk';\nimport { optimizeChunks, parsePseudoBin, findFirstData } from './util';\nimport IndexFile from './indexFile';\nconst BAI_MAGIC = 21578050; // BAI\\1\nfunction roundDown(n, multiple) {\n    return n - (n % multiple);\n}\nfunction roundUp(n, multiple) {\n    return n - (n % multiple) + multiple;\n}\nfunction reg2bins(beg, end) {\n    end -= 1;\n    return [\n        [0, 0],\n        [1 + (beg >> 26), 1 + (end >> 26)],\n        [9 + (beg >> 23), 9 + (end >> 23)],\n        [73 + (beg >> 20), 73 + (end >> 20)],\n        [585 + (beg >> 17), 585 + (end >> 17)],\n        [4681 + (beg >> 14), 4681 + (end >> 14)],\n    ];\n}\nexport default class BAI extends IndexFile {\n    setupP;\n    async lineCount(refId, opts) {\n        const indexData = await this.parse(opts);\n        return indexData.indices[refId]?.stats?.lineCount || 0;\n    }\n    // fetch and parse the index\n    async _parse(_opts) {\n        const bytes = await this.filehandle.readFile();\n        const dataView = new DataView(bytes.buffer);\n        // check BAI magic numbers\n        if (dataView.getUint32(0, true) !== BAI_MAGIC) {\n            throw new Error('Not a BAI file');\n        }\n        const refCount = dataView.getInt32(4, true);\n        const depth = 5;\n        const binLimit = ((1 << ((depth + 1) * 3)) - 1) / 7;\n        // read the indexes for each reference sequence\n        let curr = 8;\n        let firstDataLine;\n        const indices = new Array(refCount);\n        for (let i = 0; i < refCount; i++) {\n            // the binning index\n            const binCount = dataView.getInt32(curr, true);\n            let stats;\n            curr += 4;\n            const binIndex = {};\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = dataView.getUint32(curr, true);\n                curr += 4;\n                if (bin === binLimit + 1) {\n                    curr += 4;\n                    stats = parsePseudoBin(bytes, curr + 16);\n                    curr += 32;\n                }\n                else if (bin > binLimit + 1) {\n                    throw new Error('bai index contains too many bins, please use CSI');\n                }\n                else {\n                    const chunkCount = dataView.getInt32(curr, true);\n                    curr += 4;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k++) {\n                        const u = fromBytes(bytes, curr);\n                        curr += 8;\n                        const v = fromBytes(bytes, curr);\n                        curr += 8;\n                        firstDataLine = findFirstData(firstDataLine, u);\n                        chunks[k] = new Chunk(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            const linearCount = dataView.getInt32(curr, true);\n            curr += 4;\n            // as we're going through the linear index, figure out the smallest\n            // virtual offset in the indexes, which tells us where the BAM header\n            // ends\n            const linearIndex = new Array(linearCount);\n            for (let j = 0; j < linearCount; j++) {\n                const offset = fromBytes(bytes, curr);\n                curr += 8;\n                firstDataLine = findFirstData(firstDataLine, offset);\n                linearIndex[j] = offset;\n            }\n            indices[i] = { binIndex, linearIndex, stats };\n        }\n        return {\n            bai: true,\n            firstDataLine,\n            maxBlockSize: 1 << 16,\n            indices,\n            refCount,\n        };\n    }\n    async indexCov(seqId, start, end, opts = {}) {\n        const v = 16384;\n        const range = start !== undefined;\n        const indexData = await this.parse(opts);\n        const seqIdx = indexData.indices[seqId];\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        if (!seqIdx) {\n            return [];\n        }\n        const { linearIndex = [], stats } = seqIdx;\n        if (linearIndex.length === 0) {\n            return [];\n        }\n        const e = end === undefined ? (linearIndex.length - 1) * v : roundUp(end, v);\n        const s = start === undefined ? 0 : roundDown(start, v);\n        const depths = range\n            ? new Array((e - s) / v)\n            : new Array(linearIndex.length - 1);\n        const totalSize = linearIndex[linearIndex.length - 1].blockPosition;\n        if (e > (linearIndex.length - 1) * v) {\n            throw new Error('query outside of range of linear index');\n        }\n        let currentPos = linearIndex[s / v].blockPosition;\n        for (let i = s / v, j = 0; i < e / v; i++, j++) {\n            depths[j] = {\n                score: linearIndex[i + 1].blockPosition - currentPos,\n                start: i * v,\n                end: i * v + v,\n            };\n            currentPos = linearIndex[i + 1].blockPosition;\n        }\n        return depths.map(d => ({\n            ...d,\n            score: (d.score * (stats?.lineCount || 0)) / totalSize,\n        }));\n    }\n    async blocksForRange(refId, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        if (!indexData) {\n            return [];\n        }\n        const ba = indexData.indices[refId];\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        if (!ba) {\n            return [];\n        }\n        // List of bin #s that overlap min, max\n        const overlappingBins = reg2bins(min, max);\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n                if (ba.binIndex[bin]) {\n                    const binChunks = ba.binIndex[bin];\n                    for (const binChunk of binChunks) {\n                        chunks.push(new Chunk(binChunk.minv, binChunk.maxv, bin));\n                    }\n                }\n            }\n        }\n        // Use the linear index to find minimum file position of chunks that could\n        // contain alignments in the region\n        const nintv = ba.linearIndex.length;\n        let lowest;\n        const minLin = Math.min(min >> 14, nintv - 1);\n        const maxLin = Math.min(max >> 14, nintv - 1);\n        for (let i = minLin; i <= maxLin; ++i) {\n            const vp = ba.linearIndex[i];\n            // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n            if (vp && (!lowest || vp.compareTo(lowest) < 0)) {\n                lowest = vp;\n            }\n        }\n        return optimizeChunks(chunks, lowest);\n    }\n    async parse(opts = {}) {\n        if (!this.setupP) {\n            this.setupP = this._parse(opts).catch((e) => {\n                this.setupP = undefined;\n                throw e;\n            });\n        }\n        return this.setupP;\n    }\n    async hasRefSeq(seqId, opts = {}) {\n        const header = await this.parse(opts);\n        return !!header.indices[seqId]?.binIndex;\n    }\n}\n//# sourceMappingURL=bai.js.map","import { unzip } from '@gmod/bgzf-filehandle';\nimport VirtualOffset, { fromBytes } from './virtualOffset';\nimport Chunk from './chunk';\nimport { optimizeChunks, findFirstData, parsePseudoBin, parseNameBytes, } from './util';\nimport IndexFile from './indexFile';\nconst CSI1_MAGIC = 21582659; // CSI\\1\nconst CSI2_MAGIC = 38359875; // CSI\\2\nfunction lshift(num, bits) {\n    return num * 2 ** bits;\n}\nfunction rshift(num, bits) {\n    return Math.floor(num / 2 ** bits);\n}\nexport default class CSI extends IndexFile {\n    maxBinNumber = 0;\n    depth = 0;\n    minShift = 0;\n    setupP;\n    async lineCount(refId, opts) {\n        const indexData = await this.parse(opts);\n        return indexData.indices[refId]?.stats?.lineCount || 0;\n    }\n    async indexCov() {\n        return [];\n    }\n    parseAuxData(bytes, offset) {\n        const dataView = new DataView(bytes.buffer);\n        const formatFlags = dataView.getUint32(offset, true);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const format = { 0: 'generic', 1: 'SAM', 2: 'VCF' }[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: dataView.getInt32(offset + 4, true),\n            start: dataView.getInt32(offset + 8, true),\n            end: dataView.getInt32(offset + 12, true),\n        };\n        const metaValue = dataView.getInt32(offset + 16, true);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : '';\n        const skipLines = dataView.getInt32(offset + 20, true);\n        const nameSectionLength = dataView.getInt32(offset + 24, true);\n        return {\n            columnNumbers,\n            coordinateType,\n            metaValue,\n            metaChar,\n            skipLines,\n            format,\n            formatFlags,\n            ...parseNameBytes(bytes.subarray(offset + 28, offset + 28 + nameSectionLength), this.renameRefSeq),\n        };\n    }\n    // fetch and parse the index\n    async _parse(opts) {\n        const buffer = await this.filehandle.readFile(opts);\n        const bytes = await unzip(buffer);\n        const dataView = new DataView(bytes.buffer);\n        let csiVersion;\n        const magic = dataView.getUint32(0, true);\n        if (magic === CSI1_MAGIC) {\n            csiVersion = 1;\n        }\n        else if (magic === CSI2_MAGIC) {\n            csiVersion = 2;\n        }\n        else {\n            throw new Error(`Not a CSI file ${magic}`);\n            // TODO: do we need to support big-endian CSI files?\n        }\n        this.minShift = dataView.getInt32(4, true);\n        this.depth = dataView.getInt32(8, true);\n        this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7;\n        const auxLength = dataView.getInt32(12, true);\n        const aux = auxLength >= 30 ? this.parseAuxData(bytes, 16) : undefined;\n        const refCount = dataView.getInt32(16 + auxLength, true);\n        // read the indexes for each reference sequence\n        let curr = 16 + auxLength + 4;\n        let firstDataLine;\n        const indices = new Array(refCount);\n        for (let i = 0; i < refCount; i++) {\n            // the binning index\n            const binCount = dataView.getInt32(curr, true);\n            curr += 4;\n            const binIndex = {};\n            let stats; // < provided by parsing a pseudo-bin, if present\n            for (let j = 0; j < binCount; j++) {\n                const bin = dataView.getUint32(curr, true);\n                curr += 4;\n                if (bin > this.maxBinNumber) {\n                    stats = parsePseudoBin(bytes, curr + 28);\n                    curr += 28 + 16;\n                }\n                else {\n                    firstDataLine = findFirstData(firstDataLine, fromBytes(bytes, curr));\n                    curr += 8;\n                    const chunkCount = dataView.getInt32(curr, true);\n                    curr += 4;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = fromBytes(bytes, curr);\n                        curr += 8;\n                        const v = fromBytes(bytes, curr);\n                        curr += 8;\n                        firstDataLine = findFirstData(firstDataLine, u);\n                        chunks[k] = new Chunk(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            indices[i] = { binIndex, stats };\n        }\n        return {\n            csiVersion,\n            firstDataLine,\n            indices,\n            refCount,\n            csi: true,\n            maxBlockSize: 1 << 16,\n            ...aux,\n        };\n    }\n    async blocksForRange(refId, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        const ba = indexData.indices[refId];\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        if (!ba) {\n            return [];\n        }\n        const overlappingBins = this.reg2bins(min, max);\n        if (overlappingBins.length === 0) {\n            return [];\n        }\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n                if (ba.binIndex[bin]) {\n                    const binChunks = ba.binIndex[bin];\n                    for (const c of binChunks) {\n                        chunks.push(c);\n                    }\n                }\n            }\n        }\n        return optimizeChunks(chunks, new VirtualOffset(0, 0));\n    }\n    /**\n     * calculate the list of bins that may overlap with region [beg,end)\n     * (zero-based half-open)\n     */\n    reg2bins(beg, end) {\n        beg -= 1; // < convert to 1-based closed\n        if (beg < 1) {\n            beg = 1;\n        }\n        if (end > 2 ** 50) {\n            end = 2 ** 34;\n        } // 17 GiB ought to be enough for anybody\n        end -= 1;\n        let l = 0;\n        let t = 0;\n        let s = this.minShift + this.depth * 3;\n        const bins = [];\n        for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n            const b = t + rshift(beg, s);\n            const e = t + rshift(end, s);\n            if (e - b + bins.length > this.maxBinNumber) {\n                throw new Error(`query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`);\n            }\n            bins.push([b, e]);\n        }\n        return bins;\n    }\n    async parse(opts = {}) {\n        if (!this.setupP) {\n            this.setupP = this._parse(opts).catch((e) => {\n                this.setupP = undefined;\n                throw e;\n            });\n        }\n        return this.setupP;\n    }\n    async hasRefSeq(seqId, opts = {}) {\n        const header = await this.parse(opts);\n        return !!header.indices[seqId]?.binIndex;\n    }\n}\n//# sourceMappingURL=csi.js.map","export default {\n    //  the read is paired in sequencing, no matter whether it is mapped in a pair\n    BAM_FPAIRED: 1,\n    //  the read is mapped in a proper pair\n    BAM_FPROPER_PAIR: 2,\n    //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR\n    BAM_FUNMAP: 4,\n    //  the mate is unmapped\n    BAM_FMUNMAP: 8,\n    //  the read is mapped to the reverse strand\n    BAM_FREVERSE: 16,\n    //  the mate is mapped to the reverse strand\n    BAM_FMREVERSE: 32,\n    //  this is read1\n    BAM_FREAD1: 64,\n    //  this is read2\n    BAM_FREAD2: 128,\n    //  not primary alignment\n    BAM_FSECONDARY: 256,\n    //  QC failure\n    BAM_FQCFAIL: 512,\n    //  optical or PCR duplicate\n    BAM_FDUP: 1024,\n    //  supplementary alignment\n    BAM_FSUPPLEMENTARY: 2048,\n};\n//# sourceMappingURL=constants.js.map","import Constants from './constants';\nconst SEQRET_DECODER = '=ACMGRSVTWYHKDBN'.split('');\nconst CIGAR_DECODER = 'MIDNSHP=X???????'.split('');\nexport default class BamRecord {\n    fileOffset;\n    bytes;\n    #dataView;\n    constructor(args) {\n        this.bytes = args.bytes;\n        this.fileOffset = args.fileOffset;\n        this.#dataView = new DataView(this.bytes.byteArray.buffer);\n    }\n    get byteArray() {\n        return this.bytes.byteArray;\n    }\n    get flags() {\n        return ((this.#dataView.getInt32(this.bytes.start + 16, true) & 0xffff0000) >> 16);\n    }\n    get ref_id() {\n        return this.#dataView.getInt32(this.bytes.start + 4, true);\n    }\n    get start() {\n        return this.#dataView.getInt32(this.bytes.start + 8, true);\n    }\n    get end() {\n        return this.start + this.length_on_ref;\n    }\n    get id() {\n        return this.fileOffset;\n    }\n    get mq() {\n        const mq = (this.bin_mq_nl & 0xff00) >> 8;\n        return mq === 255 ? undefined : mq;\n    }\n    get score() {\n        return this.mq;\n    }\n    get qual() {\n        if (this.isSegmentUnmapped()) {\n            return;\n        }\n        const p = this.b0 +\n            this.read_name_length +\n            this.num_cigar_ops * 4 +\n            this.num_seq_bytes;\n        return this.byteArray.subarray(p, p + this.seq_length);\n    }\n    get strand() {\n        return this.isReverseComplemented() ? -1 : 1;\n    }\n    get b0() {\n        return this.bytes.start + 36;\n    }\n    get name() {\n        let str = '';\n        for (let i = 0; i < this.read_name_length - 1; i++) {\n            str += String.fromCharCode(this.byteArray[this.b0 + i]);\n        }\n        return str;\n    }\n    get tags() {\n        let p = this.b0 +\n            this.read_name_length +\n            this.num_cigar_ops * 4 +\n            this.num_seq_bytes +\n            this.seq_length;\n        const blockEnd = this.bytes.end;\n        const tags = {};\n        while (p < blockEnd) {\n            const tag = String.fromCharCode(this.byteArray[p], this.byteArray[p + 1]);\n            const type = String.fromCharCode(this.byteArray[p + 2]);\n            p += 3;\n            if (type === 'A') {\n                tags[tag] = String.fromCharCode(this.byteArray[p]);\n                p += 1;\n            }\n            else if (type === 'i') {\n                tags[tag] = this.#dataView.getInt32(p, true);\n                p += 4;\n            }\n            else if (type === 'I') {\n                tags[tag] = this.#dataView.getUint32(p, true);\n                p += 4;\n            }\n            else if (type === 'c') {\n                tags[tag] = this.#dataView.getInt8(p);\n                p += 1;\n            }\n            else if (type === 'C') {\n                tags[tag] = this.#dataView.getUint8(p);\n                p += 1;\n            }\n            else if (type === 's') {\n                tags[tag] = this.#dataView.getInt16(p, true);\n                p += 2;\n            }\n            else if (type === 'S') {\n                tags[tag] = this.#dataView.getUint16(p, true);\n                p += 2;\n            }\n            else if (type === 'f') {\n                tags[tag] = this.#dataView.getFloat32(p, true);\n                p += 4;\n            }\n            else if (type === 'Z' || type === 'H') {\n                const value = [];\n                while (p <= blockEnd) {\n                    const cc = this.byteArray[p++];\n                    if (cc !== 0) {\n                        value.push(String.fromCharCode(cc));\n                    }\n                    else {\n                        break;\n                    }\n                }\n                tags[tag] = value.join('');\n            }\n            else if (type === 'B') {\n                const cc = this.byteArray[p++];\n                const Btype = String.fromCharCode(cc);\n                const limit = this.#dataView.getInt32(p, true);\n                p += 4;\n                if (Btype === 'i') {\n                    if (tag === 'CG') {\n                        const value = [];\n                        for (let k = 0; k < limit; k++) {\n                            const cigop = this.#dataView.getInt32(p, true);\n                            const lop = cigop >> 4;\n                            const op = CIGAR_DECODER[cigop & 0xf];\n                            value.push(lop + op);\n                            p += 4;\n                        }\n                        tags[tag] = value.join('');\n                    }\n                    else {\n                        const value = [];\n                        for (let k = 0; k < limit; k++) {\n                            value.push(this.#dataView.getInt32(p, true));\n                            p += 4;\n                        }\n                        tags[tag] = value;\n                    }\n                }\n                else if (Btype === 'I') {\n                    if (tag === 'CG') {\n                        const value = [];\n                        for (let k = 0; k < limit; k++) {\n                            const cigop = this.#dataView.getUint32(p, true);\n                            const lop = cigop >> 4;\n                            const op = CIGAR_DECODER[cigop & 0xf];\n                            value.push(lop + op);\n                            p += 4;\n                        }\n                        tags[tag] = value.join('');\n                    }\n                    else {\n                        const value = [];\n                        for (let k = 0; k < limit; k++) {\n                            value.push(this.#dataView.getUint32(p, true));\n                            p += 4;\n                        }\n                        tags[tag] = value;\n                    }\n                }\n                else if (Btype === 's') {\n                    const value = [];\n                    for (let k = 0; k < limit; k++) {\n                        value.push(this.#dataView.getInt16(p, true));\n                        p += 2;\n                    }\n                    tags[tag] = value;\n                }\n                else if (Btype === 'S') {\n                    const value = [];\n                    for (let k = 0; k < limit; k++) {\n                        value.push(this.#dataView.getUint16(p, true));\n                        p += 2;\n                    }\n                    tags[tag] = value;\n                }\n                else if (Btype === 'c') {\n                    const value = [];\n                    for (let k = 0; k < limit; k++) {\n                        value.push(this.#dataView.getInt8(p));\n                        p += 1;\n                    }\n                    tags[tag] = value;\n                }\n                else if (Btype === 'C') {\n                    const value = [];\n                    for (let k = 0; k < limit; k++) {\n                        value.push(this.#dataView.getUint8(p));\n                        p += 1;\n                    }\n                    tags[tag] = value;\n                }\n                else if (Btype === 'f') {\n                    const value = [];\n                    for (let k = 0; k < limit; k++) {\n                        value.push(this.#dataView.getFloat32(p, true));\n                        p += 4;\n                    }\n                    tags[tag] = value;\n                }\n            }\n            else {\n                console.error('Unknown BAM tag type', type);\n                break;\n            }\n        }\n        return tags;\n    }\n    /**\n     * @returns {boolean} true if the read is paired, regardless of whether both\n     * segments are mapped\n     */\n    isPaired() {\n        return !!(this.flags & Constants.BAM_FPAIRED);\n    }\n    /** @returns {boolean} true if the read is paired, and both segments are mapped */\n    isProperlyPaired() {\n        return !!(this.flags & Constants.BAM_FPROPER_PAIR);\n    }\n    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n    isSegmentUnmapped() {\n        return !!(this.flags & Constants.BAM_FUNMAP);\n    }\n    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n    isMateUnmapped() {\n        return !!(this.flags & Constants.BAM_FMUNMAP);\n    }\n    /** @returns {boolean} true if the read is mapped to the reverse strand */\n    isReverseComplemented() {\n        return !!(this.flags & Constants.BAM_FREVERSE);\n    }\n    /** @returns {boolean} true if the mate is mapped to the reverse strand */\n    isMateReverseComplemented() {\n        return !!(this.flags & Constants.BAM_FMREVERSE);\n    }\n    /** @returns {boolean} true if this is read number 1 in a pair */\n    isRead1() {\n        return !!(this.flags & Constants.BAM_FREAD1);\n    }\n    /** @returns {boolean} true if this is read number 2 in a pair */\n    isRead2() {\n        return !!(this.flags & Constants.BAM_FREAD2);\n    }\n    /** @returns {boolean} true if this is a secondary alignment */\n    isSecondary() {\n        return !!(this.flags & Constants.BAM_FSECONDARY);\n    }\n    /** @returns {boolean} true if this read has failed QC checks */\n    isFailedQc() {\n        return !!(this.flags & Constants.BAM_FQCFAIL);\n    }\n    /** @returns {boolean} true if the read is an optical or PCR duplicate */\n    isDuplicate() {\n        return !!(this.flags & Constants.BAM_FDUP);\n    }\n    /** @returns {boolean} true if this is a supplementary alignment */\n    isSupplementary() {\n        return !!(this.flags & Constants.BAM_FSUPPLEMENTARY);\n    }\n    get cigarAndLength() {\n        if (this.isSegmentUnmapped()) {\n            return {\n                length_on_ref: 0,\n                CIGAR: '',\n            };\n        }\n        const numCigarOps = this.num_cigar_ops;\n        let p = this.b0 + this.read_name_length;\n        const CIGAR = [];\n        // check for CG tag by inspecting whether the CIGAR field contains a clip\n        // that consumes entire seqLen\n        let cigop = this.#dataView.getInt32(p, true);\n        let lop = cigop >> 4;\n        let op = CIGAR_DECODER[cigop & 0xf];\n        if (op === 'S' && lop === this.seq_length) {\n            // if there is a CG the second CIGAR field will be a N tag the represents\n            // the length on ref\n            p += 4;\n            cigop = this.#dataView.getInt32(p, true);\n            lop = cigop >> 4;\n            op = CIGAR_DECODER[cigop & 0xf];\n            if (op !== 'N') {\n                console.warn('CG tag with no N tag');\n            }\n            return {\n                CIGAR: this.tags.CG,\n                length_on_ref: lop,\n            };\n        }\n        else {\n            let lref = 0;\n            for (let c = 0; c < numCigarOps; ++c) {\n                cigop = this.#dataView.getInt32(p, true);\n                lop = cigop >> 4;\n                op = CIGAR_DECODER[cigop & 0xf];\n                CIGAR.push(lop + op);\n                // soft clip, hard clip, and insertion don't count toward the length on\n                // the reference\n                if (op !== 'H' && op !== 'S' && op !== 'I') {\n                    lref += lop;\n                }\n                p += 4;\n            }\n            return {\n                CIGAR: CIGAR.join(''),\n                length_on_ref: lref,\n            };\n        }\n    }\n    get length_on_ref() {\n        return this.cigarAndLength.length_on_ref;\n    }\n    get CIGAR() {\n        return this.cigarAndLength.CIGAR;\n    }\n    get num_cigar_ops() {\n        return this.flag_nc & 0xffff;\n    }\n    get read_name_length() {\n        return this.bin_mq_nl & 0xff;\n    }\n    get num_seq_bytes() {\n        return (this.seq_length + 1) >> 1;\n    }\n    get seq() {\n        const { byteArray } = this.bytes;\n        const p = this.b0 + this.read_name_length + this.num_cigar_ops * 4;\n        const seqBytes = this.num_seq_bytes;\n        const len = this.seq_length;\n        const buf = [];\n        let i = 0;\n        for (let j = 0; j < seqBytes; ++j) {\n            const sb = byteArray[p + j];\n            buf.push(SEQRET_DECODER[(sb & 0xf0) >> 4]);\n            i++;\n            if (i < len) {\n                buf.push(SEQRET_DECODER[sb & 0x0f]);\n                i++;\n            }\n        }\n        return buf.join('');\n    }\n    // adapted from igv.js\n    get pair_orientation() {\n        if (!this.isSegmentUnmapped() &&\n            !this.isMateUnmapped() &&\n            this.ref_id === this.next_refid) {\n            const s1 = this.isReverseComplemented() ? 'R' : 'F';\n            const s2 = this.isMateReverseComplemented() ? 'R' : 'F';\n            let o1 = ' ';\n            let o2 = ' ';\n            if (this.isRead1()) {\n                o1 = '1';\n                o2 = '2';\n            }\n            else if (this.isRead2()) {\n                o1 = '2';\n                o2 = '1';\n            }\n            const tmp = [];\n            const isize = this.template_length;\n            if (isize > 0) {\n                tmp[0] = s1;\n                tmp[1] = o1;\n                tmp[2] = s2;\n                tmp[3] = o2;\n            }\n            else {\n                tmp[2] = s1;\n                tmp[3] = o1;\n                tmp[0] = s2;\n                tmp[1] = o2;\n            }\n            return tmp.join('');\n        }\n        return undefined;\n    }\n    get bin_mq_nl() {\n        return this.#dataView.getInt32(this.bytes.start + 12, true);\n    }\n    get flag_nc() {\n        return this.#dataView.getInt32(this.bytes.start + 16, true);\n    }\n    get seq_length() {\n        return this.#dataView.getInt32(this.bytes.start + 20, true);\n    }\n    get next_refid() {\n        return this.#dataView.getInt32(this.bytes.start + 24, true);\n    }\n    get next_pos() {\n        return this.#dataView.getInt32(this.bytes.start + 28, true);\n    }\n    get template_length() {\n        return this.#dataView.getInt32(this.bytes.start + 32, true);\n    }\n    toJSON() {\n        const data = {};\n        for (const k of Object.keys(this)) {\n            if (k.startsWith('_') || k === 'bytes') {\n                continue;\n            }\n            //@ts-ignore\n            data[k] = this[k];\n        }\n        return data;\n    }\n}\nfunction cacheGetter(ctor, prop) {\n    const desc = Object.getOwnPropertyDescriptor(ctor.prototype, prop);\n    if (!desc) {\n        throw new Error('OH NO, NO PROPERTY DESCRIPTOR');\n    }\n    // eslint-disable-next-line @typescript-eslint/unbound-method\n    const getter = desc.get;\n    if (!getter) {\n        throw new Error('OH NO, NOT A GETTER');\n    }\n    Object.defineProperty(ctor.prototype, prop, {\n        get() {\n            const ret = getter.call(this);\n            Object.defineProperty(this, prop, { value: ret });\n            return ret;\n        },\n    });\n}\ncacheGetter(BamRecord, 'tags');\ncacheGetter(BamRecord, 'cigarAndLength');\ncacheGetter(BamRecord, 'seq');\ncacheGetter(BamRecord, 'qual');\n//# sourceMappingURL=record.js.map","export function parseHeaderText(text) {\n    const lines = text.split(/\\r?\\n/);\n    const data = [];\n    for (const line of lines) {\n        const [tag, ...fields] = line.split(/\\t/);\n        if (tag) {\n            data.push({\n                tag: tag.slice(1),\n                data: fields.map(f => {\n                    const r = f.indexOf(':');\n                    const fieldTag = f.slice(0, r);\n                    const value = f.slice(r + 1);\n                    return { tag: fieldTag, value };\n                }),\n            });\n        }\n    }\n    return data;\n}\n//# sourceMappingURL=sam.js.map","import crc32 from 'crc/calculators/crc32';\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle';\nimport { LocalFile, RemoteFile } from 'generic-filehandle2';\nimport AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport QuickLRU from 'quick-lru';\n// locals\nimport BAI from './bai';\nimport CSI from './csi';\nimport BAMFeature from './record';\nimport { parseHeaderText } from './sam';\nimport { checkAbortSignal, timeout, makeOpts } from './util';\nexport const BAM_MAGIC = 21840194;\nconst blockLen = 1 << 16;\nasync function gen2array(gen) {\n    let out = [];\n    for await (const x of gen) {\n        out = out.concat(x);\n    }\n    return out;\n}\nclass NullFilehandle {\n    read() {\n        throw new Error('never called');\n    }\n    stat() {\n        throw new Error('never called');\n    }\n    readFile() {\n        throw new Error('never called');\n    }\n    close() {\n        throw new Error('never called');\n    }\n}\nexport default class BamFile {\n    renameRefSeq;\n    bam;\n    header;\n    chrToIndex;\n    indexToChr;\n    yieldThreadTime;\n    index;\n    htsget = false;\n    headerP;\n    featureCache = new AbortablePromiseCache({\n        cache: new QuickLRU({\n            maxSize: 50,\n        }),\n        fill: async (args, signal) => {\n            const { chunk, opts } = args;\n            const { data, cpositions, dpositions } = await this._readChunk({\n                chunk,\n                opts: { ...opts, signal },\n            });\n            return this.readBamFeatures(data, cpositions, dpositions, chunk);\n        },\n    });\n    constructor({ bamFilehandle, bamPath, bamUrl, baiPath, baiFilehandle, baiUrl, csiPath, csiFilehandle, csiUrl, htsget, yieldThreadTime = 100, renameRefSeqs = n => n, }) {\n        this.renameRefSeq = renameRefSeqs;\n        if (bamFilehandle) {\n            this.bam = bamFilehandle;\n        }\n        else if (bamPath) {\n            this.bam = new LocalFile(bamPath);\n        }\n        else if (bamUrl) {\n            this.bam = new RemoteFile(bamUrl);\n        }\n        else if (htsget) {\n            this.htsget = true;\n            this.bam = new NullFilehandle();\n        }\n        else {\n            throw new Error('unable to initialize bam');\n        }\n        if (csiFilehandle) {\n            this.index = new CSI({ filehandle: csiFilehandle });\n        }\n        else if (csiPath) {\n            this.index = new CSI({ filehandle: new LocalFile(csiPath) });\n        }\n        else if (csiUrl) {\n            this.index = new CSI({ filehandle: new RemoteFile(csiUrl) });\n        }\n        else if (baiFilehandle) {\n            this.index = new BAI({ filehandle: baiFilehandle });\n        }\n        else if (baiPath) {\n            this.index = new BAI({ filehandle: new LocalFile(baiPath) });\n        }\n        else if (baiUrl) {\n            this.index = new BAI({ filehandle: new RemoteFile(baiUrl) });\n        }\n        else if (bamPath) {\n            this.index = new BAI({ filehandle: new LocalFile(`${bamPath}.bai`) });\n        }\n        else if (bamUrl) {\n            this.index = new BAI({ filehandle: new RemoteFile(`${bamUrl}.bai`) });\n        }\n        else if (htsget) {\n            this.htsget = true;\n        }\n        else {\n            throw new Error('unable to infer index format');\n        }\n        this.yieldThreadTime = yieldThreadTime;\n    }\n    async getHeaderPre(origOpts) {\n        const opts = makeOpts(origOpts);\n        if (!this.index) {\n            return;\n        }\n        const indexData = await this.index.parse(opts);\n        const ret = indexData.firstDataLine\n            ? indexData.firstDataLine.blockPosition + 65535\n            : undefined;\n        let buffer;\n        if (ret) {\n            const s = ret + blockLen;\n            buffer = await this.bam.read(s, 0);\n        }\n        else {\n            buffer = await this.bam.readFile(opts);\n        }\n        const uncba = await unzip(buffer);\n        const dataView = new DataView(uncba.buffer);\n        if (dataView.getInt32(0, true) !== BAM_MAGIC) {\n            throw new Error('Not a BAM file');\n        }\n        const headLen = dataView.getInt32(4, true);\n        const decoder = new TextDecoder('utf8');\n        this.header = decoder.decode(uncba.subarray(8, 8 + headLen));\n        const { chrToIndex, indexToChr } = await this._readRefSeqs(headLen + 8, 65535, opts);\n        this.chrToIndex = chrToIndex;\n        this.indexToChr = indexToChr;\n        return parseHeaderText(this.header);\n    }\n    getHeader(opts) {\n        if (!this.headerP) {\n            this.headerP = this.getHeaderPre(opts).catch((e) => {\n                this.headerP = undefined;\n                throw e;\n            });\n        }\n        return this.headerP;\n    }\n    async getHeaderText(opts = {}) {\n        await this.getHeader(opts);\n        return this.header;\n    }\n    // the full length of the refseq block is not given in advance so this grabs\n    // a chunk and doubles it if all refseqs haven't been processed\n    async _readRefSeqs(start, refSeqBytes, opts) {\n        if (start > refSeqBytes) {\n            return this._readRefSeqs(start, refSeqBytes * 2, opts);\n        }\n        // const size = refSeqBytes + blockLen <-- use this?\n        const buffer = await this.bam.read(refSeqBytes, 0, opts);\n        const uncba = await unzip(buffer);\n        const dataView = new DataView(uncba.buffer);\n        const nRef = dataView.getInt32(start, true);\n        let p = start + 4;\n        const chrToIndex = {};\n        const indexToChr = [];\n        const decoder = new TextDecoder('utf8');\n        for (let i = 0; i < nRef; i += 1) {\n            const lName = dataView.getInt32(p, true);\n            const refName = this.renameRefSeq(decoder.decode(uncba.subarray(p + 4, p + 4 + lName - 1)));\n            const lRef = dataView.getInt32(p + lName + 4, true);\n            chrToIndex[refName] = i;\n            indexToChr.push({ refName, length: lRef });\n            p = p + 8 + lName;\n            if (p > uncba.length) {\n                console.warn(`BAM header is very big.  Re-fetching ${refSeqBytes} bytes.`);\n                return this._readRefSeqs(start, refSeqBytes * 2, opts);\n            }\n        }\n        return { chrToIndex, indexToChr };\n    }\n    async getRecordsForRange(chr, min, max, opts) {\n        return gen2array(this.streamRecordsForRange(chr, min, max, opts));\n    }\n    async *streamRecordsForRange(chr, min, max, opts) {\n        await this.getHeader(opts);\n        const chrId = this.chrToIndex?.[chr];\n        if (chrId === undefined || !this.index) {\n            yield [];\n        }\n        else {\n            const chunks = await this.index.blocksForRange(chrId, min - 1, max, opts);\n            yield* this._fetchChunkFeatures(chunks, chrId, min, max, opts);\n        }\n    }\n    async *_fetchChunkFeatures(chunks, chrId, min, max, opts = {}) {\n        const { viewAsPairs } = opts;\n        const feats = [];\n        let done = false;\n        for (const chunk of chunks) {\n            const records = await this.featureCache.get(chunk.toString(), { chunk, opts }, opts.signal);\n            const recs = [];\n            for (const feature of records) {\n                if (feature.ref_id === chrId) {\n                    if (feature.start >= max) {\n                        // past end of range, can stop iterating\n                        done = true;\n                        break;\n                    }\n                    else if (feature.end >= min) {\n                        // must be in range\n                        recs.push(feature);\n                    }\n                }\n            }\n            feats.push(recs);\n            yield recs;\n            if (done) {\n                break;\n            }\n        }\n        checkAbortSignal(opts.signal);\n        if (viewAsPairs) {\n            yield this.fetchPairs(chrId, feats, opts);\n        }\n    }\n    async fetchPairs(chrId, feats, opts) {\n        const { pairAcrossChr, maxInsertSize = 200000 } = opts;\n        const unmatedPairs = {};\n        const readIds = {};\n        feats.map(ret => {\n            const readNames = {};\n            for (const element of ret) {\n                const name = element.name;\n                const id = element.id;\n                if (!readNames[name]) {\n                    readNames[name] = 0;\n                }\n                readNames[name]++;\n                readIds[id] = 1;\n            }\n            for (const [k, v] of Object.entries(readNames)) {\n                if (v === 1) {\n                    unmatedPairs[k] = true;\n                }\n            }\n        });\n        const matePromises = [];\n        feats.map(ret => {\n            for (const f of ret) {\n                const name = f.name;\n                const start = f.start;\n                const pnext = f.next_pos;\n                const rnext = f.next_refid;\n                if (this.index &&\n                    unmatedPairs[name] &&\n                    (pairAcrossChr ||\n                        (rnext === chrId && Math.abs(start - pnext) < maxInsertSize))) {\n                    matePromises.push(this.index.blocksForRange(rnext, pnext, pnext + 1, opts));\n                }\n            }\n        });\n        // filter out duplicate chunks (the blocks are lists of chunks, blocks are\n        // concatenated, then filter dup chunks)\n        const map = new Map();\n        const res = await Promise.all(matePromises);\n        for (const m of res.flat()) {\n            if (!map.has(m.toString())) {\n                map.set(m.toString(), m);\n            }\n        }\n        const mateFeatPromises = await Promise.all([...map.values()].map(async (c) => {\n            const { data, cpositions, dpositions, chunk } = await this._readChunk({\n                chunk: c,\n                opts,\n            });\n            const mateRecs = [];\n            for (const feature of await this.readBamFeatures(data, cpositions, dpositions, chunk)) {\n                if (unmatedPairs[feature.name] && !readIds[feature.id]) {\n                    mateRecs.push(feature);\n                }\n            }\n            return mateRecs;\n        }));\n        return mateFeatPromises.flat();\n    }\n    async _readRegion(position, size, opts = {}) {\n        return this.bam.read(size, position, opts);\n    }\n    async _readChunk({ chunk, opts }) {\n        const buffer = await this._readRegion(chunk.minv.blockPosition, chunk.fetchedSize(), opts);\n        const { buffer: data, cpositions, dpositions, } = await unzipChunkSlice(buffer, chunk);\n        return { data, cpositions, dpositions, chunk };\n    }\n    async readBamFeatures(ba, cpositions, dpositions, chunk) {\n        let blockStart = 0;\n        const sink = [];\n        let pos = 0;\n        let last = +Date.now();\n        const dataView = new DataView(ba.buffer);\n        while (blockStart + 4 < ba.length) {\n            const blockSize = dataView.getInt32(blockStart, true);\n            const blockEnd = blockStart + 4 + blockSize - 1;\n            // increment position to the current decompressed status\n            // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n            if (dpositions) {\n                while (blockStart + chunk.minv.dataPosition >= dpositions[pos++]) { }\n                pos--;\n            }\n            // only try to read the feature if we have all the bytes for it\n            if (blockEnd < ba.length) {\n                const feature = new BAMFeature({\n                    bytes: {\n                        byteArray: ba,\n                        start: blockStart,\n                        end: blockEnd,\n                    },\n                    // the below results in an automatically calculated file-offset based\n                    // ID if the info for that is available, otherwise crc32 of the\n                    // features\n                    //\n                    // cpositions[pos] refers to actual file offset of a bgzip block\n                    // boundaries\n                    //\n                    // we multiply by (1 <<8) in order to make sure each block has a\n                    // \"unique\" address space so that data in that block could never\n                    // overlap\n                    //\n                    // then the blockStart-dpositions is an uncompressed file offset from\n                    // that bgzip block boundary, and since the cpositions are multiplied\n                    // by (1 << 8) these uncompressed offsets get a unique space\n                    //\n                    // this has an extra chunk.minv.dataPosition added on because it\n                    // blockStart starts at 0 instead of chunk.minv.dataPosition\n                    //\n                    // the +1 is just to avoid any possible uniqueId 0 but this does not\n                    // realistically happen\n                    fileOffset: cpositions.length > 0\n                        ? cpositions[pos] * (1 << 8) +\n                            (blockStart - dpositions[pos]) +\n                            chunk.minv.dataPosition +\n                            1\n                        : // this shift >>> 0 is equivalent to crc32(b).unsigned but uses the\n                            // internal calculator of crc32 to avoid accidentally importing buffer\n                            // https://github.com/alexgorbatchev/crc/blob/31fc3853e417b5fb5ec83335428805842575f699/src/define_crc.ts#L5\n                            crc32(ba.subarray(blockStart, blockEnd)) >>> 0,\n                });\n                sink.push(feature);\n                if (this.yieldThreadTime && +Date.now() - last > this.yieldThreadTime) {\n                    await timeout(1);\n                    last = +Date.now();\n                }\n            }\n            blockStart = blockEnd + 1;\n        }\n        return sink;\n    }\n    async hasRefSeq(seqName) {\n        const seqId = this.chrToIndex?.[seqName];\n        return seqId === undefined ? false : this.index?.hasRefSeq(seqId);\n    }\n    async lineCount(seqName) {\n        const seqId = this.chrToIndex?.[seqName];\n        return seqId === undefined || !this.index ? 0 : this.index.lineCount(seqId);\n    }\n    async indexCov(seqName, start, end) {\n        if (!this.index) {\n            return [];\n        }\n        await this.index.parse();\n        const seqId = this.chrToIndex?.[seqName];\n        return seqId === undefined ? [] : this.index.indexCov(seqId, start, end);\n    }\n    async blocksForRange(seqName, start, end, opts) {\n        if (!this.index) {\n            return [];\n        }\n        await this.index.parse();\n        const seqId = this.chrToIndex?.[seqName];\n        return seqId === undefined\n            ? []\n            : this.index.blocksForRange(seqId, start, end, opts);\n    }\n}\n//# sourceMappingURL=bamFile.js.map","import { unzip } from '@gmod/bgzf-filehandle';\nimport { concatUint8Array } from './util';\nimport BamFile, { BAM_MAGIC } from './bamFile';\nimport { parseHeaderText } from './sam';\nasync function concat(arr, opts) {\n    const res = await Promise.all(arr.map(async (chunk) => {\n        const { url, headers } = chunk;\n        if (url.startsWith('data:')) {\n            // pass base64 data url to fetch to decode to buffer\n            // https://stackoverflow.com/a/54123275/2129219\n            const res = await fetch(url);\n            if (!res.ok) {\n                throw new Error('failed to decode base64');\n            }\n            const ret = await res.arrayBuffer();\n            return new Uint8Array(ret);\n        }\n        else {\n            //remove referer header, it is not even allowed to be specified\n            // @ts-expect-error\n            const { referer, ...rest } = headers;\n            const res = await fetch(url, {\n                ...opts,\n                headers: { ...opts?.headers, ...rest },\n            });\n            if (!res.ok) {\n                throw new Error(`HTTP ${res.status} fetching ${url}: ${await res.text()}`);\n            }\n            return new Uint8Array(await res.arrayBuffer());\n        }\n    }));\n    return concatUint8Array(await Promise.all(res.map(elt => unzip(elt))));\n}\nexport default class HtsgetFile extends BamFile {\n    baseUrl;\n    trackId;\n    constructor(args) {\n        super({ htsget: true });\n        this.baseUrl = args.baseUrl;\n        this.trackId = args.trackId;\n    }\n    async *streamRecordsForRange(chr, min, max, opts) {\n        const base = `${this.baseUrl}/${this.trackId}`;\n        const url = `${base}?referenceName=${chr}&start=${min}&end=${max}&format=BAM`;\n        const chrId = this.chrToIndex?.[chr];\n        if (chrId === undefined) {\n            yield [];\n        }\n        else {\n            const result = await fetch(url, { ...opts });\n            if (!result.ok) {\n                throw new Error(`HTTP ${result.status} fetching ${url}: ${await result.text()}`);\n            }\n            const data = await result.json();\n            const uncba = await concat(data.htsget.urls.slice(1), opts);\n            yield* this._fetchChunkFeatures([\n                // fake stuff to pretend to be a Chunk\n                {\n                    buffer: uncba,\n                    _fetchedSize: undefined,\n                    bin: 0,\n                    compareTo() {\n                        return 0;\n                    },\n                    toUniqueString() {\n                        return `${chr}_${min}_${max}`;\n                    },\n                    fetchedSize() {\n                        return 0;\n                    },\n                    minv: {\n                        dataPosition: 0,\n                        blockPosition: 0,\n                        compareTo: () => 0,\n                    },\n                    maxv: {\n                        dataPosition: Number.MAX_SAFE_INTEGER,\n                        blockPosition: 0,\n                        compareTo: () => 0,\n                    },\n                    toString() {\n                        return `${chr}_${min}_${max}`;\n                    },\n                },\n            ], chrId, min, max, opts);\n        }\n    }\n    // @ts-expect-error\n    async _readChunk({ chunk }) {\n        if (!chunk.buffer) {\n            throw new Error('expected chunk.buffer in htsget');\n        }\n        return {\n            data: chunk.buffer,\n            cpositions: [],\n            dpositions: [],\n            chunk,\n        };\n    }\n    async getHeader(opts = {}) {\n        const url = `${this.baseUrl}/${this.trackId}?referenceName=na&class=header`;\n        const result = await fetch(url, opts);\n        if (!result.ok) {\n            throw new Error(`HTTP ${result.status} fetching ${url}: ${await result.text()}`);\n        }\n        const data = await result.json();\n        const uncba = await concat(data.htsget.urls, opts);\n        const dataView = new DataView(uncba.buffer);\n        if (dataView.getInt32(0, true) !== BAM_MAGIC) {\n            throw new Error('Not a BAM file');\n        }\n        const headLen = dataView.getInt32(4, true);\n        const decoder = new TextDecoder('utf8');\n        const headerText = decoder.decode(uncba.subarray(8, 8 + headLen));\n        const samHeader = parseHeaderText(headerText);\n        // use the @SQ lines in the header to figure out the\n        // mapping between ref ref ID numbers and names\n        const idToName = [];\n        const nameToId = {};\n        const sqLines = samHeader.filter(l => l.tag === 'SQ');\n        for (const [refId, sqLine] of sqLines.entries()) {\n            let refName = '';\n            let length = 0;\n            for (const item of sqLine.data) {\n                if (item.tag === 'SN') {\n                    refName = item.value;\n                }\n                else if (item.tag === 'LN') {\n                    length = +item.value;\n                }\n            }\n            nameToId[refName] = refId;\n            idToName[refId] = { refName, length };\n        }\n        this.chrToIndex = nameToId;\n        this.indexToChr = idToName;\n        return samHeader;\n    }\n}\n//# sourceMappingURL=htsget.js.map","export { default as BAI } from './bai';\nexport { default as BamFile } from './bamFile';\nexport { default as CSI } from './csi';\nexport { default as BamRecord } from './record';\nexport { default as HtsgetFile } from './htsget';\n//# sourceMappingURL=index.js.map","import { getMismatches } from '../MismatchParser';\nimport { cacheGetter } from '../shared/util';\nexport default class BamSlightlyLazyFeature {\n    constructor(record, adapter, ref) {\n        this.record = record;\n        this.adapter = adapter;\n        this.ref = ref;\n    }\n    id() {\n        return `${this.adapter.id}-${this.record.id}`;\n    }\n    get mismatches() {\n        return getMismatches(this.record.CIGAR, this.record.tags.MD, this.record.seq, this.ref, this.record.qual);\n    }\n    get qual() {\n        var _a;\n        return (_a = this.record.qual) === null || _a === void 0 ? void 0 : _a.join(' ');\n    }\n    get(field) {\n        return field === 'mismatches'\n            ? this.mismatches\n            : field === 'qual'\n                ? this.qual\n                : this.fields[field];\n    }\n    parent() {\n        return undefined;\n    }\n    children() {\n        return undefined;\n    }\n    get fields() {\n        const r = this.record;\n        const a = this.adapter;\n        const p = r.isPaired();\n        return {\n            start: r.start,\n            name: r.name,\n            end: r.end,\n            score: r.score,\n            strand: r.strand,\n            template_length: r.template_length,\n            flags: r.flags,\n            tags: r.tags,\n            refName: a.refIdToName(r.ref_id),\n            CIGAR: r.CIGAR,\n            seq: r.seq,\n            type: 'match',\n            pair_orientation: r.pair_orientation,\n            next_ref: p ? a.refIdToName(r.next_refid) : undefined,\n            next_pos: p ? r.next_pos : undefined,\n            next_segment_position: p\n                ? `${a.refIdToName(r.next_refid)}:${r.next_pos + 1}`\n                : undefined,\n            uniqueId: this.id(),\n        };\n    }\n    toJSON() {\n        return {\n            ...this.fields,\n            qual: this.qual,\n        };\n    }\n}\ncacheGetter(BamSlightlyLazyFeature, 'fields');\ncacheGetter(BamSlightlyLazyFeature, 'mismatches');\n","import { BamFile } from '@gmod/bam';\nimport { BaseFeatureDataAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { bytesForRegions, updateStatus } from '@jbrowse/core/util';\nimport QuickLRU from '@jbrowse/core/util/QuickLRU';\nimport { openLocation } from '@jbrowse/core/util/io';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport { checkStopToken } from '@jbrowse/core/util/stopToken';\nimport { firstValueFrom } from 'rxjs';\nimport { toArray } from 'rxjs/operators';\nimport BamSlightlyLazyFeature from './BamSlightlyLazyFeature';\nimport { filterReadFlag, filterTagValue } from '../shared/util';\nexport default class BamAdapter extends BaseFeatureDataAdapter {\n    constructor() {\n        super(...arguments);\n        this.ultraLongFeatureCache = new QuickLRU({\n            maxSize: 500,\n        });\n    }\n    async configurePre() {\n        const bamLocation = this.getConf('bamLocation');\n        const location = this.getConf(['index', 'location']);\n        const indexType = this.getConf(['index', 'indexType']);\n        const pm = this.pluginManager;\n        const csi = indexType === 'CSI';\n        const bam = new BamFile({\n            bamFilehandle: openLocation(bamLocation, pm),\n            csiFilehandle: csi ? openLocation(location, pm) : undefined,\n            baiFilehandle: !csi ? openLocation(location, pm) : undefined,\n            yieldThreadTime: Number.POSITIVE_INFINITY,\n        });\n        const adapterConfig = this.getConf('sequenceAdapter');\n        if (adapterConfig && this.getSubAdapter) {\n            const { dataAdapter } = await this.getSubAdapter(adapterConfig);\n            return {\n                bam,\n                sequenceAdapter: dataAdapter,\n            };\n        }\n        return { bam };\n    }\n    async configure() {\n        if (!this.configureP) {\n            this.configureP = this.configurePre().catch((e) => {\n                this.configureP = undefined;\n                throw e;\n            });\n        }\n        return this.configureP;\n    }\n    async getHeader(_opts) {\n        const { bam } = await this.configure();\n        return bam.getHeaderText();\n    }\n    async setupPre(opts) {\n        const { statusCallback = () => { } } = opts || {};\n        const { bam } = await this.configure();\n        this.samHeader = await updateStatus('Downloading index', statusCallback, async () => {\n            const samHeader = await bam.getHeader();\n            const idToName = [];\n            const nameToId = {};\n            samHeader === null || samHeader === void 0 ? void 0 : samHeader.filter(l => l.tag === 'SQ').forEach((sqLine, refId) => {\n                const SN = sqLine.data.find(item => item.tag === 'SN');\n                if (SN) {\n                    const refName = SN.value;\n                    nameToId[refName] = refId;\n                    idToName[refId] = refName;\n                }\n            });\n            return { idToName, nameToId };\n        });\n        return this.samHeader;\n    }\n    async setup(opts) {\n        if (!this.setupP) {\n            this.setupP = this.setupPre(opts).catch((e) => {\n                this.setupP = undefined;\n                throw e;\n            });\n        }\n        return this.setupP;\n    }\n    async getRefNames(opts) {\n        const { idToName } = await this.setup(opts);\n        return idToName;\n    }\n    async seqFetch(refName, start, end) {\n        const { sequenceAdapter } = await this.configure();\n        const refSeqStore = sequenceAdapter;\n        if (!refSeqStore) {\n            return undefined;\n        }\n        if (!refName) {\n            return undefined;\n        }\n        const features = refSeqStore.getFeatures({\n            refName,\n            start,\n            end,\n            assemblyName: '',\n        });\n        const seqChunks = await firstValueFrom(features.pipe(toArray()));\n        let sequence = '';\n        seqChunks\n            .sort((a, b) => a.get('start') - b.get('start'))\n            .forEach(chunk => {\n            const chunkStart = chunk.get('start');\n            const chunkEnd = chunk.get('end');\n            const trimStart = Math.max(start - chunkStart, 0);\n            const trimEnd = Math.min(end - chunkStart, chunkEnd - chunkStart);\n            const trimLength = trimEnd - trimStart;\n            const chunkSeq = chunk.get('seq') || chunk.get('residues');\n            sequence += chunkSeq.slice(trimStart, trimStart + trimLength);\n        });\n        if (sequence.length !== end - start) {\n            throw new Error(`sequence fetch failed: fetching ${refName}:${(start - 1).toLocaleString()}-${end.toLocaleString()} returned ${sequence.length.toLocaleString()} bases, but should have returned ${(end - start).toLocaleString()}`);\n        }\n        return sequence;\n    }\n    getFeatures(region, opts) {\n        const { refName, start, end, originalRefName } = region;\n        const { stopToken, filterBy, statusCallback = () => { } } = opts || {};\n        return ObservableCreate(async (observer) => {\n            const { bam } = await this.configure();\n            await this.setup(opts);\n            checkStopToken(stopToken);\n            const records = await updateStatus('Downloading alignments', statusCallback, () => bam.getRecordsForRange(refName, start, end));\n            checkStopToken(stopToken);\n            await updateStatus('Processing alignments', statusCallback, async () => {\n                const { flagInclude = 0, flagExclude = 0, tagFilter, readName, } = filterBy || {};\n                for (const record of records) {\n                    let ref;\n                    if (!record.tags.MD) {\n                        ref = await this.seqFetch(originalRefName || refName, record.start, record.end);\n                    }\n                    if (filterReadFlag(record.flags, flagInclude, flagExclude)) {\n                        continue;\n                    }\n                    if (tagFilter &&\n                        filterTagValue(record.tags[tagFilter.tag], tagFilter.value)) {\n                        continue;\n                    }\n                    if (readName && record.name !== readName) {\n                        continue;\n                    }\n                    const ret = this.ultraLongFeatureCache.get(`${record.id}`);\n                    if (!ret) {\n                        const elt = new BamSlightlyLazyFeature(record, this, ref);\n                        this.ultraLongFeatureCache.set(`${record.id}`, elt);\n                        observer.next(elt);\n                    }\n                    else {\n                        observer.next(ret);\n                    }\n                }\n                observer.complete();\n            });\n        });\n    }\n    async getMultiRegionFeatureDensityStats(regions, opts) {\n        const { bam } = await this.configure();\n        if (bam.index) {\n            const bytes = await bytesForRegions(regions, bam);\n            const fetchSizeLimit = this.getConf('fetchSizeLimit');\n            return { bytes, fetchSizeLimit };\n        }\n        return super.getMultiRegionFeatureDensityStats(regions, opts);\n    }\n    freeResources() { }\n    refIdToName(refId) {\n        var _a;\n        return (_a = this.samHeader) === null || _a === void 0 ? void 0 : _a.idToName[refId];\n    }\n}\n","// Generated by `./pycrc.py --algorithm=table-driven --model=crc-32 --generate=c`\nlet TABLE = [\n    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f, 0xe963a535, 0x9e6495a3,\n    0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91,\n    0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,\n    0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5,\n    0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n    0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,\n    0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599, 0xb8bda50f,\n    0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924, 0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d,\n    0x76dc4190, 0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,\n    0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n    0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457,\n    0x65b0d9c6, 0x12b7e950, 0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,\n    0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb,\n    0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9,\n    0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad,\n    0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683,\n    0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,\n    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7,\n    0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n    0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,\n    0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79,\n    0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236, 0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f,\n    0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,\n    0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n    0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21,\n    0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,\n    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45,\n    0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db,\n    0xaed16a4a, 0xd9d65adc, 0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf,\n    0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d,\n];\nif (typeof Int32Array !== 'undefined') {\n    TABLE = new Int32Array(TABLE);\n}\nconst crc32 = (current, previous) => {\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    let crc = previous === 0 ? 0 : ~~previous ^ -1;\n    for (let index = 0; index < current.length; index++) {\n        crc = TABLE[(crc ^ current[index]) & 0xff] ^ (crc >>> 8);\n    }\n    return crc ^ -1;\n};\nexport default crc32;\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}