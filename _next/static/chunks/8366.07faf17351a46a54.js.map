{"version":3,"file":"static/chunks/8366.07faf17351a46a54.js","mappings":"kFACgE,UAG/D,WAAuB,aAGxB,uBAWA,6EAUA,oEAOA,cACA,wBACA,CAIA,cACA,sBACA,CACA,cACA,gBACA,iEACA,CAMA,0BACA,OACA,SACA,OACA,OACA,OACA,OACA,QACA,OACA,MACA,CACA,CACA,cACA,GAjCA,mBAiCA,CACA,mBAGA,OAFA,YACA,SACA,CACA,CACA,SACA,4BAIA,OAHA,YACA,UACA,SACA,CACA,CACA,GAxCA,sBAyCA,CA/BA,aA+BA,GA9BA,OACA,+DA6BA,CACA,GAnDA,OAmDA,GACA,YACA,6BAUA,OATA,YACA,UACA,SACA,kBACA,EACA,kBACA,EACA,EACA,EACA,CACA,CAyBA,gBACA,WACA,oBAGA,IAGA,IAIA,KACA,YAAwB,WAAmB,KAC3C,WAEA,OACA,KACA,QACA,CAIA,GAFA,KAEA,SAIA,aACA,GACA,KACA,IACA,KAEA,GAGA,WAEA,QACA,CAGA,SACA,IACA,CACA,SACA,YAAwB,IAAa,IACrC,YAEA,4BACA,SAEA,QACA,CAgEA,OA5DA,cACA,UACA,SACA,WACA,SACA,aACA,WACA,SACA,UACA,OACA,mBAEA,EACA,qBAEA,EACA,OAxFA,EAyFA,EAzFA,QAGA,MAsFA,EAtFA,KACA,OAqFA,EArFA,KAIA,gBAjBA,GAGA,qBACA,SACA,yBACA,qBACA,EAUA,QAiFA,EAjFA,UAmFA,EAEA,cACA,cACA,mBAEA,EAEA,kBAEA,KACA,KACA,CACA,OACA,qBACA,UAGA,OACA,OACA,QACA,SAEA,sBACA,MACA,cACA,kBAIA,eAEA,UACA,CACA,OACA,eACA,SACA,kDACA,CACA,CAIA,CAAC,qHC5OM,yBAAmD,EAC1D,mBAAY,MAAsB,EAClC,IACA,iBAA0C,gBAAkB,EAC5D,0BACA,8BACA,CACA,SACA,sBACA,gBACA,2BACA,6BACA,QAEA,QACA,CACA,CACO,oBACP,OAAW,IAAO,IAClB,CCjBe,QACf,QDekB,ICflB,UAAkB,kBAA2B,EAO7C,GANA,gBACA,oBAA8B,GAAqB,EACnD,SAAuB,MAAQ,CAAG,UAAoB,EACtD,mCACA,CAAS,EACT,gBACA,eACA,iDAEA,CACA,0BACA,eACA,aACA,qCACA,iCACA,iBACA,eACA,sBACA,CACA,oBACA,IAEA,EAFA,KACA,WAEA,YAEA,IADA,UACA,KACA,IAGA,WAKA,aACA,EAEA,CACA,CACA,kBAEA,OAAe,EADK,EAAM,mCAAoC,OAAO,qBAC9C,eAAuB,kBAAoB,CAClE,CACA,qCACA,qCACA,mCACA,KACA,mCAA8D,gCAA8D,MAC5H,6BAEA,cACA,kBACA,SACA,eACA,SACA,MAGA,wBAGA,aACA,IACA,oDAEA,CACA,gBACA,gBACA,IACA,2CACA,EACA,EACA,EAEA,CACA,CACA,oBAOA,8BAEA,0BACA,uBACA,4CANA,SAMA,SAEA,CACA,uBAGA,eACA,UACA,cACA,sCACA,wCACA,kCACA,YAAqC,KAAgB,KACrD,OAEA,CACA,QACA,CACA,CClBA,QACA,eACA,eACA,eACA,YAAyB,WAAqB,MAC9C,kBACA,YAA4B,yBAAmC,KAC/D,sCAEA,sBACA,gBAEA,2BACA,qBAEA,CACA,CAIA,eACA,sDACA,yCACA,OACA,CACA,SACA,0BACA,+BAGA,sBACA,0BACA,+BAEA,mDACA,0BAMA,QALA,8BACA,4BAEA,MAGA,CACA,cACA,cACA,eACA,CACA,CACA,cACA,UACA,aAEA,CACA,kBAGA,0BACA,mBACA,oBACA,kBAIA,CAwBA,YAIA,OAHA,iBACA,wCAEA,gBAKA,iBACA,SACA,GACA,OACA,gDACA,KACA,mBAGA,CAAa,CACb,SACA,kCACA,KACA,qBAGA,CAAa,CACb,OACA,sBACa,CAEb,0BACA,yBAIA,6BAEA,mCACA,cACA,YAEA,EADA,kBACA,UACA,WACA,CAAa,CACb,CAAS,EAET,wCAoBA,OAlBA,2BACA,WAEA,2BAIA,WACA,yBAJA,WAEA,CAWA,CAAS,EACT,CACA,CACA,CC/Oe,QACf,yBAAkB,kDAA2D,IAM7E,GALA,mBACA,iBACA,cACA,6BACA,gBACA,GACA,6CAEA,qBAA8B,GAAqB,EACnD,SAAuB,MAAQ,CAAG,UAAoB,EACtD,6BACA,CAAS,CACT,CAOA,aACA,0BACA,CAOA,kBACA,gBACA,4BACA,mCACA,+BACA,KACA,YAAqC,KAAoB,KACzD,iCAEA,gBACA,gBACA,oCACA,CACA,CACA,kBACA,qCAAiD,OAAO,OAKxD,OAJA,cACA,GAAkB,EAAM,iBAGxB,GADA,MAA2B,EAAQ,iBACnC,CAEA,0BAEA,uBACA,kBACA,iCACA,YAAiC,KAAe,KAChD,gBAGA,CC/DA,aACA,sBAEA,aACA,oBAEA,aACA,8BACA,CAYe,QACf,qBAAkB,0CAAgD,EAIlE,GAHA,eACA,mBAA8B,QAC9B,gBACA,eACA,0DAEA,wBAAiC,GAAqB,EACtD,SAAuB,MAAQ,CAAG,UAAoB,EACtD,kCACA,CAAS,CACT,CACA,aACA,WAAmB,EAAa,CAAG,GAAH,MAAG,cAAyB,CAC5D,CACA,kBACA,mGACA,CACA,eACA,kCACA,CACA,iBACA,MAAoB,EAAM,oCAAqC,aAAa,oBAE5E,OAAe,EAAQ,yBAEvB,yBACA,CACA,oBACA,OACA,yBACA,OACA,8BACA,CAAa,CAEb,eACA,YAAgC,EAAS,OFyLjB,EAAC,EEzLgB,UACzC,wBAEA,eAAgB,GAAa,EAC7B,YAEA,YAA4B,gBAA4B,KACxD,wBAAmD,EAAS,CAAG,MAAH,GAAG,uCAA4D,GAE3H,gBACA,CAeA,OAbA,eACA,uCACA,iBACA,YACA,2BACA,uBACA,6BACA,mBAEA,CAAqB,CACrB,CAAiB,CACjB,CAAa,EAEb,CACA,CACA,wBAEA,MADA,gCACA,MAcA,yCAAsC,wCAA4C,EAClF,gCACA,KACA,eAEA,KACA,0BAGA,qFAIA,MADA,0BACA,0BAaA,wBAEA,YAAwB,4BAAkC,KAC1D,sCACA,0BAIA,sBAEA,yCAGA,kCACA,gBACA,SACA,YAA8B,IAAe,KAC7C,OAEA,kDAIA,0BAEA,OAAqB,eACrB,CAIA,OAAiB,KADjB,gCACiB,QACjB,CAWA,4BAAyB,gBAAqB,EAC9C,gCACA,uBACA,4CAMA,iBACA,kBACA,4BAA4D,EAAQ,GAAG,EAAS,EAChF,CACA,OACA,CACA,CAGA,yBACA,YACA,cACA,cACA,OACA,YACA,WACA,aACA,2CACA,4BAAkD,EAAG,GAAG,EAAE,IAC1D,CAAS,EACT,cACA,CACA,iDE9MA,OAAmB,kBACnB,GAAmB,iBACJ,SACf,mBACA,iBACA,wBACA,mBACA,CACA,MACA,8BACA,CACA,kBAEA,MADA,UACA,aACA,CACA,kBACA,sBACA,cACA,CACA,OACA,wDACA,qBACA,wBAEA,CACA,CACA,OACA,2DACA,CACA,KACA,qBAEA,SACA,yBAEA,WACA,8BACA,CACA,SACA,OAAuB,oBACvB,oCACA,6BACA,uBACA,mBACA,6BACA,wBAIA,MAEA,CACA,QACA,CACA,CChDe,gBAA4B,wBAAsB,CACjE,mBACA,aACA,+BACA,iCACA,uBACA,gBAA0B,EAAW,CACrC,QADqC,GAErC,kBACA,gBAAmC,YAAU,kBAC7C,gCACA,cACA,CAAS,CACT,CACA,kBAAiC,EACjC,MAAe,sBAAgB,WAC/B,cAAoB,GAAY,EAChC,gDACgB,oBAAc,IAC9B,4BAEA,YACA,CAAS,CACT,CACA,eACA,WAAmB,EAAa,YAA0B,QAAQ,GAAG,OAAe,EACpF,CACA,2BACA,MACA,uCACA,gEACA,CACA,oBACA,+BAEA,iBACA","sources":["webpack://_N_E/./node_modules/@jridgewell/resolve-uri/dist/resolve-uri.umd.js","webpack://_N_E/./node_modules/@gmod/nclist/esm/util.js","webpack://_N_E/./node_modules/@gmod/nclist/esm/nclist.js","webpack://_N_E/./node_modules/@gmod/nclist/esm/array_representation.js","webpack://_N_E/./node_modules/@gmod/nclist/esm/lazy_array.js","webpack://_N_E/./node_modules/@gmod/nclist/esm/feature_store.js","webpack://_N_E/./node_modules/@gmod/nclist/esm/index.js","webpack://_N_E/./node_modules/@jbrowse/plugin-legacy-jbrowse/esm/NCListAdapter/NCListFeature.js","webpack://_N_E/./node_modules/@jbrowse/plugin-legacy-jbrowse/esm/NCListAdapter/NCListAdapter.js"],"sourcesContent":["(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :\n    typeof define === 'function' && define.amd ? define(factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, global.resolveURI = factory());\n})(this, (function () { 'use strict';\n\n    // Matches the scheme of a URL, eg \"http://\"\n    const schemeRegex = /^[\\w+.-]+:\\/\\//;\n    /**\n     * Matches the parts of a URL:\n     * 1. Scheme, including \":\", guaranteed.\n     * 2. User/password, including \"@\", optional.\n     * 3. Host, guaranteed.\n     * 4. Port, including \":\", optional.\n     * 5. Path, including \"/\", optional.\n     * 6. Query, including \"?\", optional.\n     * 7. Hash, including \"#\", optional.\n     */\n    const urlRegex = /^([\\w+.-]+:)\\/\\/([^@/#?]*@)?([^:/#?]*)(:\\d+)?(\\/[^#?]*)?(\\?[^#]*)?(#.*)?/;\n    /**\n     * File URLs are weird. They dont' need the regular `//` in the scheme, they may or may not start\n     * with a leading `/`, they can have a domain (but only if they don't start with a Windows drive).\n     *\n     * 1. Host, optional.\n     * 2. Path, which may include \"/\", guaranteed.\n     * 3. Query, including \"?\", optional.\n     * 4. Hash, including \"#\", optional.\n     */\n    const fileRegex = /^file:(?:\\/\\/((?![a-z]:)[^/#?]*)?)?(\\/?[^#?]*)(\\?[^#]*)?(#.*)?/i;\n    function isAbsoluteUrl(input) {\n        return schemeRegex.test(input);\n    }\n    function isSchemeRelativeUrl(input) {\n        return input.startsWith('//');\n    }\n    function isAbsolutePath(input) {\n        return input.startsWith('/');\n    }\n    function isFileUrl(input) {\n        return input.startsWith('file:');\n    }\n    function isRelative(input) {\n        return /^[.?#]/.test(input);\n    }\n    function parseAbsoluteUrl(input) {\n        const match = urlRegex.exec(input);\n        return makeUrl(match[1], match[2] || '', match[3], match[4] || '', match[5] || '/', match[6] || '', match[7] || '');\n    }\n    function parseFileUrl(input) {\n        const match = fileRegex.exec(input);\n        const path = match[2];\n        return makeUrl('file:', '', match[1] || '', '', isAbsolutePath(path) ? path : '/' + path, match[3] || '', match[4] || '');\n    }\n    function makeUrl(scheme, user, host, port, path, query, hash) {\n        return {\n            scheme,\n            user,\n            host,\n            port,\n            path,\n            query,\n            hash,\n            type: 7 /* Absolute */,\n        };\n    }\n    function parseUrl(input) {\n        if (isSchemeRelativeUrl(input)) {\n            const url = parseAbsoluteUrl('http:' + input);\n            url.scheme = '';\n            url.type = 6 /* SchemeRelative */;\n            return url;\n        }\n        if (isAbsolutePath(input)) {\n            const url = parseAbsoluteUrl('http://foo.com' + input);\n            url.scheme = '';\n            url.host = '';\n            url.type = 5 /* AbsolutePath */;\n            return url;\n        }\n        if (isFileUrl(input))\n            return parseFileUrl(input);\n        if (isAbsoluteUrl(input))\n            return parseAbsoluteUrl(input);\n        const url = parseAbsoluteUrl('http://foo.com/' + input);\n        url.scheme = '';\n        url.host = '';\n        url.type = input\n            ? input.startsWith('?')\n                ? 3 /* Query */\n                : input.startsWith('#')\n                    ? 2 /* Hash */\n                    : 4 /* RelativePath */\n            : 1 /* Empty */;\n        return url;\n    }\n    function stripPathFilename(path) {\n        // If a path ends with a parent directory \"..\", then it's a relative path with excess parent\n        // paths. It's not a file, so we can't strip it.\n        if (path.endsWith('/..'))\n            return path;\n        const index = path.lastIndexOf('/');\n        return path.slice(0, index + 1);\n    }\n    function mergePaths(url, base) {\n        normalizePath(base, base.type);\n        // If the path is just a \"/\", then it was an empty path to begin with (remember, we're a relative\n        // path).\n        if (url.path === '/') {\n            url.path = base.path;\n        }\n        else {\n            // Resolution happens relative to the base path's directory, not the file.\n            url.path = stripPathFilename(base.path) + url.path;\n        }\n    }\n    /**\n     * The path can have empty directories \"//\", unneeded parents \"foo/..\", or current directory\n     * \"foo/.\". We need to normalize to a standard representation.\n     */\n    function normalizePath(url, type) {\n        const rel = type <= 4 /* RelativePath */;\n        const pieces = url.path.split('/');\n        // We need to preserve the first piece always, so that we output a leading slash. The item at\n        // pieces[0] is an empty string.\n        let pointer = 1;\n        // Positive is the number of real directories we've output, used for popping a parent directory.\n        // Eg, \"foo/bar/..\" will have a positive 2, and we can decrement to be left with just \"foo\".\n        let positive = 0;\n        // We need to keep a trailing slash if we encounter an empty directory (eg, splitting \"foo/\" will\n        // generate `[\"foo\", \"\"]` pieces). And, if we pop a parent directory. But once we encounter a\n        // real directory, we won't need to append, unless the other conditions happen again.\n        let addTrailingSlash = false;\n        for (let i = 1; i < pieces.length; i++) {\n            const piece = pieces[i];\n            // An empty directory, could be a trailing slash, or just a double \"//\" in the path.\n            if (!piece) {\n                addTrailingSlash = true;\n                continue;\n            }\n            // If we encounter a real directory, then we don't need to append anymore.\n            addTrailingSlash = false;\n            // A current directory, which we can always drop.\n            if (piece === '.')\n                continue;\n            // A parent directory, we need to see if there are any real directories we can pop. Else, we\n            // have an excess of parents, and we'll need to keep the \"..\".\n            if (piece === '..') {\n                if (positive) {\n                    addTrailingSlash = true;\n                    positive--;\n                    pointer--;\n                }\n                else if (rel) {\n                    // If we're in a relativePath, then we need to keep the excess parents. Else, in an absolute\n                    // URL, protocol relative URL, or an absolute path, we don't need to keep excess.\n                    pieces[pointer++] = piece;\n                }\n                continue;\n            }\n            // We've encountered a real directory. Move it to the next insertion pointer, which accounts for\n            // any popped or dropped directories.\n            pieces[pointer++] = piece;\n            positive++;\n        }\n        let path = '';\n        for (let i = 1; i < pointer; i++) {\n            path += '/' + pieces[i];\n        }\n        if (!path || (addTrailingSlash && !path.endsWith('/..'))) {\n            path += '/';\n        }\n        url.path = path;\n    }\n    /**\n     * Attempts to resolve `input` URL/path relative to `base`.\n     */\n    function resolve(input, base) {\n        if (!input && !base)\n            return '';\n        const url = parseUrl(input);\n        let inputType = url.type;\n        if (base && inputType !== 7 /* Absolute */) {\n            const baseUrl = parseUrl(base);\n            const baseType = baseUrl.type;\n            switch (inputType) {\n                case 1 /* Empty */:\n                    url.hash = baseUrl.hash;\n                // fall through\n                case 2 /* Hash */:\n                    url.query = baseUrl.query;\n                // fall through\n                case 3 /* Query */:\n                case 4 /* RelativePath */:\n                    mergePaths(url, baseUrl);\n                // fall through\n                case 5 /* AbsolutePath */:\n                    // The host, user, and port are joined, you can't copy one without the others.\n                    url.user = baseUrl.user;\n                    url.host = baseUrl.host;\n                    url.port = baseUrl.port;\n                // fall through\n                case 6 /* SchemeRelative */:\n                    // The input doesn't have a schema at least, so we need to copy at least that over.\n                    url.scheme = baseUrl.scheme;\n            }\n            if (baseType > inputType)\n                inputType = baseType;\n        }\n        normalizePath(url, inputType);\n        const queryHash = url.query + url.hash;\n        switch (inputType) {\n            // This is impossible, because of the empty checks at the start of the function.\n            // case UrlType.Empty:\n            case 2 /* Hash */:\n            case 3 /* Query */:\n                return queryHash;\n            case 4 /* RelativePath */: {\n                // The first char is always a \"/\", and we need it to be relative.\n                const path = url.path.slice(1);\n                if (!path)\n                    return queryHash || '.';\n                if (isRelative(base || input) && !isRelative(path)) {\n                    // If base started with a leading \".\", or there is no base and input started with a \".\",\n                    // then we need to ensure that the relative path starts with a \".\". We don't know if\n                    // relative starts with a \"..\", though, so check before prepending.\n                    return './' + path + queryHash;\n                }\n                return path + queryHash;\n            }\n            case 5 /* AbsolutePath */:\n                return url.path + queryHash;\n            default:\n                return url.scheme + '//' + url.user + url.host + url.port + url.path + queryHash;\n        }\n    }\n\n    return resolve;\n\n}));\n//# sourceMappingURL=resolve-uri.umd.js.map\n","//@ts-nocheck\nimport resolve from '@jridgewell/resolve-uri';\nexport async function readJSON(url, readFile, options = {}) {\n    const { defaultContent = {} } = options;\n    try {\n        const str = await readFile(url, { encoding: 'utf8' });\n        const decoder = new TextDecoder('utf8');\n        return JSON.parse(decoder.decode(str));\n    }\n    catch (error) {\n        if (error.code === 'ENOENT' ||\n            error.status === 404 ||\n            error.message.includes('404') ||\n            error.message.includes('ENOENT')) {\n            return defaultContent;\n        }\n        throw error;\n    }\n}\nexport function newURL(arg, base = '.') {\n    return resolve(arg, base);\n}\n//# sourceMappingURL=util.js.map","//@ts-nocheck\nimport QuickLRU from 'quick-lru';\nimport AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport { newURL, readJSON } from './util';\nexport default class NCList {\n    constructor({ readFile, cacheSize = 100 }) {\n        this.topList = [];\n        this.chunkCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: cacheSize }),\n            fill: this.readChunkItems.bind(this),\n        });\n        this.readFile = readFile;\n        if (!this.readFile) {\n            throw new Error(`must provide a \"readFile\" function`);\n        }\n    }\n    importExisting(nclist, attrs, baseURL, lazyUrlTemplate, lazyClass) {\n        this.topList = nclist;\n        this.attrs = attrs;\n        this.start = attrs.makeFastGetter('Start');\n        this.end = attrs.makeFastGetter('End');\n        this.lazyClass = lazyClass;\n        this.baseURL = baseURL;\n        this.lazyUrlTemplate = lazyUrlTemplate;\n    }\n    binarySearch(arr, item, getter) {\n        let low = -1;\n        let high = arr.length;\n        let mid;\n        while (high - low > 1) {\n            mid = (low + high) >>> 1;\n            if (getter(arr[mid]) >= item) {\n                high = mid;\n            }\n            else {\n                low = mid;\n            }\n        }\n        // if we're iterating rightward, return the high index;\n        // if leftward, the low index\n        if (getter === this.end) {\n            return high;\n        }\n        return low;\n    }\n    readChunkItems(chunkNum) {\n        const url = newURL(this.lazyUrlTemplate.replaceAll(/\\{Chunk\\}/gi, chunkNum), this.baseURL);\n        return readJSON(url, this.readFile, { defaultContent: [] });\n    }\n    async *iterateSublist(arr, from, to, inc, searchGet, testGet, path) {\n        const getChunk = this.attrs.makeGetter('Chunk');\n        const getSublist = this.attrs.makeGetter('Sublist');\n        const pendingPromises = [];\n        for (let i = this.binarySearch(arr, from, searchGet); i < arr.length && i >= 0 && inc * testGet(arr[i]) < inc * to; i += inc) {\n            if (arr[i][0] === this.lazyClass) {\n                // this is a lazily-loaded chunk of the nclist\n                const chunkNum = getChunk(arr[i]);\n                const chunkItemsP = this.chunkCache\n                    .get(chunkNum, chunkNum)\n                    .then(item => [item, chunkNum]);\n                pendingPromises.push(chunkItemsP);\n            }\n            else {\n                // this is just a regular feature\n                yield [arr[i], path.concat(i)];\n            }\n            // if this node has a contained sublist, process that too\n            const sublist = getSublist(arr[i]);\n            if (sublist) {\n                yield* this.iterateSublist(sublist, from, to, inc, searchGet, testGet, path.concat(i));\n            }\n        }\n        for (const p of pendingPromises) {\n            const [item, chunkNum] = await p;\n            if (item) {\n                yield* this.iterateSublist(item, from, to, inc, searchGet, testGet, [\n                    ...path,\n                    chunkNum,\n                ]);\n            }\n        }\n    }\n    async *iterate(from, to) {\n        // calls the given function once for each of the\n        // intervals that overlap the given interval\n        // if from <= to, iterates left-to-right, otherwise iterates right-to-left\n        // inc: iterate leftward or rightward\n        const inc = from > to ? -1 : 1;\n        // searchGet: search on start or end\n        const searchGet = from > to ? this.start : this.end;\n        // testGet: test on start or end\n        const testGet = from > to ? this.end : this.start;\n        if (this.topList.length > 0) {\n            yield* this.iterateSublist(this.topList, from, to, inc, searchGet, testGet, [0]);\n        }\n    }\n    async histogram(from, to, numBins) {\n        // calls callback with a histogram of the feature density\n        // in the given interval\n        const result = new Array(numBins);\n        result.fill(0);\n        const binWidth = (to - from) / numBins;\n        for await (const feat of this.iterate(from, to)) {\n            const firstBin = Math.max(0, ((this.start(feat) - from) / binWidth) | 0);\n            const lastBin = Math.min(numBins, ((this.end(feat) - from) / binWidth) | 0);\n            for (let bin = firstBin; bin <= lastBin; bin += 1) {\n                result[bin] += 1;\n            }\n        }\n        return result;\n    }\n}\n//# sourceMappingURL=nclist.js.map","//@ts-nocheck\n/**\n * @class ArrayRepr\n *\n * Class for operating on indexed array representations of objects.\n *\n * For example, if we have a lot of objects with similar attributes, e.g.:\n *\n * <pre class=\"code\">\n *     [\n *         {start: 1, end: 2, strand: -1},\n *         {start: 5, end: 6, strand: 1},\n *         ...\n *     ]\n * </pre>\n *\n * @description\n * we can represent them more compactly (e.g., in JSON) something like this:\n *\n * <pre class=\"code\">\n *     class = [\"start\", \"end\", \"strand\"]\n *     [\n *         [1, 2, -1],\n *         [5, 6, 1],\n *         ...\n *     ]\n * </pre>\n *\n * If we want to represent a few different kinds of objects in our big list,\n * we can have multiple \"class\" arrays, and tag each object to identify\n * which \"class\" array describes it.\n *\n * For example, if we have a lot of instances of a few types of objects,\n * like this:\n *\n * <pre class=\"code\">\n *     [\n *         {start: 1, end: 2, strand: 1, id: 1},\n *         {start: 5, end: 6, strand: 1, id: 2},\n *         ...\n *         {start: 10, end: 20, chunk: 1},\n *         {start: 30, end: 40, chunk: 2},\n *         ...\n *     ]\n * </pre>\n *\n * We could use the first array position to indicate the \"class\" for the\n * object, like this:\n *\n * <pre class=\"code\">\n *     classes = [[\"start\", \"end\", \"strand\", \"id\"], [\"start\", \"end\", \"chunk\"]]\n *     [\n *         [0, 1, 2, 1, 1],\n *         [0, 5, 6, 1, 2],\n *         ...\n *         [1, 10, 20, 1],\n *         [1, 30, 40, 1]\n *     ]\n * </pre>\n *\n * Also, if we occasionally want to add an ad-hoc attribute, we could just\n * stick an optional dictionary onto the end:\n *\n * <pre class=\"code\">\n *     classes = [[\"start\", \"end\", \"strand\", \"id\"], [\"start\", \"end\", \"chunk\"]]\n *     [\n *         [0, 1, 2, 1, 1],\n *         [0, 5, 6, 1, 2, {foo: 1}]\n *     ]\n * </pre>\n *\n * Given that individual objects are being represented by arrays, generic\n * code needs some way to differentiate arrays that are meant to be objects\n * from arrays that are actually meant to be arrays.\n * So for each class, we include a dict with <attribute name>: true mappings\n * for each attribute that is meant to be an array.\n *\n * Also, in cases where some attribute values are the same for all objects\n * in a particular set, it may be convenient to define a \"prototype\"\n * with default values for all objects in the set\n *\n * In the end, we get something like this:\n *\n * <pre class=\"code\">\n *     classes=[\n *         {'attributes': ['Start', 'End', 'Subfeatures'],\n *          'proto': {'Chrom': 'chr1'},\n *          'isArrayAttr': {Subfeatures: true}}\n *         ]\n * </pre>\n *\n * That's what this class facilitates.\n */\nclass ArrayRepr {\n    constructor(classes) {\n        this.classes = classes;\n        this.fields = [];\n        for (let cl = 0; cl < classes.length; cl += 1) {\n            this.fields[cl] = {};\n            for (let f = 0; f < classes[cl].attributes.length; f += 1) {\n                this.fields[cl][classes[cl].attributes[f]] = f + 1;\n            }\n            if (classes[cl].proto === undefined) {\n                classes[cl].proto = {};\n            }\n            if (classes[cl].isArrayAttr === undefined) {\n                classes[cl].isArrayAttr = {};\n            }\n        }\n    }\n    /**\n     * @private\n     */\n    attrIndices(attr) {\n        return this.classes.map(x => x.attributes.indexOf(attr) + 1 ||\n            x.attributes.indexOf(attr.toLowerCase()) + 1 ||\n            undefined);\n    }\n    get(obj, attr) {\n        if (attr in this.fields[obj[0]]) {\n            return obj[this.fields[obj[0]][attr]];\n        }\n        // try lowercase\n        const lcattr = attr.toLowerCase();\n        if (lcattr in this.fields[obj[0]]) {\n            return obj[this.fields[obj[0]][lcattr]];\n        }\n        const adhocIndex = this.classes[obj[0]].attributes.length + 1;\n        if (adhocIndex >= obj.length || !(attr in obj[adhocIndex])) {\n            if (attr in this.classes[obj[0]].proto) {\n                return this.classes[obj[0]].proto[attr];\n            }\n            return undefined;\n        }\n        return obj[adhocIndex][attr];\n    }\n    makeSetter(attr) {\n        return (obj, val) => {\n            this.set(obj, attr, val);\n        };\n    }\n    makeGetter(attr) {\n        return obj => {\n            return this.get(obj, attr);\n        };\n    }\n    makeFastGetter(attr) {\n        // can be used only if attr is guaranteed to be in\n        // the \"classes\" array for this object\n        const indices = this.attrIndices(attr);\n        return function get(obj) {\n            if (indices[obj[0]] !== undefined) {\n                return obj[indices[obj[0]]];\n            }\n            return undefined;\n        };\n    }\n    // construct(self, obj, klass) {\n    //   const result = new Array(self.classes[klass].length)\n    //   Object.keys(obj).forEach(attr => {\n    //     this.set(result, attr, obj[attr])\n    //   })\n    //   return result\n    // }\n    /**\n     * Returns fast pre-compiled getter and setter functions for use with\n     * Arrays that use this representation.\n     * When the returned <code>get</code> and <code>set</code> functions are\n     * added as methods to an Array that contains data in this\n     * representation, they provide fast access by name to the data.\n     *\n     * @returns {Object} <code>{ get: function() {...}, set: function(val) {...} }</code>\n     *\n     * @example\n     * var accessors = attrs.accessors();\n     * var feature = get_feature_from_someplace();\n     * feature.get = accessors.get;\n     * // print out the feature start and end\n     * console.log( feature.get('start') + ',' + feature.get('end') );\n     */\n    accessors() {\n        if (!this._accessors) {\n            this._accessors = this._makeAccessors();\n        }\n        return this._accessors;\n    }\n    /**\n     * @private\n     */\n    _makeAccessors() {\n        const indices = {};\n        const accessors = {\n            get(field) {\n                const f = this.get.field_accessors[field.toLowerCase()];\n                if (f) {\n                    return f.call(this);\n                }\n                return undefined;\n            },\n            set(field, val) {\n                const f = this.set.field_accessors[field];\n                if (f) {\n                    return f.call(this, val);\n                }\n                return undefined;\n            },\n            tags() {\n                return tags[this[0]] || [];\n            },\n        };\n        accessors.get.field_accessors = {};\n        accessors.set.field_accessors = {};\n        // make a data structure as: { attr_name: [offset,offset,offset], }\n        // that will be convenient for finding the location of the attr\n        // for a given class like: indexForAttr{attrname}[classnum]\n        this.classes.forEach((cdef, classnum) => {\n            ;\n            (cdef.attributes || []).forEach((attrname, offset) => {\n                indices[attrname] = indices[attrname] || [];\n                indices[attrname][classnum] = offset + 1;\n                attrname = attrname.toLowerCase();\n                indices[attrname] = indices[attrname] || [];\n                indices[attrname][classnum] = offset + 1;\n            });\n        });\n        // lowercase all the class attributes\n        const tags = this.classes.map(c => c.attributes);\n        // use that to make precalculated get and set accessors for each field\n        Object.keys(indices).forEach(attrname => {\n            const attrIndices = indices[attrname];\n            // get\n            accessors.get.field_accessors[attrname] = !attrIndices\n                ? function get() {\n                    return undefined;\n                }\n                : function get() {\n                    return this[attrIndices[this[0]]];\n                };\n            // // set\n            // accessors.set.field_accessors[attrname] = !attrIndices\n            //   ? () => undefined\n            //   : v => {\n            //       this[attrIndices[this[0]]] = v\n            //       return v\n            //     }\n        });\n        return accessors;\n    }\n}\nexport default ArrayRepr;\n/*\n\nCopyright (c) 2007-2010 The Evolutionary Software Foundation\n\nCreated by Mitchell Skinner <mitch_skinner@berkeley.edu>\n\nThis package and its accompanying libraries are free software; you can\nredistribute it and/or modify it under the terms of the LGPL (either\nversion 2.1, or at your option, any later version) or the Artistic\nLicense 2.0.  Refer to LICENSE for the full license text.\n\n*/\n//# sourceMappingURL=array_representation.js.map","//@ts-nocheck\nimport QuickLRU from 'quick-lru';\nimport AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport { newURL, readJSON } from './util';\n/**\n * For a JSON array that gets too large to load in one go, this class\n * helps break it up into chunks and provides an\n * async API for using the information in the array.\n */\nexport default class LazyArray {\n    constructor({ urlTemplate, chunkSize, length, cacheSize = 100, readFile }, baseUrl) {\n        this.urlTemplate = urlTemplate;\n        this.chunkSize = chunkSize;\n        this.length = length;\n        this.baseUrl = baseUrl === undefined ? '' : baseUrl;\n        this.readFile = readFile;\n        if (!readFile) {\n            throw new Error('must provide readFile callback');\n        }\n        this.chunkCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: cacheSize }),\n            fill: this.getChunk.bind(this),\n        });\n    }\n    /**\n     * call the callback on one element of the array\n     * @param i index\n     * @param callback callback, gets called with (i, value, param)\n     * @param param (optional) callback will get this as its last parameter\n     */\n    index(i, callback, param) {\n        this.range(i, i, callback, undefined, param);\n    }\n    /**\n     * async generator for the elements in the range [start,end]\n     *\n     * @param start index of first element to call the callback on\n     * @param end index of last element to call the callback on\n     */\n    async *range(start, end) {\n        start = Math.max(0, start);\n        end = Math.min(end, this.length - 1);\n        const firstChunk = Math.floor(start / this.chunkSize);\n        const lastChunk = Math.floor(end / this.chunkSize);\n        const chunkreadFiles = [];\n        for (let chunk = firstChunk; chunk <= lastChunk; chunk += 1) {\n            chunkreadFiles.push(this.chunkCache.get(chunk, chunk));\n        }\n        for (const elt of chunkreadFiles) {\n            const [chunkNumber, chunkData] = await elt;\n            yield* this.filterChunkData(start, end, chunkNumber, chunkData);\n        }\n    }\n    async getChunk(chunkNumber) {\n        let url = this.urlTemplate.replaceAll(/\\{Chunk\\}/gi, chunkNumber);\n        if (this.baseUrl) {\n            url = newURL(url, this.baseUrl);\n        }\n        const data = await readJSON(url, this.readFile);\n        return [chunkNumber, data];\n    }\n    *filterChunkData(queryStart, queryEnd, chunkNumber, chunkData) {\n        // index (in the overall lazy array) of the first position in this chunk\n        const firstIndex = chunkNumber * this.chunkSize;\n        const chunkStart = Math.max(0, queryStart - firstIndex);\n        const chunkEnd = Math.min(queryEnd - firstIndex, this.chunkSize - 1);\n        for (let i = chunkStart; i <= chunkEnd; i += 1) {\n            yield [i + firstIndex, chunkData[i]];\n        }\n    }\n}\n//# sourceMappingURL=lazy_array.js.map","//@ts-nocheck\nimport QuickLRU from 'quick-lru';\nimport AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport GenericNCList from './nclist';\nimport ArrayRepr from './array_representation';\nimport LazyArray from './lazy_array';\nimport { newURL, readJSON } from './util';\nfunction idfunc() {\n    return this._uniqueID;\n}\nfunction parentfunc() {\n    return this._parent;\n}\nfunction childrenfunc() {\n    return this.get('subfeatures');\n}\n/**\n * Sequence feature store using nested containment\n * lists held in JSON files that are lazily read.\n *\n * @param {object} args constructor args\n * @param {string} args.baseUrl base URL for resolving relative URLs\n * @param {string} args.urlTemplate Template string for\n *  the root file of each reference sequence. The reference sequence\n *  name will be interpolated into this string where `{refseq}` appears.\n * @param {function} args.readFile function to use for reading remote from URLs.\n */\nexport default class NCListStore {\n    constructor({ baseUrl, urlTemplate, readFile, cacheSize = 10 }) {\n        this.baseUrl = baseUrl;\n        this.urlTemplates = { root: urlTemplate };\n        this.readFile = readFile;\n        if (!this.readFile) {\n            throw new Error(`must provide a \"readFile\" function argument`);\n        }\n        this.dataRootCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: cacheSize }),\n            fill: this.fetchDataRoot.bind(this),\n        });\n    }\n    makeNCList() {\n        return new GenericNCList({ readFile: this.readFile });\n    }\n    loadNCList(refData, trackInfo, listUrl) {\n        refData.nclist.importExisting(trackInfo.intervals.nclist, refData.attrs, listUrl, trackInfo.intervals.urlTemplate, trackInfo.intervals.lazyClass);\n    }\n    getDataRoot(refName) {\n        return this.dataRootCache.get(refName, refName);\n    }\n    fetchDataRoot(refName) {\n        const url = newURL(this.urlTemplates.root.replaceAll(/{\\s*refseq\\s*}/g, refName), this.baseUrl);\n        // fetch the trackdata\n        return readJSON(url, this.readFile).then(trackInfo => \n        // trackInfo = JSON.parse( trackInfo );\n        this.parseTrackInfo(trackInfo, url));\n    }\n    parseTrackInfo(trackInfo, url) {\n        const refData = {\n            nclist: this.makeNCList(),\n            stats: {\n                featureCount: trackInfo.featureCount || 0,\n            },\n        };\n        if (trackInfo.intervals) {\n            refData.attrs = new ArrayRepr(trackInfo.intervals.classes);\n            this.loadNCList(refData, trackInfo, url);\n        }\n        const { histograms } = trackInfo;\n        if (histograms?.meta) {\n            // eslint-disable-next-line @typescript-eslint/prefer-for-of\n            for (let i = 0; i < histograms.meta.length; i += 1) {\n                histograms.meta[i].lazyArray = new LazyArray({ ...histograms.meta[i].arrayParams, readFile: this.readFile }, url);\n            }\n            refData._histograms = histograms;\n        }\n        // parse any strings in the histogram data that look like numbers\n        if (refData._histograms) {\n            Object.keys(refData._histograms).forEach(key => {\n                const entries = refData._histograms[key];\n                entries.forEach(entry => {\n                    Object.keys(entry).forEach(key2 => {\n                        if (typeof entry[key2] === 'string' &&\n                            String(Number(entry[key2])) === entry[key2]) {\n                            entry[key2] = Number(entry[key2]);\n                        }\n                    });\n                });\n            });\n        }\n        return refData;\n    }\n    async getRegionStats(query) {\n        const data = await this.getDataRoot(query.ref);\n        return data.stats;\n    }\n    /**\n     * fetch binned counts of feature coverage in the given region.\n     *\n     * @param {object} query\n     * @param {string} query.refName reference sequence name\n     * @param {number} query.start region start\n     * @param {number} query.end region end\n     * @param {number} query.numBins number of bins desired in the feature counts\n     * @param {number} query.basesPerBin number of bp desired in each feature counting bin\n     * @returns {object} as:\n     *    `{ bins: hist, stats: statEntry }`\n     */\n    async getRegionFeatureDensities({ refName, start, end, numBins, basesPerBin, }) {\n        const data = await this.getDataRoot(refName);\n        if (numBins) {\n            basesPerBin = (end - start) / numBins;\n        }\n        else if (basesPerBin) {\n            numBins = Math.ceil((end - start) / basesPerBin);\n        }\n        else {\n            throw new TypeError('numBins or basesPerBin arg required for getRegionFeatureDensities');\n        }\n        // pick the relevant entry in our pre-calculated stats\n        const stats = data._histograms.stats || [];\n        const statEntry = stats.find(entry => entry.basesPerBin >= basesPerBin);\n        // The histogramMeta array describes multiple levels of histogram detail,\n        // going from the finest (smallest number of bases per bin) to the coarsest\n        // (largest number of bases per bin).\n        //\n        // We want to use coarsest histogramMeta that's at least as fine as the one\n        // we're currently rendering.\n        //\n        // TODO: take into account that the histogramMeta chosen here might not fit\n        // neatly into the current histogram (e.g., if the current histogram is at\n        // 50,000 bases/bin, and we have server histograms at 20,000 and 2,000\n        // bases/bin, then we should choose the 2,000 histogramMeta rather than the\n        // 20,000)\n        let histogramMeta = data._histograms.meta[0];\n        // eslint-disable-next-line @typescript-eslint/prefer-for-of\n        for (let i = 0; i < data._histograms.meta.length; i += 1) {\n            if (basesPerBin >= data._histograms.meta[i].basesPerBin) {\n                histogramMeta = data._histograms.meta[i];\n            }\n        }\n        // number of bins in the server-supplied histogram for each current bin\n        let binRatio = basesPerBin / histogramMeta.basesPerBin;\n        // if the server-supplied histogram fits neatly into our requested\n        if (binRatio > 0.9 && Math.abs(binRatio - Math.round(binRatio)) < 0.0001) {\n            // console.log('server-supplied',query);\n            // we can use the server-supplied counts\n            const firstServerBin = Math.floor(start / histogramMeta.basesPerBin);\n            binRatio = Math.round(binRatio);\n            const histogram = [];\n            for (let bin = 0; bin < numBins; bin += 1) {\n                histogram[bin] = 0;\n            }\n            for await (const [i, val] of histogramMeta.lazyArray.range(firstServerBin, firstServerBin + binRatio * numBins - 1)) {\n                // this will count features that span the boundaries of\n                // the original histogram multiple times, so it's not\n                // perfectly quantitative.  Hopefully it's still useful, though.\n                histogram[Math.floor((i - firstServerBin) / binRatio)] += val;\n            }\n            return { bins: histogram, stats: statEntry };\n        }\n        // console.log('make own',query);\n        // make our own counts\n        const hist = await data.nclist.histogram(start, end, numBins);\n        return { bins: hist, stats: statEntry };\n    }\n    /**\n     * Fetch features in a given region. This method is an asynchronous generator\n     * yielding feature objects.\n     *\n     * @param {object} args\n     * @param {string} args.refName reference sequence name\n     * @param {number} args.start start of region. 0-based half-open.\n     * @param {number} args.end end of region. 0-based half-open.\n     * @yields {object}\n     */\n    async *getFeatures({ refName, start, end }) {\n        const data = await this.getDataRoot(refName);\n        const accessors = data.attrs?.accessors();\n        for await (const [feature, path] of data.nclist.iterate(start, end)) {\n            // the unique ID is a stringification of the path in the\n            // NCList where the feature lives; it's unique across the\n            // top-level NCList (the top-level NCList covers a\n            // track/chromosome combination)\n            // only need to decorate a feature once\n            if (!feature.decorated) {\n                const uniqueID = path.join(',');\n                this.decorateFeature(accessors, feature, `${refName},${uniqueID}`);\n            }\n            yield feature;\n        }\n    }\n    // helper method to recursively add .get and .tags methods to a feature and its\n    // subfeatures\n    decorateFeature(accessors, feature, id, parent) {\n        feature.get = accessors.get;\n        feature.tags = accessors.tags;\n        feature._uniqueID = id;\n        feature.id = idfunc;\n        feature._parent = parent;\n        feature.parent = parentfunc;\n        feature.children = childrenfunc;\n        (feature.get('subfeatures') || []).forEach((f, i) => {\n            this.decorateFeature(accessors, f, `${id}-${i}`, feature);\n        });\n        feature.decorated = true;\n    }\n}\n//# sourceMappingURL=feature_store.js.map","//@ts-nocheck\nexport { default } from './feature_store';\n//# sourceMappingURL=index.js.map","const jb2ToJb1 = { refName: 'seq_id' };\nconst jb1ToJb2 = { seq_id: 'refName' };\nexport default class NCListFeature {\n    constructor(ncFeature, parent, id) {\n        this.ncFeature = ncFeature;\n        this.uniqueId = id || ncFeature.id();\n        this.parentHandle = parent;\n    }\n    set() {\n        throw new Error('not implemented');\n    }\n    jb2TagToJb1Tag(tag) {\n        const mapped = jb2ToJb1[tag] || tag;\n        return mapped.toLowerCase();\n    }\n    jb1TagToJb2Tag(tag) {\n        const t = tag.toLowerCase();\n        return jb1ToJb2[t] || t;\n    }\n    get(attrName) {\n        const attr = this.ncFeature.get(this.jb2TagToJb1Tag(attrName));\n        if (attr && attrName === 'subfeatures') {\n            return attr.map((subfeature) => new NCListFeature(subfeature, this));\n        }\n        return attr;\n    }\n    tags() {\n        return this.ncFeature.tags().map((t) => this.jb1TagToJb2Tag(t));\n    }\n    id() {\n        return this.uniqueId;\n    }\n    parent() {\n        return this.parentHandle;\n    }\n    children() {\n        return this.get('subfeatures');\n    }\n    toJSON() {\n        const data = { uniqueId: this.id() };\n        for (const tag of this.ncFeature.tags()) {\n            const mappedTag = this.jb1TagToJb2Tag(tag);\n            const value = this.ncFeature.get(tag);\n            if (mappedTag === 'subfeatures') {\n                data.subfeatures = (value || []).map((f) => {\n                    return new NCListFeature(f, this).toJSON();\n                });\n            }\n            else {\n                data[mappedTag] = value;\n            }\n        }\n        return data;\n    }\n}\n","import NCListStore from '@gmod/nclist';\nimport { BaseFeatureDataAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport { checkStopToken } from '@jbrowse/core/util/stopToken';\nimport { RemoteFile } from 'generic-filehandle2';\nimport NCListFeature from './NCListFeature';\nexport default class NCListAdapter extends BaseFeatureDataAdapter {\n    constructor(config, getSubAdapter, pluginManager) {\n        super(config, getSubAdapter, pluginManager);\n        const refNames = this.getConf('refNames');\n        const rootUrlTemplate = this.getConf('rootUrlTemplate');\n        this.configRefNames = refNames;\n        this.nclist = new NCListStore({\n            baseUrl: '',\n            urlTemplate: rootUrlTemplate.uri,\n            readFile: (url) => new RemoteFile(String(rootUrlTemplate.baseUri\n                ? new URL(url, rootUrlTemplate.baseUri).toString()\n                : url)).readFile(),\n        });\n    }\n    getFeatures(region, opts = {}) {\n        return ObservableCreate(async (observer) => {\n            const { stopToken } = opts;\n            for await (const feature of this.nclist.getFeatures(region, opts)) {\n                checkStopToken(stopToken);\n                observer.next(this.wrapFeature(feature));\n            }\n            observer.complete();\n        });\n    }\n    wrapFeature(ncFeature) {\n        return new NCListFeature(ncFeature, undefined, `${this.id}-${ncFeature.id()}`);\n    }\n    async hasDataForRefName(refName) {\n        var _a;\n        const root = await this.nclist.getDataRoot(refName);\n        return !!((_a = root === null || root === void 0 ? void 0 : root.stats) === null || _a === void 0 ? void 0 : _a.featureCount);\n    }\n    async getRefNames() {\n        return this.configRefNames || [];\n    }\n    freeResources() { }\n}\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8]}