{"version":3,"file":"static/chunks/8432.70be54d817bd7486.js","mappings":"mHAiCA,MAAmB,EAAQ,KAAY,EACvC,EAAiB,EAAQ,KAAY,CADX,CAE1B,EAAkB,EAAQ,KAAc,CADhB,CAExB,EAAc,EAAQ,KAAO,CADJ,CASzB,UARqB,MASrB,UAEA,OADA,qBACA,8BACA,CACA,oBACA,IAUA,EAVA,wBAVA,IAWA,GACA,4BACA,QACA,EAjBA,EAiBA,EAEA,OACA,wCAOA,GArBA,IAgBA,GAEA,yCAGA,KACA,yCAEA,GA7BA,EA6BA,EACA,yCAEA,GA5BA,GA4BA,EACA,QACA,+BACA,oCAGA,QACA,4BACA,4BAKA,OAxCA,IAsCA,GACA,2BACA,CACA,CACA,YAKA,GAJA,yCACA,CADmE,GACnE,qBA/CA,GAgDA,GACA,iCACA,IACA,OAAmB,EAAM,QACzB,yCACA,sCACA,EACA,IAGA,EAHA,MACA,iBASA,CA9DA,IAwDA,GACA,6BAzDA,IA2DA,GACA,2BAEA,MACA,EACA,iCACA,iCAGA,EACA,8BACA,6BAEA,CAGA,aACA,UAAyB,EAAM,eAC/B,cACA,OACA,QACA,eACA,WACA,sBACA,YAAwB,IAAW,IACnC,wBACA,QACA,CACA,eAGA,QADA,IACA,IAAwB,IAAU,IAClC,QACA,SAHA,IAKA,aACA,eAEA,QADA,WACA,IAAwB,IAAU,IAClC,wBAEA,OADA,uBACA,oBACA,CAGA,aACA,UAAyB,EAAM,eAC/B,cACA,OACA,QAEA,QADA,WACA,IAAwB,IAAa,IACrC,cAFA,IAGA,WACA,sBAEA,QADA,IACA,IAAwB,IAAW,IACnC,2BACA,OAEA,QACA,CACA,eAGA,QADA,IACA,IAAwB,IAAU,IAClC,QACA,SAGA,QADA,aACA,IAAwB,IAAa,IACrC,cACA,eAGA,QAFA,WACA,IACA,IAAwB,IAAU,IAClC,2BACA,OAGA,OADA,uBACA,oBACA,CAGA,eAEA,UAAyB,EAAM,eAC/B,8BACA,cACA,IACA,GACA,uBACA,SACgB,EAAM,kBACtB,YACA,YAEA,EAAU,YACV,QACA,CACA,eAIA,CAGA,gBACA,UAAyB,EAAM,eAC/B,cACA,OACA,QAGA,QAFA,WACA,aACA,IAAwB,OAAU,IAClC,cAHA,IAIA,WACA,sBAEA,IADA,QACA,MACA,wBAIA,IAHA,+BACA,IACA,MACA,MACA,wBACA,MACA,KAEA,YAA4B,KAAU,IACtC,YACA,MACA,CACA,QACA,CACA,kBAGA,QADA,IACA,IAAwB,IAAU,IAClC,QACA,SAIA,QAFA,aACA,aACA,IAAwB,OAAU,IAClC,cACA,eAGA,IAFA,eACA,IACA,MACA,wBAEA,IADA,QACA,qBACA,GACA,KACA,WACA,KACA,OACA,eAIA,IAHA,wBACA,KACA,MACA,MACA,WACA,wBACA,MACA,IAEA,CAEA,OADA,uBACA,oBACA,CAGA,gBACA,UAAyB,EAAM,eAC/B,cACA,OACA,QAEA,QADA,WACA,IAAwB,IAAa,IACrC,cAEA,QADA,aACA,IAAwB,OAAU,IAClC,cALA,IAMA,WACA,sBAGA,IAFA,QACA,IACA,MACA,2BACA,OAIA,IAHA,+BACA,IACA,MACA,MACA,wBACA,MACA,KAEA,YAA4B,KAAU,IACtC,YACA,MACA,CACA,QACA,CACA,kBAGA,QADA,IACA,IAAwB,IAAU,IAClC,QACA,SAGA,QADA,aACA,IAAwB,IAAa,IACrC,cAEA,QADA,aACA,IAAwB,OAAU,IAClC,cACA,eAIA,IAHA,eACA,IACA,IACA,MACA,2BAEA,IADA,QACA,qBACA,GACA,KACA,WACA,OACA,OACA,eAIA,IAHA,wBACA,KACA,MACA,MACA,WACA,wBACA,MACA,IAEA,CAEA,OADA,uBACA,oBACA,CAGA,kBACA,uBAEA,QADA,mBACA,IAAwB,YAAe,IACvC,kBAEA,SADA,cACA,CAEA,kBACA,UAAsB,EAAM,eAC5B,gBAEA,YAA4B,IAAS,IACrC,eAEA,gBAEA,gBAAmC,IAAS,KAC5C,UACA,aACA,YACA,KACA,MAEA,gBAEA,gBAAmC,IAAS,KAC5C,UACA,aACA,YACA,KACA,MAEA,oBAWA,cATA,gBAAmC,IAAS,KAC5C,UACA,aACA,aACA,KACA,CAMA,QACA,CAEA,YAIA,QAHA,mBAEA,aACA,IAAwB,WAAgB,IACxC,UAEA,gBAAkC,MAAS,IAC3C,MACA,WACA,CAD+B,CAC/B,aAGA,YAAwB,MAAS,IACjC,OACA,eACA,CADqC,CACrC,MAGA,cAEA,cAEA,yBACA,IAFA,MAEA,WACA,IACA,QAGA,OADA,gBACA,OAA8B,EAAM,kBAEpC,SAGA,QADA,MAA0B,EAAM,iCAChC,QAAmC,SAAgB,SACnD,KACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,QACA,OAEA,IADA,QACA,KACA,mBACA,GAEA,IACA,CAEA,OADA,gBACA,eAEA,SAGA,QADA,MAA0B,EAAM,iCAChC,QAAmC,SAAgB,SACnD,KACA,eACA,eACA,eACA,eACA,QACA,OAEA,IADA,QACA,KACA,mBACA,IAEA,IACA,CAEA,OADA,gBACA,cACA,CACA,UAGA,QADA,MAA0B,EAAM,iCAChC,QAAmC,SAAgB,SACnD,mCAIA,OAHA,KACA,mBACA,gBACA,eAIA,OADA,uBACA,eAIA,oBACA,MACA,MAIA,CAJmB,GAInB,IAFA,WACA,WACA,IAAwB,IAAO,IAC/B,2CACA,iBAEA,gBAA+B,WAAgB,SAC/C,YAA4B,IAAO,IACnC,eACA,iBAKA,QAFA,WACA,IACA,IAAwB,IAAO,KAE/B,0BACA,qBACA,4BACA,eAnBA,IAsBA,sBACA,eACA,YAAwB,IAAO,IAC/B,0BACA,YAAwB,IAAO,IAC/B,8BACA,+BACA,CACA,kBAKA,QAJA,eAEA,WACA,WACA,IAAwB,IAAO,IAC/B,mBAGA,QADA,WACA,IAAwB,IAAO,IAC/B,6BACA,+BAIA,QADA,MAAsB,EAAM,eAC5B,IAAwB,IAAO,IAC/B,YAA4B,OAAa,IACzC,iBAGA,QACA,CAGA,eAEA,QADA,MAAsB,EAAM,eAC5B,IAAwB,IAAS,IACjC,kBACA,QACA,CACA,0BClgBA,gBACA,eACA,WACA,sBACA,YACA,aACA,aACA,YACA,CACA,oBACA,YAAwB,IAAO,IAC/B,qCACA,uBACA,cACA,CACA,CAF0B,iBAE1B,GAGA,OAFA,oCAEA,gCAGA,CACA,qBAKA,IAFA,wBACA,cACA,sBACA,gBACA,oCAEA,CACA,iBAUA,mCAIA,IAFA,mCAEA,YACA,0BACA,YAGA,0BACA,YACA,MAEA,YAEA,EAF0B,GAE1B,SACA,aACA,CACA,CAFyB,WAEzB,SACA,eAcA,IAbA,oCACA,uBACA,cACA,CADyB,GACzB,UAIA,aACA,eACA,qCACA,cAGA,sBACA,gBACA,qBAEA,CACA,qBACA,YAAwB,IAAO,IAC/B,qBACA,CACA,0BCxFA,gBACA,mBACA,kBACA,iBACA,UACA,UACA,YAAwB,gBAAmB,IAC3C,YACA,WAEA,CACA,iBAMA,IAJA,2CAEA,IACA,IACA,gBACA,eAKA,6CAEA,WA1BA,GA2BA,iBA3BA,GA4BA,gBA7BA,OA8BA,wBAEA,gBACA,+BACA,gBACA,sBACA,cACA,YACA,sBACA,aACA,CACA,QACA,CACA,mBAEA,kBACA,YAAwB,gBAAmB,IAC3C,mCACA,2BAGA,mBAGA,QADA,IACA,IAAwB,aAAkB,IAC1C,aAEA,6CAEA,WA1DA,GA2DA,iBA3DA,GA4DA,gBA7DA,OA+DA,wBAEA,gBACA,+BACA,eACA,uBACA,cACA,YACA,sBACA,aACA,CACA,CACA,gEC9EA,MAAiB,EAAQ,KAAY,EACrC,EAAkB,EAAQ,KAAc,CADhB,CAExB,EAAmB,EAAQ,KAAY,CADd,CAKzB,UAJ0B,CAI1B,OAMA,IALA,QACA,CADe,CACf,EACA,CADe,CACf,GAEA,cACA,CAD6B,CAC7B,IACA,mBAGA,GAFA,SACA,KACA,MACA,mBAEA,IADA,OACA,KACA,QACA,CACA,GACA,CAEA,QAGA,IAFA,IACA,IACA,MACA,QACA,GACA,aACA,IACA,EAAU,aACV,UACA,QACA,IACA,CACA,CAkaA,kBASA,IARA,QACA,CADe,CACf,EACA,CADe,CACf,WACA,IAKA,MAGA,IADA,QACA,cACA,IACA,UAEA,GACA,qBACA,UACA,IACA,EAAU,YACV,IACA,CAKA,SACA,aACA,IAGA,IAFA,IAEA,CAFW,CAEX,IACA,aAEA,GADA,SACA,MAEA,IADA,QACA,uBACA,GACA,WACA,MAEA,GAEA,CAEA,gBACA,CA8MA,WAAmB,OAxanB,cAGA,gBA/EA,KAEA,oBACA,EA3FA,YACA,OACA,SACA,EAGA,MADA,aACA,CACA,gDACA,MACA,CACA,mBACA,EArFA,EAqFA,iBACA,0BACA,CAD6D,CAC7D,WACA,GAvFA,EAuFA,EACA,eACA,eAEA,CACA,YAAwB,IAAY,IACpC,OACA,KAAe,MAAS,IACxB,QACA,CACA,SAhGA,EAgGA,EACA,SACA,YACA,yBACA,YAAoB,IAAY,IAChC,YAhFA,YACA,QAEA,EAFgB,CAEhB,uBACA,sBACA,sBACA,uBACA,SAnCA,EAmCA,SACA,sBACA,SAnCA,GAmCA,SACA,uBACA,UAnCA,IAmCA,SACA,uBACA,mBAWA,GAVA,aACA,cACA,eACA,YACA,YACA,eACA,YACA,YAEA,kBAlDA,GAmDA,SACA,YAAwB,YAAe,IACvC,4BAIA,YAAwB,MAAS,IACjC,YAIA,CAJ2B,EAG3B,mBACA,WA3DA,IA2DA,SACA,qBAIA,YAAwB,MAAS,IACjC,YAQA,CAR2B,MAE3B,mBArEA,GAsEA,UACA,iBACA,kBAvEA,GAwEA,UACA,gBACA,CACA,EA8BA,GACA,+BACA,gCAEA,QACA,EAyDA,GACA,MAEA,eACA,kBAEA,WA9DA,GACA,QACA,qBACA,YAAoB,QAAa,IACjC,4BACA,EAD4D,CAC5D,WACA,YAAoB,IAAO,IAC3B,oBAKA,OAJA,eACA,eACA,aACA,2BACA,CADwD,EAmDxD,GAEA,WACA,sBAgBA,IAfA,UAAqB,EAAM,eAE3B,GACA,OACA,QACA,QACA,IACA,IACA,IACA,MACA,SACA,KACA,EAEA,IACA,CADe,CACf,IACA,WAEA,IApEA,sBAEA,YACA,2BAGA,MAEA,gBACA,oBAEA,mBAEA,gCACA,gCACA,iCACA,iCACA,eACA,gBACA,MAEA,cAEA,SACA,UACA,kCACA,WA9JA,EA+JA,UACA,wBACA,aAEA,MACA,GADmB,IACnB,GACA,SACA,UACA,OACA,EA+BA,aACA,YACA,wBAEA,YAAoC,MAAS,IAC7C,oBACA,SACA,MACA,QACA,CAEA,cACA,oBACA,YAGA,gCAKA,kBACA,CADsC,CACtC,SAlNA,OACA,gBAgBA,OAfA,oCACA,CADiE,EACjE,gCACA,CADqE,CACrE,QACA,wCACA,aACA,yCAIA,wBACA,WAEA,UACA,iBACA,MACA,OACA,EAgMA,MACA,CAGA,OAFA,UACA,SAGA,SAGA,IAFA,QACA,IACA,MACA,QAGA,IAFA,QACA,SACA,MACA,aACA,cACA,SACA,IACA,GACA,CAEA,UAEA,EApBA,SACA,EACA,EAoBA,SAEA,EACA,EAoamB,OAlBnB,gBAMA,QALA,OACA,OACA,OACA,OACA,aACA,IAAoB,IAAO,IAC3B,gBACA,gBACA,iBACA,gBATA,IAWA,+BACA,CAD2D,CAC3D,qBACA,MA7ZA,kBAGA,QADA,OACA,IAAoB,YACpB,QADuC,KAQvC,QALA,kBAEA,IACA,IAEA,IAAoB,MAAS,IAC7B,UAGA,QAFA,IACA,IACA,IAAoB,WAAgB,IACpC,MACA,0BAEA,aACA,IAEA,YAAoB,MAAS,IAC7B,UAEA,KACA,MACA,KAzBA,IA2BA,IACA,IAsFA,OAnFA,QACA,IAEA,CAFqB,CACrB,KACA,EACA,KACA,EACA,KACA,EAEA,GA0EA,CACA,CACA,cACA,SACA,OACA,QACA,oBACA,OACA,cACA,SACA,QAGA,QACA,QACA,UACA,UACA,UACA,OACA,UACA,WACA,0BACA,SACA,SACA,SACA,kBACA,UAGA,qBACA,QACA,eACA,UACA,QAYA,CAAS,CACT,EA2PA,SACA,EAxMA,wBAMA,QALA,GACA,kDACA,kDACA,4BACA,CACA,IAAoB,WAAmB,IACvC,OACA,CADqB,IACV,MAAS,IACpB,gBAEA,eACA,CADsB,GACtB,cAvdA,EAudA,GACA,cAvdA,EAudA,GAIA,GAHA,eAzdA,EA0dA,GACA,sBACA,CADsC,CACtC,GACA,oBACA,KACA,IACA,eACA,UACA,CAEA,YAAoB,WAAmB,KAgBvC,GAfA,4BACA,0BAveA,IAueA,GACA,eAzeA,GAyeA,GACA,aA3eA,GA2eA,GACA,cA7eA,GA6eA,GACA,aA/eA,EA+eA,CA/eoB,EAgfpB,gBAjfA,EAifA,GACA,eAnfA,EAmfA,IACA,aACA,uBAEA,0BACA,uCACA,oCACA,oCACA,cACA,uBAEA,QADA,IACA,IAA4B,MAAS,IACrC,UACA,eACA,aAIA,KAAmB,YAAoB,IACvC,cACA,MAGA,YAA4B,MAAS,IACrC,UAEA,CAFiC,EAEjC,cAWA,YAA4B,MAAS,IACrC,SACA,eACA,aACA,CACA,iBACA,YAA4B,OAAU,IACtC,mDACA,cACA,CACA,iBACA,YAA4B,MAAS,IACrC,wBACA,yBACA,YAA4B,MAAS,IACrC,+CACA,aACA,CACA,CACA,QACA,EA8GA,eACA,OA9GA,8BAGA,oBACA,KACA,IAIA,QAHA,WAEA,IACA,IAAoB,WAAmB,IACvC,gBACA,iBAEA,QADA,eACA,IAAoB,QAAa,IACjC,gBAEA,QADA,SACA,IAAoB,IAAO,IAC3B,gBACA,SACA,SASA,IARA,iBAGA,WAEA,IACA,CADe,CACf,EACA,CADe,CACf,EACA,MACA,SAEA,WACA,cAGA,qBAEA,WAEA,8BACA,eACA,mBAGA,4BACA,+BACA,gCACA,gCACA,mBAA8C,CAK9C,4BACA,+BACA,gCACA,iCAEA,eACgB,EAAO,QACvB,CADiC,CACjC,EACA,QAEA,eACA,IACA,GACA,CAEA,aACA,UACA,wBAGA,2BAEA,EADA,aACA,mCAIA,cACA,uCACA,eACA,oCACA,YACA,KAEA,aACA,kBACA,SACA,GACA,CAEA,OADA,uBACA,oBACA,EAiBA,oBACA,CACmB,sDCjsBnB,EAAW,EAAQ,KAAQ,EAC3B,EAAY,EAAQ,KAAY,CADd,CAElB,EAAY,EAAQ,KAAa,CADd,CAEnB,EAAc,EAAQ,KAAW,CADd,CAEnB,EAAW,EAAQ,KAAQ,CAqB3B,YACA,gBArBA,cACA,uBACA,EAoBA,iBAnBA,cACA,uBACA,EAkBA,iBAjBA,cAGA,oCACA,EAcA,mBAbA,cAEA,WADA,IACA,WACA,EAWA,gBAVA,cAEA,yBACI,EAAM,4BACV,CAOA,sDCjCA,gBACA,uBACA,MACA,SAAuB,EAAM,eAC7B,gBAGA,WACA,sBAEA,UACA,CAGA,MACA,4BACA,CACA,YACA,0CAEA,OADA,YACA,CACA,CACA,WACA,yBAEA,OADA,WACA,CACA,CACA,WACA,yBAEA,OADA,WACA,sBACA,CACA,aAGA,OAFA,gBACA,kBAEA,CACA,aACA,qCAEA,OADA,YACA,CACA,CAEA,aACA,SACA,GACA,2BACA,GACA,2BACA,EAAU,QACV,QACA,CAaA,YAEA,QACA,GACA,sBACA,YACA,EAAU,YACV,QACA,CACA,WACA,yBAyCA,OAxCA,WAEA,QAGA,EADA,aAEA,4BACA,2BACA,0BACA,2BACA,aAGA,QAGA,EADA,aAEA,4BACA,0BACA,2BACA,aAGA,QAGA,EADA,aACA,sDACA,aAGA,SAGA,EADA,YACA,mBACA,YAMA,CACA,CAGA,aACA,sBACA,CACA,aACA,oCACA,CACA,eACA,YAAwB,WAAgB,IACxC,oCACA,uBACA,CACA,eACA,YAAwB,IAAS,IACjC,0BAEA,eACA,2BACA,CACA,eAEA,sBACA,wBACA,CACA,eACA,kCACA,WACA,CAOA,cACA,QACA,IACA,GACA,KACA,YACU,KACV,GACA,KACA,4CACU,KAEV,aAEA,KACA,QACA,OAEA,uBAEA,UAEA,2CACA,4BAEA,UAEA,6CACA,2CACA,4BAEA,aAEA,iDACA,6CACA,2CACA,6BAIA,kDACA,+CACA,4CACA,yCACA,0BAEA,CAIA,gBACA,sBACA,CACA,sDC/MA,MAAiB,EAAQ,KAAY,EAiBrC,UAjBwB,CAiBxB,GAGA,QAFA,cACA,IACA,IAAoB,OAAY,KAChC,gBACA,GACA,OACA,CACA,QACA,CACA,kBACA,2BACA,CACA,gBACA,gBACA,sBACA,QACA,CAKA,gBACA,0BACA,0BACA,yBACA,wBACA,CAcA,sBAIA,OADA,cADA,YAfA,SAEA,IADA,wBACA,MACA,sBACA,MAEA,QACA,EAQA,UACA,YAEA,CA+BA,kBAEA,YAAoB,MAAS,IAC7B,OACA,mBACA,IACA,IAEA,GACA,kBACA,QACA,KACA,IACA,KAGA,kBACA,KACA,iBAEA,GACA,EAAM,WAEN,OACA,YAAoB,OAAU,IAC9B,iBAiCA,cAGA,QADA,IACA,IAAoB,MAAS,IAC7B,QAFA,IAKA,EADA,KACA,EACA,GACA,QACA,IACA,IACA,IACA,YAAwB,MAAS,IACjC,UAEA,SACA,OACA,KAEA,wBACA,SACA,SACA,QAGA,GApBA,KAsBA,MAtBA,KAsBA,EAEA,EAxBA,KAwBA,eAEA,QA1BA,WA4BA,IAEA,OACA,IAEA,EAAM,QAEN,gBAEA,QADA,IACA,IAAoB,MAAS,IAC7B,SAGA,OACA,SAGA,GADA,eACA,eAIA,UAAkC,YAAqB,KAEvD,OACA,cACA,CAEA,kBAEA,cACA,CAqOA,WAAmB,OA1XnB,YACA,eACA,eACA,eACA,4BACA,KACA,SAgDA,KAEA,iBACA,aACA,SAKA,QAHA,OAEA,SACA,IAAoB,IAAO,IAC3B,oBAGA,QADA,MAAqB,EAAM,eAC3B,IAAoB,IAAY,KAChC,UAEA,IAnIA,KAkIA,KACA,CACA,CADwB,CACxB,KACA,uBACA,cACA,CACA,QACA,EAtEA,KAkNA,cAEA,iBACA,cA7BA,gBAEA,YAAoB,MAAS,KAC7B,gBACA,gBACA,YAAwB,MAAS,IACjC,SACA,CACA,mBACA,IACA,IAEA,GACA,eACA,KACA,IACA,KAGA,kBACA,KACA,iBAEA,UACM,OAMN,OAGA,QADA,aACA,IAAoB,MAAS,IAC7B,aAIA,QAFA,SACA,SACA,IAAoB,IAAO,IAC3B,oBACA,OAKA,QAFA,MAAqB,EAAM,eAC3B,kBACA,IAAoB,IAAa,IACjC,YAAwB,IAAO,KAC/B,MA1SA,KA0SA,KAEA,YACA,YACA,mCACA,eACA,MACA,CAMA,IADA,KACA,MACA,MAxTA,KAwTA,KACA,EAvTA,cAKA,IADA,QACA,WACA,IACA,QACA,EA+SA,UACA,UACA,mCACA,eACA,MACA,CACA,QACA,EA1PA,IAEA,EA+WmB,OA9WnB,qBAIA,KACA,SAqIA,GACA,eACA,sBACA,eACA,CADyB,CACzB,eACA,CAD2B,CAC3B,eAEA,CAF2B,GAE3B,cACA,SA/EA,KACA,YAAoB,MAAS,IAC7B,OACA,YAAoB,WAAgB,IACpC,SACA,EA0EA,KACA,KACA,OAEA,gBACA,QACA,YAAoB,MAAS,IAC7B,mBAGA,QADA,SACA,IAAoB,IAAO,IAC3B,KAvMA,QA2MA,QAHA,yBACA,gBAEA,MAA6B,KAAQ,IACrC,sCACA,YAAoB,KAAQ,IAC5B,UATA,IAWA,QAGA,OAFA,2CACA,wBACW,EAAM,QACjB,qBACA,4BACA,sBACA,EAxKA,GAGA,SAgSA,GACA,eACA,yBACA,eACA,CADyB,CACzB,eACA,CAD2B,CAC3B,eAKA,CAL2B,GAK3B,IAHA,aACA,aACA,aACA,IAAoB,MAAS,IAC7B,gBACA,iBAEA,SA5DA,OACA,YAAoB,MAAS,KAC7B,OACA,YAAwB,MAAS,IACjC,SACA,CAEA,QADA,IACA,IAAoB,WAAgB,IACpC,UACA,aAEA,OAGA,2BACA,2BACA,2BACA,OACA,EA0CA,OAzCA,cACA,YAAoB,MAAS,IAC7B,MACA,OACA,EAsCA,KArCA,gBAGA,QAFA,IAEA,IAAoB,MAAS,IAC7B,SAGA,OACA,SAGA,GADA,eACA,eACA,UAAkC,YAAsB,KAExD,OACA,cACA,CAEA,UAEA,cACA,EAiBA,OAEA,YAAoB,MAAS,IAC7B,SAEA,UACA,YAAwB,MAAS,IACjC,4BAKA,QAFA,SACA,SACA,IAAoB,IAAO,IAC3B,KA/WA,QAgXA,OAOA,QALA,gBAEA,kBACA,SACA,SACA,IAAoB,IAAO,IAC3B,eACA,eAGA,YACA,cAA6B,QAAqB,IAClD,8CACA,UAGA,cACA,YAAwB,KAAQ,KAChC,cACA,wCACA,OACA,MACA,CAEA,YAAoB,KAAQ,IAC5B,wCAEA,YAAoB,KAAQ,IAC5B,UAEA,YAGA,OAFA,2CACA,wBACW,EAAM,QACjB,qBACA,4BACA,sBACA,EArWA,EAEA,CAoWmB,sDC7bnB,MAAiB,EAAQ,KAAY,EAkBrC,UAlBwB,CAkBxB,KAIA,QAHA,OACA,WACA,IACA,IAAoB,IAAS,KAC7B,gBACA,GACA,OACA,CACA,QACA,CACA,oBACA,8BACA,CACA,gBAGA,OAFA,SACA,2BACA,CACA,CAKA,gBACA,0BACA,0BACA,yBACA,wBACA,CAgBA,sBAIA,OADA,cADA,YAjBA,SAGA,IADA,kBACA,MACA,yBACA,sBACA,OAEA,QACA,EAQA,UACA,YAEA,CAsWA,cAEA,QADA,aACA,IAAoB,MAAS,IAC7B,OAFA,IAGA,IACA,eACA,IACA,GACA,OACA,KACA,IACA,KAGA,kBACA,KACA,iBAEA,UACM,MACN,QACA,CAoBA,kBAEA,iBACA,cApBA,gBAEA,YAAoB,MAAS,IAC7B,OAIA,QAFA,OAEA,IAAoB,MAAS,IAC7B,QACA,qBAEA,QAEA,OACA,YAAoB,OAAU,IAC9B,kBAMA,OAKA,QAHA,UAEA,WACA,IAAoB,IAAO,IAC3B,oBAGA,QADA,MAAqB,EAAM,eAC3B,IAAoB,IAAY,KAChC,YAEA,IA5dA,KA2dA,KACA,CACA,CADwB,CACxB,KACA,0BACA,cACA,CAEA,QACA,CASA,gBAGA,QADA,IACA,IAAoB,MAAS,IAC7B,QAEA,WACA,UACA,GACA,QACA,IACA,IACA,IACA,YAAwB,MAAS,IACjC,UAEA,SACA,OACA,KAEA,wBACA,SACA,SACA,QAGA,KAEA,UAEA,mBAEA,UAEA,OAEA,MACA,IAEA,EAAM,QAEN,gBAGA,QADA,IACA,IAAoB,MAAS,IAC7B,QACA,kBAGA,IADA,QACA,QACA,KACA,IAGA,YAAoB,MAAS,IAC7B,SACA,CACA,gBAEA,QADA,IACA,IAAoB,MAAS,IAC7B,SAEA,OACA,SAGA,GADA,eACA,eAIA,UAAkC,YAAqB,KAEvD,OACA,cACA,EAGA,cACA,CAQA,gBACA,eACA,sBAEA,cAhGA,cACA,YAAoB,MAAS,IAC7B,OACA,YAAoB,WAAgB,IACpC,SACA,EA4FA,KACA,8BACA,MACA,OACA,OAhBA,cACA,OACA,YAAoB,MAAS,IAC7B,MACA,kBAEA,EAWA,KACA,QAEA,gBACA,QACA,YAAoB,MAAS,IAC7B,mBAGA,QADA,WACA,IAAoB,IAAO,IAC3B,KArjBA,MAyjBA,QAFA,wCAEA,MAA6B,KAAQ,IACrC,sCACA,cAAwB,KAAQ,IAChC,UAIA,OAAW,EAAM,QACjB,qBACA,4BACA,sBACA,CAkPA,WAAmB,OAvgBnB,YAEA,gBAEA,OACA,mBAMA,OACA,QACA,EANA,IAMA,KAIA,GARA,MAMA,kBAPA,IAUA,OA3CA,cAKA,QAJA,eAEA,WACA,WACA,IAAoB,IAAO,IAC3B,mBAGA,QADA,WACA,IAAoB,IAAO,IAC3B,6BACA,eAIA,QADA,MAAkB,EAAM,eACxB,IAAoB,IAAO,IAC3B,YAAwB,OAAa,IACrC,iBAGA,QACA,EAsBA,KAEA,KACA,QACA,iBA1IA,GAGA,QAFA,eACA,WACA,IAAoB,IAAU,IAC9B,kBAEA,WADA,cACA,EAoIA,GAGA,KACA,QACA,iBA3PA,KACA,oBACA,gBAEA,OACA,8BAEA,CACA,oBACA,gBACA,mBACA,CAEA,eACA,aACA,cACA,OACA,QACA,YAAoB,IAAO,IAC3B,kBACA,eAuOA,KAGA,GApBA,KAqBA,yBACA,MA1BA,MA2BA,oBAEA,eAyRA,OAEA,mBACA,OACA,IACA,OACA,oBACA,gBACA,uBACA,kBAGA,iBACA,cACA,SAhDA,SAEA,YAAoB,MAAS,KAC7B,gBACA,gBACA,YAAwB,MAAS,IACjC,SACA,CAIA,QAFA,OAEA,IAAoB,MAAS,IAC7B,SAGA,QADA,IACA,IAAwB,MAAS,IACjC,OAEA,IACA,KAGA,sBACA,YACA,mBAGA,UAEA,UACA,YAAwB,MAAS,IACjC,0BAEA,EAeA,SAGA,QADA,aACA,IAAoB,MAAS,IAE7B,eAIA,QAFA,WACA,WACA,IAAoB,IAAO,IAC3B,oBACA,OAKA,QAFA,MAAqB,EAAM,eAC3B,kBACA,IAAoB,IAAa,IACjC,YAAwB,IAAO,KAC/B,WA5qBA,IA4qBA,CA5qBA,IA8qBA,aACA,WACA,qCACA,eACA,MACA,CAMA,IADA,KACA,MACA,aA1rBA,IA0rBA,CA1rBA,IA2rBA,WAzrBA,KAKA,IADA,QACA,WACA,IAEA,QACA,EAgrBA,YACA,UACA,6CACA,mBACA,QACA,CACA,QACA,EA/UA,OAMA,OAJA,GACA,YAhPA,SACA,SAIA,QAHA,MAAkB,EAAM,eAExB,IACA,IAAoB,IAAS,KAC7B,WACA,QAEA,QADA,gBACA,IAA4B,KAAU,IACtC,cAGA,QAEA,CACA,QACA,EA+NA,UACA,GACA,YAlJA,SACA,UAAkB,EAAM,eACxB,IAEA,QACA,YAAwB,IAAS,IACjC,eAGA,QACA,QAAoB,IAAS,KAC7B,UACA,aACA,YACA,KACA,MAGA,QACA,QAAoB,IAAS,KAC7B,UACA,YACA,aACA,KACA,MAGA,SACA,QAAoB,IAAS,KAC7B,UACA,aACA,aACA,KACA,CAEA,QACA,EA8GA,UACA,CACA,EAzCA,SACA,EACA,EAogBmB,OA5dnB,gBACA,qBACA,eACA,UACA,MACA,MACA,OACA,OACA,OACA,QACA,SAIA,CAJ6B,EAE7B,GACA,uBACA,EACA,OAAe,EAAM,QACrB,qBACA,SAvHA,OACA,MACA,MAAe,IAIf,IAFA,WACA,WACA,IAAoB,IAAO,IAC3B,2CACA,iBAEA,gBAA2B,WAAgB,SAC3C,YAAwB,IAAO,IAC/B,eACA,iBAKA,QAFA,WACA,IACA,IAAoB,IAAO,KAE3B,gBACA,WACA,4BACA,eAnBA,IAsBA,sBACA,eACA,YAAoB,IAAO,IAC3B,0BACA,YAAoB,IAAO,IAC3B,8BACA,+BACA,EAsFA,IANA,MAOA,EACA,UAAwB,EAAM,SAC9B,GACA,gBAtPA,GAGA,QADA,aACA,IAAoB,MAAS,IAC7B,OACA,YAAoB,WAAgB,IACpC,UAGA,QAFA,aACA,IACA,IAAoB,MAAS,IAC7B,QACA,WACA,YAKA,QAEA,UAAuB,EAAM,oBAE7B,SAEA,UAAuB,EAAM,mCAC7B,KACA,QAAoB,WAAgB,IACpC,QACA,WACA,kBAEA,MACA,SAEA,UAAuB,EAAM,mCAC7B,KACA,QAAoB,WAAgB,IACpC,QACA,WACA,oBAEA,KACA,CAEA,UAAuB,EAAM,mCAC7B,KACA,QAAoB,WAAgB,IACpC,QACA,WACA,oBAEA,CAEA,sBACA,eAEA,QADA,IACA,IAAoB,MAAS,IAC7B,SACA,SACA,gBAIA,OADA,uBACA,yBACA,EAuLA,IACA,UAAuB,EAAM,SAQ7B,GAPA,GACA,gBAnVA,KAGA,QADA,aACA,IAAoB,MAAS,IAC7B,OAEA,QADA,KACA,IAAoB,WAAgB,IACpC,sBACA,OAGA,QADA,IACA,IAAoB,MAAS,IAC7B,QACA,IACA,IAEA,IACA,QAGA,+BACA,eACA,YAAoB,MAAS,IAC7B,QACA,eAIA,QAFA,MAAmB,EAAM,sBACzB,IACA,IAAoB,WAAgB,IAEpC,GADA,YACA,WACA,OAEA,IADA,QACA,6BACA,IACA,gBACA,IACA,CAXA,IAcA,4BACA,iBACA,sBACA,gBACA,IAD0B,QAC1B,WACA,CADkC,GAClC,EAAe,EAAM,iCACrB,wBAqSA,MACA,mBAEA,IACA,cAEA,EACA,aACA,QACA,kBAEA,eAsWA,KACA,eAMA,QALA,qBAEA,aACA,aACA,aACA,IAAoB,MAAS,IAC7B,gBACA,iBAxEA,kBACA,YAAoB,MAAS,KAC7B,OACA,YAAwB,MAAS,IACjC,SACA,CAEA,QADA,IACA,IAAoB,WAAgB,IACpC,OACA,aACA,OAEA,OAEA,YAAoB,IAAO,IAC3B,mCACA,UACA,EA2DA,SA1DA,gBACA,YAAoB,MAAS,IAC7B,SAEA,iCACA,EAoDA,IAnDA,GAmDA,EAnDA,EACA,UAEA,EAkDA,IAFA,GAIA,0BA9CA,gBACA,OACA,YAAoB,MAAS,IAC7B,QAGA,SADA,IACA,IAAwB,MAAS,IACjC,SAEA,KACA,SAIA,GADA,sBACA,UAEA,cAAwC,MAAS,IACjD,SAEA,cACA,SAEA,MAEA,cACA,EAEA,CAEA,EAkBA,OACA,+BACA,iBACA,iBACA,oBACA,uBACA,0BAGA,iBACA,0BA9DA,gBACA,YAAoB,MAAS,IAC7B,MACA,OA4CA,GA3CA,EA6DA,IAlBA,GAmBA,YAAoB,MAAS,IAC7B,SAEA,UACA,YAAwB,MAAS,IACjC,4BAKA,QAFA,WACA,WACA,IAAoB,IAAO,IAC3B,KA7wBA,MA8wBA,OAOA,QALA,wCAEA,kBACA,WACA,WACA,IAAoB,IAAO,IAC3B,eACA,eAGA,cACA,cAA6B,QAAqB,IAClD,kDA7CA,IA8CA,YAIA,IADA,eACA,UAEA,cAA4B,KAAQ,IACpC,aACA,cAA4B,KAAQ,IACpC,0CAvDA,IAwDA,UACA,MAEA,CACA,cAAwB,KAAQ,IAChC,oCA7DA,IA+DA,cAAwB,KAAQ,IAChC,UAEA,OAAW,EAAM,QACjB,qBACA,4BACA,sBACA,EAxbA,KACA,OAAW,EAAM,oCACjB,CAubmB,sDCx1BnB,MAAiB,EAAQ,KAAY,EACrC,EAAa,EAAQ,KAAY,CADT,CAGxB,UADkB,EAAQ,MAAa,EAoDvC,SApDyB,EAoDzB,KAEA,IADA,WACA,YACA,QACA,QACA,CAwPA,WAAmB,OA/KnB,cAEA,kBACA,sBACA,8BACA,oBACA,6BACA,GAD2D,UAC3D,WACA,wBACA,eAOA,QALA,kBACA,KACA,qBACA,CADoC,CACpC,EACA,IACA,IAAoB,WAAkB,KACtC,kBAyFA,WACA,QAEA,KACA,iBACA,KAEA,SACA,KA7OA,EA8OA,YAIA,SACA,KAlPA,EAmPA,YACA,EAEA,OAGA,QADA,wBAAuC,IAAI,qBAC3C,IAAoB,WAAgB,KACpC,UACA,CADuB,CA/PvB,EAiQA,OAOA,GANA,0BACA,EAjQA,EAkQA,wBACA,EA/PA,EAgQA,gBACA,GAtQA,CAsQA,EACA,eACA,qBACA,EAjQA,GAkQA,UAEA,qCACA,oBACA,OACA,wBACA,EA1QA,EA2QA,IAEA,MACA,qBA7QA,GA6QA,eACA,8BACA,oBACA,OACA,wBACA,EAlRA,EAmRA,IAEA,EAEA,SACA,SACA,MACA,MACA,EACA,wBAEA,wBAEA,CAIA,OAHA,WACA,KA/RA,EAgSA,EACA,OACA,EA7JA,cACA,KACA,MACA,KACA,KACA,CAEA,YAAuB,IAAgB,KAEvC,QADA,YACA,IAA2B,GA9I3B,GA8I4C,IAC5C,4BACA,CAKA,sBAEA,YAAoB,WAAkB,IACtC,8BAEA,QAGA,OADA,EAxKA,EAwKA,yBACA,cACA,KApKA,EAqKA,EArKA,EAqKA,0BACA,KACA,MAxKA,EAyKA,EAzKA,EAyKA,0BACA,KACA,MA/KA,EAgLA,EAhLA,EAgLA,0BACA,KACA,MAjLA,EAkLA,EAlLA,EAkLA,wBACA,KACA,MA/KA,EAgLA,EAhLA,EAgLA,0BACA,KACA,MAtLA,EAuLA,EAvLA,EAuLA,0BACA,EAvLA,EAuLA,+BACA,KACA,MArLA,EAwLA,KAvLA,EAqLA,sCAKA,CAEA,GAzCA,aACA,SAyCA,SAEA,YAAuB,GA5LvB,GA4LwC,IACxC,mBAEA,4BAEA,gCACA,MAKA,cACA,IACA,EADA,aAEA,0BACA,gBACA,WACA,8BAEA,yBAEA,IACA,mCACA,CACA,SACA,OACA,CACA,gBACA,WACA,KAEA,CACA,QACA,EA3BA,QACA,uBACA,wBAEA,EArDA,QACA,CACA,2BACA,EA+ImB,OApMnB,gBACA,eACA,eACA,qBACA,eACA,WAjGA,SAGA,IAFA,SACA,aACA,WACA,mBACA,QACA,OACA,OAKA,GAJA,GAEA,mBAzBA,GA2BA,MACA,sBAlBA,GAmBA,MA7BA,EA6BA,OAA0C,EAAM,oBAChD,CACA,MACA,mBACA,cACA,2BACA,KACA,CACA,oBACA,gBACA,EACA,oBAEA,oBACA,sBACA,CACA,CACA,QACA,EAiEA,SACA,WACA,WACA,IACA,aACA,SACA,YAAoB,IAAY,IAChC,GA/DA,kBACA,WAzDA,EAyDA,YAEA,IADA,qBAEA,GAvDA,GAuDA,EAGA,OAFA,UACA,UACA,KAEA,OACA,SACA,gBACA,GAEA,OADA,OArEA,EAqEA,aAEA,KArEA,EAsEA,aAtEA,EAsEA,YACA,KACA,MAzEA,EA0EA,aA1EA,EA0EA,cACA,KACA,MAtEA,EAuEA,aAvEA,EAuEA,cACA,KACA,MA7EA,EA8EA,WA9EA,EA8EA,cACA,OA9EA,EA8EA,WACA,gBACA,KACA,MA7EA,EA8EA,0BA9EA,EA8EA,YACA,KACA,MA/EA,EAgFA,wBAhFA,EAgFA,YACA,iBACA,eACA,KACA,MAnFA,GAoFA,gBACA,KACA,SACA,UAEA,CACA,iBACM,KAzFN,IAyFM,GACN,aAiBA,WACA,QACA,CAsLmB,8DCxSnB,MAjDA,CACA,UAgDe,SAAS,EAAC,UAhDzB,EACA,qBACA,4BACA,mBAOA,cAEA,mBAEA,aAEA,cAEA,gBAEA,iBAEA,cAEA,eAEA,mBAEA,gBAEA,cAEA,uBAeA,EC2CA,GACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,GACA,EAiDA,cACA,SACA,iBACA,OAAe,EAAK,cACpB,QAAgB,EAAK,UAErB,QACA,CACO,QAvCA,CACP,aACA,qBACA,sBACA,mBACA,2BAEA,+BAEA,aAEA,cAEA,kBAEA,iBAEA,mBAEA,uBACA,EAoBO,IAnBA,CACP,8BACA,eACA,yBACA,2BACA,EAeO,IAdA,CACP,uBACA,eACA,CAee,SACf,aAAkB,kOAAkN,EACpO,aACA,iBACA,kBACA,sBACA,mBACA,qBACA,GACA,mBAEA,mBACA,gBACA,kBACA,gBACA,oBACA,sBACA,YAEA,GACA,sBAEA,GACA,YACA,kBACA,wBACA,4BACA,oCACA,EAEA,GACA,yBAEA,CAIA,WACA,oBAA+B,EAAS,YACxC,CAEA,mBACA,oBAA+B,EAAS,iBACxC,CAEA,oBACA,oBAA+B,EAAS,WACxC,CAEA,iBACA,oBAA+B,EAAS,YACxC,CAEA,wBACA,oBAA+B,EAAS,aACxC,CAEA,4BACA,oBAA+B,EAAS,cACxC,CAEA,UACA,oBAA+B,EAAS,WACxC,CAEA,UACA,oBAA+B,EAAS,WACxC,CAEA,cACA,oBAA+B,EAAS,eACxC,CAEA,aACA,oBAA+B,EAAS,YACxC,CAEA,cACA,oBAA+B,EAAS,SACxC,CAEA,kBACA,oBAA+B,EAAS,mBACxC,CAIA,aACA,wBAAmC,EAAS,mBAC5C,CAEA,oBACA,wBAAmC,EAAS,0BAC5C,CAEA,4BACA,wBAAmC,EAAS,+BAC5C,CAEA,iBACA,wBAAmC,EAAS,iBAC5C,CAKA,eACA,qCACA,eAhRA,KAEA,kCAGA,mBAFA,YAMA,+BACA,mBACA,aACA,8BACA,cAEA,SACA,IACA,IACA,4BACA,4BACA,wBACA,8BACA,UAEA,uBAGA,GADA,KACA,cAEA,aACA,KACA,WACA,KACA,cAGA,aACA,MAEA,cAEA,SACA,MAEA,aAEA,UAEA,aAEA,UAEA,aAEA,UAEA,aAIA,UAEA,aAGA,UAEA,cAGA,YAIA,4BAEA,wCACA,KACA,YAEA,KACA,CAEA,6CACA,KACA,YAGA,sBACA,EAuLA,sBACA,GACA,kBAEA,CACA,sBAMA,qBACA,8BACA,iBACA,wBACA,WACA,wCACA,2CACA,2CACA,MACA,MACA,gBACA,MACA,OAEA,iBACA,MACA,OAEA,SACA,yCACA,cACA,kEAiBA,OAfA,mDACA,OAEA,KACA,OACA,OACA,OACA,SAGA,OACA,OACA,OACA,QAEA,UACA,CACA,WACA,CAcA,0BACA,mBAGA,8BACA,cACA,SAlPA,SAEA,uBACA,kBACA,GACA,UAEA,gBACA,OACA,MAGA,QADA,sBACA,QACA,GACA,SAEA,EAkOA,QAEA,CAAa,EAIb,iBACA,8BACA,OACA,2DACA,mBAEA,CACA,SACA,SAQA,OAPA,8BACA,mBAGA,cACA,CAAS,EACT,gCACA,CACA,CACA,iGCjXO,uBACP,CAEO,sBACP,CAEO,kBACP,CASO,kBACP,gBCfO,cACP,OAAW,QAAM,MAAM,aAAO,IAC9B,CEDA,QAEA,cACA,cACA,aACA,CACA,CACA,QAGA,cACA,mBACA,YAAwB,iBAAoB,KAC5C,gBAEA,YACA,CACA,CACA,QAGA,cACA,kBACA,gBACA,CACA,CAgBA,WACA,EACA,EACA,EACA,GAGA,mBAFA,QAEA,GACA,CAsDA,MAAe,CACf,KACA,aACA,iBACA,WAhFA,gBACA,eACA,UAAkB,EAAkB,oCAEpC,iBACA,UAAkB,EAAkB,kCAEpC,WACA,QACA,EAwEA,cACA,kBA1DA,SACA,EACA,EACA,GACA,4BACA,EAsDA,IApDA,cACA,iBACA,EAmDA,cA3BA,SACA,EACA,EACA,EACA,GACA,gBAvBA,EACA,EACA,EACA,EACA,GAKA,IAFA,GAEY,CAFZ,UAFA,QAEA,KD1EA,QC6EA,GAEA,OADA,kBAEU,EDhFV,ECgFqB,MAAW,CAEhC,IAFgC,GAEhC,CACA,EAOA,qBACA,EAsBA,YApBA,SACA,EACA,GAEA,KDjGA,ECiGY,MACZ,GACA,yBACU,EDpGV,ECoGqB,MAAW,CAEhC,IAFgC,GAEhC,CACA,CAWA,CAAC,CChHD,CDgHE,QChHF,KACA,MACA,UAAkB,EAAkB,mBAEpC,CGmHA,QACA,mBACA,eACA,iBACA,oBACA,CACA,MACA,mCAEA,OADA,kBACA,CACA,CACA,UACA,iBACA,CACA,aACA,uBAEA,WACA,sBAEA,OAGA,OAFA,+BACA,kBACA,CACA,CACA,WAEA,OADA,kBACA,CACA,CACA,eAEA,OADA,iBACA,CACA,CACA,SACA,+CAEA,OADA,kBACA,CACA,CACA,YACA,0CAEA,4CCpKO,uBACP,CACO,kBACP,QACA,wCACA,SACA,2EAEA,YAA6B,EAAM,IAEnC,MACA,sCACA,iBACA,iBACA,oBAEA,iBAEA,QACA,CCDO,gBACP,IAEA,EAFA,IACA,OAoCA,GAlCA,OACA,IACA,MAEA,OACA,sBACA,MAEA,OACA,EACA,yBACA,QACA,MAEA,OACA,EACA,OACA,WACA,UACA,QACA,UACA,OAGA,EACA,WACA,WACA,WACA,UACA,UAGA,MAEA,WACA,UAAkB,EAAsB,yCAA0C,6BAElF,cAEO,gBACP,IAEA,EAFA,IACA,OAEA,SACA,IACA,UAEA,SACA,yBACA,UAEA,SACA,EACA,UACA,UACA,QACA,QACA,iCACA,UAEA,SACA,EACA,UACA,WACA,UACA,QACA,UACA,UAEA,SACA,EACA,mCACA,YACA,UACA,QAEA,UAEA,SACA,EACA,iCACA,aACA,YACA,UACA,QACA,UAEA,SACA,EACA,cACA,UACA,QACA,YACA,aACA,YACA,UACA,QACA,UAEA,UAEA,GADA,GAAY,eAAgB,oBAC5B,sCACA,oCACA,gCAEA,eACA,IACA,KACA,CAEA,GADA,GAAY,eAAgB,oBAC5B,sCACA,oCACA,gCAEA,eACA,IACA,CACA,cAEO,wBACP,WAAY,WAAgB,OAC5B,OACA,KACA,iBACA,SACA,CACA,CAKO,gBACP,qBACA,WAAkC,EAAW,EAC7C,0BACA,iBACA,kBACA,WACA,8BACA,eACa,CACb,CACA,eAEA,CCrKO,aACP,OACA,iBAEA,mDACA,IACA,+BACA,KACA,oBACA,KACA,oBAOA,OANA,KAMA,CACA,OACA,QACA,eACA,eACA,OAVA,EACA,iBACA,WACA,mBAQA,CAAiB,CACjB,OARA,KASA,CACA,CAAS,CACT,YACA,CACA,CAuEA,kBACA,6BACA,KACA,YAAoB,WAAgB,KACpC,uBAEA,QACA,CAyFA,cACA,SACA,YAAiB,WAAa,SAC9B,MACA,8BAA0C,GAAK,SAE/C,OAEA,QACA,CACO,cACP,kCA6IA,gBAEA,yCADA,EACA,QACA,MAAkC,EAAS,KAE3C,EAF2C,CAE3C,GAA0C,EAAS,EADnD,KACmD,CACnD,KACA,SACA,eAGA,UAEA,SAAiC,EAAS,IAC1C,GAD0C,cAC1C,GACA,IACA,MACA,UAEA,SAAkC,EAAS,IAC3C,GAD2C,MAC3C,GAEA,SAAiC,EAAS,EAD1C,KAC0C,CAC1C,MACA,IACA,MACA,UAEA,MAAoB,EAAS,KAC7B,EAD6B,CAC7B,IACA,QACA,SACA,YAAwB,IAAc,KACtC,MAAyB,EAAS,KAClC,EADkC,IAClC,OACA,QAEA,YACA,MAAqB,EAAS,KAC9B,EAD8B,CAC9B,IACA,eACA,aACA,eACA,QACA,SACA,YAAwB,IAAgB,KACxC,MAAwB,EAAS,KACjC,EADiC,CACjC,KACA,YACA,CACA,cACA,MACA,UAEA,IAAgB,kBAA6C,MAC7D,qBAEA,IAAgB,kBAA4C,IAD5D,IAEA,oBACA,GACA,MACA,UAEA,yBAEA,SAA6C,EAAS,EADtD,KACsD,CACtD,mBACA,IACA,MACA,UAEA,SAAkC,EAAS,IAC3C,YAEA,SAAkC,EAAS,EAD3C,KAC2C,CAC3C,WACA,IACA,MACA,UAEA,SAAkC,EAAS,IAC3C,GAD2C,MAC3C,GAEA,SAAgC,EAAS,EADzC,KACyC,CACzC,MACA,IACA,MACA,UAEA,SAAkC,EAAS,IAC3C,GAD2C,MAC3C,GAEA,SAAkC,EAAS,EAD3C,KAC2C,CAC3C,UACA,IACA,MACA,UAEA,SAAkC,EAAS,IAC3C,YACA,IACA,MAEA,+BAA2C,EAAQ,GAEnD,OACA,OACA,UACA,kBACA,YACA,CAAS,CACT,QACA,CACA,CACA,aACA,OACA,eACA,SAA0C,EAAS,KAEnD,EAFmD,CAEnD,GAA2C,EAAS,EADpD,KACoD,CACpD,KACA,SACA,YAA4B,IAAc,KAC1C,gCACA,4BAEA,OAAwB,YAA4B,IADpD,MAEA,IACA,YAA4B,UAAY,CACxC,CACA,OACA,OACA,UACA,OACA,UACA,CAAiB,CACjB,QACA,CACA,CAAS,CAET,CACA,aACA,OACA,eACA,SAA0C,EAAS,KAEnD,EAFmD,CAEnD,GAA2C,EAAS,EADpD,KACoD,CACpD,KACA,SACA,YAA4B,IAAc,KAC1C,SAAyC,EAAS,KAClD,EADkD,CAClD,EACA,qCACA,8BACA,2BACA,OAAwB,YAA4B,OACpD,IACA,YAA4B,UAAY,CACxC,CACA,OACA,OACA,UACA,OACA,UACA,CAAiB,CACjB,QACA,CACA,CAAS,CAET,CAuHO,cACP,OACA,uBACA,gBA9iBA,CAAa,OAlDb,UAEA,mBADA,EACA,OADA,EACA,WADA,EACA,QACA,IACA,gBACA,GACA,MACA,OACA,QACA,OACA,OACA,WACA,QACA,UACA,OACA,IACA,MACA,yCAAyD,GAAG,kBAE5D,KACA,oBACA,GACA,cACA,qBACA,sBACA,wBACA,gBACA,YACA,IACA,MACA,6CAA6D,EAAE,GAG/D,SAAwC,EAAS,EADjD,KACiD,CAEjD,MAA6C,EAAS,EADtD,KACsD,CAEtD,MAA+C,EAAS,EADxD,KACwD,CAExD,OACA,OAFA,KAGA,OACA,mBACA,iBACA,YACA,cACA,mBACA,CAAa,CAEb,EACa,cA+iBb,eA5iBA,CACA,eAGA,MADA,aADA,EACA,OADA,EACA,WADA,EACA,QACA,gBAEA,OACA,OAFA,KAGA,OACA,OACA,CAAiB,CAEjB,CAAS,CACT,WACA,EA+hBA,8BACA,uBACA,sBA5HA,CACA,eAIA,IAAoB,kBAlYpB,EACA,eAEA,mDACA,MAA0C,EAAS,KAEnD,EAFmD,CAEnD,GAA2C,EAAS,EADpD,KACoD,CACpD,KACA,SACA,YAA4B,IAAc,KAC1C,gCACA,4BAEA,GADA,KACA,UACA,UACA,UACA,UACA,UACA,SACA,QACA,MACA,qBACA,CAAqB,EACrB,UAEA,YACA,QACA,MACA,OACA,cACA,gBACA,gBACA,gBACA,gBACA,CACqB,EACrB,UAEA,aACA,IAA4B,kBApE5B,EACA,eACA,SAAuC,EAAS,KAChD,EADgD,CAChD,EACA,wBACA,KACA,SACA,IACA,IACA,KAAmB,WAAmB,IACtC,OACA,iBACA,OAMA,OAHA,KACA,iBAEA,CACA,OACA,OACA,MACA,CAAiB,CACjB,QACA,CACA,CACA,GA0CuD,YACvD,YAAgC,eAAwB,EACxD,GACA,MAEA,2BAAmD,EAAI,EAEvD,CACA,OACA,OACA,UACA,WACA,MACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,EA0U8D,YAC9D,IACA,IAAoB,kBAAgD,gBACpE,IACA,IAAoB,kBAAyC,gBAE7D,OADA,IACA,CACA,OACA,wBACA,kBACA,gBACA,CAAiB,CACjB,QACA,CACA,CAAS,EA0GT,aA5SA,CACA,oBACA,EA2SA,yBA7XA,OA/CA,YA6BA,EA5BA,SAAyC,EAAS,KAClD,EADkD,CAClD,EACA,QAEA,SACA,SAAqC,EAAS,KAC9C,EAD8C,CAC9C,EACA,GACA,MACA,OAkaA,EAlaA,CACA,SAAqC,EAAS,KAC9C,EAD8C,CAC9C,EACA,GACA,MAEA,gCAEA,SAAwC,EAAS,KAEjD,EAFiD,CAEjD,GAA4C,EAAS,EADrD,KACqD,CACrD,KACA,SACA,YAAwB,IAAmB,KAC3C,SAAqC,EAAS,KAC9C,EAD8C,CAC9C,EACA,SACA,CAOA,OA0YA,GA9YA,IACA,0BACA,OAEA,CACA,OACA,gBACA,MACA,aACA,gBACA,YACA,YACA,CAAa,CACb,QACA,CACA,EAGA,qBA6XA,uBAjXA,mBA0CA,EAxCA,SAA2C,EAAS,KAEpD,EAFoD,CAEpD,GAA8C,EAAS,EADvD,KACuD,CAEvD,MAA6C,EAAS,EADtD,KACsD,CAEtD,MAA6C,EAAS,EADtD,KACsD,CACtD,KAGA,QACA,SACA,SAAyC,EAAS,KAClD,EADkD,CAClD,EACA,GACA,MACA,OA+VA,EA/VA,CACA,SAAyC,EAAS,KAClD,EADkD,CAClD,EACA,GACA,MAEA,2DAIA,SAA4C,EAAS,KAErD,EAFqD,CAErD,GAAgD,EAAS,EADzD,KACyD,CACzD,KACA,SACA,YAA4B,IAAmB,KAC/C,SAAyC,EAAS,KAClD,EADkD,CAClD,EACA,SACA,CACA,SAAiD,EAAS,KAS1D,EAT0D,KAC1D,KA0UA,GAtUA,IACA,0BACA,OAEA,CACA,OACA,MACA,YACA,aACA,gBACA,aACA,WACA,cACA,gBACA,iBACA,YACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,qBAmTA,sBAnGA,aACA,mBA8BA,EA1BA,MAFA,aADA,EACA,oBADA,EACA,QAEA,eAIA,MAA2C,EAAS,EAHpD,KAGoD,CAEpD,MAA8C,EAAS,EADvD,KACuD,CAEvD,MAAgD,EAAS,EADzD,KACyD,CAEzD,MAA6C,EAAS,EADtD,KACsD,CACtD,KACA,QACA,SACA,SAAyC,EAAS,KAClD,EADkD,EAElD,IACA,MACA,OA4EA,EA5EA,CACA,SAAyC,EAAS,KAClD,IACA,IACA,MAEA,wCAGA,QACA,SAAwC,EAAS,KACjD,EADiD,EAEjD,IACA,CACA,SAA4C,EAAS,KAErD,EAFqD,CAErD,GAA+C,EAAS,EADxD,KACwD,CAExD,OACA,OACA,SACA,WACA,cACA,gBACA,YACA,eACA,WACA,gBACA,YACA,CAAiB,CACjB,OAbA,IAcA,CACA,CAAS,EA6CT,sBAxCA,mBAWA,EATA,mBADA,EACA,OADA,EACA,qBACA,MAA+C,EAAS,KACxD,EADwD,CACxD,EACA,SACA,YAA4B,IAAkB,KAC9C,SAA+C,EAAS,KACxD,EADwD,CACxD,EACA,SACA,CAMA,OAwBA,GA5BA,IACA,oBACA,MAEA,CACA,OACA,iBAAiD,OAAI,EAAO,CAC5D,eACA,WACA,CAAiB,CACjB,QACA,CACA,CAAS,CACT,qBAgBA,CACA,CCpoBA,cACA,SACA,YAAoB,qBAAsC,IAC1D,6BAEA,QACA,CC8Ge,QACf,mBACA,iBACA,yBACA,iBACA,iBAGA,kBAEA,IAAgB,gBAAe,gCAC/B,EAA+B,EAAiB,GAChD,mCACA,MACA,4CAEA,uEACA,cACA,sCAEA,0CACA,MAA4B,EAAS,2DACrC,OAAqB,qBACrB,CACA,4CACA,MAA4B,EAAS,6DACrC,OAAqB,qBACrB,CAEA,UAAsB,EAAkB,0DAA2D,cAAmB,EAEtH,CAEA,kBACA,6BAEA,iBACA,mCACA,YAAwB,WAAmB,KAC3C,mCACA,cACA,8BAEA,QACA,oBAEA,QACA,CAEA,yBAEA,MADA,wBACA,IAGA,iCACA,6BACA,KAMA,OALA,cACA,iCACA,kBAEA,CAAS,EACT,CACA,CACA,6BAEA,MADA,uCACA,IAEA,2BAEA,6CACA,IAAa,EAAmB,GAChC,cADgC,yBAGhC,gBACA,OAEA,kDACA,cACA,4CAEA,wBACA,uDACA,MACA,UAA0B,EAAkB,oEAO5C,OACA,4BACA,oBACA,iCACA,kBAEA,CACA,wBACA,0CACA,6CACA,oHAEA,4GACA,2BACA,UAA0B,EAAiB,uEAE3C,OACA,MACA,oBACA,iCACA,kBAEA,CAEA,CACA,gBACA,8BACA,CACA,0BACA,IACA,IAAgB,gBAAe,gCAC/B,8CACA,cACA,4CAEA,6BACA,wCAEA,QACA,oCACY,EAAmB,kBAC/B,6BACA,qFACA,sCACA,MACA,QAAwB,iBAAkB,EAC1C,EH5FW,IAAG,GG4FiB,MH5FjB,KG4F4B,EH5F5B,oCG6Fd,oGACA,SACA,UAA8B,EAAkB,2CAA4C,0BAAoC,MAAM,EAAM,IAAI,EAAI,kBAAkB,EAAU,oBAAoB,EAAO,EAE3M,CACA,CAKA,oCACA,GACA,mBAAgC,EAAmB,mBACnD,0BACA,EACA,WAAyB,6BAAiC,CAC1D,gBACA,YACA,aACA,sBAKA,OAJA,aACA,GAA8B,8BAC9B,mBAEA,CACA,CAAiB,CACJ,EAEb,MACA,iCACA,MACA,UAA0B,EAAkB,wBAAyB,GAAgB,cAIrF,OADA,oBAEA,EACA,oCACA,YAAwB,WAAoB,KAC5C,IACA,MD5He,YC4H0B,CD5H1B,eACf,IAqFA,EAlEA,EAIA,EACA,EACA,EAwDA,EACA,EACA,EACA,EApFA,UAIA,UACA,IAAS,EAAmB,uBAC5B,iCAEA,yCACA,QACA,yBACA,UAEA,SACA,YACA,0BAEA,uBACA,cASA,GAPA,qBACA,eAMQ,EAAgB,mBAIxB,EADA,aAEA,sBAEA,GADA,YACA,EAEA,cACA,UACA,WACA,IACA,YACA,iBACA,qBACA,cACA,GAEA,UAEY,EAAgB,eAC5B,GAAoB,EAAe,oBAGvB,EAAgB,uBAC5B,GAAoB,EAAe,8BAGnC,MACa,EAAgB,yBAC7B,gBAIA,cACA,OAEA,UAAkB,EAAkB,oBAEpC,SAEA,mBACA,WACA,YAAoB,IAAW,MAC/B,WACA,eACA,eACA,IACA,kBACA,eACA,MACA,8BAzLA,KACA,WACA,YAEA,WACA,iCAEA,WACA,oCAEA,WACA,mCAEA,WACA,mCAEA,WACA,oCAEA,WACA,kCAEA,WACA,YAEA,WACA,qCAEA,WACA,kDAEA,WACA,OAtFA,YACA,gCAGA,EAFA,uBAEA,YADA,IAEA,WAEA,GADA,aACA,SACA,8BACA,YAAwB,IAAY,KACpC,eAGA,YACA,+BACA,YAAwB,IAAY,KACpC,eAGA,YACA,+BACA,YAAwB,IAAY,KACpC,eAGA,YACA,gCACA,YAAwB,IAAY,KACpC,eAGA,YACA,+BACA,YAAwB,IAAY,KACpC,eAGA,YACA,gCACA,YAAwB,IAAY,KACpC,eAGA,YACA,iCACA,YAAwB,IAAY,KACpC,SAEA,MAEA,6BAAyC,EAAU,GAEnD,QACA,EAiCA,EAEA,WAAc,EAAkB,yBAA0B,EAAQ,EAClE,EAsJA,IACA,CAMA,GAAS,EAAe,sBAmCxB,GAAa,EAAgB,0BAC7B,OACA,WAEA,CACA,eACA,YAAwB,WAAkB,KAC1C,aAGA,GADA,4BACY,EAAgB,8BAC5B,WACA,YAA4B,WAAkB,KAC9C,YAEA,CACA,MAnDwB,CAExB,cAOA,GANA,GACA,GAhKA,oBACA,QACA,MACA,WACA,kBACA,WACA,mBACA,8BAEA,iBACA,SACA,YAA4B,eAAqB,IACjD,6BAEA,QACA,OACA,eACA,YAKA,CACA,CACA,YAAoB,IAAsB,MAC1C,mCACA,UAEA,GACA,qBACA,2BACA,kBACA,kBACA,kBACA,qBACA,kBACA,oBACA,kBACA,kBACA,kBACA,kBACS,IACT,MACA,UAAsB,EAAkB,8BAA+B,EAAK,IAE5E,WAEA,GAA8B,kBAAqB,IACnD,GACA,aAGA,MADA,KAGA,EADA,IAGA,kBACA,KAEA,iBACA,YAEA,SACA,OAEA,WAA4B,wBAC5B,CACA,QACA,EA4FA,YAIA,IACA,EACA,aAAyB,UAAa,IACtC,iBACA,KAEA,iBACA,YAEA,SACA,OAUA,GANA,kBACA,gBAA4B,MAAe,EAAW,GAAG,EAAe,GAAG,mCAC3E,KAGA,UACY,EAAgB,8BAC5B,WACA,YAA4B,WAA0B,IACtD,YAEA,CACA,CAkBA,OACA,aACA,aACA,YACA,QACA,iBACA,cACA,WACA,YACA,eACA,mBACA,eACA,cACA,iBACA,gBACA,YACA,MACA,CACA,ECjCyC,qBACzC,UAAiC,EAAU,CAC3C,KACA,EAF2C,OAE3C,kBACA,8BACA,EACA,CACA,CAAiB,CACjB,CACA,SACA,gBAAiC,EAAsB,CACvD,mBADuD,wDAEvD,KACA,CAEA,OAEA,CAIA,YAAwB,WAAoB,MAC5C,qBAAoB,GAAmB,UACvC,aAtQA,kBACA,iBACA,6BACA,uBAEA,cACA,8BACA,uBAEA,QACA,wBACA,gCACA,qBAEA,YACA,6BAKA,uCACA,QACA,wBACA,gCACA,qBAEA,YACA,8BAKA,SAAwB,EAAS,YAEjC,QAA2B,EAAS,YACpC,UAA4B,EAAS,aAGrC,QAA2B,EAAS,YAEpC,UAA4B,EAAS,aAGrC,QAA2B,EAAS,cACpC,UAA4B,EAAS,eAErC,QAA2B,EAAS,cACpC,UAA4B,EAAS,eAErC,4BACA,EACA,SAnGA,OAaA,MAZA,cACA,UACA,gCACA,uBACA,4BACA,MACA,UAA0B,EAAkB,gEAE5C,eACA,CACA,QACA,EACA,GACA,6BAEA,cADA,2CACA,iBACA,MACA,cACA,6BACA,UAA0B,EAAkB,iGAE5C,mBACA,CAAS,CAET,EA0EA,OAGA,SArEA,KAGA,kDAEA,OADA,qEACA,GACA,oBACA,kBACA,EA6DA,MAKA,yBACA,EA2MA,cAEA,CACA,QACA,CACA,oBAEA,yDACA,2CACA,IACA,uBACA,4CAGA,MADA,UACA,UAEA,uDACA,6BACA,GAAgB,EAAmB,kBACnC,8BACA,+BACA,CACA,kCACA,yBACA,OACA,8CACA,cACA,4CAEA,SAGA,gBACA,gCACA,OACA,IACA,GACA,KACA,uBACA,6BACA,QACA,EACA,QAEA,uBACA,8BACA,EACA,SACA,UAEA,0BACA,0BAEA,CAUA,aARA,iDACA,WACA,gBACA,0CACA,0EAEA,CAAiB,GAEjB,IAEA,QADA,0BACA,CACA,yBACA,YACA,wBAAsD,WAAmB,GACzE,CACA,CACA,CACA,CACA,QACA,CACA,CAEA,sEACI,EAAW,IACf,CAAC,CCnZc,GDkZA,IClZA,EACf,iBACA,kBACA,eACA,CACA,CCEe,gBAA8B,EAC7C,OADsD,KACtD,KASA,GARA,WACA,cACA,iBACA,oBACA,8BACA,uBACA,kCACA,uBACA,wCACA,mBAAmC,eAAe,oDAElD,qBACA,kBACA,mBAGA,mCACA,yCAEA,CACA,gBAEA,sCACA,YAAwB,2BAA8B,IACtD,MACA,kCACA,yCAIA,4DACA,iBACA,cACA,4BACA,gCAEA,yCACA,CAAS,CACT,CACA,aACA,cACA,CADyB,GACzB,IACA,KACA,gCAHqE,KAGrE,WACA,4BACA,kBApDA,MACA,EAoDA,OACA,YACA,QACA,SACA,EACA,KACA,UAIA,GAHA,MACA,CAFyD,CAEzD,GADgD,IAChD,GACA,KA3DA,CADA,GA2D0C,CA3D1C,YADA,GADA,EA+DA,GA9DA,kBACA,qBACA,gCA4DA,EACA,UAA8B,EAAkB,sBAEhD,gBACA,CAAa,CACb,CAAS,CACT,CACA,cACA,qGACA,4DACA,uDACA,oEACA,sCACA,yCACA,YAAwB,6BAAgC,KACxD,kDAEA,CACA,gBACA,oCACA,CAKA,wBACA,iCAEA,eACA,gBACA,IACA,IACA,YAAwB,0BAA6B,MACrD,oCACA,QACA,GAAoB,EAAO,SAC3B,GACA,EACA,6BACA,+CACA,qCAEA,YAAgC,qCAChC,0BAAiD,KACjD,IAEA,CACA,CACA,UAAkB,EAAkB,4BACpC,CACA,CChHe,iBAA4B,EAC3C,OADoD,KACpD,KAEA,GADA,WACA,sBACA,sCAEA,0BACA,uCAGA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,4CAAmB,EAE/D,CACA,gBACA,mBAAgB,GAAiB,gBACjC,OACA,MACA,UAAsB,EAAkB,kCAAmC,GAAgB,GAE3F,oCACA,4BACA,CACA,gBACA,SAAoC,EAAS,0BAE7C,OADA,gCACA,CACA,CACA,iBACA,oCACA,UAAsB,EAAsB,qEAE5C,mCAEA,CClCe,iBAAiC,EAChD,gBACA,mBAAgB,GAAiB,gBACjC,OACA,MACA,UAAsB,EAAkB,kCAAmC,EAAe,GAE1F,oCACA,iCACA,CACA,sBACA,gBACA,UAAgB,GAAW,gBAE3B,iBACA,iBACA,eACA,aACA,gBACA,UAA0B,EAAsB,uDAEhD,IACA,CAEA,OADA,mBACA,eACA,CACA,CC3Be,MAAM,WAA2B,EAChD,OADyD,KACzD,OACA,EAFuC,GAEvC,MACA,uBACA,CACA,gBAEA,MADA,uBACA,gBACA,uBACA,oBACA,YAAwB,IAAiB,KACzC,uBAEA,QACA,CAEA,kBACA,sCACA,qCACA,CAEA,gBACA,qCACA,sCACA,CACA,CACA,uDACI,EAAY,GAAkB,EAClC,CAAC,CC3Bc,ED0BA,KC1BA,WAAwB,EACvC,ODyBkC,KCzBlC,KAEA,GADA,WACA,sBACA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,wCAAmB,EAE/D,CACA,gBAEA,OADyB,EAAO,8CAChC,sBACA,CACA,CCXe,iBAAyB,EACxC,OADiD,KACjD,KAEA,GADA,WACA,sBACA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,yCAAmB,EAE/D,CACA,gBACA,QACA,KAAe,MAAO,0BACtB,KAIA,MADA,GADgC,2BAChC,QACA,uBAEA,CChBe,iBAA0B,EACzC,OADkD,KAClD,KAEA,GADA,WACA,sBACA,UAAsB,EAAsB,GAAI,eAAe,EAAnB,0CAAmB,EAE/D,CACA,gBACA,IAIA,EACA,EALA,IACA,KAAe,EAAO,0BACtB,KAIA,SACA,oBACA,EAAgB,EAAO,6BAEvB,CACA,wBACA,MAAyB,EAAO,yBAChC,QACA,CACA,+BACA,CACA,CCpBA,QACA,EAAO,GAEP,EAAO,EACP,EAAO,GACP,CAJoB,CAIb,GACP,EAAO,CAHe,EAItB,EAAO,GAEP,CAHgB,CAGT,EACP,CALyB,CASlB,EAPW,IAED,GAKV,CAVoB,EAUpB,KACP,MAHA,GAGA,yBAHA,CAIA,MACA,UAAkB,EAAsB,qCAAsC,UAAqB,GAEnG,+BACA,CCxBA,QACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,SACA,UACA,SACA,SACA,UACA,SACA,UACA,eACA,eACA,SACA,UACA,eACA,SACA,SACA,SACA,SACA,eACA,UACA,eACA,QAGA,CA4Be,UACf,eACA,6BACA,sBACA,oBAEA,yCACA,+BACA,2CACA,wCACA,wBArCA,YACA,cACA,YAAoB,IAAO,KAC3B,YAsBA,OApBA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,oBACA,CACA,EAWA,mBACA,6CACA,+BAMA,kBACA,4BACA,KAUA,QAVA,EACA,0BACA,MACA,sCAEA,MAAwB,GAAgB,eAExC,OADA,wBACA,CACA,CAIA,CAMA,eACA,gCAEA,yBACA,mCACA,eACA,iCAEA,MACA,YAEA,MACA,UAA8B,EAAkB,oBAAqB,GAAgB,yCAErF,EAAoB,GAAgB,KAEpC,QAFoC,iBAEpC,KACA,CACA,CACA,QACA,CACA,SACA,SAOA,OANA,8BACA,qBAGA,cACA,CAAS,EACT,CACA,CACA,CC/He,SACf,iBACA,YACA,mBACA,CACA,YACA,mDACA,CACA,kCACA,6BAGA,kCACA,YAEA,iBAAgB,GAAe,gCAC/B,EAA+B,EAAiB,GAChD,YADgD,CAChD,gBACA,cACA,OAEA,wCACA,UAAsB,EAAkB,wBAAyB,eAAmB,8BAEpF,MAAwB,EAAS,8DACjC,OACA,KACA,eACA,CACA,CACA,sBACA,6BACA,KAGA,0CACA,CAGA,6BACA,6CACA,KAGA,WAAmB,GAA8B,gBACjD,CACA,cAGA,WAAmB,EAAS,SAC5B,CACA,kCdvDO,EcwDP,iBAAgB,GAAe,gCAE/B,sBAAgB,0BADe,EAAiB,GAEhD,CAAgB,QAAiB,GAFe,GAEf,iBACjC,SACA,oBAAgC,EAAS,aAAa,GAAU,oBAChE,MACA,CAGA,MAAuB,QAAM,yBAC7B,yCACA,MAAwB,EAAS,YACjC,EdpEA,MADO,EcqEkC,SAAR,KAAQ,EdjEzC,CciEyC,MdjEzC,EAGA,WAGA,cAGA,EAFA,EAHA,EAHA,EAHA,EcoEA,kBAEA,6BAAyC,GAAU,qBAAqB,EAAS,aACjF,MACA,CACA,MAAuB,QAAM,yCAC7B,mEACA,MAAwB,EAAS,YAQjC,OAPA,+CACA,mGAAgK,EAAS,GAEzK,mBACA,wBACA,gCACA,CAAS,CAET,CACA,CACA,2DACA,WACA,YACI,EAAW,KACf,CAAC,GADc,eC7Ff,SAAS,GAAI,OACb,KACA,SAEA,KACA,WAAmB,aAAU,IAE7B,KACA,WAAmB,YAAS,GAE5B,iEACA,CCZO,eACP,uBACA,KACA,gBACA,0BACA,GACA,QACA,eACA,eACA,qBACA,cACA,CACA,iBACA,kBACA,EAIA,CACA,MACA,QACA,CACA,CAAiB,CACjB,CAAa,CAEb,CACA,QACA,CCUe,SACf,eACA,MAcA,GAbA,UAAoB,GAAI,2BACxB,0BACA,+CACA,cACA,oCACA,kDACA,EAIA,qBAAgC,MAAQ,CACxC,+BACS,EA5BT,WAEA,yBADA,0BACA,eACA,UACA,EAEA,CAFkB,IAElB,KACA,EAGA,CAHkB,EAGA,EAmBlB,EACA,gEAEA,CAEA,cACA,8BACA,CAEA,OACA,uBACA,CAEA,sBACA,IAAgB,sBAAoB,IACpC,EAA0B,QAAM,IADwB,QACxB,GAChC,+BACA,iBACA,0CACA,UAAsB,EAAsB,gBAAiB,IAAjB,UAAiB,EAAyB,gBAEtF,QACA,CAEA,qBACA,qCACA,MACA,UAAsB,EAAkB,+BAExC,8BACA,cACA,OAAmB,GAAe,IAElC,QAFkC,OAElC,CACA,mBAEA,oBADA,EACA,KAEA,OADA,cACe,GAAe,EAC9B,CACA,SAF8B,YAE9B,CAEA,OADA,0BACA,YAEA,8BAOA,EANA,iBAAgB,GAAe,2BAC/B,EAA+B,EAAiB,GAChD,YADgD,UAChD,WACA,CAAgB,QAAiB,uBACjC,sBAAgB,GAAuB,EAGvC,YAAwB,KAAsB,KAG9C,sBACA,OAEA,iCACA,0BACA,MACA,UAA0B,EAAkB,aAAc,GAAiB,oBAK3E,UACA,iBACA,YAAgC,cAA6B,KAC7D,8BACA,cACA,OAEA,iBAEA,MAIA,mBAEA,CACA,QACA,CACA,0BACA,MAAkB,QAAM,eACxB,+BACA,MAAgC,GAAK,aACrC,SACA,UAAsB,EAAkB,mBAAoB,EAAY,qBAAqB,EAAc,2BAA2B,EAAgB,EAEtJ,CAIA,uBACA,iBAAgB,GAAe,2BAC/B,EAA+B,EAAiB,GAChD,CAAgB,QAAiB,GADe,GACf,iBACjC,sBAAgB,GAAuB,EACvC,IACA,iCACA,yBACA,uDACA,MACA,MAKA,UACA,iBACA,YAAgC,cAA6B,KAC7D,8BACA,cACA,OAEA,iBAEA,MAIA,oBAEA,IACA,CACA,QACA,CACA,0BACA,WAAmB,GAAa,OAChC,CACA,EAFgC,IAEhC,mBACA,iBAAgB,GAAe,2BAE/B,iBAAgB,GADe,EAAiB,GAEhD,CAAgB,QAAiB,GAFe,GAEf,iBACjC,oBACA,OAEA,MAAuB,QAAM,0BAE7B,OADA,wCACe,EAAS,eACxB,CACA,6CACA,EACA,KACA,QAEA,CACA,IAAoB,QAAiB,uBACrC,UACA,OAEA,EAAqB,QAAM,gBAC3B,6BACA,CACA,MAAqB,EAAS,gBAC9B,eACA,UAAsB,EAAkB,sCAAuC,GAAM,6BAA6B,QAAW,GAE7H,QACA,CACA,yBACA,cAC2B,EAAK,GAChC,aAEA,oBAIA,EAHA,MAAyB,SAAW,IACpC,EAAuB,UAAY,IACnC,IAEA,GAEA,KADA,GAAwB,cAAgB,SAEpB,QAAM,mBAC1B,YACA,mBAEc,aAEd,eACA,uBAA0D,kBAAgB,KA5N1E,gBACA,SACA,UA0N0E,GAzN1E,SACA,CAAS,CACJ,IAwNmB,QAAM,6BAC9B,OACA,MACA,eACY,SnB3EY,CAAU,KmB2ER,CnB3EQ,EAClC,MADkC,CAClC,SAEA,OADA,UAGA,iBAEA,UACA,gBACA,UAAkB,EAAkB,sBAAuB,EAAM,GAGjE,KADA,WACA,cAzKA,EA0KA,UAAkB,EAAkB,2BAEpC,iBACA,WAAkD,QAAM,iBAExD,cACA,UAAkB,EAAkB,kCAAmC,GAAY,SAEnF,UACA,OACA,gBAjGA,EACA,GAEA,UAAkB,EAAQ,WAC1B,aACA,YAAoB,WAAiB,KACrC,SAAsB,EAAQ,gBAE1B,SH1FJ,EG0Fe,CHzFf,CACA,GAEA,QACA,IACA,cACA,GACA,eACA,aAAgC,EAAQ,IAExC,EAFwC,EAExC,kBACA,iBACA,gBACA,0CAEA,YACQ,EAAQ,qCAEhB,KACA,WF7BA,KE6ByC,EAEzC,0BACA,aACA,8CACA,cACA,eAEA,OACA,KACA,MAGA,oBAEM,OACN,IF7CA,EE6Ce,GACf,EGqDe,EHtDO,EGsDP,GFhGA,SACf,EACA,EACA,EACA,GACA,IAyBA,EAzBA,aACA,aACA,aACA,aACA,gBACA,OACA,YAAoB,IAAe,MACnC,UAAkC,EAAQ,UAAoB,CAAR,EACtD,IAAkC,EAAQ,UAAoB,CAAR,EACtD,IAAkC,EAD4B,GACpB,GHlB1C,IGkB8D,CAAR,EACtD,IAAkC,EAD4B,GACpB,OAAoB,CAAR,EACtD,MAD8D,EAC9D,GACA,eACA,eACA,eACA,EAAgB,EAAQ,6BHxBxB,CGwBmE,GACnE,EAAgB,EAAQ,CADmD,KACnD,uBHzBxB,CGyBmE,GACnE,EAAgB,EAAQ,CADmD,KACnD,uBH1BxB,CG0BmE,GACnE,EAAgB,EAAQ,CADmD,KACnD,uBH3BxB,CG2BmE,GACnE,EAAgB,EAAQ,CADmD,KACnD,WACxB,EAAgB,EAAQ,iBACxB,EAAgB,EAAQ,iBACxB,EAAgB,EAAQ,gBACxB,CAGA,OAFA,iBAEA,KACA,OACA,KACA,QACA,MAAoB,EAAQ,MHvC5B,IGuCgD,CAAR,EACpB,MAD4B,OAC5B,cHxCpB,CGwCiE,GACjE,SACA,KACA,QACA,MAAoB,EAAQ,UAAoB,CAAR,EACpB,MAD4B,OAC5B,cH7CpB,CG6CiE,GACjE,KADyE,CACzE,GACA,MAAoB,EAAQ,UAAoB,CACpC,EAAQ,MAD4B,OAC5B,cHhDpB,CGgDiE,GACjE,SACA,KACA,QACA,MAAoB,EAAQ,MHpD5B,IGoDgD,CAAR,EACpB,2BHrDpB,CGqDiE,GACjE,KADyE,CACzE,GACA,MAAoB,EAAQ,UAAoB,CAAR,EACpB,2BHxDpB,CGwDiE,GACjE,KADyE,CACzE,GACA,MAAoB,EAAQ,MH1D5B,IG0DgD,CACpC,EAAQ,2BH3DpB,CG2DiE,GACjE,KADyE,CACzE,GACA,KACA,SACA,UAAsB,EAAkB,uDACxC,CACA,gBACA,EEmCO,QAEP,EAsFA,IACA,QACA,gBAtFA,EACA,GACA,iBACA,YAAoB,WAAc,KAClC,SAAmB,EAAQ,WAE3B,iBACA,YAAoB,WAAiB,MACrC,gBACA,YAAwB,cAAoB,KAC5C,YAA6B,EAAQ,gBHnE9B,SACP,EGqEe,CHpEf,CACA,GACA,QACA,cACA,GACA,QACA,IACA,aACA,aACA,UAAuB,EAAQ,YAE/B,GACA,kBACA,gBAAiC,EAAQ,IAEzC,EAFyC,EAEzC,qBACA,oBACA,mBACA,gDAEA,eACA,kBACA,cFvEA,EEuE+B,GAAO,CAEtC,eACA,aAAiC,EAAQ,eAE7B,EAAQ,8CAEpB,cACA,cF/EA,KE+E0C,EAE1C,gCAEA,GADA,WAC+B,EAD/B,KFlFA,MEoFA,8CACA,cACA,eAEA,OACA,KACA,MAGA,oBAEU,OACV,8CACA,cACA,eAEA,OACA,KACA,MAGA,aAEA,EAAM,aGUS,OACX,SDpHoB,CACxB,CACA,EACA,CCiHO,CDhHP,GACA,KALkC,CAKlC,cACA,aACA,aACA,aACA,aACA,OACA,IACA,IACA,MACA,MACA,IACA,IACA,IACA,IACA,KAAW,IAAW,qBACtB,iBAA4C,EAAQ,MJvBpD,IIuBwE,CAAR,EAChE,WAA4C,EAAQ,UAAoB,CAAR,EAChE,MADwE,EACxE,GAA4C,EAAQ,UAAoB,CAAR,EAChE,MADwE,EACxE,GAA4C,EAAQ,UAAoB,CAAR,EAChE,MADwE,EACxE,GACA,aACA,aACA,aACA,EAAgB,EAAQ,4BJ/BxB,CI+BgE,GAChE,EAAgB,EAAQ,CADgD,KAChD,sBJhCxB,CIgCgE,GAChE,EAAgB,EAAQ,CADgD,KAChD,sBJjCxB,CIiCgE,GAChE,EAAgB,EAAQ,CADgD,KAChD,sBJlCxB,CIkCgE,GAChE,EAAgB,EAAQ,CADgD,KAChD,WACxB,EAAgB,EAAQ,iBACxB,EAAgB,EAAQ,iBACxB,EAAgB,EAAQ,iBACxB,IACA,IACA,IACA,GACA,CAEA,KAAW,IAAiB,MAC5B,iBAA4C,EAAQ,MJ9CpD,II8CwE,CAAR,EAChE,MADwE,EACxE,GACA,EAAgB,EAAQ,0BJhDxB,CIgDmE,GACnE,GACA,CACA,CAH2E,CCuEpE,QAEP,EAsEA,IACA,SACA,UAAsB,EAAkB,uBAAwB,EAAM,EACtE,CACA,EmB8C0B,UAI1B,kBACY,oBAA0B,WAEtC,eACY,oBAA0B,WAEtC,iBACY,sBAA4B,WAExC,cACY,mBAAyB,WAGrC,UAAsB,EAAsB,GAAI,GAAmB,cAAvB,mBAAuB,EAEnE,CACA,mBACA,iBAAgB,GAAe,2BAC/B,EAA+B,EAAiB,GAChD,gCACA,cACA,OAEA,qBACA,EAAiC,QAAM,iCACvC,GACA,KACA,eACA,kBACA,SACA,EACA,gCACA,MAAmC,QAAM,8BACzC,yCACA,+CACA,MAEA,0CAEA,SAEA,oEACA,cACA,MAEA,iBAEA,wBACA,uEAGA,8BACA,QACA,iDAGA,kCACA,yBAEA,QACA,CACA,CE9SA,iBACA,kBAEA,GADA,EACA,EACA,GAFA,EAEA,KAEA,EAJA,EAIA,OACA,QACA,OACA,iBACA,aACA,YACA,CAAK,CACL,CFkSA,sEACI,EAAW,KACf,CAAC,CE7Rc,EF4RA,KE5RA,GAQf,eACA,gBAA0B,GAAI,0BAC9B,CACA,uBAjBA,EAkBA,SACA,EAlBA,MADA,EAmBA,iCAlBA,gBACe,EAAK,KAkBpB,eACA,UApC4B,EAoC5B,kBACA,UAAsB,EAAkB,iJAMxC,SACA,KACA,eACA,iBACA,WACA,+BAEA,SACA,8BACA,UAEA,UACA,8BACA,KACA,QACA,UAEA,kBAGA,UAA0B,EAAkB,4BAe5C,OAXA,GACA,8BAEA,cACA,QAGA,oCAEA,KADA,EACA,2CACA,CAAS,EACT,CACA,CACA,WAOA,OANA,kBACA,8CAEA,MADA,wBACA,CACA,EAAa,EAEb,iBAOA,qCACA,mCAaA,gCACA,iCACA,MACA,SAEA,UACA,cACA,wBACA,IACA,GAEA,KACA,EAEA,CACA,EADsB,EAEtB,GACA,eACA,UACA,UAGA,QACA,CACA,CCrIe,SAUf,eACA,MAWA,GATA,UACA,oCAAkE,GAAQ,CAC1E,cACA,gBACA,4BACA,oBACA,oCACA,sBACa,EACb,uBAAmC,GAAQ,CAC3C,6CAEA,mBACA,CAQA,mCAAuD,EAIvD,GAHA,gCACA,oCACA,qCACA,mBAEA,UAAsB,EAAsB,2CAG5C,0CADA,EACA,KAGA,uBACA,qBACA,wBACA,oCACA,2DACA,+BACA,kBACA,SACA,KACA,gBACA,iBACA,cACA,kCAEA,iBACA,MACA,SAEA,QACA,MACA,CACA,SACA,oCACA,OACA,SAEA,CAAa,EACb,SACA,gBACA,iBACA,cACA,kCAEA,SACA,QACA,qBAvCA,GAuCA,kBACA,iDACA,iBACA,qGACA,SACA,CACA,CACA,2BACA,KACA,eACA,aAGA,IACA,sDACA,sDACA,SACA,KACA,gBACA,+CACA,IACA,mCACA,4CAEA,UACA,iBACA,SACA,gBACA,uBACA,iCAEA,gCACA,SAEA,CACA,QACA,CAAiB,EACjB,SACA,CACA,2BACA,aACA,mCACA,aACA,CACA,CACA,QACA,CACA,kCAAwB,4BAAyC,IAGjE,OAFA,oCACA,cACA,aACA,CAOA,+BACA,gDACA,CACA,gHG9Ie,UACf,iBACA,cACA,aACA,CACA,WACA,4BAEA,YACA,mCACA,CACA,UACA,MACA,sEACA,CACA,YACA,kCAEA,YACA,yBAEA,aACA,+CACA,CACA,WACA,+CACA,CACA,cACA,iCAEA,cACA,sDACA,CACA,uBACA,qEACA,CACA,sBACA,4DAEA,eACA,wBACA,qDACA,MACA,CACA,4BACA,wBACA,GAAiB,qDAAqD,GAAG,gCAAgC,EACzG,MACA,CACA,gBACA,yBAEA,eACA,MACA,uEAEA,WACA,MACA,gGACA,mBAAoC,0BAA0B,iBAE9D,UACA,iCACA,CACA,YACA,ODmCO,kBACP,CCpCkC,GDoClC,KACA,KACA,MACA,IACA,MACA,SAEA,YACA,UACA,IACA,IACA,IACA,cACA,aAAqB,yBAA0B,IAgB/C,GAfA,MACA,oBACA,IACA,SACA,MAA4B,EAAO,GACnC,KAEA,aACA,MAA4B,EAAM,EAAE,EAAG,EACvC,KAEA,IACA,MACA,MAEA,SAEA,6BADA,cAEA,KACA,YACA,gBAEA,SACA,KACA,IACA,KAEA,SACA,KACA,IACA,KAEA,kBACA,KACA,GACA,OAAgC,EAAM,EAAE,GAAG,EAE3C,OACA,KAEA,kBACA,KACA,GACA,OAAgC,EAAM,EAAE,GAAG,EAE3C,cACA,KAEA,SACA,GACA,OAAgC,EAAM,EAAE,EAAG,GAE3C,IACA,KACA,KAEA,SACA,GACA,OAAgC,EAAM,EAAE,EAAG,GAE3C,MAA4B,EAAK,IAEjC,UACA,GACA,OAAgC,EAAM,EAAE,EAAG,GAE3C,MAA4B,EAAK,GACjC,UAKA,aAkBA,OAhBA,eACA,aACA,sBACA,aACA,MAAwB,EAAM,EAAE,EAAG,EACnC,KAEA,MACA,MAEA,QACA,OAAoB,EAAO,IAE3B,GACA,OAAoB,EAAM,EAAE,EAAG,GAE/B,CACA,EC7IkC,kGAClC,CACA,KACA,SAAkB,eAAe,GAAG,qBAAqB,EAEzD,OACA,uBACA,gBACA,WACA,UACA,YACA,WACA,eAEA,SAEA,CACA,WAEA,CACA,iBACA,ODxFO,gBACP,MACA,ECsFuC,IDtFvC,GAEA,sBACA,IACA,IACA,IACA,IACA,IACA,QAAiB,0CAAuC,IAaxD,GAZA,MACA,IACA,SACA,QACA,QACA,iBACA,QAAyB,EAAO,EAChC,QACA,EACA,KAEA,QACA,QACA,QACA,QACA,SACA,OACA,2BACA,uCACA,eACA,OAEA,WACA,QACA,QACA,iBACA,QAAyB,SAAY,EACrC,QACA,OAEA,WACA,QACA,YACA,SACA,QACA,QACA,OAEA,YACA,eACA,QACA,QACA,gBACA,SAA0B,EAAI,EAC9B,UACA,QACA,CACA,KACA,UAEA,QAEA,QACA,QACA,gBACA,SAA0B,EAAI,EAC9B,QALA,EAMA,QACA,EAEA,QACA,QACA,gBACA,SACA,QACA,QACA,EAEA,SAEA,SAEA,SAEA,SACA,KAcA,OATA,SACA,QACA,QACA,iBACA,QAAqB,EAAO,EAC5B,QACA,EACA,KAEA,YACA,ECbuC,iDACvC,CACA,aACA,OACA,iBACA,eACA,aACA,iBACA,mBACA,qCACA,iBACA,eACA,qBACA,aACA,aACA,uCACA,uBACA,uBACA,iDACA,kBACA,CACA,CACA,SACA,OACA,eACA,iBACA,eAEA,CACA,CACA,SAAW,cACX,SAAW,aACX,SAAW,iBC7GI,kBAA0B,yBAAsB,CAC/D,cACA,oBACA,kBACA,+BAAyC,UAAQ,EACjD,WACA,CAAS,EACT,+BAEA,qBACA,mCACA,+BACA,qBACA,MAAyB,GAAe,CACxC,WADwC,IACZ,mBAAY,MACxC,UAAuB,GAAS,CAAG,KAAH,MAAe,mBAAY,MAAoB,EAC/E,qCACA,mBACA,CAAS,EACT,uBACA,wCAEA,sCACA,MACA,iEAGA,OACA,OACA,gBAHA,8BAGA,YAEA,CACA,kBAOA,OANA,iBACA,+CAEA,MADA,uBACA,CACA,EAAa,EAEb,gBAEA,mBACA,SAAgB,GAAO,uBACvB,6BACA,CACA,sBACA,KACA,oBAAgB,GAAkB,uBAClC,mDACA,MACA,uBAUA,MARA,OAAgC,QAAc,GAC9C,aACA,UACA,QACA,MACA,eACA,CAAS,EACT,KAAkB,QAAO,MAEzB,2CACA,QACA,qBACA,eACA,kBAEA,EADA,kBACA,EAEA,OADA,iCACA,YACA,CAAS,EACT,SACA,MACA,gBACA,wBAAwC,EAAQ,GAAG,eAAQ,MAAY,GAAG,eAAQ,KAAO,WAAW,eAAQ,YAAmB,8BAA8B,eAAQ,IAAO,GAE5K,QACA,CACA,kBACA,mBAAgB,UAA6B,MAC7C,MAAe,mBAAY,iCAC3B,6BACA,MAAoB,GAAO,EAC3B,8BACA,KACA,KACA,EACA,wBACA,gBACA,mCACA,MACA,cACA,OACA,MACA,CACA,CAAa,EAIb,OAA2B,iCAH3B,EACA,wBACA,QAAiC,MAAQ,0EAA0G,CACxH,EAE3B,OADA,iBACA,CAAqB,iBACrB,CAAS,CACT,CACA,eAOA,OANA,aACA,wCAEA,MADA,mBACA,CACA,EAAa,EAEb,YAEA,qBACA,cAAgB,GAAY,oBAC5B,eACA,6CAEA,kBAEA,sBACA,wBACA,2BAEA,oBACA,qCAGA,CACA,eACA,QACA,4HACA,CACA,uBACA,sCAEA,iBACA,cAAgB,sCAAkD,MAClE,SAAgB,mCAAuC,EACvD,MAAe,uBAAgB,WAC/B,SAAoB,eAAkB,oBACtC,sBACA,eACA,kCACA,aACA,MACA,CACA,GACA,mCAEA,YAAkC,mBAAY,6DAClC,qBAAc,IAC1B,MAAkB,mBAAY,gCAC9B,MACA,gBAAwB,4CAAyD,MACjF,gBACA,GAAwB,SAAc,eAGtC,GACwB,SAAc,cACtC,4DACA,wBAGA,kBARA,SAWA,wCAAkE,WAAgB,GAClF,KAMA,cANA,CACA,kCACA,kCAA0D,WAAgB,KAC1E,SACA,CAIA,CACA,YACA,CAAa,CACb,CAAS,GACT,CACA,iBACA,uBACA,WAAmB,GAAuB,OAC1C,CACA,YAF0C,4BAE1C,KAGA,OACA,MAHA,gCAIA,eAHA,8BAIA,CACA,CACA,2BACA,SAAgB,GAAO,uBAQvB,MAPA,6BACA,YAAoB,iBAAsB,EAC1C,sBACA,kBACA,kCACA,EAAqB,aAAe,EAC3B,IACT,sCACA,CACA,aCxMA,SAEA,oBACA,QACA,IACA,6BACA,mBAEA,IADA,QACA,MACA,SACA,OACA,MACA,eACA,IACA,OAEA,MACA,6BACA,KACA,IAEA,CACA,QACA,CACA,EAEA,qBACA,IACA,IADA,cACA,KACA,IACA,GAIA,IAFA,wBAGA,UACA,uBAEM,OACN,oBACA,IACA,YAAoB,WAAmB,IACvC,OACA,WACA,gBAEA,QACA,EAEA,qBACA,kBACA,6BACA,cACA,YACA,0BACA,QACA,EAKA,6BAQA,iBAA4B,IAAO,IACnC,qBACA,qBACA,UACA,CADmB,EACnB,kBACA,+BAEA,GADA,MACA,CADc,CACd,GACA,oCACA,YACA,KAXA,IAYA,gDACA,YACA,sBACA,IACA,QAAgB,KAAQ,IACxB,cACA,YACA,QAAwB,KAAQ,IAChC,WACA,eAGA,CAGA,WACA,YACA,qBACA,YACA,QACA,WAEA,QADA,KACA,CADwB,CACxB,EAAoB,IAAgB,IACpC,OAGA,QAFA,wBAEA,IAAoB,IAAgB,KACpC,YAAwB,KAAS,IACjC,QACA,4BACA,WACA,cACA,CADgC,CAChC,cACA,MACA,CAIA,QAFA,MACA,KACA,IAAoB,IAAgB,KACpC,IAuDA,QAmFA,MA1HA,IAQA,EAxBA,iBAxDA,KAyDA,qBACA,OACA,CADqB,GACrB,QAAwB,IAAc,KACtC,QACA,UA9DA,GA+DA,uDACA,SACA,MACA,KAGA,IAFA,GAGA,CACA,MACA,CAEA,SACA,YAAwB,IAAc,IACtC,OACA,OACA,QACA,QAIA,CADA,YACA,wBAlFA,KAmFA,4BACA,2BACA,WACA,WAIA,QAHA,qBACA,sBACA,IACA,IAA6B,KAAa,IAC1C,YAA4B,IAAc,IAC1C,SACA,mBACA,QAAyB,KAAa,IACtC,YACA,QAAoB,IAAc,IAClC,UAEA,IADA,MACA,IAAyB,IAAY,IACrC,QACA,SACA,MACA,kBAEA,eACA,MACA,CAEA,QADA,uBACA,IAAoB,MAAS,IAC7B,OAEA,UAEA,IADA,sBA5GA,OA6GA,CACA,SAEA,GADA,KACA,KACA,yCAEA,EADA,cACA,iBACA,qBACA,CAGA,IADA,IADA,cAEA,CACA,cACA,2BACA,WACA,KACA,KACA,WACA,CAEA,GADA,UACA,MAtIA,IAuIA,qBACA,mBACA,eACA,IACA,IACA,KA3IA,GA6IA,EACA,KAEA,OACA,MACA,QACA,CACA,MAEA,GADA,IACA,KAlJA,IAmJA,aAGA,IAFA,UACA,QACA,KACA,QACA,CACA,OACA,MACA,MA3JA,IA4JA,wCAEA,IADA,MACA,CACA,cACA,gBACA,OACA,OACA,QACA,CACA,aACA,sEAEA,QADA,IACA,IAAoB,MAAS,IAC7B,SACA,OACA,IAEA,YAAoB,IAAW,IAC/B,WACA,cACA,OATA,IAWA,IACA,IACA,IACA,IAEA,MADA,SAEA,MACA,MAGA,qBA5LA,KA8LA,IAGA,IAFA,GACA,QACA,IAcA,IAbA,IACA,IAEA,MADA,SAEA,MACA,QACA,IACA,IACA,OAEA,IACA,KAEA,KAIA,GAFA,SAEA,KACA,SAEA,MACA,KACA,CAGA,sBACA,EAEA,uBClTA,OAEA,MAEA,0BACA,2DACA,CAAK,CAGL,0BACA,yDACA,CACA,CAAG,CAGH,KAEA,0BACA,iBAAkC,WAAgB,IAClD,4BACA,QACA,CAAK,CAGL,0BACA,iBAAgC,WAAkB,IAClD,kCACA,iBACA,CACA,CACA,EAEA,wBChCA,WACA,MACA,mEAEA,GAEA,mBACA,oBACA,CAAK,CAGL,mBACA,oBACA,CAAK,CAGL,mBAEA,yBACA,oDAIA,YAAsB,WAAc,IACpC,oBACA,QACA,CAAK,CAGL,wBACA,aAA2B,IAAO,IAClC,sCACA,QACA,CAAK,CAGL,yBACA,qBAAyC,WAAkB,SAC3D,wBACA,QACA,CAAK,CAGL,yBACA,iBAAkC,cAAuB,KACzD,+BACA,QACA,CAAK,CAGL,uBACA,iBAAgC,WAAkB,IAClD,gCACA,+BAEA,iBACA,CAAK,CAGL,uBACA,iBAAkC,WAAgB,KAClD,mCACA,QACA,CAAK,CAGL,0BACA,iBAAmC,WAAkB,KAErD,QADA,4BACA,IAAwB,IAAO,IAC/B,oBACA,iCAEA,YAEA,iBACA,CAAK,CAGL,0BAEA,iCAEA,qBAA6C,WAC7C,QACA,MACA,iCACA,2BACA,gCAEA,QACA,CACA,CAEA,YACA,CAAC,cClFD,cACA,2FACA,CANA,sBACA,uBASA,mBATA,EASA,gCATA,EASA,SATA,EASA,aATA,cACA,oBCXA,WACA,MAAc,EAAQ,KAAO,EAC7B,EAAa,QADQ,CACR,KAAuB,EACnB,EAAQ,KAAW,EACpC,EAAY,QADY,CACZ,IAAsB,EAGlC,cAEA,sBAEA,EADA,yBACA,mBAEA,mBACA,KACA,kCACA,8CACA,iBAWA,QARA,oBACA,aACA,aACA,cACA,cACA,aAGA,IAAoB,WAAc,IAClC,kCACA,8BAIA,qBACA,sBAQA,QALA,QACA,QACA,QACA,QAEA,IAAoB,WAAc,OAElC,QACA,IACA,IACA,IAEA,kCACA,mCACA,kCACA,mCACA,iCACA,kCACA,mCACA,kCACA,iCACA,mCACA,+BACA,oCACA,kCACA,mCACA,oCACA,mCAEA,iCACA,kCACA,mCACA,mCACA,kCACA,iCACA,oCACA,mCACA,iCACA,mCACA,kCACA,kCACA,mCACA,iCACA,kCACA,oCAEA,8BACA,mCACA,mCACA,mCACA,kCACA,kCACA,kCACA,oCACA,kCACA,mCACA,mCACA,iCACA,kCACA,oCACA,mCACA,mCAEA,iCACA,kCACA,oCACA,kCACA,kCACA,mCACA,iCACA,mCACA,iCACA,mCACA,mCACA,mCACA,iCACA,oCACA,kCACA,mCAEA,UACA,UACA,UACA,SACA,CAEA,0BACA,CAGA,+BACA,6BACA,uBACA,EACA,8BACA,6BACA,uBACA,EACA,8BACA,0BACA,uBACA,EACA,8BACA,6BACA,uBACA,EAGA,gBACA,iBAEA,wBACA,WACA,mCAEA,6BACA,sBACA,iCACA,eACA,CAEA,CAAC,8BC1JD,IASC,GACD,MACA,GADyB,UAEzB,QAGA,IAEA,iCAAwC,42gBAExC,CAAO,CAEP,IAEA,WAEA,CAAO,CACP,CAGA,KAGA,SAAmB,EAAmB,GAEtC,WACA,cACA,EAJsC,KAItC,UAGA,YAGA,UACA,EAMA,OAHA,iBAAiE,GAGjE,UAOW,EAAmB,UAC9B,OAXoF,CAWpF,OACgB,EAAmB,GAFL,CAEK,KAAwB,EAAmB,QAC9E,WADmC,UACnC,MAAoD,uBAAwC,CAG5F,EAKW,EAAmB,mDAMnB,EAAmB,MAC9B,wBAD8B,IAC9B,oBACA,4CAAkE,eAAiB,EAEnF,sCAA2D,SAAa,CACxE,EAIA,IAAI,EAAmB,GAiIvB,MA/HA,MACA,EAAmB,EAAG,GACD,EAAmB,EAAG,EAAmB,CAC9D,gBAFyC,CAEzC,CAFmB,GAEnB,CACA,CAF8D,EAAtB,IAGxC,EAAwF,EAAmB,GAG3G,2BAH2G,IAG3G,EAGQ,EAAmB,wBAK3B,EACA,IAN2B,QAM3B,GACA,uBACA,gCACA,uCACA,gBACA,2BACA,oCACA,qCACA,qCAGA,eACA,gBAEA,IADA,wCACA,SACA,iDACA,eACA,CAEA,gBACA,6CAEA,GADA,gBACA,aACA,sDAAsE,EAAO,GAG7E,OAAiB,SADjB,2DACiB,eACjB,CAEA,iBACA,qCAGA,qBACA,oCAGA,oBACA,2BACA,CAEA,UACA,uCACA,iBACA,CAEA,WACA,yCACA,sDACA,wDAEA,CACA,CAEA,kBACA,qCACA,6BACA,qBACA,uCAAuH,aACvH,qDAEA,kCADA,GAEA,8BAGA,mBACA,EACA,WACA,gBAEA,OACA,eACA,mBACA,oFAEA,0BACA,CAAa,CAEb,cACA,uBACA,+BACA,SAAgC,WAAc,eAC9C,GACA,KAEA,CACA,uCACA,+BACA,eACA,CAEA,wBACA,sBACA,sBAEA,aACA,YACA,CADyC,CACzC,QAEA,CAAa,CACb,YACA,YACA,CADqC,CACrC,SAEA,CAAS,CACT,CACA,EAEA,CAAC,GAEgB,CACjB,EAAU,GAlNV,YAA2B,EAAQ,KAAY,CAiNX,WAjNF,sCCNlC,OACA,8EACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,wFACA,wFACA,wFACA,sFACA,sFACA,wFACA,wFACA,wFACA,sFACA,wFACA,wFACA,CACA,gCACA,qCChCA,MADA,OAA0C,QAAM,WEDhD,CFE2B,CCHZ,CDGa,QCHb,KACf,eAAmD,EAAY,UAI/D,CAJ+D,MAC/D,kBAAoD,EAAY,MAChE,KADgE,KAChE,GACA,UACA,CACA,ECLwB,SHoCxB,QAEA,WGtCyC,CHsCzC,CGtC0C,CHsC1C,OACA,YAAwB,WAAwB,IAChD,wBAEA,WACA","sources":["webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/arith_gen.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/arith_sh.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/byte_model.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/fqzcomp.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/iostream.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/rans.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/rans4x16.js","webpack://_N_E/./node_modules/@gmod/cram/esm/htscodecs/tok3.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/constants.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/record.js","webpack://_N_E/./node_modules/@gmod/cram/esm/errors.js","webpack://_N_E/./node_modules/@gmod/cram/esm/unzip-pako.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/constants.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/decoding.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/frequencies.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/d04.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/d14.js","webpack://_N_E/./node_modules/@gmod/cram/esm/rans/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/getBits.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/util.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/sectionParsers.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/slice/decodeRecord.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/slice/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/huffman.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/external.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayStop.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayLength.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/beta.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/gamma.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/subexp.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/codecs/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/container/compressionScheme.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/container/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/io/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/sam.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/file.js","webpack://_N_E/./node_modules/@gmod/cram/esm/cramFile/index.js","webpack://_N_E/./node_modules/@gmod/cram/esm/craiIndex.js","webpack://_N_E/./node_modules/@gmod/cram/esm/indexedCramFile.js","webpack://_N_E/./node_modules/@gmod/cram/esm/index.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/util.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramSlightlyLazyFeature.js","webpack://_N_E/./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramAdapter.js","webpack://_N_E/./node_modules/bzip2/bzip2.js","webpack://_N_E/./node_modules/charenc/charenc.js","webpack://_N_E/./node_modules/crypt/crypt.js","webpack://_N_E/./node_modules/is-buffer/index.js","webpack://_N_E/./node_modules/md5/md5.js","webpack://_N_E/./node_modules/xz-decompress/dist/package/xz-decompress.js","webpack://_N_E/./node_modules/crc/mjs/calculators/crc32.js","webpack://_N_E/./node_modules/crc/mjs/create_buffer.js","webpack://_N_E/./node_modules/crc/mjs/define_crc.js","webpack://_N_E/./node_modules/crc/mjs/crc32.js"],"sourcesContent":["\"use strict\";\n/*\n * Copyright (c) 2019,2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nconst RangeCoder = require('./arith_sh');\nconst IOStream = require('./iostream');\nconst ByteModel = require('./byte_model');\nconst bzip2 = require('bzip2');\nconst ARITH_ORDER = 1;\nconst ARITH_EXT = 4;\nconst ARITH_STRIPE = 8;\nconst ARITH_NOSIZE = 16;\nconst ARITH_CAT = 32;\nconst ARITH_RLE = 64;\nconst ARITH_PACK = 128;\nmodule.exports = class RangeCoderGen {\n    decode(src) {\n        this.stream = new IOStream(src);\n        return this.decodeStream(this.stream);\n    }\n    decodeStream(stream, n_out = 0) {\n        var flags = this.stream.ReadByte();\n        if (!(flags & ARITH_NOSIZE))\n            n_out = this.stream.ReadUint7();\n        var e_len = n_out;\n        var order = flags & ARITH_ORDER;\n        // 4-way recursion\n        if (flags & ARITH_STRIPE)\n            return this.decodeStripe(this.stream, n_out);\n        // Meta data\n        if (flags & ARITH_PACK) {\n            var P;\n            [P, e_len] = this.decodePackMeta(this.stream);\n        }\n        // NOP, useful for tiny blocks\n        if (flags & ARITH_CAT)\n            var data = this.decodeCat(this.stream, e_len);\n        // Entropy decode\n        else if (flags & ARITH_EXT) {\n            var data = this.decodeExt(this.stream, e_len);\n        }\n        else if (flags & ARITH_RLE) {\n            var data = order\n                ? this.decodeRLE1(this.stream, e_len)\n                : this.decodeRLE0(this.stream, e_len);\n        }\n        else {\n            var data = order\n                ? this.decode1(this.stream, e_len)\n                : this.decode0(this.stream, e_len);\n        }\n        // Transforms\n        if (flags & ARITH_PACK)\n            data = this.decodePack(data, P, n_out);\n        return data;\n    }\n    encode(src, flags) {\n        this.stream = new IOStream('', 0, src.length * 1.1 + 100); // guestimate worst case!\n        this.stream.WriteByte(flags);\n        if (!(flags & ARITH_NOSIZE))\n            this.stream.WriteUint7(src.length);\n        if (flags & ARITH_STRIPE)\n            return Buffer.concat([\n                this.stream.buf.slice(0, this.stream.pos),\n                this.encodeStripe(this.stream, src, flags >> 8),\n            ]);\n        var order = flags & ARITH_ORDER;\n        var e_len = src.length;\n        // step 1: Encode meta-data\n        var pack_meta;\n        if (flags & ARITH_PACK)\n            [pack_meta, src, e_len] = this.encodePack(src);\n        // step 2: Write any meta data\n        if (flags & ARITH_PACK)\n            this.stream.WriteStream(pack_meta);\n        // step 3: arith encoding below\n        if (flags & ARITH_RLE) {\n            return order\n                ? this.encodeRLE1(src, e_len, this.stream)\n                : this.encodeRLE0(src, e_len, this.stream);\n        }\n        else {\n            return order\n                ? this.encode1(src, e_len, this.stream)\n                : this.encode0(src, e_len, this.stream);\n        }\n    }\n    //----------------------------------------------------------------------\n    // Order-0 codec\n    decode0(stream, n_out) {\n        var output = new Buffer.allocUnsafe(n_out);\n        var max_sym = stream.ReadByte();\n        if (max_sym == 0)\n            max_sym = 256;\n        var byte_model = new ByteModel(max_sym);\n        var rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        for (var i = 0; i < n_out; i++)\n            output[i] = byte_model.ModelDecode(stream, rc);\n        return output;\n    }\n    encode0(src, n_in, out) {\n        // Count the maximum symbol present\n        var max_sym = 0;\n        for (var i = 0; i < n_in; i++)\n            if (max_sym < src[i])\n                max_sym = src[i];\n        max_sym++; // FIXME not what spec states!?\n        var byte_model = new ByteModel(max_sym);\n        out.WriteByte(max_sym);\n        var rc = new RangeCoder(out);\n        for (var i = 0; i < n_in; i++)\n            byte_model.ModelEncode(out, rc, src[i]);\n        rc.RangeFinishEncode(out);\n        return out.buf.slice(0, out.pos);\n    }\n    //----------------------------------------------------------------------\n    // Order-1 codec\n    decode1(stream, n_out) {\n        var output = new Buffer.allocUnsafe(n_out);\n        var max_sym = stream.ReadByte();\n        if (max_sym == 0)\n            max_sym = 256;\n        var byte_model = new Array(max_sym);\n        for (var i = 0; i < max_sym; i++)\n            byte_model[i] = new ByteModel(max_sym);\n        var rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        var last = 0;\n        for (var i = 0; i < n_out; i++) {\n            output[i] = byte_model[last].ModelDecode(stream, rc);\n            last = output[i];\n        }\n        return output;\n    }\n    encode1(src, n_in, out) {\n        // Count the maximum symbol present\n        var max_sym = 0;\n        for (var i = 0; i < n_in; i++)\n            if (max_sym < src[i])\n                max_sym = src[i];\n        max_sym++; // FIXME not what spec states!\n        var byte_model = new Array(max_sym);\n        for (var i = 0; i < max_sym; i++)\n            byte_model[i] = new ByteModel(max_sym);\n        out.WriteByte(max_sym);\n        var rc = new RangeCoder(out);\n        var last = 0;\n        for (var i = 0; i < n_in; i++) {\n            byte_model[last].ModelEncode(out, rc, src[i]);\n            last = src[i];\n        }\n        rc.RangeFinishEncode(out);\n        return out.buf.slice(0, out.pos);\n    }\n    //----------------------------------------------------------------------\n    // External codec\n    decodeExt(stream, n_out) {\n        // Bzip2 only for now\n        var output = new Buffer.allocUnsafe(n_out);\n        var bits = bzip2.array(stream.buf.slice(stream.pos));\n        var size = bzip2.header(bits);\n        var j = 0;\n        do {\n            var chunk = bzip2.decompress(bits, size);\n            if (chunk != -1) {\n                Buffer.from(chunk).copy(output, j);\n                j += chunk.length;\n                size -= chunk.length;\n            }\n        } while (chunk != -1);\n        return output;\n    }\n    encodeExt(stream, n_out) {\n        // We cannot compress using Bzip2 now as it's\n        // absent from bzip2.js, but consider using\n        // https://github.com/cscott/compressjs\n    }\n    //----------------------------------------------------------------------\n    // Order-0 RLE codec\n    decodeRLE0(stream, n_out) {\n        var output = new Buffer.allocUnsafe(n_out);\n        var max_sym = stream.ReadByte();\n        if (max_sym == 0)\n            max_sym = 256;\n        var model_lit = new ByteModel(max_sym);\n        var model_run = new Array(258);\n        for (var i = 0; i <= 257; i++)\n            model_run[i] = new ByteModel(4);\n        var rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        var i = 0;\n        while (i < n_out) {\n            output[i] = model_lit.ModelDecode(stream, rc);\n            var part = model_run[output[i]].ModelDecode(stream, rc);\n            var run = part;\n            var rctx = 256;\n            while (part == 3) {\n                part = model_run[rctx].ModelDecode(stream, rc);\n                rctx = 257;\n                run += part;\n            }\n            for (var j = 1; j <= run; j++)\n                output[i + j] = output[i];\n            i += run + 1;\n        }\n        return output;\n    }\n    encodeRLE0(src, n_in, out) {\n        // Count the maximum symbol present\n        var max_sym = 0;\n        for (var i = 0; i < n_in; i++)\n            if (max_sym < src[i])\n                max_sym = src[i];\n        max_sym++; // FIXME not what spec states!\n        var model_lit = new ByteModel(max_sym);\n        var model_run = new Array(258);\n        for (var i = 0; i <= 257; i++)\n            model_run[i] = new ByteModel(4);\n        out.WriteByte(max_sym);\n        var rc = new RangeCoder(out);\n        var i = 0;\n        while (i < n_in) {\n            model_lit.ModelEncode(out, rc, src[i]);\n            var run = 1;\n            while (i + run < n_in && src[i + run] == src[i])\n                run++;\n            run--;\n            var rctx = src[i];\n            var last = src[i];\n            i += run + 1;\n            var part = run >= 3 ? 3 : run;\n            model_run[rctx].ModelEncode(out, rc, part);\n            run -= part;\n            rctx = 256;\n            while (part == 3) {\n                part = run >= 3 ? 3 : run;\n                model_run[rctx].ModelEncode(out, rc, part);\n                rctx = 257;\n                run -= part;\n            }\n        }\n        rc.RangeFinishEncode(out);\n        return out.buf.slice(0, out.pos);\n    }\n    //----------------------------------------------------------------------\n    // Order-1 RLE codec\n    decodeRLE1(stream, n_out) {\n        var output = new Buffer.allocUnsafe(n_out);\n        var max_sym = stream.ReadByte();\n        if (max_sym == 0)\n            max_sym = 256;\n        var model_lit = new Array(max_sym);\n        for (var i = 0; i < max_sym; i++)\n            model_lit[i] = new ByteModel(max_sym);\n        var model_run = new Array(258);\n        for (var i = 0; i <= 257; i++)\n            model_run[i] = new ByteModel(4);\n        var rc = new RangeCoder(stream);\n        rc.RangeStartDecode(stream);\n        var last = 0;\n        var i = 0;\n        while (i < n_out) {\n            output[i] = model_lit[last].ModelDecode(stream, rc);\n            last = output[i];\n            var part = model_run[output[i]].ModelDecode(stream, rc);\n            var run = part;\n            var rctx = 256;\n            while (part == 3) {\n                part = model_run[rctx].ModelDecode(stream, rc);\n                rctx = 257;\n                run += part;\n            }\n            for (var j = 1; j <= run; j++)\n                output[i + j] = output[i];\n            i += run + 1;\n        }\n        return output;\n    }\n    encodeRLE1(src, n_in, out) {\n        // Count the maximum symbol present\n        var max_sym = 0;\n        for (var i = 0; i < n_in; i++)\n            if (max_sym < src[i])\n                max_sym = src[i];\n        max_sym++; // FIXME not what spec states!\n        var model_lit = new Array(max_sym);\n        for (var i = 0; i < max_sym; i++)\n            model_lit[i] = new ByteModel(max_sym);\n        var model_run = new Array(258);\n        for (var i = 0; i <= 257; i++)\n            model_run[i] = new ByteModel(4);\n        out.WriteByte(max_sym);\n        var rc = new RangeCoder(out);\n        var i = 0;\n        var last = 0;\n        while (i < n_in) {\n            model_lit[last].ModelEncode(out, rc, src[i]);\n            var run = 1;\n            while (i + run < n_in && src[i + run] == src[i])\n                run++;\n            run--;\n            var rctx = src[i];\n            last = src[i];\n            i += run + 1;\n            var part = run >= 3 ? 3 : run;\n            model_run[rctx].ModelEncode(out, rc, part);\n            run -= part;\n            rctx = 256;\n            while (part == 3) {\n                part = run >= 3 ? 3 : run;\n                model_run[rctx].ModelEncode(out, rc, part);\n                rctx = 257;\n                run -= part;\n            }\n        }\n        rc.RangeFinishEncode(out);\n        return out.buf.slice(0, out.pos);\n    }\n    //----------------------------------------------------------------------\n    // Pack method\n    decodePackMeta(stream) {\n        this.nsym = stream.ReadByte();\n        var M = new Array(this.nsym);\n        for (var i = 0; i < this.nsym; i++)\n            M[i] = stream.ReadByte();\n        var e_len = stream.ReadUint7(); // Could be derived data from nsym and n_out\n        return [M, e_len];\n    }\n    decodePack(data, M, len) {\n        var out = new Buffer.allocUnsafe(len);\n        if (this.nsym <= 1) {\n            // Constant value\n            for (var i = 0; i < len; i++)\n                out[i] = M[0];\n        }\n        else if (this.nsym <= 2) {\n            // 1 bit per value\n            for (var i = 0, j = 0; i < len; i++) {\n                if (i % 8 == 0)\n                    var v = data[j++];\n                out[i] = M[v & 1];\n                v >>= 1;\n            }\n        }\n        else if (this.nsym <= 4) {\n            // 2 bits per value\n            for (var i = 0, j = 0; i < len; i++) {\n                if (i % 4 == 0)\n                    var v = data[j++];\n                out[i] = M[v & 3];\n                v >>= 2;\n            }\n        }\n        else if (this.nsym <= 16) {\n            // 4 bits per value\n            for (var i = 0, j = 0; i < len; i++) {\n                if (i % 2 == 0)\n                    var v = data[j++];\n                out[i] = M[v & 15];\n                v >>= 4;\n            }\n        }\n        else {\n            // 8 bits per value: NOP\n            return data;\n        }\n        return out;\n    }\n    // Compute M array and return meta-data stream\n    packMeta(src) {\n        var stream = new IOStream('', 0, 1024);\n        // Count symbols\n        var M = new Array(256);\n        for (var i = 0; i < src.length; i++)\n            M[src[i]] = 1;\n        // Write Map\n        for (var nsym = 0, i = 0; i < 256; i++)\n            if (M[i])\n                M[i] = ++nsym; // map to 1..N\n        stream.WriteByte(nsym);\n        // FIXME: add check for nsym > 16?\n        // Or just accept it as an inefficient waste of time.\n        for (var i = 0; i < 256; i++) {\n            if (M[i]) {\n                stream.WriteByte(i); // adjust to 0..N-1\n                M[i]--;\n            }\n        }\n        return [stream, M, nsym];\n    }\n    encodePack(data) {\n        var meta, M, nsym;\n        [meta, M, nsym] = this.packMeta(data);\n        var len = data.length;\n        var i = 0;\n        if (nsym <= 1) {\n            // Constant values\n            meta.WriteUint7(0);\n            return [meta, new Buffer.allocUnsafe(0), 0];\n        }\n        if (nsym <= 2) {\n            // 1 bit per value\n            var out = new Buffer.allocUnsafe(Math.floor((len + 7) / 8));\n            for (var i = 0, j = 0; i < (len & ~7); i += 8, j++)\n                out[j] =\n                    (M[data[i + 0]] << 0) +\n                        (M[data[i + 1]] << 1) +\n                        (M[data[i + 2]] << 2) +\n                        (M[data[i + 3]] << 3) +\n                        (M[data[i + 4]] << 4) +\n                        (M[data[i + 5]] << 5) +\n                        (M[data[i + 6]] << 6) +\n                        (M[data[i + 7]] << 7);\n            if (i < len) {\n                out[j] = 0;\n                var v = 0;\n                while (i < len) {\n                    out[j] |= M[data[i++]] << v;\n                    v++;\n                }\n                j++;\n            }\n            meta.WriteUint7(j);\n            return [meta, out, out.length];\n        }\n        if (nsym <= 4) {\n            // 2 bits per value\n            var out = new Buffer.allocUnsafe(Math.floor((len + 3) / 4));\n            for (var i = 0, j = 0; i < (len & ~3); i += 4, j++)\n                out[j] =\n                    (M[data[i + 0]] << 0) +\n                        (M[data[i + 1]] << 2) +\n                        (M[data[i + 2]] << 4) +\n                        (M[data[i + 3]] << 6);\n            if (i < len) {\n                out[j] = 0;\n                var v = 0;\n                while (i < len) {\n                    out[j] |= M[data[i++]] << v;\n                    v += 2;\n                }\n                j++;\n            }\n            meta.WriteUint7(j);\n            return [meta, out, out.length];\n        }\n        if (nsym <= 16) {\n            // 4 bits per value\n            var out = new Buffer.allocUnsafe(Math.floor((len + 1) / 2));\n            for (var i = 0, j = 0; i < (len & ~1); i += 2, j++)\n                out[j] = (M[data[i + 0]] << 0) + (M[data[i + 1]] << 4);\n            if (i < len)\n                out[j++] = M[data[i++]];\n            meta.WriteUint7(j);\n            return [meta, out, out.length];\n        }\n        // Otherwise an expensive NOP\n        meta.WriteUint7(data.length);\n        return [meta, data, data.length];\n    }\n    //----------------------------------------------------------------------\n    // STRIPE method\n    encodeStripe(hdr, src, N) {\n        if (N == 0)\n            N = 4; // old default\n        // Split into multiple streams\n        var part = new Array(N);\n        var ulen = new Array(N);\n        for (var s = 0; s < N; s++) {\n            ulen[s] = Math.floor(src.length / N) + (src.length % N > s);\n            part[s] = new Array(ulen[s]);\n        }\n        for (var x = 0, i = 0; i < src.length; i += N, x++) {\n            for (var j = 0; j < N; j++)\n                if (x < part[j].length)\n                    part[j][x] = src[i + j];\n        }\n        // Compress each part\n        var comp = new Array(N);\n        var total = 0;\n        for (var s = 0; s < N; s++) {\n            // Example: try O0 and O1 and choose best\n            var comp0 = this.encode(part[s], 0);\n            var comp1 = this.encode(part[s], 1);\n            comp[s] = comp1.length < comp0.length ? comp1 : comp0;\n            total += comp[s].length;\n        }\n        // Serialise\n        var out = new IOStream('', 0, total + 5 * N + 1);\n        out.WriteByte(N);\n        for (var s = 0; s < N; s++)\n            out.WriteUint7(comp[s].length);\n        for (var s = 0; s < N; s++)\n            out.WriteData(comp[s], comp[s].length);\n        return out.buf.slice(0, out.buf.pos);\n    }\n    decodeStripe(stream, len) {\n        var N = stream.ReadByte();\n        // Retrieve lengths\n        var clen = new Array(N);\n        var ulen = new Array(N);\n        for (var j = 0; j < N; j++)\n            clen[j] = stream.ReadUint7();\n        // Decode streams\n        var T = new Array(N);\n        for (var j = 0; j < N; j++) {\n            ulen[j] = Math.floor(len / N) + (len % N > j);\n            T[j] = this.decodeStream(stream, ulen[j]);\n        }\n        // Transpose\n        var out = new Buffer.allocUnsafe(len);\n        for (var j = 0; j < N; j++) {\n            for (var i = 0; i < ulen[j]; i++) {\n                out[i * N + j] = T[j][i];\n            }\n        }\n        return out;\n    }\n    //----------------------------------------------------------------------\n    // Cat method\n    decodeCat(stream, len) {\n        var out = new Buffer.allocUnsafe(len);\n        for (var i = 0; i < len; i++)\n            out[i] = stream.ReadByte();\n        return out;\n    }\n};\n//# sourceMappingURL=arith_gen.js.map","\"use strict\";\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// An arithmetic coder, based on Eugene Shelwien's reimplementation of\n// Michael Schindler range coder.\n//\n// Order-0 byte stream of ~/scratch/data/q40b\n// C:              3.1s decode  (approx same vs 32-bit and 64-bit)\n// Arith_sh.js     6.7s decode  (32-bit with carries)\n// Arith.js      317.0s decode  (64-bit no carries); int64 crippling it.\n//----------------------------------------------------------------------\n// Arithmetic (range) coder\nmodule.exports = class RangeCoder {\n    constructor(src) {\n        this.low = 0;\n        this.range = 0xffffffff;\n        this.code = 0;\n        this.FFnum = 0;\n        this.carry = 0;\n        this.cache = 0;\n    }\n    RangeStartDecode(src) {\n        for (var i = 0; i < 5; i++)\n            this.code = (this.code << 8) + src.ReadByte();\n        this.code &= 0xffffffff;\n        this.code >>>= 0; // force to be +ve int\n    }\n    RangeGetFrequency(tot_freq) {\n        this.range = Math.floor(this.range / tot_freq);\n        //return this.code / this.range;\n        return Math.floor(this.code / this.range);\n        // Conceptual scenario; return freq only and don't modify range yet\n        //return Math.floor(this.code / (Math.floor(this.range / tot_freq)));\n    }\n    RangeDecode(src, sym_low, sym_freq, tot_freq) {\n        // Conceptually we divide range here, but in practice we cached it earlier\n        //this.range = Math.floor(this.range / tot_freq);\n        this.code -= sym_low * this.range;\n        this.range *= sym_freq;\n        while (this.range < 1 << 24) {\n            this.range *= 256;\n            this.code = this.code * 256 + src.ReadByte();\n        }\n    }\n    RangeShiftLow(dst) {\n        // We know range is < (1<<24) as we got here.  We already have a\n        // cached copy of 8 bits from low.  Is this correct, or does it need\n        // fixing?  Possible scenarios.\n        // 1. Low < 0xff000000 thus low+range < 0xffffffff and cache\n        //    cannot possibly change.  Output cache and as many ffs as needed.\n        // 2. We already detected an overflow in RangeEncode, setting carry.\n        //    In this case output cached byte + 1 and any 00s needed.\n        // 3. Neither case - range is low but we haven't yet detected if we're\n        //    XXffffff or XY000000 scenario.  Increase counter for ff/00s.\n        if ((this.low < 0xff000000) | this.carry) {\n            // cached byte if no overflow, byte+1 otherwise\n            dst.WriteByte(this.cache + this.carry);\n            // Flush any tracked FFs (no carry) or 00s (carry).\n            while (this.FFnum) {\n                dst.WriteByte(this.carry - 1);\n                this.FFnum--;\n            }\n            // Take a copy of top byte ready for next flush\n            this.cache = this.low >>> 24;\n            this.carry = 0;\n        }\n        else {\n            this.FFnum++; // keep track of number of trailing ff/00 bytes to write\n        }\n        this.low <<= 8;\n        this.low >>>= 0; // force to be +ve int\n    }\n    RangeEncode(dst, sym_low, sym_freq, tot_freq) {\n        var old_low = this.low;\n        this.range = Math.floor(this.range / tot_freq);\n        this.low += sym_low * this.range;\n        this.low >>>= 0; // Truncate to +ve int so we can spot overflow\n        this.range *= sym_freq;\n        // \"low + sym*range < old_low\" means we overflow; set carry.\n        // NB: can this.low < old_low occur twice before range < (1<<24)?\n        // We claim not, but prove it!\n        if (this.low < old_low) {\n            if (this.carry != 0)\n                console.log('ERROR: Multiple carry');\n            this.carry = 1;\n        }\n        // Renormalise if range gets too small\n        while (this.range < 1 << 24) {\n            this.range *= 256;\n            this.RangeShiftLow(dst);\n        }\n    }\n    RangeFinishEncode(dst) {\n        for (var i = 0; i < 5; i++)\n            this.RangeShiftLow(dst);\n    }\n};\n//# sourceMappingURL=arith_sh.js.map","\"use strict\";\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// An adaptive probability model for encoding and decoding of symbols\n// within a given alphabet, using the range coder to get/put the\n// compressed data.\nconst MAX_FREQ = (1 << 16) - 17;\nconst STEP = 16;\nmodule.exports = class ByteModel {\n    constructor(max_sym = 256) {\n        this.total_freq = max_sym;\n        this.max_sym = max_sym - 1;\n        this.S = new Array();\n        this.F = new Array();\n        for (var i = 0; i <= this.max_sym; i++) {\n            this.S[i] = i;\n            this.F[i] = 1;\n        }\n    }\n    ModelDecode(src, rc) {\n        // Find symbol\n        var freq = rc.RangeGetFrequency(this.total_freq);\n        // Linear scan to find cumulative frequency 'freq'\n        var acc = 0;\n        var x = 0;\n        while (acc + this.F[x] <= freq)\n            acc += this.F[x++];\n        //\tfor (var acc = 0; (acc += this.F[x]) <= freq; x++)\n        //\t    ;\n        //\tacc -= this.F[x];\n        // Update range coder\n        rc.RangeDecode(src, acc, this.F[x], this.total_freq);\n        // Update model\n        this.F[x] += STEP;\n        this.total_freq += STEP;\n        if (this.total_freq > MAX_FREQ)\n            this.ModelRenormalise();\n        // Keep symbols approximately frequency sorted\n        var sym = this.S[x];\n        if (x > 0 && this.F[x] > this.F[x - 1]) {\n            var tmp = this.F[x];\n            this.F[x] = this.F[x - 1];\n            this.F[x - 1] = tmp;\n            tmp = this.S[x];\n            this.S[x] = this.S[x - 1];\n            this.S[x - 1] = tmp;\n        }\n        return sym;\n    }\n    ModelRenormalise() {\n        // Halve all the frequencies, being careful not to hit zero\n        this.total_freq = 0;\n        for (var i = 0; i <= this.max_sym; i++) {\n            this.F[i] -= Math.floor(this.F[i] / 2);\n            this.total_freq += this.F[i];\n        }\n    }\n    ModelEncode(dst, rc, sym) {\n        // Find cumulative frequency\n        var acc = 0;\n        for (var x = 0; this.S[x] != sym; x++)\n            acc += this.F[x];\n        // Encode\n        rc.RangeEncode(dst, acc, this.F[x], this.total_freq);\n        // Update model\n        this.F[x] += STEP;\n        this.total_freq += STEP;\n        if (this.total_freq > MAX_FREQ)\n            // FIXME x2\n            this.ModelRenormalise();\n        // Keep symbols approximately frequency sorted\n        var sym = this.S[x];\n        if (x > 0 && this.F[x] > this.F[x - 1]) {\n            var tmp = this.F[x];\n            this.F[x] = this.F[x - 1];\n            this.F[x - 1] = tmp;\n            tmp = this.S[x];\n            this.S[x] = this.S[x - 1];\n            this.S[x - 1] = tmp;\n        }\n    }\n};\n//# sourceMappingURL=byte_model.js.map","\"use strict\";\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nconst IOStream = require('./iostream');\nconst ByteModel = require('./byte_model');\nconst RangeCoder = require('./arith_sh');\n//----------------------------------------------------------------------\n// Main arithmetic entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nfunction read_array(src, tab, size) {\n    var j = 0; // array value\n    var z = 0; // array index: tab[j]\n    var last = -1;\n    // Remove first level of run-length encoding\n    var R = new Array(1024); // runs\n    while (z < size) {\n        var run = src.ReadByte();\n        R[j++] = run;\n        z += run;\n        if (run == last) {\n            var copy = src.ReadByte();\n            z += run * copy;\n            while (copy--)\n                R[j++] = run;\n        }\n        last = run;\n    }\n    // Now expand runs in R to tab, noting 255 is max run\n    var i = 0;\n    j = 0;\n    z = 0;\n    while (z < size) {\n        var run_len = 0;\n        do {\n            var part = R[j++];\n            run_len += part;\n        } while (part == 255);\n        while (run_len--)\n            tab[z++] = i;\n        i++;\n    }\n}\nconst QMAX = 256;\nconst FLAG_DEDUP = 2;\nconst FLAG_FLEN = 4;\nconst FLAG_SEL = 8; // whether selector is used in context\nconst FLAG_QMAP = 16;\nconst FLAG_PTAB = 32;\nconst FLAG_DTAB = 64;\nconst FLAG_QTAB = 128;\nconst GFLAG_MULTI_PARAM = 1;\nconst GFLAG_HAVE_STAB = 2;\nconst GFLAG_DO_REV = 4;\n// Compute a new context from our current state and qual q\nfunction fqz_update_ctx(params, state, q) {\n    var last = params.context;\n    state.qctx = (state.qctx << params.qshift) + params.qtab[q]; // >>> 0\n    last += (state.qctx & ((1 << params.qbits) - 1)) << params.qloc; // >>> 0\n    if (params.do_pos)\n        last += params.ptab[Math.min(state.p, 1023)] << params.ploc;\n    if (params.do_delta) {\n        last += params.dtab[Math.min(state.delta, 255)] << params.dloc;\n        // Is it better to use q here or qtab[q]?\n        // If qtab[q] we can map eg [a-z0-9A-Z]->0 ,->1 and have\n        // delta being a token number count into comma separated lists?\n        state.delta += state.prevq != q ? 1 : 0;\n        state.prevq = q;\n    }\n    if (params.do_sel)\n        last += state.s << params.sloc;\n    state.p--;\n    return last & 0xffff;\n}\nfunction decode_fqz_single_param(src) {\n    var p = {}; // params\n    // Load FQZ parameters\n    p.context = src.ReadUint16();\n    p.pflags = src.ReadByte();\n    p.do_dedup = p.pflags & FLAG_DEDUP;\n    p.fixed_len = p.pflags & FLAG_FLEN;\n    p.do_sel = p.pflags & FLAG_SEL;\n    p.do_qmap = p.pflags & FLAG_QMAP;\n    p.do_pos = p.pflags & FLAG_PTAB;\n    p.do_delta = p.pflags & FLAG_DTAB;\n    p.do_qtab = p.pflags & FLAG_QTAB;\n    p.max_sym = src.ReadByte();\n    var x = src.ReadByte();\n    p.qbits = x >> 4;\n    p.qshift = x & 15;\n    x = src.ReadByte();\n    p.qloc = x >> 4;\n    p.sloc = x & 15;\n    x = src.ReadByte();\n    p.ploc = x >> 4;\n    p.dloc = x & 15;\n    // Qual map, eg to \"unbin\" Illumina qualities\n    p.qmap = new Array(256);\n    if (p.pflags & FLAG_QMAP) {\n        for (var i = 0; i < p.max_sym; i++)\n            p.qmap[i] = src.ReadByte();\n    }\n    else {\n        // Useful optimisation to speed up main loop\n        for (var i = 0; i < 256; i++)\n            p.qmap[i] = i; // NOP\n    }\n    // Read tables\n    p.qtab = new Array(1024);\n    if (p.qbits > 0 && p.pflags & FLAG_QTAB) {\n        read_array(src, p.qtab, 256);\n    }\n    else {\n        // Useful optimisation to speed up main loop\n        for (var i = 0; i < 256; i++)\n            p.qtab[i] = i; // NOP\n    }\n    p.ptab = new Array(1024);\n    if (p.pflags & FLAG_PTAB)\n        read_array(src, p.ptab, 1024);\n    p.dtab = new Array(256);\n    if (p.pflags & FLAG_DTAB)\n        read_array(src, p.dtab, 256);\n    return p;\n}\nfunction decode_fqz_params(src) {\n    var gparams = {\n        max_sym: 0,\n    };\n    // Check fqz format version\n    var vers = src.ReadByte();\n    if (vers != 5) {\n        console.error('Invalid FQZComp version number');\n        return;\n    }\n    var gflags = src.ReadByte();\n    var nparam = gflags & GFLAG_MULTI_PARAM ? src.ReadByte() : 1;\n    var max_sel = gflags.nparam > 1 ? gflags.nparam - 1 : 0; // Note max_sel, not num_sel\n    var stab = new Array(256);\n    if (gflags & GFLAG_HAVE_STAB) {\n        max_sel = src.ReadByte();\n        read_array(src, stab, 256);\n    }\n    else {\n        for (var i = 0; i < nparam; i++)\n            stab[i] = i;\n        for (; i < 256; i++)\n            stab[i] = nparam - 1;\n    }\n    gparams.do_rev = gflags & GFLAG_DO_REV;\n    gparams.stab = stab;\n    gparams.max_sel = max_sel;\n    gparams.params = new Array(gparams.nparam);\n    for (var p = 0; p < nparam; p++) {\n        gparams.params[p] = decode_fqz_single_param(src);\n        if (gparams.max_sym < gparams.params[p].max_sym)\n            gparams.max_sym = gparams.params[p].max_sym;\n    }\n    return gparams;\n}\nfunction fqz_create_models(gparams) {\n    var model = {};\n    model.qual = new Array(1 << 16);\n    for (var i = 0; i < 1 << 16; i++)\n        model.qual[i] = new ByteModel(gparams.max_sym + 1); // +1 as max value not num. values\n    model.len = new Array(4);\n    for (var i = 0; i < 4; i++)\n        model.len[i] = new ByteModel(256);\n    model.rev = new ByteModel(2);\n    model.dup = new ByteModel(2);\n    if (gparams.max_sel > 0)\n        model.sel = new ByteModel(gparams.max_sel + 1); // +1 as max value not num. values\n    return model;\n}\n// Initialise a new record, updating state.\n// Returns 1 if dup, otherwise 0\nfunction decode_fqz_new_record(src, rc, gparams, model, state, rev) {\n    // Parameter selector\n    if (gparams.max_sel > 0) {\n        state.s = model.sel.ModelDecode(src, rc);\n    }\n    else {\n        state.s = 0;\n    }\n    state.x = gparams.stab[state.s];\n    var params = gparams.params[state.x];\n    // Reset contexts at the start of each new record\n    if (params.fixed_len >= 0) {\n        // Not fixed or fixed but first record\n        var len = model.len[0].ModelDecode(src, rc);\n        len |= model.len[1].ModelDecode(src, rc) << 8;\n        len |= model.len[2].ModelDecode(src, rc) << 16;\n        len |= model.len[3].ModelDecode(src, rc) << 24;\n        if (params.fixed_len > 0)\n            params.fixed_len = -len;\n    }\n    else {\n        len = -params.fixed_len;\n    }\n    state.len = len;\n    if (gparams.do_rev)\n        rev[state.rec] = model.rev.ModelDecode(src, rc);\n    state.is_dup = 0;\n    if (params.pflags & FLAG_DEDUP) {\n        if (model.dup.ModelDecode(src, rc))\n            state.is_dup = 1;\n    }\n    state.p = len; // number of remaining bytes in this record\n    state.delta = 0;\n    state.qctx = 0;\n    state.prevq = 0;\n    state.rec++;\n}\nfunction decode_fqz(src, q_lens) {\n    // Decode parameter block\n    var n_out = src.ReadUint7();\n    var gparams = decode_fqz_params(src);\n    if (!gparams)\n        return;\n    var params = gparams.params;\n    var rev = new Array(q_lens.length);\n    // Create initial models\n    var model = fqz_create_models(gparams);\n    // Create our entropy encoder and output buffers\n    var rc = new RangeCoder(src);\n    rc.RangeStartDecode(src);\n    var output = new Buffer.allocUnsafe(n_out);\n    // Internal FQZ state\n    var state = {\n        qctx: 0, // Qual-only sub-context\n        prevq: 0, // Previous quality value\n        delta: 0, // Running delta (q vs prevq)\n        p: 0, // Number of bases left in current record\n        s: 0, // Current parameter selector value (0 if unused)\n        x: 0, // \"stab\" tabulated copy of s\n        len: 0, // Length of current string\n        is_dup: 0, // This string is a duplicate of last\n        rec: 0, // Record number\n    };\n    // The main decode loop itself\n    var i = 0; // position in output buffer\n    while (i < n_out) {\n        if (state.p == 0) {\n            decode_fqz_new_record(src, rc, gparams, model, state, rev);\n            if (state.is_dup > 0) {\n                if (model.dup.ModelDecode(src, rc)) {\n                    // Duplicate of last line\n                    for (var x = 0; x < len; x++)\n                        output[i + x] = output[i + x - state.len];\n                    i += state.len;\n                    state.p = 0;\n                    continue;\n                }\n            }\n            q_lens.push(state.len);\n            var params = gparams.params[state.x];\n            var last = params.context;\n        }\n        // Decode the current quality (possibly mapped via qmap)\n        var Q = model.qual[last].ModelDecode(src, rc);\n        //if (params.do_qmap)\n        //    output[i++] = params.qmap[Q];\n        //else\n        //    output[i++] = Q\n        output[i++] = params.qmap[Q]; // optimised version of above\n        last = fqz_update_ctx(params, state, Q);\n    }\n    if (gparams.do_rev)\n        reverse_qualities(output, n_out, rev, q_lens);\n    return output;\n}\nfunction reverse_qualities(qual, qual_len, rev, len) {\n    var rec = 0;\n    var i = 0;\n    while (i < qual_len) {\n        if (rev[rec]) {\n            var j = 0;\n            var k = len[rec] - 1;\n            while (j < k) {\n                var tmp = qual[i + j];\n                qual[i + j] = qual[i + k];\n                qual[i + k] = tmp;\n                j++;\n                k--;\n            }\n        }\n        i += len[rec++];\n    }\n}\nfunction decode(src, q_lens) {\n    var stream = new IOStream(src);\n    //var n_out = stream.ReadUint32(); stream.ReadUint32(); // move to main\n    return decode_fqz(stream, q_lens);\n}\n//----------------------------------------------------------------------\n// FQZComp encoder.\nfunction pick_fqz_params(src, q_lens, q_dirs, qhist) {\n    // Find cardinality of q_dirs\n    var qd_last = q_dirs[0];\n    for (var i = 0; i < q_dirs.length; i++)\n        if (q_dirs[i] != qd_last)\n            break;\n    var qd_fixed = i == q_dirs.length ? 1 : 0;\n    // Scan input to find number of symbols and max symbol\n    var nsym = 0;\n    var max_sym = 0;\n    // selector == 0: Assume one single input dataset\n    for (var i = 0; i < 256; i++)\n        qhist[0][i] = 0;\n    var rec = 0;\n    var len = 0;\n    for (var i = 0; i < src.length; i++) {\n        if (len == 0) {\n            len = q_lens[rec < q_lens.length - 1 ? rec++ : rec];\n        }\n        qhist[0][src[i]]++;\n        len--;\n    }\n    for (var i = 0; i < 256; i++) {\n        if (!qhist[0][i])\n            continue;\n        if (max_sym < i)\n            max_sym = i;\n        nsym++;\n    }\n    var qshift = 5;\n    var do_qmap = 0;\n    // Reduced symbol frequencies implies lower qshift and\n    // a lookup table to go from qual to Q\n    if (nsym <= 16) {\n        do_qmap = 1; // based on qhist\n        if (nsym <= 2)\n            qshift = 1;\n        else if (nsym <= 4)\n            qshift = 2;\n        else if (nsym <= 8)\n            qshift = 3;\n        else\n            qshift = 4;\n    }\n    //    // Two params and a 1-bit selector.\n    //    // This is 1% overhead vs two data sets compressed independently.\n    //    // It's 6.9% smaller than compressing both together with 1 param.\n    //    if (0) return [{\n    //\t// q4\n    //\tqbits:     8,\n    //\tqshift:    2,\n    //\tqloc:      7,\n    //\n    //\tpbits:     7,\n    //\tpshift:    1,\n    //\tploc:      0,\n    //\n    //\tdbits:     0,\n    //\tdshift:    0,\n    //\tdloc:      0,\n    //\n    //      sbits:     0,\n    //      sloc:      0,\n    //\n    //\t//sbits:     2,\n    //\t//do_stab:   1,\n    //\tsbits:     1,\n    //\tdo_stab:   0,\n    //\tcontext:   (0<<15),\n    //\n    //\tmax_sym:   36,\n    //\tnsym:      4,\n    //\n    //\tdo_qmap:   1,\n    //\tdo_dedup:  0,\n    //\tfixed_len: 1,\n    //\tdo_sel:  0,\n    //\tdo_rev:    0,\n    //\tdo_pos:    1,\n    //\tdo_delta:  0,\n    //\tdo_qtab:   0\n    //    }, {\n    //\t//q40\n    //\tqbits:     9,\n    //\tqshift:    5,\n    //\tqloc:      7,\n    //\n    //\tpbits:     7,\n    //\tpshift:    0,\n    //\tploc:      0,\n    //\n    //\tdbits:     0,\n    //\tdshift:    0,\n    //\tdloc:      0,\n    //\n    //      sbits:     0,\n    //      sloc:      0,\n    //\n    //\t//sbits:     2,\n    //\t//do_stab:   1,\n    //\tsbits:     1,\n    //\tdo_stab:   0,\n    //\tcontext:   (1<<15),\n    //\n    //\tmax_sym:   44,\n    //\tnsym:      45,\n    //\n    //\tdo_qmap:   0,\n    //\tdo_dedup:  0,\n    //\tfixed_len: 1,\n    //\tdo_sel:  0,\n    //\tdo_rev:    0,\n    //\tdo_pos:    1,\n    //\tdo_delta:  0,\n    //\tdo_qtab:   0\n    //    }]\n    return [\n        {\n            qbits: 8 + (qshift > 4),\n            qshift: qshift,\n            qloc: 7,\n            pbits: 7,\n            pshift: q_lens[0] > 128 ? 1 : 0,\n            ploc: 0,\n            dbits: qshift > 4 ? 0 : 1,\n            dshift: 3,\n            dloc: 15,\n            // NB: Also useful as a way of embedding sel and doing sel\n            // specific contexts. Identical bar context. Eg 0<<15 or 1<<15.\n            sbits: 0,\n            sloc: 15,\n            do_stab: 0,\n            context: 0 << 15,\n            max_sym: max_sym,\n            nsym: nsym,\n            do_qmap: do_qmap,\n            do_dedup: 0,\n            fixed_len: q_lens.length == 1 ? 1 : 0,\n            do_sel: 0,\n            do_rev: 0,\n            do_pos: 1,\n            do_delta: qshift <= 4 ? 1 : 0,\n            do_qtab: 0,\n            // Override above with some attempt at using selectors\n            // when the q_dirs are specific and non-fixed.\n            qbits: 8 + (qshift > 4) - (qd_fixed == 0),\n            sbits: 1,\n            sloc: 15 - (qshift <= 4), // read1 vs read2\n            do_stab: 1,\n            do_sel: 1,\n            //\t     // q4+dir: 7245769 with, 7353962 without. 1.5% saving\n            //\t     qbits:     6,\n            //\t     dbits:     2,\n            //\t     dshift:    2,\n            //\t     dloc:      13,\n            //\t     sbits:     1,\n            //\t     sloc:      15,\n            //\t     do_stab:   1,\n            //\t     do_sel:    1,\n            // with 20 bits of context, q40 = 31741545\n            // qbits 10, dbits 2, pbits 7, sbits 1\n        },\n    ];\n}\nfunction store_array(out, tab, size) {\n    var i = 0; // index into tab\n    var j = 0; // current value in tab[i]\n    var tmp1 = new Array(size * 2);\n    var sz1 = 0;\n    // First level of RLE.  Replace all runs of 'j' values\n    // with run-lengths, including zeros for missing values.\n    // Eg 0 1 2 2 2 3 3 3 4 4 4 5 5 5 5   7 7\n    // to 1 1 3     3     3     4       0 2\n    while (i < size) {\n        // Length of j^{th} element\n        var i_start = i;\n        while (i < size && tab[i] == j)\n            i++;\n        var run_len = i - i_start;\n        // Encode run length to tmp array\n        do {\n            var r = Math.min(255, run_len);\n            tmp1[sz1++] = r;\n            run_len -= r;\n        } while (r == 255);\n        j++;\n    }\n    // Second round of RLE on our tmp array, using a different\n    // RLE algorithm.\n    // Eg 1 1    3 3  3 4 0 2\n    // to 1 1 +0 3 3 +1 4 0 2\n    var last = -1;\n    var tmp2 = new Array(size * 2);\n    var sz2 = 0;\n    i = 0; // index into tmp1]\n    // k is used size of tmp1[]\n    while (i < sz1) {\n        var curr = tmp1[i++];\n        tmp2[sz2++] = curr;\n        if (curr == last) {\n            var i_start = i;\n            while (i < sz1 && tmp1[i] == last && i - i_start < 255)\n                i++;\n            tmp2[sz2++] = i - i_start;\n        }\n        else {\n            last = curr;\n        }\n    }\n    // Append 2nd RLE, tmp2, to out.\n    out.WriteData(tmp2, sz2);\n}\n// q_lens is an array of quality lengths per record.\n// (If they're all the same, just set one value.)\nfunction encode_fqz_params(out, params, qhist, qtab, ptab, dtab, stab) {\n    var dsqr = [\n        0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n    ];\n    for (var i = 0; i < params.length; i++)\n        stab[i] = i; // 1 parameter set per selector value\n    for (; i < 256; i++)\n        stab[i] = params.length - 1;\n    // Store global meta-data\n    out.WriteByte(5); // FQZ format number\n    var gflags = (params.length > 1 ? GFLAG_MULTI_PARAM : 0) |\n        (params[0].do_stab ? GFLAG_HAVE_STAB : 0);\n    out.WriteByte(gflags);\n    if (gflags & GFLAG_MULTI_PARAM)\n        out.WriteByte(params.length); // Number of parameter blocks.\n    if (gflags & GFLAG_HAVE_STAB) {\n        var max_sel = 1 << params[0].sbits;\n        if (max_sel > 0)\n            max_sel--;\n        out.WriteByte(max_sel);\n        store_array(out, stab, 256);\n    }\n    // Store per-param meta-data\n    for (var p = 0; p < params.length; p++) {\n        out.WriteUint16(params[p].context);\n        out.WriteByte((params[p].do_qtab ? FLAG_QTAB : 0) | // FLAG\n            (params[p].do_delta ? FLAG_DTAB : 0) |\n            (params[p].do_pos ? FLAG_PTAB : 0) |\n            (params[p].do_qmap ? FLAG_QMAP : 0) |\n            (params[p].do_sel ? FLAG_SEL : 0) |\n            (params[p].fixed_len ? FLAG_FLEN : 0) |\n            (params[p].do_dedup ? FLAG_DEDUP : 0));\n        if (params[p].do_qmap)\n            out.WriteByte(params[p].nsym);\n        else\n            out.WriteByte(params[p].max_sym);\n        out.WriteByte((params[p].qbits << 4) | params[p].qshift);\n        out.WriteByte((params[p].qloc << 4) | params[p].sloc);\n        out.WriteByte((params[p].ploc << 4) | params[p].dloc);\n        if (params[p].do_qmap) {\n            params[p].max_sym = params[p].nsym;\n            var n = 0;\n            for (var i = 0; i < 256; i++) {\n                if (qhist[p][i]) {\n                    out.WriteByte(i);\n                    qhist[p][i] = n++;\n                }\n            }\n            // Ensure we have all matched input params\n            for (; n < params[p].nsym; n++)\n                out.WriteByte(0);\n        }\n        else {\n            //params[p].nsym = 255;\n            for (var i = 0; i < 256; i++)\n                qhist[p][i] = i; // NOP\n        }\n        if (params[p].qbits > 0) {\n            //\t// Eg map 0-44 to a smaller range, to improve context usage.\n            //\t// Makes q40 test set go from 33596471 to 33450075 (-0.4%)\n            //\tparams[p].do_qtab = 1;\n            //\tfor (var j = i = 0; i < params[p].max_sym; i++) {\n            //\t    qtab[i]=j;\n            //\t    if ((i%3)!=0 | i >= 28) j++\n            //\t    console.log(\"qtab[\",i,\"]=\",qtab[i]);\n            //\t}\n            //\tfor (; i < 256; i++)\n            //\t    qtab[i] = qtab[params[p].max_sym-1]\n            for (var i = 0; i < 256; i++)\n                qtab[p][i] = i; // NOP for now\n            if (params[p].do_qtab)\n                store_array(out, qtab[p], 256);\n        }\n        if (params[p].pbits > 0) {\n            for (var i = 0; i < 1024; i++)\n                ptab[p][i] = Math.min((1 << params[p].pbits) - 1, i >> params[p].pshift);\n            store_array(out, ptab[p], 1024);\n        }\n        if (params[p].dbits > 0) {\n            for (var i = 0; i < 256; i++)\n                if (dsqr[i] > (1 << params[p].dbits) - 1)\n                    dsqr[i] = (1 << params[p].dbits) - 1;\n            for (var i = 0; i < 256; i++)\n                dtab[p][i] = dsqr[Math.min(dsqr.length - 1, i >> params[p].dshift)];\n            store_array(out, dtab[p], 256);\n        }\n    }\n    return out;\n}\nfunction encode_fqz(out, src, q_lens, q_dirs, params, qhist, qtab, ptab, dtab, stab) {\n    //console.error(\"0:\",params[0])\n    //console.error(\"1:\",params[1])\n    var max_sel = 1 << params[0].sbits;\n    if (max_sel > 0)\n        max_sel--;\n    var n_in = src.length;\n    // Create the models\n    var max_sym = 0;\n    for (var p = 0; p < params.length; p++)\n        if (max_sym < params[p].max_sym)\n            max_sym = params[p].max_sym;\n    var model_qual = new Array(1 << 16);\n    for (var i = 0; i < 1 << 16; i++)\n        model_qual[i] = new ByteModel(max_sym + 1);\n    var model_len = new Array(4);\n    for (var i = 0; i < 4; i++)\n        model_len[i] = new ByteModel(256);\n    var model_rev = new ByteModel(2);\n    var model_dup = new ByteModel(2);\n    var model_sel = new ByteModel(max_sel + 1);\n    // Note: our JavaScript encoder doesn't have a way for reversing\n    // some quality strings, so we ignore do_rev for now.\n    var rc = new RangeCoder(src);\n    // The main encoding loop\n    var p = 0; // remaining position along current record\n    var i = 0; // index in src data\n    var rec = 0;\n    while (i < n_in) {\n        if (p == 0) {\n            //var s = 0 // single non-mixed sample\n            var s = q_dirs[rec];\n            if (params[0].sbits > 0) {\n                // FIXME: check All params[].do_stab / sbits must be identical\n                //console.log(\"Ssel\", s)\n                model_sel.ModelEncode(out, rc, s);\n            }\n            var x = stab[s];\n            // Reset contexts at the statr of each new record\n            var len = q_lens[Math.min(q_lens.length - 1, rec++)];\n            if (params[x].fixed_len) {\n                if (params[x].fixed_len > 0) {\n                    // First length\n                    //console.log(\"Len\", len)\n                    model_len[0].ModelEncode(out, rc, len & 0xff);\n                    model_len[1].ModelEncode(out, rc, (len >> 8) & 0xff);\n                    model_len[2].ModelEncode(out, rc, (len >> 16) & 0xff);\n                    model_len[3].ModelEncode(out, rc, (len >> 24) & 0xff);\n                    params[x].fixed_len = -1; // indicate we've stored it once\n                }\n            }\n            else {\n                //console.log(\"len\", len)\n                model_len[0].ModelEncode(out, rc, len & 0xff);\n                model_len[1].ModelEncode(out, rc, (len >> 8) & 0xff);\n                model_len[2].ModelEncode(out, rc, (len >> 16) & 0xff);\n                model_len[3].ModelEncode(out, rc, (len >> 24) & 0xff);\n            }\n            if (params[x].do_dedup)\n                process.exit(1); // FIXME\n            p = len;\n            var delta = 0;\n            //var last  = 0\n            var last = params[x].context;\n            var qlast = 0;\n            var q1 = 0;\n        }\n        // Encode current quality\n        var q = src[i++];\n        var Q = qhist[x][q];\n        model_qual[last].ModelEncode(out, rc, Q);\n        //console.log(\"Ctx\",last,qhist[x][q])\n        // Update contexts for next quality\n        qlast = (qlast << params[x].qshift) + qtab[x][Q];\n        last = params[x].context;\n        last += (qlast & ((1 << params[x].qbits) - 1)) << params[x].qloc;\n        // 46.6-48.6 billion cycles with ifs + \"<< params[x].?loc\" shifts\n        // 47.3-47.3 billion cycles with ifs\n        // 47.1-47.9 billion cycles without ifs\n        if (params[x].pbits > 0)\n            last += ptab[x][Math.min(p, 1023)] << params[x].ploc;\n        if (params[x].dbits > 0) {\n            last += dtab[x][Math.min(delta, 255)] << params[x].dloc;\n            delta += q1 != Q ? 1 : 0;\n            q1 = Q;\n        }\n        if (params[x].do_sel)\n            last += s << params[x].sloc;\n        last = last & 0xffff;\n        p--;\n    }\n    rc.RangeFinishEncode(out);\n    return out.buf.slice(0, out.pos);\n}\nfunction encode(src, q_lens, q_dirs) {\n    var qhist = new Array(2);\n    var qtab = new Array(2);\n    var ptab = new Array(2);\n    var dtab = new Array(2);\n    var stab = new Array(256);\n    for (var s = 0; s < 2; s++) {\n        qhist[s] = new Array(256);\n        qtab[s] = new Array(256);\n        ptab[s] = new Array(1024);\n        dtab[s] = new Array(256);\n    }\n    var out = new IOStream('', 0, src.length * 1.1 + 100); // FIXME: guestimate worst case\n    out.WriteUint7(src.length);\n    var params = pick_fqz_params(src, q_lens, q_dirs, qhist);\n    var out = encode_fqz_params(out, params, qhist, qtab, ptab, dtab, stab);\n    return encode_fqz(out, src, q_lens, q_dirs, params, qhist, qtab, ptab, dtab, stab);\n}\nmodule.exports = { decode, encode };\n//# sourceMappingURL=fqzcomp.js.map","/*\n * Copyright (c) 2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// This is an interface to the htscodecs reference implementation of\n// the CRAM 3.1 codecs.\n// This JavaScript file is not part of the reference implementation\n// and is simply and interface to get a consistent interface for cram-js.\n'use strict';\nvar r4x8 = require('./rans');\nvar r4x16 = require('./rans4x16');\nvar arith = require('./arith_gen');\nvar fqzcomp = require('./fqzcomp');\nvar tok3 = require('./tok3');\nfunction r4x8_uncompress(inputBuffer, outputBuffer) {\n    r4x8.decode(inputBuffer).copy(outputBuffer, 0, 0);\n}\nfunction r4x16_uncompress(inputBuffer, outputBuffer) {\n    r4x16.decode(inputBuffer).copy(outputBuffer, 0, 0);\n}\nfunction arith_uncompress(inputBuffer, outputBuffer) {\n    // fix by @cmdcolin for CRAM 3.1\n    // xref https://github.com/jkbonfield/htscodecs/pull/1/files\n    return new arith().decode(inputBuffer).copy(outputBuffer, 0, 0);\n}\nfunction fqzcomp_uncompress(inputBuffer, outputBuffer) {\n    var q_lens = new Array();\n    fqzcomp.decode(inputBuffer, q_lens).copy(outputBuffer, 0, 0);\n}\nfunction tok3_uncompress(inputBuffer, outputBuffer) {\n    // Returns in string form instead of buffer\n    var out = tok3.decode(inputBuffer, 0, '\\0');\n    Buffer.from(out, 'binary').copy(outputBuffer, 0, 0);\n}\nmodule.exports = {\n    r4x8_uncompress: r4x8_uncompress,\n    r4x16_uncompress: r4x16_uncompress,\n    arith_uncompress: arith_uncompress,\n    fqzcomp_uncompress: fqzcomp_uncompress,\n    tok3_uncompress: tok3_uncompress,\n};\n//# sourceMappingURL=index.js.map","\"use strict\";\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// Turn a buffer into a fake stream with get / put commands.\n// This enables up to closely match the published pseudocode.\nmodule.exports = class IOStream {\n    constructor(buf, start_pos = 0, size = 0) {\n        if (size != 0) {\n            this.buf = Buffer.allocUnsafe(size);\n            this.length = size;\n        }\n        else {\n            this.buf = buf;\n            this.length = buf.length;\n        }\n        this.pos = start_pos;\n    }\n    // ----------\n    // Reading\n    EOF() {\n        return this.pos >= this.length;\n    }\n    ReadData(len) {\n        var A = this.buf.slice(this.pos, this.pos + len);\n        this.pos += len;\n        return A;\n    }\n    ReadByte() {\n        const b = this.buf[this.pos];\n        this.pos++;\n        return b;\n    }\n    ReadChar() {\n        const b = this.buf[this.pos];\n        this.pos++;\n        return String.fromCharCode(b);\n    }\n    ReadUint16() {\n        var i = this.ReadByte();\n        i |= this.ReadByte() << 8;\n        return i;\n    }\n    ReadUint32() {\n        const i = this.buf.readInt32LE(this.pos);\n        this.pos += 4;\n        return i;\n    }\n    // nul terminated string\n    ReadString() {\n        var s = '';\n        do {\n            var b = this.buf[this.pos++];\n            if (b)\n                s += String.fromCharCode(b);\n        } while (b);\n        return s;\n    }\n    //    ReadUint7() {\n    //\t// Variable sized unsigned integers\n    //\tvar i = 0;\n    //\tvar s = 0;\n    //\tdo {\n    //\t    var c = this.ReadByte();\n    //\t    i = i | ((c & 0x7f)<<s);\n    //\t    s += 7;\n    //\t} while ((c & 0x80))\n    //\n    //\treturn i;\n    //    }\n    ReadUint7() {\n        // Variable sized unsigned integers\n        var i = 0;\n        do {\n            var c = this.ReadByte();\n            i = (i << 7) | (c & 0x7f);\n        } while (c & 0x80);\n        return i;\n    }\n    ReadITF8() {\n        var i = this.buf[this.pos];\n        this.pos++;\n        //process.stderr.write(\"i=\"+i+\"\\n\");\n        if (i >= 0xf0) {\n            // 1111xxxx => +4 bytes\n            i = (i & 0x0f) << 28;\n            i +=\n                (this.buf[this.pos + 0] << 20) +\n                    (this.buf[this.pos + 1] << 12) +\n                    (this.buf[this.pos + 2] << 4) +\n                    (this.buf[this.pos + 3] >> 4);\n            this.pos += 4;\n            //process.stderr.write(\"  4i=\"+i+\"\\n\");\n        }\n        else if (i >= 0xe0) {\n            // 1110xxxx => +3 bytes\n            i = (i & 0x0f) << 24;\n            i +=\n                (this.buf[this.pos + 0] << 16) +\n                    (this.buf[this.pos + 1] << 8) +\n                    (this.buf[this.pos + 2] << 0);\n            this.pos += 3;\n            //process.stderr.write(\"  3i=\"+i+\"\\n\");\n        }\n        else if (i >= 0xc0) {\n            // 110xxxxx => +2 bytes\n            i = (i & 0x1f) << 16;\n            i += (this.buf[this.pos + 0] << 8) + (this.buf[this.pos + 1] << 0);\n            this.pos += 2;\n            //process.stderr.write(\"  2i=\"+i+\"\\n\");\n        }\n        else if (i >= 0x80) {\n            // 10xxxxxx => +1 bytes\n            i = (i & 0x3f) << 8;\n            i += this.buf[this.pos];\n            this.pos++;\n            //process.stderr.write(\"  1i=\"+i+\"\\n\");\n        }\n        else {\n            // 0xxxxxxx => +0 bytes\n        }\n        return i;\n    }\n    // ----------\n    // Writing\n    WriteByte(b) {\n        this.buf[this.pos++] = b;\n    }\n    WriteChar(b) {\n        this.buf[this.pos++] = b.charCodeAt(0);\n    }\n    WriteString(str) {\n        for (var i = 0; i < str.length; i++)\n            this.buf[this.pos++] = str.charCodeAt(i);\n        this.buf[this.pos++] = 0;\n    }\n    WriteData(buf, len) {\n        for (var i = 0; i < len; i++)\n            this.buf[this.pos++] = buf[i];\n    }\n    WriteStream(stream) {\n        this.WriteData(stream.buf, stream.pos);\n    }\n    WriteUint16(u) {\n        //this.buf.writeInt16LE(u, this.pos);\n        this.WriteByte(u & 0xff);\n        this.WriteByte((u >> 8) & 0xff);\n    }\n    WriteUint32(u) {\n        this.buf.writeInt32LE(u, this.pos);\n        this.pos += 4;\n    }\n    //    WriteUint7(i) {\n    //\tdo {\n    //\t    this.WriteByte((i & 0x7f) | ((i > 0x80) << 7));\n    //\t    i >>= 7;\n    //\t} while (i > 0);\n    //    }\n    WriteUint7(i) {\n        var s = 0;\n        var X = i;\n        do {\n            s += 7;\n            X >>= 7;\n        } while (X > 0);\n        do {\n            s -= 7;\n            this.WriteByte(((i >> s) & 0x7f) + ((s > 0) << 7));\n        } while (s > 0);\n    }\n    WriteITF8(i) {\n        // Horrid, ITF8 is unsigned, but we still write signed into it\n        if (i < 0)\n            i = (1 << 32) + i;\n        if (i <= 0x0000007f) {\n            // 1 byte\n            this.buf[this.pos++] = i;\n        }\n        else if (i <= 0x00003fff) {\n            // 2 bytes\n            this.buf[this.pos++] = 0x80 | Math.floor(i / 256);\n            this.buf[this.pos++] = i & 0xff;\n        }\n        else if (i < 0x0001ffff) {\n            // 3 bytes\n            this.buf[this.pos++] = 0xc0 | Math.floor(i / 65536);\n            this.buf[this.pos++] = Math.floor(i / 256) & 0xff;\n            this.buf[this.pos++] = i & 0xff;\n        }\n        else if (i < 0x0fffffff) {\n            // 4 bytes\n            this.buf[this.pos++] = 0xe0 | Math.floor(i / 16777216);\n            this.buf[this.pos++] = Math.floor(i / 65536) & 0xff;\n            this.buf[this.pos++] = Math.floor(i / 256) & 0xff;\n            this.buf[this.pos++] = i & 0xff;\n        }\n        else {\n            // 5 bytes; oddly using 4.5 bytes\n            this.buf[this.pos++] = 0xf0 | Math.floor(i / 268435456);\n            this.buf[this.pos++] = Math.floor(i / 1048576) & 0xff;\n            this.buf[this.pos++] = Math.floor(i / 4096) & 0xff;\n            this.buf[this.pos++] = Math.floor(i / 4) & 0xff;\n            this.buf[this.pos++] = i & 0x0f;\n        }\n    }\n    // ----------\n    // Writing from end of buffer going backwards.\n    // Needed by rANS codec.\n    WriteByteNeg(b) {\n        this.buf[--this.pos] = b;\n    }\n};\n//# sourceMappingURL=iostream.js.map","\"use strict\";\n/*\n * Copyright (c) 2019-2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nconst IOStream = require('./iostream');\n//----------------------------------------------------------------------\n// rANS primitives itself\n//\n// RansGet* is decoder side\nfunction RansGetCumulativeFreq(R) {\n    return R & 0xfff;\n}\nfunction RansGetSymbolFromFreq(C, f) {\n    // NOTE: Inefficient.\n    // In practice we would implement this via a precomputed\n    // lookup table C2S[f]; see RansBuildC2S below.\n    var s = 0;\n    while (f >= C[s + 1])\n        s++;\n    return s;\n}\nfunction RansBuildC2S(C) {\n    var C2S = new Array(0x1000);\n    var s = 0;\n    for (var f = 0; f < 0x1000; f++) {\n        while (f >= C[s + 1])\n            s++;\n        C2S[f] = s;\n    }\n    return C2S;\n}\nfunction RansAdvanceStep(R, c, f) {\n    return f * (R >> 12) + (R & 0xfff) - c;\n}\nfunction RansRenorm(src, R) {\n    while (R < 1 << 23)\n        R = (R << 8) + src.ReadByte();\n    return R;\n}\n// RanEnc* is for encoder\nfunction RansEncInit() {\n    return 1 << 23;\n}\nfunction RansEncFlush(R, dst) {\n    dst.WriteByteNeg((R >> 24) & 0xff);\n    dst.WriteByteNeg((R >> 16) & 0xff);\n    dst.WriteByteNeg((R >> 8) & 0xff);\n    dst.WriteByteNeg((R >> 0) & 0xff);\n}\nfunction RansEncRenorm(R, dst, freq, scale_bits) {\n    var R_max = (((1 << 23) >> scale_bits) << 8) * freq;\n    while (R >= R_max) {\n        dst.WriteByteNeg(R & 0xff);\n        R >>= 8;\n    }\n    return R;\n}\n// Puts a symbol with frequency freq, cumulative freq start\n// and total freq 1<<scale_bits.\n//\n// Note with static probabilities, /freq and %freq could be\n// precomputed via multiplies and shifts.\nfunction RansEncPut(R, dst, start, freq, scale_bits) {\n    var scale = 1 << scale_bits;\n    R = RansEncRenorm(R, dst, freq, scale_bits);\n    R = (Math.floor(R / freq) << scale_bits) + (R % freq) + start;\n    return R;\n}\n//----------------------------------------------------------------------\n// Main rANS entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nfunction decode(src) {\n    var stream = new IOStream(src);\n    var order = stream.ReadByte();\n    var n_in = stream.ReadUint32();\n    var n_out = stream.ReadUint32();\n    if (order == 0) {\n        return RansDecode0(stream, n_out);\n    }\n    else {\n        return RansDecode1(stream, n_out);\n    }\n}\nfunction encode(src, order) {\n    //var stream = new IOStream(src);\n    //var n_in  = stream.ReadUint32();\n    //var n_out = stream.ReadUint32();\n    if (order == 0) {\n        return RansEncode0(src);\n    }\n    else {\n        return RansEncode1(src);\n    }\n}\n//----------------------------------------------------------------------\n// Order-0 decoder\n// Decode a single table of order-0 frequences,\n// filling out the F and C arrays.\nfunction ReadFrequencies0(src, F, C) {\n    // Initialise; not in the specification - implicit?\n    for (var i = 0; i < 256; i++)\n        F[i] = 0;\n    var sym = src.ReadByte();\n    var last_sym = sym;\n    var rle = 0;\n    // Read F[]\n    do {\n        var f = src.ReadITF8();\n        F[sym] = f;\n        if (rle > 0) {\n            rle--;\n            sym++;\n        }\n        else {\n            sym = src.ReadByte();\n            if (sym == last_sym + 1)\n                rle = src.ReadByte();\n        }\n        last_sym = sym;\n    } while (sym != 0);\n    // Compute C[] from F[]\n    C[0] = 0;\n    for (var i = 0; i <= 255; i++)\n        C[i + 1] = C[i] + F[i];\n}\nfunction RansDecode0(src, nbytes) {\n    // Decode frequencies\n    var F = new Array(256);\n    var C = new Array(256);\n    ReadFrequencies0(src, F, C);\n    // Fast lookup to avoid slow RansGetSymbolFromFreq\n    var C2S = RansBuildC2S(C);\n    // Initialise rANS state\n    var R = new Array(4);\n    for (var i = 0; i < 4; i++)\n        R[i] = src.ReadUint32();\n    // Main decode loop\n    var output = new Buffer.allocUnsafe(nbytes);\n    for (var i = 0; i < nbytes; i++) {\n        var i4 = i % 4;\n        var f = RansGetCumulativeFreq(R[i4]);\n        var s = C2S[f]; // Equiv to RansGetSymbolFromFreq(C, f);\n        output[i] = s;\n        R[i4] = RansAdvanceStep(R[i4], C[s], F[s]);\n        R[i4] = RansRenorm(src, R[i4]);\n    }\n    return output;\n}\n//----------------------------------------------------------------------\n// Order-0 encoder\nfunction BuildFrequencies0(src, F) {\n    for (var i = 0; i < 256; i++)\n        F[i] = 0;\n    for (var i = 0; i < src.length; i++)\n        F[src[i]]++;\n}\nfunction NormaliseFrequencies0(F) {\n    // Compute total\n    var tot = 0;\n    for (var i = 0; i < 256; i++)\n        tot += F[i];\n    // Scale total of frequencies to max\n    const max = 1 << 12;\n    var scale = max / tot;\n    do {\n        var max_val = 0;\n        var max_idx = 0;\n        var renorm = 0;\n        tot = 0;\n        for (var i = 0; i < 256; i++) {\n            if (F[i] == 0)\n                continue;\n            if (max_val < F[i]) {\n                max_val = F[i];\n                max_idx = i;\n            }\n            F[i] = Math.floor(F[i] * scale);\n            if (F[i] == 0)\n                F[i] = 1;\n            tot += F[i];\n        }\n        // Adjust new tot to ensure it matches.\n        if (tot < max) {\n            // Too low, boost the most common symbol\n            F[max_idx] += max - tot;\n        }\n        else if (tot - max < F[max_idx] / 2 && F[max_idx] > 2) {\n            // Too high, reduce the common symbol\n            F[max_idx] -= tot - max;\n        }\n        else if (tot != max) {\n            // Much too high, fudge scale and try again.\n            scale = scale * 0.99;\n            renorm = 1;\n        }\n    } while (renorm);\n}\nfunction WriteFrequencies0(out, F) {\n    var rle = 0;\n    for (var i = 0; i < 256; i++) {\n        if (!F[i])\n            continue;\n        // Output Symbol if needed and Frequency\n        if (rle > 0)\n            rle--;\n        else {\n            out.WriteByte(i);\n            if (i > 0 && F[i - 1] > 0) {\n                // We've encoded two symbol frequencies in a row.\n                // How many more are there?  Store that count so\n                // we can avoid writing consecutive symbols.\n                for (rle = i + 1; rle < 256 && F[rle]; rle++)\n                    ;\n                rle -= i + 1;\n                out.WriteByte(rle);\n            }\n        }\n        out.WriteITF8(F[i]);\n    }\n    out.WriteByte(0);\n}\nfunction RansEncode0(src) {\n    const nbytes = src.length;\n    var output = new IOStream('', 0, 257 * 3 + 9);\n    output.WriteByte(0); // Order 0\n    output.WriteUint32(0); // compressed size: correct later\n    output.WriteUint32(0); // uncompressed size: correct later\n    // Compute frequencies\n    var F = new Array(256);\n    BuildFrequencies0(src, F);\n    NormaliseFrequencies0(F);\n    WriteFrequencies0(output, F);\n    // Compute cumulative frequencies\n    var C = new Array(256);\n    C[0] = 0;\n    for (var i = 1; i < 256; i++)\n        C[i] = C[i - 1] + F[i - 1];\n    // Initialise rANS state\n    var R = new Array(4);\n    for (var i = 0; i < 4; i++)\n        R[i] = RansEncInit();\n    var alloc = Math.floor(nbytes * 1.05 + 100);\n    var rans_out = new IOStream('', alloc, alloc);\n    // Main encode loop\n    for (var i = nbytes - 1; i >= 0; i--)\n        R[i % 4] = RansEncPut(R[i % 4], rans_out, C[src[i]], F[src[i]], 12);\n    for (var i = 3; i >= 0; i--)\n        RansEncFlush(R[i], rans_out);\n    // Stitch blocks together into final output buffer\n    var freq_tab = output.pos;\n    output.buf.writeInt32LE(freq_tab - 9 + (rans_out.length - rans_out.pos), 1);\n    output.buf.writeInt32LE(nbytes, 5);\n    return Buffer.concat([\n        output.buf.slice(0, output.pos),\n        rans_out.buf.slice(rans_out.pos, rans_out.length),\n    ], output.pos + rans_out.length - rans_out.pos);\n}\n//----------------------------------------------------------------------\n// Order-1 decoder\n// Decode a table of order-1 frequences,\n// filling out the F and C arrays.\nfunction ReadFrequencies1(src, F, C) {\n    // Initialise; not in the specification - implicit?\n    for (var i = 0; i < 256; i++) {\n        F[i] = new Array(256);\n        C[i] = new Array(256);\n        for (var j = 0; j < 256; j++)\n            F[i][j] = 0;\n    }\n    var sym = src.ReadByte();\n    var last_sym = sym;\n    var rle = 0;\n    // Read F[]\n    do {\n        ReadFrequencies0(src, F[sym], C[sym]);\n        if (rle > 0) {\n            rle--;\n            sym++;\n        }\n        else {\n            sym = src.ReadByte();\n            if (sym == last_sym + 1)\n                rle = src.ReadByte();\n        }\n        last_sym = sym;\n    } while (sym != 0);\n}\nfunction RansDecode1(src, nbytes) {\n    // Decode frequencies\n    var F = new Array(256);\n    var C = new Array(256);\n    ReadFrequencies1(src, F, C);\n    // Fast lookup to avoid slow RansGetSymbolFromFreq\n    var C2S = new Array(256);\n    for (var i = 0; i < 256; i++)\n        C2S[i] = RansBuildC2S(C[i]);\n    // Initialise rANS state\n    var R = new Array(4);\n    var L = new Array(4);\n    for (var j = 0; j < 4; j++) {\n        R[j] = src.ReadUint32();\n        L[j] = 0;\n    }\n    // Main decode loop\n    var output = new Buffer.allocUnsafe(nbytes);\n    var nbytes4 = Math.floor(nbytes / 4);\n    for (var i = 0; i < nbytes4; i++) {\n        for (var j = 0; j < 4; j++) {\n            var f = RansGetCumulativeFreq(R[j]);\n            //var s = RansGetSymbolFromFreq(C[L[j]], f);\n            var s = C2S[L[j]][f]; // Precomputed version of above\n            output[i + j * nbytes4] = s;\n            R[j] = RansAdvanceStep(R[j], C[L[j]][s], F[L[j]][s]);\n            R[j] = RansRenorm(src, R[j]);\n            L[j] = s;\n        }\n    }\n    // Now deal with the remainder if buffer size is not a multiple of 4,\n    // using rANS state 3 exclusively.  (It'd have been nice to have\n    // designed this to just act as if we kept going with a bail out.)\n    i = 4 * i;\n    while (i < nbytes) {\n        var f = RansGetCumulativeFreq(R[3]);\n        var s = RansGetSymbolFromFreq(C[L[3]], f);\n        output[i++] = s;\n        R[3] = RansAdvanceStep(R[3], C[L[3]][s], F[L[3]][s]);\n        R[3] = RansRenorm(src, R[3]);\n        L[3] = s;\n    }\n    return output;\n}\n//----------------------------------------------------------------------\n// Order-1 encoder\nfunction BuildFrequencies1(src, F, F0) {\n    for (var i = 0; i < 256; i++) {\n        F0[i] = 0;\n        for (var j = 0; j < 256; j++)\n            F[i][j] = 0;\n    }\n    var last = 0;\n    for (var i = 0; i < src.length; i++) {\n        F0[src[i]]++;\n        F[last][src[i]]++;\n        //F[last][src[i]]++;\n        last = src[i];\n    }\n    // Also accept we'll be starting at 4 points, not just byte 0\n    F[0][src[1 * (src.length >> 2)]]++;\n    F[0][src[2 * (src.length >> 2)]]++;\n    F[0][src[3 * (src.length >> 2)]]++;\n    F0[0] += 3;\n}\nfunction NormaliseFrequencies1(F, F0) {\n    for (var i = 0; i < 256; i++)\n        if (F0[i])\n            NormaliseFrequencies0(F[i]);\n}\nfunction WriteFrequencies1(out, F, F0) {\n    var rle = 0;\n    var last_sym = 0;\n    for (var i = 0; i < 256; i++) {\n        if (!F0[i])\n            continue;\n        // Output Symbol if needed and Frequency\n        if (rle > 0)\n            rle--;\n        else {\n            out.WriteByte(i);\n            if (i > 0 && F0[i - 1] > 0) {\n                for (rle = i + 1; rle < 256 && F0[rle]; rle++)\n                    ;\n                rle -= i + 1;\n                out.WriteByte(rle);\n            }\n        }\n        WriteFrequencies0(out, F[i]);\n    }\n    out.WriteByte(0);\n}\nfunction RansEncode1(src) {\n    const nbytes = src.length;\n    var output = new IOStream('', 0, 257 * 257 * 3 + 9);\n    output.WriteByte(1); // Order 0\n    output.WriteUint32(0); // compressed size: correct later\n    output.WriteUint32(0); // uncompressed size: correct later\n    // Compute frequencies\n    var F0 = new Array(256);\n    var F = new Array(256);\n    var C = new Array(256);\n    for (var i = 0; i < 256; i++) {\n        F[i] = new Array(256);\n        C[i] = new Array(256);\n    }\n    BuildFrequencies1(src, F, F0);\n    NormaliseFrequencies1(F, F0);\n    WriteFrequencies1(output, F, F0);\n    // Compute cumulative frequencies\n    for (var i = 0; i < 256; i++) {\n        if (!F0[i])\n            continue;\n        C[i][0] = 0;\n        for (var j = 1; j < 256; j++)\n            C[i][j] = C[i][j - 1] + F[i][j - 1];\n    }\n    // Initialise rANS state\n    var R = new Array(4);\n    var L = new Array(4);\n    for (var j = 0; j < 4; j++) {\n        R[j] = RansEncInit();\n        L[j] = 0;\n    }\n    var rans_out = new IOStream('', nbytes, nbytes);\n    // We have 4 rans codecs running in parallel on its own 1/4tr of buffer\n    var nbytes4 = Math.floor(nbytes / 4);\n    var idx = new Array(4);\n    var last = new Array(4);\n    for (var j = 0; j < 4; j++) {\n        idx[j] = (j + 1) * nbytes4 - 2;\n        last[j] = src[idx[j] + 1];\n    }\n    // Deal with the remainder if not a multiple of 4\n    last[3] = src[nbytes - 1];\n    for (var i = nbytes - 2; i > 4 * nbytes4 - 2; i--) {\n        R[3] = RansEncPut(R[3], rans_out, C[src[i]][last[3]], F[src[i]][last[3]], 12);\n        last[3] = src[i];\n    }\n    // Main encode loop\n    while (idx[0] >= 0) {\n        for (var j = 3; j >= 0; j--) {\n            var s = src[idx[j]];\n            R[j] = RansEncPut(R[j], rans_out, C[s][last[j]], F[s][last[j]], 12);\n            last[j] = s;\n            idx[j]--;\n        }\n    }\n    for (var j = 3; j >= 0; j--) {\n        R[j] = RansEncPut(R[j], rans_out, C[0][last[j]], F[0][last[j]], 12);\n    }\n    for (var i = 3; i >= 0; i--)\n        RansEncFlush(R[i], rans_out);\n    // Stitch blocks together into final output buffer\n    var freq_tab = output.pos;\n    output.buf.writeInt32LE(freq_tab - 9 + (rans_out.length - rans_out.pos), 1);\n    output.buf.writeInt32LE(nbytes, 5);\n    return Buffer.concat([\n        output.buf.slice(0, output.pos),\n        rans_out.buf.slice(rans_out.pos, rans_out.length),\n    ], output.pos + rans_out.length - rans_out.pos);\n}\nmodule.exports = { decode, encode };\n//# sourceMappingURL=rans.js.map","\"use strict\";\n/*\n * Copyright (c) 2019,2020 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nconst IOStream = require('./iostream');\n//----------------------------------------------------------------------\n// rANS primitives itself\n//\n// RansGet* is decoder side\nfunction RansGetCumulativeFreq(R, bits) {\n    return R & ((1 << bits) - 1);\n}\nfunction RansGetSymbolFromFreq(C, f) {\n    // NOTE: Inefficient.\n    // In practice we would implement this via a precomputed\n    // lookup table C2S[f]; see RansBuildC2S below.\n    var s = 0;\n    while (f >= C[s + 1])\n        s++;\n    //console.error(f, C, s)\n    return s;\n}\nfunction RansBuildC2S(C, bits) {\n    var max = 1 << bits;\n    var C2S = new Array(max);\n    var s = 0;\n    for (var f = 0; f < max; f++) {\n        while (f >= C[s + 1])\n            s++;\n        C2S[f] = s;\n    }\n    return C2S;\n}\nfunction RansAdvanceStep(R, c, f, bits) {\n    return f * (R >> bits) + (R & ((1 << bits) - 1)) - c;\n}\nfunction RansRenorm(src, R) {\n    if (R < 1 << 15)\n        R = (R << 16) + src.ReadUint16();\n    return R;\n}\n// RanEnc* is for encoder\nfunction RansEncInit() {\n    return 1 << 15;\n}\nfunction RansEncFlush(R, dst) {\n    dst.WriteByteNeg((R >> 24) & 0xff);\n    dst.WriteByteNeg((R >> 16) & 0xff);\n    dst.WriteByteNeg((R >> 8) & 0xff);\n    dst.WriteByteNeg((R >> 0) & 0xff);\n}\nfunction RansEncRenorm(R, dst, freq, scale_bits) {\n    //var R_max = (((1 << 15) >> scale_bits) << 16) * freq;\n    var R_max = (1 << (31 - scale_bits)) * freq;\n    while (R >= R_max) {\n        dst.WriteByteNeg((R >> 8) & 0xff);\n        dst.WriteByteNeg(R & 0xff);\n        R >>= 16;\n    }\n    return R;\n}\n// Puts a symbol with frequency freq, cumulative freq start\n// and total freq 1<<scale_bits.\n//\n// Note with static probabilities, /freq and %freq could be\n// precomputed via multiplies and shifts.\nfunction RansEncPut(R, dst, start, freq, scale_bits) {\n    var scale = 1 << scale_bits;\n    R = RansEncRenorm(R, dst, freq, scale_bits);\n    R = (Math.floor(R / freq) << scale_bits) + (R % freq) + start;\n    return R;\n}\n//----------------------------------------------------------------------\n// Run length encoding\nfunction EncodeRLE(src, N) {\n    // Step 1: find which symbols benefit from RLE\n    var L = new Array(256);\n    for (var i = 0; i < 256; i++)\n        L[i] = 0;\n    var last = -1;\n    for (var i = 0; i < src.length; i++) {\n        L[src[i]] += src[i] == last ? 1 : -1;\n        last = src[i];\n    }\n    var nrle = 0;\n    for (var i = 0; i < 256; i++)\n        if (L[i] > 0)\n            nrle++;\n    if (!nrle) {\n        // Format cannot cope with zero RLE symbols, so pick one!\n        nrle = 1;\n        L[0] = 1;\n    }\n    // Start meta-data as list of symbols to RLE\n    var meta = new IOStream('', 0, nrle + 1 + src.length);\n    meta.WriteByte(nrle);\n    for (var i = 0; i < 256; i++)\n        if (L[i] > 0)\n            meta.WriteByte(i);\n    // Step 2: Now apply RLE itself\n    var data = new Buffer.allocUnsafe(src.length);\n    var dpos = 0;\n    for (var i = 0; i < src.length; i++) {\n        data[dpos++] = src[i];\n        if (L[src[i]] > 0) {\n            last = src[i];\n            var run = 0;\n            while (i + run + 1 < src.length && src[i + run + 1] == last)\n                run++;\n            meta.WriteUint7(run);\n            i += run;\n        }\n    }\n    // Compress the meta-data\n    var cmeta = RansEncode0(meta.buf.slice(0, meta.pos), N);\n    var hdr = new IOStream('', 0, 16);\n    hdr.WriteUint7(meta.pos * 2); // Uncompressed meta-data length + compressed-bit-flag(0)\n    hdr.WriteUint7(dpos); // Length of RLE encoded data\n    hdr.WriteUint7(cmeta.length); // Compressed meta-data length\n    var meta = Buffer.concat([hdr.buf.slice(0, hdr.pos), cmeta]);\n    return [meta, data.slice(0, dpos)];\n}\nfunction DecodeRLEMeta(src, N) {\n    var u_meta_len = src.ReadUint7();\n    var rle_len = src.ReadUint7();\n    // Decode RLE lengths\n    if (u_meta_len & 1) {\n        var rle_meta = src.ReadData((u_meta_len - 1) / 2);\n    }\n    else {\n        var comp_meta_len = src.ReadUint7();\n        var rle_meta = src.ReadData(comp_meta_len);\n        rle_meta = RansDecode0(new IOStream(rle_meta), u_meta_len / 2, N);\n    }\n    // Decode list of symbols for which RLE lengths are applied\n    var rle_meta = new IOStream(rle_meta);\n    var L = new Array(256);\n    var n = rle_meta.ReadByte();\n    if (n == 0)\n        n = 256;\n    for (var i = 0; i < n; i++)\n        L[rle_meta.ReadByte()] = 1;\n    return [L, rle_meta, rle_len];\n}\nfunction DecodeRLE(buf, L, rle_meta, len) {\n    var src = new IOStream(buf);\n    var out = new Buffer.allocUnsafe(len);\n    // Expand up buf+meta to out; i = buf index, j = out index\n    var j = 0;\n    for (var i = 0; j < len; i++) {\n        var sym = buf[i];\n        if (L[sym]) {\n            var run = rle_meta.ReadUint7();\n            for (var r = 0; r <= run; r++)\n                out[j++] = sym;\n        }\n        else {\n            out[j++] = sym;\n        }\n    }\n    return out;\n}\n//----------------------------------------------------------------------\n// Bit packing\nfunction EncodePack(src) {\n    // Step 1: identify number of distinct symbols\n    var F = new Array(256);\n    for (var i = 0; i < 256; i++)\n        F[i] = 0;\n    for (var i = 0; i < src.length; i++)\n        F[src[i]]++;\n    var P = new Array(256);\n    var nsym = 0;\n    for (var i = 0; i < 256; i++)\n        if (F[i] > 0)\n            P[i] = nsym++;\n    if (nsym > 16) {\n        //console.error(\"Too many symbols to pack:\",nsym)\n        return;\n    }\n    // Pack data\n    if (nsym <= 1) {\n        // Constant\n        var data = new Buffer.allocUnsafe(0);\n    }\n    else if (nsym <= 2) {\n        // 1 bit per value\n        var data = new Buffer.allocUnsafe(Math.ceil(src.length / 8));\n        var j = -1;\n        for (i = 0; i < src.length; i++) {\n            if (i % 8 == 0)\n                data[++j] = 0;\n            data[j] += P[src[i]] << i % 8;\n        }\n    }\n    else if (nsym <= 4) {\n        // 2 bits per value\n        var data = new Buffer.allocUnsafe(Math.ceil(src.length / 4));\n        var j = -1;\n        for (i = 0; i < src.length; i++) {\n            if (i % 4 == 0)\n                data[++j] = 0;\n            data[j] += P[src[i]] << ((i % 4) * 2);\n        }\n    }\n    else {\n        // 4 bits per value\n        var data = new Buffer.allocUnsafe(Math.ceil(src.length / 2));\n        var j = -1;\n        for (i = 0; i < src.length; i++) {\n            if (i % 2 == 0)\n                data[++j] = 0;\n            data[j] += P[src[i]] << ((i % 2) * 4);\n        }\n    }\n    // Produce pack meta-data\n    var meta = new IOStream('', 0, nsym + 5);\n    meta.WriteByte(nsym);\n    var j = 0;\n    for (var i = 0; i < 256; i++) {\n        if (F[i] > 0) {\n            F[i] = j++;\n            meta.WriteByte(i);\n        }\n    }\n    meta.WriteUint7(data.length);\n    return [meta.buf.slice(0, meta.pos), data];\n}\n// Pack meta data is the number and value of distinct symbols plus\n// the length of the packed byte stream.\nfunction DecodePackMeta(src) {\n    var nsym = src.ReadByte();\n    var P = new Array(nsym);\n    for (var i = 0; i < nsym; i++)\n        P[i] = src.ReadByte();\n    var len = src.ReadUint7();\n    return [P, nsym, len];\n}\n// Extract bits from src producing output of length len.\n// Nsym is number of distinct symbols used.\nfunction DecodePack(data, P, nsym, len) {\n    var out = new Buffer.allocUnsafe(len);\n    var j = 0;\n    // Constant value\n    if (nsym <= 1) {\n        for (var i = 0; i < len; i++)\n            out[i] = P[0];\n    }\n    // 1 bit per value\n    else if (nsym <= 2) {\n        for (i = 0; i < len; i++) {\n            if (i % 8 == 0)\n                var v = data[j++];\n            out[i] = P[v & 1];\n            v >>= 1;\n        }\n    }\n    // 2 bits per value\n    else if (nsym <= 4) {\n        for (i = 0; i < len; i++) {\n            if (i % 4 == 0)\n                var v = data[j++];\n            out[i] = P[v & 3];\n            v >>= 2;\n        }\n    }\n    // 4 bits per value\n    else if (nsym <= 16) {\n        for (i = 0; i < len; i++) {\n            if (i % 2 == 0)\n                var v = data[j++];\n            out[i] = P[v & 15];\n            v >>= 4;\n        }\n    }\n    return out;\n}\n//----------------------------------------------------------------------\n// 4 way interleaving.\n// This is simply 4 rANS streams interleaved to form bytes 0,4,8...,\n// 1,5,9..., 2,6,10... and 3,7,11...\n//\n// It works well when the distributions differ for each of the 4 bytes,\n// for example when compressing a series of 32-bit integers.\n//\n// Maybe make this more general purpose of X* where we specify the stripe\n// size instead of fixing it at 4?\nfunction RansEncodeStripe(hdr, src, N) {\n    if (N == 0)\n        N = 4; // old default\n    // Split into multiple streams\n    var part = new Array(N);\n    var ulen = new Array(N);\n    for (var s = 0; s < N; s++) {\n        ulen[s] = Math.floor(src.length / N) + (src.length % N > s);\n        part[s] = new Array(ulen[s]);\n    }\n    for (var x = 0, i = 0; i < src.length; i += N, x++) {\n        for (var j = 0; j < N; j++)\n            if (x < part[j].length)\n                part[j][x] = src[i + j];\n    }\n    // Compress each part\n    var comp = new Array(N);\n    var total = 0;\n    for (var s = 0; s < N; s++) {\n        // Example: try O0 and O1 and choose best\n        var comp0 = encode(part[s], 0);\n        var comp1 = encode(part[s], 1);\n        comp[s] = comp1.length < comp0.length ? comp1 : comp0;\n        total += comp[s].length;\n    }\n    // Serialise\n    var out = new IOStream('', 0, total + 5 * N + 1);\n    out.WriteByte(N);\n    for (var s = 0; s < N; s++)\n        out.WriteUint7(comp[s].length);\n    for (var s = 0; s < N; s++)\n        out.WriteData(comp[s], comp[s].length);\n    return out.buf.slice(0, out.buf.pos);\n}\nfunction RansDecodeStripe(src, len) {\n    var N = src.ReadByte();\n    // Retrieve lengths\n    var clen = new Array(N);\n    var ulen = new Array(N);\n    for (var j = 0; j < N; j++)\n        clen[j] = src.ReadUint7();\n    // Decode streams\n    var T = new Array(N);\n    for (var j = 0; j < N; j++) {\n        ulen[j] = Math.floor(len / N) + (len % N > j);\n        T[j] = RansDecodeStream(src, ulen[j]);\n    }\n    // Transpose\n    var out = new Buffer.allocUnsafe(len);\n    for (var j = 0; j < N; j++) {\n        for (var i = 0; i < ulen[j]; i++) {\n            out[i * N + j] = T[j][i];\n        }\n    }\n    return out;\n}\n//----------------------------------------------------------------------\n// Main rANS entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nfunction decode(src) {\n    var stream = new IOStream(src);\n    return RansDecodeStream(stream, 0);\n}\nfunction RansDecodeStream(stream, n_out) {\n    var format = stream.ReadByte();\n    var order = format & 1;\n    var x32 = format & 4;\n    var stripe = format & 8;\n    var nosz = format & 16;\n    var cat = format & 32;\n    var rle = format & 64;\n    var pack = format & 128;\n    var Nway = x32 ? 32 : 4;\n    if (!nosz)\n        n_out = stream.ReadUint7();\n    // N-way interleaving\n    if (stripe)\n        return RansDecodeStripe(stream, n_out);\n    // Bit packing\n    if (pack) {\n        var pack_len = n_out;\n        var [P, nsym, n_out] = DecodePackMeta(stream);\n    }\n    // Run length encoding\n    if (rle) {\n        var rle_len = n_out;\n        var [L, rle_meta, n_out] = DecodeRLEMeta(stream, Nway);\n    }\n    // Uncompress data (all, packed or run literals)\n    if (cat)\n        var buf = stream.ReadData(n_out);\n    else if (order == 0)\n        var buf = RansDecode0(stream, n_out, Nway);\n    else\n        var buf = RansDecode1(stream, n_out, Nway);\n    // Apply expansion transforms\n    if (rle)\n        buf = DecodeRLE(buf, L, rle_meta, rle_len);\n    if (pack)\n        buf = DecodePack(buf, P, nsym, pack_len);\n    return buf;\n}\nfunction encode(src, format) {\n    var hdr = new IOStream('', 0, 10);\n    hdr.WriteByte(format);\n    var order = format & 1;\n    var x32 = format & 4;\n    var stripe = format & 8;\n    var nosz = format & 16;\n    var cat = format & 32;\n    var rle = format & 64;\n    var pack = format & 128;\n    var Nway = x32 ? 32 : 4; // interleaving amount\n    var N = format >> 8; // stripe size\n    if (!nosz)\n        hdr.WriteUint7(src.length);\n    if (stripe)\n        return Buffer.concat([\n            hdr.buf.slice(0, hdr.pos),\n            RansEncodeStripe(hdr, src, N),\n        ]);\n    var pack_meta = new Buffer.alloc(0);\n    if (pack)\n        [pack_meta, src] = EncodePack(src);\n    var rle_meta = new Buffer.alloc(0);\n    if (rle)\n        [rle_meta, src] = EncodeRLE(src, Nway);\n    if (src.length < 4 && order == 1) {\n        // Protect against short order-1 data due to RLE/Pack\n        order = 0;\n        hdr.buf[0] &= ~1;\n    }\n    if (cat)\n        var comp = src;\n    else if (order == 0)\n        var comp = RansEncode0(src, Nway);\n    else\n        var comp = RansEncode1(src, Nway);\n    return Buffer.concat([hdr.buf.slice(0, hdr.pos), pack_meta, rle_meta, comp]);\n}\n//----------------------------------------------------------------------\n// Order-0 decoder\nfunction ReadAlphabet(src) {\n    var A = new Array(256);\n    for (var i = 0; i < 256; i++)\n        A[i] = 0;\n    var rle = 0;\n    var sym = src.ReadByte();\n    var last_sym = sym;\n    do {\n        A[sym] = 1;\n        if (rle > 0) {\n            rle--;\n            sym++;\n        }\n        else {\n            sym = src.ReadByte();\n            if (sym == last_sym + 1)\n                rle = src.ReadByte();\n        }\n        last_sym = sym;\n    } while (sym != 0);\n    return A;\n}\n// Decode a single table of order-0 frequences,\n// filling out the F and C arrays.\nfunction ReadFrequencies0(src, F, C) {\n    // Initialise; not in the specification - implicit?\n    for (var i = 0; i < 256; i++)\n        F[i] = 0;\n    // Fetch alphabet\n    var A = ReadAlphabet(src);\n    // Fetch frequencies for the symbols listed in our alphabet\n    for (var i = 0; i < 256; i++) {\n        if (A[i] > 0)\n            F[i] = src.ReadUint7();\n    }\n    NormaliseFrequencies0_Shift(F, 12);\n    // Compute C[] from F[]\n    C[0] = 0;\n    for (var i = 0; i <= 255; i++)\n        C[i + 1] = C[i] + F[i];\n}\nfunction RansDecode0(src, nbytes, N) {\n    // Decode frequencies\n    var F = new Array(256);\n    var C = new Array(256);\n    ReadFrequencies0(src, F, C);\n    // Fast lookup to avoid slow RansGetSymbolFromFreq\n    var C2S = RansBuildC2S(C, 12);\n    // Initialise rANS state\n    var R = new Array(N);\n    for (var i = 0; i < N; i++)\n        R[i] = src.ReadUint32();\n    // Main decode loop\n    var output = new Buffer.allocUnsafe(nbytes);\n    for (var i = 0; i < nbytes; i++) {\n        var ix = i & (N - 1); // equiv to i%N as N is power of 2\n        var f = RansGetCumulativeFreq(R[ix], 12);\n        var s = C2S[f]; // Equiv to RansGetSymbolFromFreq(C, f);\n        output[i] = s;\n        R[ix] = RansAdvanceStep(R[ix], C[s], F[s], 12);\n        R[ix] = RansRenorm(src, R[ix]);\n    }\n    // Main decode loop\n    return output;\n}\n//----------------------------------------------------------------------\n// Order-0 encoder\nfunction BuildFrequencies0(src, F) {\n    for (var i = 0; i < 256; i++)\n        F[i] = 0;\n    for (var i = 0; i < src.length; i++)\n        F[src[i]]++;\n}\nfunction NormaliseFrequencies0(F, bits) {\n    // Compute total\n    var tot = 0;\n    for (var i = 0; i < 256; i++)\n        tot += F[i];\n    // Scale total of frequencies to max\n    const max = 1 << bits;\n    var scale = max / tot;\n    do {\n        var max_val = 0;\n        var max_idx = 0;\n        var renorm = 0;\n        tot = 0;\n        for (var i = 0; i < 256; i++) {\n            if (F[i] == 0)\n                continue;\n            if (max_val < F[i]) {\n                max_val = F[i];\n                max_idx = i;\n            }\n            F[i] = Math.floor(F[i] * scale);\n            if (F[i] == 0)\n                F[i] = 1;\n            tot += F[i];\n        }\n        // Adjust new tot to ensure it matches.\n        if (tot < max) {\n            // Too low, boost the most common symbol\n            F[max_idx] += max - tot;\n        }\n        else if (tot - max < F[max_idx] / 2 && F[max_idx] > 2) {\n            // Too high, reduce the common symbol\n            F[max_idx] -= tot - max;\n        }\n        else if (tot != max) {\n            // Much too high, fudge scale and try again.\n            scale = max / tot;\n            renorm = 1;\n        }\n    } while (renorm);\n}\nfunction NormaliseFrequencies0_Shift(F, bits) {\n    // Compute total and number of bits to shift by\n    var tot = 0;\n    for (var i = 0; i < 256; i++)\n        tot += F[i];\n    if (tot == 0 || tot == 1 << bits)\n        return;\n    var shift = 0;\n    while (tot < 1 << bits) {\n        tot *= 2;\n        shift++;\n    }\n    // Scale total of frequencies to (1<<bits)\n    for (var i = 0; i < 256; i++)\n        F[i] <<= shift;\n}\nfunction WriteAlphabet(out, F) {\n    var rle = 0;\n    for (var i = 0; i < 256; i++) {\n        if (!F[i])\n            continue;\n        if (rle > 0)\n            rle--;\n        else {\n            out.WriteByte(i);\n            if (i > 0 && F[i - 1] > 0) {\n                // We've encoded two symbol frequencies in a row.\n                // How many more are there?  Store that count so\n                // we can avoid writing consecutive symbols.\n                for (rle = i + 1; rle < 256 && F[rle]; rle++)\n                    ;\n                rle -= i + 1;\n                out.WriteByte(rle);\n            }\n        }\n    }\n    out.WriteByte(0);\n}\nfunction WriteFrequencies0(out, F) {\n    WriteAlphabet(out, F);\n    for (var i = 0; i < 256; i++) {\n        if (F[i])\n            out.WriteUint7(F[i]);\n    }\n}\nfunction RansEncode0(src, N) {\n    const nbytes = src.length;\n    var output = new IOStream('', 0, 257 * 3 + 9);\n    // Compute frequencies\n    var F = new Array(256);\n    BuildFrequencies0(src, F);\n    var bit_size = Math.ceil(Math.log2(nbytes));\n    if (bit_size > 12)\n        bit_size = 12;\n    NormaliseFrequencies0(F, bit_size);\n    WriteFrequencies0(output, F);\n    NormaliseFrequencies0(F, 12);\n    // Compute cumulative frequencies\n    var C = new Array(256);\n    C[0] = 0;\n    for (var i = 1; i < 256; i++)\n        C[i] = C[i - 1] + F[i - 1];\n    // Initialise rANS state\n    var R = new Array(N);\n    for (var i = 0; i < N; i++)\n        R[i] = RansEncInit();\n    // Allow expansion room if trying to compress random data.\n    var rans_out = new IOStream('', (nbytes * 1.05 + 100) >> 0, (nbytes * 1.05 + 100) >> 0);\n    // Main encode loop\n    for (var i = nbytes - 1; i >= 0; i--)\n        R[i % N] = RansEncPut(R[i % N], rans_out, C[src[i]], F[src[i]], 12);\n    for (var i = N - 1; i >= 0; i--)\n        RansEncFlush(R[i], rans_out);\n    // Stitch blocks together into final output buffer\n    //console.error(\"pos=\",rans_out.pos, \" len=\",rans_out.length)\n    //console.error(rans_out.buf.slice(rans_out.pos, rans_out.length))\n    return Buffer.concat([\n        output.buf.slice(0, output.pos),\n        rans_out.buf.slice(rans_out.pos, rans_out.length),\n    ], output.pos + rans_out.length - rans_out.pos);\n}\n//----------------------------------------------------------------------\n// Order-1 decoder\n// Decode a table of order-1 frequences,\n// filling out the F and C arrays.\nfunction ReadFrequencies1(src, F, C, shift) {\n    // Initialise; not in the specification - implicit?\n    for (var i = 0; i < 256; i++) {\n        F[i] = new Array(256);\n        C[i] = new Array(256);\n        for (var j = 0; j < 256; j++)\n            F[i][j] = 0;\n    }\n    // Fetch alphabet\n    var A = ReadAlphabet(src);\n    // Read F[]\n    for (var i = 0; i < 256; i++) {\n        if (!A[i])\n            continue;\n        var run = 0;\n        for (var j = 0; j < 256; j++) {\n            if (!A[j])\n                continue;\n            if (run > 0) {\n                run--;\n            }\n            else {\n                F[i][j] = src.ReadUint7();\n                if (F[i][j] == 0)\n                    run = src.ReadByte();\n            }\n        }\n        NormaliseFrequencies0_Shift(F[i], shift);\n        // Compute C[] from F[]\n        C[i][0] = 0;\n        for (var j = 0; j < 256; j++)\n            C[i][j + 1] = C[i][j] + F[i][j];\n    }\n}\nfunction RansDecode1(src, nbytes, N) {\n    // FIXME: this bit is missing from the RansDecode0 pseudocode.\n    var comp = src.ReadByte();\n    var shift = comp >> 4;\n    var freq_src = src;\n    if (comp & 1) {\n        var ulen = src.ReadUint7();\n        var clen = src.ReadUint7();\n        var comp = new IOStream(src.ReadData(clen));\n        var freq_src = new IOStream(RansDecode0(comp, ulen, 4));\n    }\n    // Decode frequencies\n    var F = new Array(256);\n    var C = new Array(256);\n    ReadFrequencies1(freq_src, F, C, shift);\n    // Fast lookup to avoid slow RansGetSymbolFromFreq\n    var C2S = new Array(256);\n    for (var i = 0; i < 256; i++)\n        // Could do only for symbols in alphabet?\n        C2S[i] = RansBuildC2S(C[i], shift);\n    // Initialise rANS state\n    var R = new Array(N);\n    var L = new Array(N);\n    for (var j = 0; j < N; j++) {\n        R[j] = src.ReadUint32();\n        L[j] = 0;\n    }\n    // Main decode loop\n    var output = new Buffer.allocUnsafe(nbytes);\n    var nbytesx = Math.floor(nbytes / N);\n    for (var i = 0; i < nbytesx; i++) {\n        for (var j = 0; j < N; j++) {\n            var f = RansGetCumulativeFreq(R[j], shift);\n            //var s = RansGetSymbolFromFreq(C[L[j]], f);\n            var s = C2S[L[j]][f]; // Precomputed version of above\n            output[i + j * nbytesx] = s;\n            R[j] = RansAdvanceStep(R[j], C[L[j]][s], F[L[j]][s], shift);\n            R[j] = RansRenorm(src, R[j]);\n            L[j] = s;\n        }\n    }\n    // Now deal with the remainder if buffer size is not a multiple of N,\n    // using the last rANS state exclusively.  (It'd have been nice to have\n    // designed this to just act as if we kept going with a bail out.)\n    i = N * i;\n    while (i < nbytes) {\n        var f = RansGetCumulativeFreq(R[N - 1], shift);\n        var s = RansGetSymbolFromFreq(C[L[N - 1]], f);\n        output[i++] = s;\n        R[N - 1] = RansAdvanceStep(R[N - 1], C[L[N - 1]][s], F[L[N - 1]][s], shift);\n        R[N - 1] = RansRenorm(src, R[N - 1]);\n        L[N - 1] = s;\n    }\n    return output;\n}\n//----------------------------------------------------------------------\n// Order-1 encoder\nfunction BuildFrequencies1(src, F, F0, N) {\n    for (var i = 0; i < 256; i++) {\n        F0[i] = 0;\n        for (var j = 0; j < 256; j++)\n            F[i][j] = 0;\n    }\n    var last = 0;\n    for (var i = 0; i < src.length; i++) {\n        F0[last]++;\n        F[last][src[i]]++;\n        last = src[i];\n    }\n    F0[last]++;\n    // Also accept we'll be starting at N points, not just byte 0\n    for (var i = 1; i < N; i++)\n        F[0][src[i * Math.floor(src.length / N)]]++;\n    F0[0] += N - 1;\n}\nfunction NormaliseFrequencies1(F, F0, shift) {\n    for (var i = 0; i < 256; i++) {\n        if (!F0[i])\n            continue;\n        var bit_size = Math.ceil(Math.log2(F0[i]));\n        if (bit_size > shift)\n            bit_size = shift;\n        NormaliseFrequencies0(F[i], bit_size);\n    }\n}\nfunction NormaliseFrequencies1_Shift(F, F0, shift) {\n    for (var i = 0; i < 256; i++)\n        if (F0[i])\n            NormaliseFrequencies0_Shift(F[i], shift);\n}\nfunction WriteFrequencies1(out, F, F0) {\n    WriteAlphabet(out, F0);\n    for (var i = 0; i < 256; i++) {\n        if (!F0[i])\n            continue;\n        var run = 0;\n        for (var j = 0; j < 256; j++) {\n            if (!F0[j])\n                continue;\n            if (run) {\n                run--;\n            }\n            else {\n                out.WriteUint7(F[i][j]);\n                if (!F[i][j]) {\n                    // Count how many more zero-freqs we have\n                    for (var k = j + 1; k < 256; k++) {\n                        if (!F0[k])\n                            continue;\n                        if (F[i][k] == 0)\n                            run++;\n                        else\n                            break;\n                    }\n                    out.WriteByte(run);\n                }\n            }\n        }\n    }\n}\nfunction RansEncode1(src, N) {\n    const nbytes = src.length;\n    var output = new IOStream('', 0, 257 * 257 * 3 + 9);\n    // Compute frequencies\n    var F0 = new Array(256);\n    var F = new Array(256);\n    var C = new Array(256);\n    for (var i = 0; i < 256; i++) {\n        F[i] = new Array(256);\n        C[i] = new Array(256);\n    }\n    // Frequency precision\n    var shift = 12;\n    BuildFrequencies1(src, F, F0, N);\n    NormaliseFrequencies1(F, F0, shift);\n    // Store frequencies, possibly compressed\n    var freq = new IOStream('', 0, 257 * 257 * 3 + 9);\n    WriteFrequencies1(freq, F, F0);\n    var cfreq = RansEncode0(freq.buf.slice(0, freq.pos), 4);\n    if (cfreq.length < freq.pos) {\n        output.WriteByte(1 | (shift << 4));\n        output.WriteUint7(freq.pos);\n        output.WriteUint7(cfreq.length);\n        output.WriteData(cfreq, cfreq.length);\n    }\n    else {\n        output.WriteByte(0 | (shift << 4));\n        output.WriteData(freq.buf, freq.pos);\n    }\n    // Normalise and compute cumulative frequencies\n    NormaliseFrequencies1_Shift(F, F0, shift);\n    for (var i = 0; i < 256; i++) {\n        if (!F0[i])\n            continue;\n        C[i][0] = 0;\n        for (var j = 1; j < 256; j++)\n            C[i][j] = C[i][j - 1] + F[i][j - 1];\n    }\n    // Initialise rANS state\n    var R = new Array(N);\n    var L = new Array(N);\n    for (var j = 0; j < N; j++) {\n        R[j] = RansEncInit();\n        L[j] = 0;\n    }\n    var rans_out = new IOStream('', (nbytes * 1.05 + 100) >> 0, (nbytes * 1.05 + 100) >> 0);\n    // We have N rans codecs running in parallel on its own 1/Nth of buffer\n    var nbytesx = Math.floor(nbytes / N);\n    var idx = new Array(N);\n    var last = new Array(N);\n    for (var j = 0; j < N; j++) {\n        idx[j] = (j + 1) * nbytesx - 2;\n        last[j] = src[idx[j] + 1];\n    }\n    // Deal with the remainder if not a multiple of N\n    last[N - 1] = src[nbytes - 1];\n    for (var i = nbytes - 2; i > N * nbytesx - 2; i--) {\n        R[N - 1] = RansEncPut(R[N - 1], rans_out, C[src[i]][last[N - 1]], F[src[i]][last[N - 1]], shift);\n        last[N - 1] = src[i];\n    }\n    // Main encode loop\n    var s = new Array(N);\n    while (idx[0] >= 0) {\n        // Separate loop as a speed optimisation\n        for (var j = N - 1; j >= 0; j--)\n            s[j] = src[idx[j]];\n        for (var j = N - 1; j >= 0; j--) {\n            R[j] = RansEncPut(R[j], rans_out, C[s[j]][last[j]], F[s[j]][last[j]], shift);\n            last[j] = s[j];\n            idx[j]--;\n        }\n    }\n    for (var j = N - 1; j >= 0; j--) {\n        R[j] = RansEncPut(R[j], rans_out, C[0][last[j]], F[0][last[j]], shift);\n    }\n    for (var i = N - 1; i >= 0; i--)\n        RansEncFlush(R[i], rans_out);\n    // Stitch blocks together into final output buffer\n    return Buffer.concat([\n        output.buf.slice(0, output.pos),\n        rans_out.buf.slice(rans_out.pos, rans_out.length),\n    ], output.pos + rans_out.length - rans_out.pos);\n}\nmodule.exports = { decode, encode };\n//# sourceMappingURL=rans4x16.js.map","\"use strict\";\n/*\n * Copyright (c) 2019 Genome Research Ltd.\n * Author(s): James Bonfield\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *    1. Redistributions of source code must retain the above copyright notice,\n *       this list of conditions and the following disclaimer.\n *\n *    2. Redistributions in binary form must reproduce the above\n *       copyright notice, this list of conditions and the following\n *       disclaimer in the documentation and/or other materials provided\n *       with the distribution.\n *\n *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger\n *       Institute nor the names of its contributors may be used to endorse\n *       or promote products derived from this software without specific\n *       prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH\n * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n// Name tokeniser\n//\n// This is a reference implementation designed to match the\n// written specification as closely as possible.  It is *NOT*\n// an efficient implementation, but see comments below.\nconst IOStream = require('./iostream');\nconst rans = require('./rans4x16');\nconst arith_gen = require('./arith_gen');\nvar arith = new arith_gen();\nconst TOK_TYPE = 0;\nconst TOK_STRING = 1;\nconst TOK_CHAR = 2;\nconst TOK_DIGITS0 = 3;\nconst TOK_DZLEN = 4;\nconst TOK_DUP = 5;\nconst TOK_DIFF = 6;\nconst TOK_DIGITS = 7;\nconst TOK_DELTA = 8;\nconst TOK_DELTA0 = 9;\nconst TOK_MATCH = 10;\nconst TOK_NOP = 11;\nconst TOK_END = 12;\n//----------------------------------------------------------------------\n// Token byte streams\nfunction DecodeTokenByteStreams(src, in_size, use_arith, nnames) {\n    var t = -1;\n    var B = new Array(256);\n    while (!src.EOF()) {\n        var ttype = src.ReadByte();\n        var tok_new = ttype & 128;\n        var tok_dup = ttype & 64;\n        var type = ttype & 63;\n        if (tok_new) {\n            t++;\n            B[t] = new Array(13);\n        }\n        if (type != TOK_TYPE && tok_new) {\n            var M = new Array(nnames - 1).fill(TOK_MATCH);\n            B[t][TOK_TYPE] = new IOStream(Buffer.from([type].concat(M)));\n        }\n        if (tok_dup) {\n            var dup_pos = src.ReadByte();\n            var dup_type = src.ReadByte();\n            B[t][type] = new IOStream(B[dup_pos][dup_type].buf);\n        }\n        else {\n            var clen = src.ReadUint7();\n            var data = src.ReadData(clen);\n            if (use_arith)\n                B[t][type] = arith.decode(data);\n            else\n                B[t][type] = rans.decode(data);\n            B[t][type] = new IOStream(B[t][type]);\n        }\n    }\n    return B;\n}\n//----------------------------------------------------------------------\n// Token decode\nfunction LeftPadNumber(val, len) {\n    var str = val + '';\n    while (str.length < len)\n        str = '0' + str;\n    return str;\n}\nfunction DecodeSingleName(B, N, T, n) {\n    var type = B[0][TOK_TYPE].ReadByte();\n    var dist = B[0][type].ReadUint32();\n    var m = n - dist;\n    if (type == TOK_DUP) {\n        N[n] = N[m];\n        T[n] = T[m];\n        return N[n];\n    }\n    var t = 1;\n    N[n] = '';\n    T[n] = new Array(256);\n    do {\n        type = B[t][TOK_TYPE].ReadByte();\n        switch (type) {\n            case TOK_CHAR:\n                T[n][t] = B[t][TOK_CHAR].ReadChar();\n                break;\n            case TOK_STRING:\n                T[n][t] = B[t][TOK_STRING].ReadString();\n                break;\n            case TOK_DIGITS:\n                T[n][t] = B[t][TOK_DIGITS].ReadUint32();\n                break;\n            case TOK_DIGITS0:\n                var d = B[t][TOK_DIGITS0].ReadUint32();\n                var l = B[t][TOK_DZLEN].ReadByte();\n                T[n][t] = LeftPadNumber(d, l);\n                break;\n            case TOK_DELTA:\n                T[n][t] = (T[m][t] >> 0) + B[t][TOK_DELTA].ReadByte();\n                break;\n            case TOK_DELTA0:\n                var d = (T[m][t] >> 0) + B[t][TOK_DELTA0].ReadByte();\n                var l = T[m][t].length;\n                T[n][t] = LeftPadNumber(d, l);\n                break;\n            case TOK_MATCH:\n                T[n][t] = T[m][t];\n                break;\n            default:\n                T[n][t] = '';\n                break;\n        }\n        N[n] += T[n][t++];\n    } while (type != TOK_END);\n    return N[n];\n}\n//----------------------------------------------------------------------\n// Main tokeniser decode entry function: decodes a compressed src and\n// returns the uncompressed buffer.\nfunction decode(src, len, separator) {\n    var src = new IOStream(src);\n    var ulen = src.ReadUint32();\n    var nnames = src.ReadUint32();\n    var use_arith = src.ReadByte();\n    var B = DecodeTokenByteStreams(src, len, use_arith, nnames);\n    var N = new Array(nnames);\n    var T = new Array(nnames);\n    var str = '';\n    if (typeof separator === 'undefined')\n        separator = '\\n';\n    for (var i = 0; i < nnames; i++)\n        str += DecodeSingleName(B, N, T, i) + separator;\n    return str;\n}\n//----------------------------------------------------------------------\n// Main tokeniser encode function\n// Encoder is trickier than decode as we have a lot of decisions to make.\n// However here we just make a simple guess without anything complex,\n// to demonstrate the basic idea.  See the C implementation for further\n// expansion on this.\nfunction encode(src, use_arith) {\n    // Convert buffer to array of names\n    var str = src.toString();\n    if (str[str.length - 1] == '\\n')\n        str = str.substring(0, str.length - 1);\n    var names = str.split('\\n');\n    var out = new IOStream('', 0, str.length * 2 + 10000); // guess max size\n    out.WriteUint32(str.length);\n    out.WriteUint32(names.length);\n    out.WriteByte(use_arith);\n    // Tokenise names\n    var T = new Array(names.length);\n    var H = {};\n    var F = new Array(256).fill(0); // DELTA vs DIGIT frequency\n    var max_tok = 0;\n    var max_len = 0;\n    for (var i = 0; i < names.length; i++) {\n        var [ntok, len] = TokeniseName(T, H, F, names[i], i);\n        if (max_tok < ntok)\n            max_tok = ntok;\n        if (max_len < len)\n            max_len = len;\n    }\n    // Convert tokens to byte streams and serialise\n    for (var tnum = 0; tnum < max_tok; tnum++) {\n        var B = new Array(TOK_END + 1);\n        for (var type = 0; type <= TOK_END; type++)\n            B[type] = new IOStream('', 0, names.length * max_len);\n        FillByteStreams(B, T, tnum, names, max_tok, max_len);\n        SerialiseByteStreams(B, tnum, use_arith, out);\n    }\n    return out.buf.slice(0, out.pos);\n}\nfunction FillByteStreams(B, T, tnum, names, max_tok, max_len) {\n    // Create byte streams B[]\n    for (var n = 0; n < names.length; n++) {\n        if (tnum > 0 && T[n][0].type == TOK_DUP)\n            continue;\n        if (!T[n][tnum])\n            continue;\n        B[TOK_TYPE].WriteByte(T[n][tnum].type);\n        switch (T[n][tnum].type) {\n            case TOK_DIFF:\n                B[TOK_DIFF].WriteUint32(T[n][tnum].val);\n                break;\n            case TOK_DUP:\n                B[TOK_DUP].WriteUint32(T[n][tnum].val);\n                break;\n            case TOK_STRING:\n                B[TOK_STRING].WriteString(T[n][tnum].val);\n                break;\n            case TOK_CHAR:\n                B[TOK_CHAR].WriteChar(T[n][tnum].val);\n                break;\n            case TOK_DIGITS:\n                B[TOK_DIGITS].WriteUint32(T[n][tnum].val);\n                break;\n            case TOK_DIGITS0:\n                B[TOK_DIGITS0].WriteUint32(T[n][tnum].val);\n                B[TOK_DZLEN].WriteByte(T[n][tnum].val.length);\n                break;\n            case TOK_DELTA:\n                B[T[n][tnum].type].WriteByte(T[n][tnum].val);\n                break;\n            case TOK_DELTA0:\n                B[T[n][tnum].type].WriteByte(T[n][tnum].val);\n                break;\n        }\n    }\n}\nfunction SerialiseByteStreams(B, tnum, use_arith, out) {\n    // Compress and serialise byte streams B[]\n    for (var type = 0; type <= TOK_END; type++) {\n        if (B[type].pos <= 0)\n            continue;\n        out.WriteByte(type + (type == 0 ? 128 : 0));\n        // IOStream to sized buffer\n        B[type] = B[type].buf.slice(0, B[type].pos);\n        var comp = try_compress(B[type], use_arith);\n        out.WriteUint7(comp.length);\n        out.WriteData(comp, comp.length);\n    }\n}\nfunction try_compress(src, use_arith) {\n    var best = 1 << 30;\n    var comp;\n    var methods = [0, 1, 64, 65, 128, 129, 193 + 8];\n    for (var i in methods) {\n        var lvl = methods[i];\n        if (lvl & 1 && src.length < 100)\n            continue;\n        if (lvl & 8 && src.length % 4 != 0)\n            continue;\n        try {\n            var tmp = use_arith ? arith.encode(src, lvl) : rans.encode(src, lvl);\n        }\n        catch (e) {\n            var tmp = 0;\n        }\n        if (tmp && best > tmp.length) {\n            best = tmp.length;\n            comp = tmp;\n        }\n    }\n    return comp;\n}\nfunction TokeniseName(T, H, F, name, n) {\n    var max_len = 0;\n    // Always compare against last name only\n    var p = n - 1;\n    T[n] = new Array(256);\n    if (H[name]) {\n        //console.error(name,H[name],n)\n        T[n][0] = {\n            type: TOK_DUP,\n            val: n - H[name],\n        };\n    }\n    else {\n        T[n][0] = {\n            type: TOK_DIFF,\n            val: n == 0 ? 0 : 1,\n        };\n    }\n    H[name] = n;\n    // Splits on alphanumerics, punctuation\n    var tok = name.match(/([a-zA-Z0-9]{1,9})|([^a-zA-Z0-9]+)/g);\n    for (var i = 0; i < tok.length; i++) {\n        var t = i + 1; // token 0 = DIFF vs DUP\n        var type = TOK_STRING;\n        var val = tok[i];\n        if (tok[i].match(/^0+[0-9]*$/g))\n            type = TOK_DIGITS0;\n        else if (tok[i].match(/^[0-9]+$/g))\n            type = TOK_DIGITS;\n        else if (tok[i].length == 1)\n            type = TOK_CHAR;\n        if (p >= 0 && T[p][t]) {\n            if (T[p][t].str == tok[i]) {\n                type = TOK_MATCH;\n                val = '';\n            }\n            else if (T[p][t].type == TOK_DIGITS || T[p][t].type == TOK_DELTA) {\n                var d = val - T[p][t].str;\n                F[t]++;\n                if (d >= 0 && d < 256 && F[t] > n / 2) {\n                    type = TOK_DELTA;\n                    val = d;\n                }\n            }\n            else if ((T[p][t].type == TOK_DIGITS0 || T[p][t].type == TOK_DELTA0) &&\n                T[p][t].str.length == val.length) {\n                var d = val - T[p][t].str;\n                F[t]++;\n                if (d >= 0 && d < 256 && F[t] > n / 2) {\n                    type = TOK_DELTA0;\n                    val = d;\n                }\n            }\n        }\n        T[n][t] = {\n            str: tok[i],\n            val: val,\n            type: type,\n        };\n        if (max_len < T[n][t].val.length + 3)\n            // +3 for integers; 5 -> (Uint32)5\n            max_len = T[n][t].val.length + 3;\n        //console.error(t,T[n][t])\n    }\n    T[n][++t] = {\n        type: TOK_END,\n    };\n    return [t + 1, max_len];\n}\nmodule.exports = { encode, decode };\n//# sourceMappingURL=tok3.js.map","const Constants = {\n    CRAM_FLAG_PRESERVE_QUAL_SCORES: 1 << 0,\n    CRAM_FLAG_DETACHED: 1 << 1,\n    CRAM_FLAG_MATE_DOWNSTREAM: 1 << 2,\n    CRAM_FLAG_NO_SEQ: 1 << 3,\n    CRAM_FLAG_MASK: (1 << 4) - 1,\n    // mate read is reversed\n    CRAM_M_REVERSE: 1,\n    // mated read is unmapped\n    CRAM_M_UNMAP: 2,\n    //  the read is paired in sequencing, no matter whether it is mapped in a pair\n    BAM_FPAIRED: 1,\n    //  the read is mapped in a proper pair\n    BAM_FPROPER_PAIR: 2,\n    //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR\n    BAM_FUNMAP: 4,\n    //  the mate is unmapped\n    BAM_FMUNMAP: 8,\n    //  the read is mapped to the reverse strand\n    BAM_FREVERSE: 16,\n    //  the mate is mapped to the reverse strand\n    BAM_FMREVERSE: 32,\n    //  this is read1\n    BAM_FREAD1: 64,\n    //  this is read2\n    BAM_FREAD2: 128,\n    //  not primary alignment\n    BAM_FSECONDARY: 256,\n    //  QC failure\n    BAM_FQCFAIL: 512,\n    //  optical or PCR duplicate\n    BAM_FDUP: 1024,\n    //  supplementary alignment\n    BAM_FSUPPLEMENTARY: 2048,\n    BAM_CMATCH: 0,\n    BAM_CINS: 1,\n    BAM_CDEL: 2,\n    BAM_CREF_SKIP: 3,\n    BAM_CSOFT_CLIP: 4,\n    BAM_CHARD_CLIP: 5,\n    BAM_CPAD: 6,\n    BAM_CEQUAL: 7,\n    BAM_CDIFF: 8,\n    BAM_CBACK: 9,\n    BAM_CIGAR_STR: 'MIDNSHP:XB',\n    BAM_CIGAR_SHIFT: 4,\n    BAM_CIGAR_MASK: 0xf,\n    BAM_CIGAR_TYPE: 0x3c1a7,\n};\nexport default Constants;\n//# sourceMappingURL=constants.js.map","import Constants from './constants';\nfunction decodeReadSequence(cramRecord, refRegion) {\n    // if it has no length, it has no sequence\n    if (!cramRecord.lengthOnRef && !cramRecord.readLength) {\n        return null;\n    }\n    if (cramRecord.isUnknownBases()) {\n        return null;\n    }\n    // remember: all coordinates are 1-based closed\n    const regionSeqOffset = cramRecord.alignmentStart - refRegion.start;\n    if (!cramRecord.readFeatures) {\n        return refRegion.seq\n            .slice(regionSeqOffset, regionSeqOffset + (cramRecord.lengthOnRef || 0))\n            .toUpperCase();\n    }\n    let bases = '';\n    let regionPos = regionSeqOffset;\n    let currentReadFeature = 0;\n    while (bases.length < cramRecord.readLength) {\n        if (currentReadFeature < cramRecord.readFeatures.length) {\n            const feature = cramRecord.readFeatures[currentReadFeature];\n            if (feature.code === 'Q' || feature.code === 'q') {\n                currentReadFeature += 1;\n            }\n            else if (feature.pos === bases.length + 1) {\n                // process the read feature\n                currentReadFeature += 1;\n                if (feature.code === 'b') {\n                    // specify a base pair for some reason\n                    const added = feature.data;\n                    bases += added;\n                    regionPos += added.length;\n                }\n                else if (feature.code === 'B') {\n                    // base pair and associated quality\n                    // TODO: do we need to set the quality in the qual scores?\n                    bases += feature.data[0];\n                    regionPos += 1;\n                }\n                else if (feature.code === 'X') {\n                    // base substitution\n                    bases += feature.sub;\n                    regionPos += 1;\n                }\n                else if (feature.code === 'I') {\n                    // insertion\n                    bases += feature.data;\n                }\n                else if (feature.code === 'D') {\n                    // deletion\n                    regionPos += feature.data;\n                }\n                else if (feature.code === 'i') {\n                    // insert single base\n                    bases += feature.data;\n                }\n                else if (feature.code === 'N') {\n                    // reference skip. delete some bases\n                    // do nothing\n                    // seqBases.splice(feature.pos - 1, feature.data)\n                    regionPos += feature.data;\n                }\n                else if (feature.code === 'S') {\n                    // soft clipped bases that should be present in the read seq\n                    // seqBases.splice(feature.pos - 1, 0, ...feature.data.split(''))\n                    bases += feature.data;\n                }\n                else if (feature.code === 'P') {\n                    // padding, do nothing\n                }\n                else if (feature.code === 'H') {\n                    // hard clip, do nothing\n                }\n            }\n            else if (currentReadFeature < cramRecord.readFeatures.length) {\n                // put down a chunk of sequence up to the next read feature\n                const chunk = refRegion.seq.slice(regionPos, regionPos + feature.pos - bases.length - 1);\n                bases += chunk;\n                regionPos += chunk.length;\n            }\n        }\n        else {\n            // put down a chunk of reference up to the full read length\n            const chunk = refRegion.seq.slice(regionPos, regionPos + cramRecord.readLength - bases.length);\n            bases += chunk;\n            regionPos += chunk.length;\n        }\n    }\n    return bases.toUpperCase();\n}\nconst baseNumbers = {\n    a: 0,\n    A: 0,\n    c: 1,\n    C: 1,\n    g: 2,\n    G: 2,\n    t: 3,\n    T: 3,\n    n: 4,\n    N: 4,\n};\nfunction decodeBaseSubstitution(cramRecord, refRegion, compressionScheme, readFeature) {\n    // decode base substitution code using the substitution matrix\n    const refCoord = readFeature.refPos - refRegion.start;\n    const refBase = refRegion.seq.charAt(refCoord);\n    if (refBase) {\n        readFeature.ref = refBase;\n    }\n    let baseNumber = baseNumbers[refBase];\n    if (baseNumber === undefined) {\n        baseNumber = 4;\n    }\n    const substitutionScheme = compressionScheme.substitutionMatrix[baseNumber];\n    const base = substitutionScheme[readFeature.data];\n    if (base) {\n        readFeature.sub = base;\n    }\n}\nexport const BamFlags = [\n    [0x1, 'Paired'],\n    [0x2, 'ProperlyPaired'],\n    [0x4, 'SegmentUnmapped'],\n    [0x8, 'MateUnmapped'],\n    [0x10, 'ReverseComplemented'],\n    //  the mate is mapped to the reverse strand\n    [0x20, 'MateReverseComplemented'],\n    //  this is read1\n    [0x40, 'Read1'],\n    //  this is read2\n    [0x80, 'Read2'],\n    //  not primary alignment\n    [0x100, 'Secondary'],\n    //  QC failure\n    [0x200, 'FailedQc'],\n    //  optical or PCR duplicate\n    [0x400, 'Duplicate'],\n    //  supplementary alignment\n    [0x800, 'Supplementary'],\n];\nexport const CramFlags = [\n    [0x1, 'PreservingQualityScores'],\n    [0x2, 'Detached'],\n    [0x4, 'WithMateDownstream'],\n    [0x8, 'DecodeSequenceAsStar'],\n];\nexport const MateFlags = [\n    [0x1, 'OnNegativeStrand'],\n    [0x2, 'Unmapped'],\n];\nfunction makeFlagsHelper(x) {\n    const r = {};\n    for (const [code, name] of x) {\n        r[`is${name}`] = (flags) => !!(flags & code);\n        r[`set${name}`] = (flags) => flags | code;\n    }\n    return r;\n}\nexport const BamFlagsDecoder = makeFlagsHelper(BamFlags);\nexport const CramFlagsDecoder = makeFlagsHelper(CramFlags);\nexport const MateFlagsDecoder = makeFlagsHelper(MateFlags);\n/**\n * Class of each CRAM record returned by this API.\n */\nexport default class CramRecord {\n    constructor({ flags, cramFlags, readLength, mappingQuality, lengthOnRef, qualityScores, mateRecordNumber, readBases, readFeatures, mateToUse, readGroupId, readName, sequenceId, uniqueId, templateSize, alignmentStart, tags, }) {\n        this.flags = flags;\n        this.cramFlags = cramFlags;\n        this.readLength = readLength;\n        this.mappingQuality = mappingQuality;\n        this.lengthOnRef = lengthOnRef;\n        this.qualityScores = qualityScores;\n        if (readBases) {\n            this.readBases = readBases;\n        }\n        this.readGroupId = readGroupId;\n        this.readName = readName;\n        this.sequenceId = sequenceId;\n        this.uniqueId = uniqueId;\n        this.templateSize = templateSize;\n        this.alignmentStart = alignmentStart;\n        this.tags = tags;\n        // backwards compatibility\n        if (readFeatures) {\n            this.readFeatures = readFeatures;\n        }\n        if (mateToUse) {\n            this.mate = {\n                flags: mateToUse.mateFlags,\n                readName: mateToUse.mateReadName,\n                sequenceId: mateToUse.mateSequenceId,\n                alignmentStart: mateToUse.mateAlignmentStart,\n            };\n        }\n        if (mateRecordNumber) {\n            this.mateRecordNumber = mateRecordNumber;\n        }\n    }\n    /**\n     * @returns {boolean} true if the read is paired, regardless of whether both segments are mapped\n     */\n    isPaired() {\n        return !!(this.flags & Constants.BAM_FPAIRED);\n    }\n    /** @returns {boolean} true if the read is paired, and both segments are mapped */\n    isProperlyPaired() {\n        return !!(this.flags & Constants.BAM_FPROPER_PAIR);\n    }\n    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n    isSegmentUnmapped() {\n        return !!(this.flags & Constants.BAM_FUNMAP);\n    }\n    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n    isMateUnmapped() {\n        return !!(this.flags & Constants.BAM_FMUNMAP);\n    }\n    /** @returns {boolean} true if the read is mapped to the reverse strand */\n    isReverseComplemented() {\n        return !!(this.flags & Constants.BAM_FREVERSE);\n    }\n    /** @returns {boolean} true if the mate is mapped to the reverse strand */\n    isMateReverseComplemented() {\n        return !!(this.flags & Constants.BAM_FMREVERSE);\n    }\n    /** @returns {boolean} true if this is read number 1 in a pair */\n    isRead1() {\n        return !!(this.flags & Constants.BAM_FREAD1);\n    }\n    /** @returns {boolean} true if this is read number 2 in a pair */\n    isRead2() {\n        return !!(this.flags & Constants.BAM_FREAD2);\n    }\n    /** @returns {boolean} true if this is a secondary alignment */\n    isSecondary() {\n        return !!(this.flags & Constants.BAM_FSECONDARY);\n    }\n    /** @returns {boolean} true if this read has failed QC checks */\n    isFailedQc() {\n        return !!(this.flags & Constants.BAM_FQCFAIL);\n    }\n    /** @returns {boolean} true if the read is an optical or PCR duplicate */\n    isDuplicate() {\n        return !!(this.flags & Constants.BAM_FDUP);\n    }\n    /** @returns {boolean} true if this is a supplementary alignment */\n    isSupplementary() {\n        return !!(this.flags & Constants.BAM_FSUPPLEMENTARY);\n    }\n    /**\n     * @returns {boolean} true if the read is detached\n     */\n    isDetached() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_DETACHED);\n    }\n    /** @returns {boolean} true if the read has a mate in this same CRAM segment */\n    hasMateDownStream() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_MATE_DOWNSTREAM);\n    }\n    /** @returns {boolean} true if the read contains qual scores */\n    isPreservingQualityScores() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_PRESERVE_QUAL_SCORES);\n    }\n    /** @returns {boolean} true if the read has no sequence bases */\n    isUnknownBases() {\n        return !!(this.cramFlags & Constants.CRAM_FLAG_NO_SEQ);\n    }\n    /**\n     * Get the original sequence of this read.\n     * @returns {String} sequence basepairs\n     */\n    getReadBases() {\n        if (!this.readBases && this._refRegion) {\n            const decoded = decodeReadSequence(this, this._refRegion);\n            if (decoded) {\n                this.readBases = decoded;\n            }\n        }\n        return this.readBases;\n    }\n    /**\n     * Get the pair orientation of a paired read. Adapted from igv.js\n     * @returns {String} of paired orientatin\n     */\n    getPairOrientation() {\n        if (!this.isSegmentUnmapped() &&\n            this.isPaired() &&\n            !this.isMateUnmapped() &&\n            this.mate &&\n            this.sequenceId === this.mate.sequenceId) {\n            const s1 = this.isReverseComplemented() ? 'R' : 'F';\n            const s2 = this.isMateReverseComplemented() ? 'R' : 'F';\n            let o1 = ' ';\n            let o2 = ' ';\n            if (this.isRead1()) {\n                o1 = '1';\n                o2 = '2';\n            }\n            else if (this.isRead2()) {\n                o1 = '2';\n                o2 = '1';\n            }\n            const tmp = [];\n            let isize = this.templateLength || this.templateSize;\n            if (isize === undefined) {\n                throw new Error('One of templateSize and templateLength must be set');\n            }\n            if (this.alignmentStart > this.mate.alignmentStart && isize > 0) {\n                isize = -isize;\n            }\n            if (isize > 0) {\n                tmp[0] = s1;\n                tmp[1] = o1;\n                tmp[2] = s2;\n                tmp[3] = o2;\n            }\n            else {\n                tmp[2] = s1;\n                tmp[3] = o1;\n                tmp[0] = s2;\n                tmp[1] = o2;\n            }\n            return tmp.join('');\n        }\n        return null;\n    }\n    /**\n     * Annotates this feature with the given reference sequence basepair\n     * information. This will add a `sub` and a `ref` item to base\n     * substitution read features given the actual substituted and reference\n     * base pairs, and will make the `getReadSequence()` method work.\n     *\n     * @param {object} refRegion\n     * @param {number} refRegion.start\n     * @param {number} refRegion.end\n     * @param {string} refRegion.seq\n     * @param {CramContainerCompressionScheme} compressionScheme\n     * @returns {undefined} nothing\n     */\n    addReferenceSequence(refRegion, compressionScheme) {\n        if (this.readFeatures) {\n            // use the reference bases to decode the bases\n            // substituted in each base substitution\n            this.readFeatures.forEach(readFeature => {\n                if (readFeature.code === 'X') {\n                    decodeBaseSubstitution(this, refRegion, compressionScheme, readFeature);\n                }\n            });\n        }\n        // if this region completely covers this read,\n        // keep a reference to it\n        if (!this.readBases &&\n            refRegion.start <= this.alignmentStart &&\n            refRegion.end >=\n                this.alignmentStart + (this.lengthOnRef || this.readLength) - 1) {\n            this._refRegion = refRegion;\n        }\n    }\n    toJSON() {\n        const data = {};\n        Object.keys(this).forEach(k => {\n            if (k.startsWith('_')) {\n                return;\n            }\n            data[k] = this[k];\n        });\n        data.readBases = this.getReadBases();\n        return data;\n    }\n}\n//# sourceMappingURL=record.js.map","export class CramError extends Error {\n}\n/** Error caused by encountering a part of the CRAM spec that has not yet been implemented */\nexport class CramUnimplementedError extends Error {\n}\n/** An error caused by malformed data.  */\nexport class CramMalformedError extends CramError {\n}\n/**\n * An error caused by data being too big, exceeding a size limit.\n */\nexport class CramSizeLimitError extends CramError {\n}\n/**\n * An invalid argument was supplied to a cram-js method or object.\n */\nexport class CramArgumentError extends CramError {\n}\n//# sourceMappingURL=errors.js.map","import { inflate } from 'pako';\nimport { Buffer } from 'buffer';\nexport function unzip(input) {\n    return Buffer.from(inflate(input));\n}\n//# sourceMappingURL=unzip-pako.js.map","const TF_SHIFT = 12;\nconst TOTFREQ = 1 << TF_SHIFT;\nconst RANS_BYTE_L = 1 << 23;\nexport { TF_SHIFT, TOTFREQ, RANS_BYTE_L };\n//# sourceMappingURL=constants.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport { RANS_BYTE_L } from './constants';\nclass FC {\n    // int F, C;\n    constructor() {\n        this.F = undefined;\n        this.C = undefined;\n    }\n}\nclass AriDecoder {\n    // final FC[] fc = new FC[256];\n    // byte[] R;\n    constructor() {\n        this.fc = new Array(256);\n        for (let i = 0; i < this.fc.length; i += 1) {\n            this.fc[i] = new FC();\n        }\n        this.R = null;\n    }\n}\nclass DecodingSymbol {\n    // int start; // Start of range.\n    // int freq; // Symbol frequency.\n    constructor() {\n        this.start = undefined;\n        this.freq = undefined;\n    }\n}\n// Initialize a decoder symbol to start \"start\" and frequency \"freq\"\nfunction symbolInit(sym, start, freq) {\n    if (!(start <= 1 << 16)) {\n        throw new CramMalformedError('assertion failed: start <= 1<<16');\n    }\n    if (!(freq <= (1 << 16) - start)) {\n        throw new CramMalformedError('assertion failed: freq <= 1<<16');\n    }\n    sym.start = start;\n    sym.freq = freq;\n}\n// Advances in the bit stream by \"popping\" a single symbol with range start\n// \"start\" and frequency \"freq\". All frequencies are assumed to sum to\n// \"1 << scaleBits\".\n// No renormalization or output happens.\n/* private static int */ function advanceStep(\n/* final int */ r, \n/* final int */ start, \n/* final int */ freq, \n/* final int */ scaleBits) {\n    /* final int */ const mask = (1 << scaleBits) - 1;\n    // s, x = D(x)\n    return freq * (r >> scaleBits) + (r & mask) - start;\n}\n// Equivalent to RansDecAdvanceStep that takes a symbol.\n/* static int  */ function advanceSymbolStep(\n/* final int */ r, \n/* final RansDecSymbol */ sym, \n/* final int */ scaleBits) {\n    return advanceStep(r, sym.start, sym.freq, scaleBits);\n}\n// Returns the current cumulative frequency (map it to a symbol yourself!)\n/* static int */ function get(/* final int */ r, /* final int */ scaleBits) {\n    return r & ((1 << scaleBits) - 1);\n}\n// Advances in the bit stream by \"popping\" a single symbol with range start\n// \"start\" and frequency \"freq\". All frequencies are assumed to sum to\n// \"1 << scaleBits\",\n// and the resulting bytes get written to ptr (which is updated).\n/* private static int */ function advance(\n/* int */ r, \n/* final ByteBuffer */ pptr, \n/* final int */ start, \n/* final int */ freq, \n/* final int */ scaleBits) {\n    /* final int */ const mask = (1 << scaleBits) - 1;\n    // s, x = D(x)\n    r = freq * (r >> scaleBits) + (r & mask) - start;\n    // re-normalize\n    if (r < RANS_BYTE_L) {\n        do {\n            /* final int */ const b = 0xff & pptr.get();\n            r = (r << 8) | b;\n        } while (r < RANS_BYTE_L);\n    }\n    return r;\n}\n// Equivalent to RansDecAdvance that takes a symbol.\n/*  static int */ function advanceSymbol(\n/* final int */ r, \n/* final ByteBuffer */ pptr, \n/* final RansDecSymbol */ sym, \n/* final int */ scaleBits) {\n    return advance(r, pptr, sym.start, sym.freq, scaleBits);\n}\n// Re-normalize.\n/*  static int */ function renormalize(\n/* int */ r, \n/* final ByteBuffer */ pptr) {\n    // re-normalize\n    if (r < RANS_BYTE_L) {\n        do {\n            r = (r << 8) | (0xff & pptr.get());\n        } while (r < RANS_BYTE_L);\n    }\n    return r;\n}\nexport default {\n    FC,\n    AriDecoder,\n    DecodingSymbol,\n    symbolInit,\n    advanceStep,\n    advanceSymbolStep,\n    get,\n    advanceSymbol,\n    renormalize,\n};\n//# sourceMappingURL=decoding.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport { TOTFREQ } from './constants';\nimport Decoding from './decoding';\nfunction assert(result) {\n    if (!result) {\n        throw new CramMalformedError('assertion failed');\n    }\n}\nexport function readStatsO0(\n/* ByteBuffer */ cp, \n/* Decoding.AriDecoder */ decoder, \n/* Decoding.RansDecSymbol[] */ syms) {\n    // Pre-compute reverse lookup of frequency.\n    let rle = 0;\n    let x = 0;\n    let j = cp.get() & 0xff;\n    do {\n        if (decoder.fc[j] == null) {\n            decoder.fc[j] = new Decoding.FC();\n        }\n        decoder.fc[j].F = cp.get() & 0xff;\n        if (decoder.fc[j].F >= 128) {\n            decoder.fc[j].F &= ~128;\n            decoder.fc[j].F = ((decoder.fc[j].F & 127) << 8) | (cp.get() & 0xff);\n        }\n        decoder.fc[j].C = x;\n        Decoding.symbolInit(syms[j], decoder.fc[j].C, decoder.fc[j].F);\n        /* Build reverse lookup table */\n        if (!decoder.R) {\n            decoder.R = new Array(TOTFREQ);\n        }\n        decoder.R.fill(j, x, x + decoder.fc[j].F);\n        x += decoder.fc[j].F;\n        if (rle === 0 && j + 1 === (0xff & cp.getByteAt(cp.position()))) {\n            j = cp.get() & 0xff;\n            rle = cp.get() & 0xff;\n        }\n        else if (rle !== 0) {\n            rle -= 1;\n            j += 1;\n        }\n        else {\n            j = cp.get() & 0xff;\n        }\n    } while (j !== 0);\n    assert(x < TOTFREQ);\n}\nexport function readStatsO1(\n/* ByteBuffer */ cp, \n/*  Decoding.AriDecoder[] */ D, \n/* Decoding.RansDecSymbol[][] */ syms) {\n    let rlei = 0;\n    let i = 0xff & cp.get();\n    do {\n        let rlej = 0;\n        let x = 0;\n        let j = 0xff & cp.get();\n        if (D[i] == null) {\n            D[i] = new Decoding.AriDecoder();\n        }\n        do {\n            if (D[i].fc[j] == null) {\n                D[i].fc[j] = new Decoding.FC();\n            }\n            D[i].fc[j].F = 0xff & cp.get();\n            if (D[i].fc[j].F >= 128) {\n                D[i].fc[j].F &= ~128;\n                D[i].fc[j].F = ((D[i].fc[j].F & 127) << 8) | (0xff & cp.get());\n            }\n            D[i].fc[j].C = x;\n            if (D[i].fc[j].F === 0) {\n                D[i].fc[j].F = TOTFREQ;\n            }\n            if (syms[i][j] == null) {\n                syms[i][j] = new Decoding.RansDecSymbol();\n            }\n            Decoding.symbolInit(syms[i][j], D[i].fc[j].C, D[i].fc[j].F);\n            /* Build reverse lookup table */\n            if (D[i].R == null) {\n                D[i].R = new Array(TOTFREQ);\n            }\n            D[i].R.fill(j, x, x + D[i].fc[j].F);\n            x += D[i].fc[j].F;\n            assert(x <= TOTFREQ);\n            if (rlej === 0 && j + 1 === (0xff & cp.getByteAt(cp.position()))) {\n                j = 0xff & cp.get();\n                rlej = 0xff & cp.get();\n            }\n            else if (rlej !== 0) {\n                rlej -= 1;\n                j += 1;\n            }\n            else {\n                j = 0xff & cp.get();\n            }\n        } while (j !== 0);\n        if (rlei === 0 && i + 1 === (0xff & cp.getByteAt(cp.position()))) {\n            i = 0xff & cp.get();\n            rlei = 0xff & cp.get();\n        }\n        else if (rlei !== 0) {\n            rlei -= 1;\n            i += 1;\n        }\n        else {\n            i = 0xff & cp.get();\n        }\n    } while (i !== 0);\n}\n//# sourceMappingURL=frequencies.js.map","// @ts-nocheck\nimport { CramMalformedError } from '../errors';\nimport { TF_SHIFT } from './constants';\nimport Decoding from './decoding';\nexport default function uncompress(\n/* ByteBuffer */ input, \n/* Decoding.AriDecoder */ D, \n/* Decoding.Symbol[] */ syms, \n/* ByteBuffer */ out) {\n    let rans0 = input.getInt();\n    let rans1 = input.getInt();\n    let rans2 = input.getInt();\n    let rans3 = input.getInt();\n    const /* int */ outputSize = out.remaining();\n    const /* int */ outputEnd = outputSize & ~3;\n    for (let i = 0; i < outputEnd; i += 4) {\n        const /* byte */ c0 = D.R[Decoding.get(rans0, TF_SHIFT)];\n        const /* byte */ c1 = D.R[Decoding.get(rans1, TF_SHIFT)];\n        const /* byte */ c2 = D.R[Decoding.get(rans2, TF_SHIFT)];\n        const /* byte */ c3 = D.R[Decoding.get(rans3, TF_SHIFT)];\n        out.putAt(i, c0);\n        out.putAt(i + 1, c1);\n        out.putAt(i + 2, c2);\n        out.putAt(i + 3, c3);\n        rans0 = Decoding.advanceSymbolStep(rans0, syms[0xff & c0], TF_SHIFT);\n        rans1 = Decoding.advanceSymbolStep(rans1, syms[0xff & c1], TF_SHIFT);\n        rans2 = Decoding.advanceSymbolStep(rans2, syms[0xff & c2], TF_SHIFT);\n        rans3 = Decoding.advanceSymbolStep(rans3, syms[0xff & c3], TF_SHIFT);\n        rans0 = Decoding.renormalize(rans0, input);\n        rans1 = Decoding.renormalize(rans1, input);\n        rans2 = Decoding.renormalize(rans2, input);\n        rans3 = Decoding.renormalize(rans3, input);\n    }\n    out.setPosition(outputEnd);\n    let /* byte */ c;\n    switch (outputSize & 3) {\n        case 0:\n            break;\n        case 1:\n            c = D.R[Decoding.get(rans0, TF_SHIFT)];\n            Decoding.advanceSymbol(rans0, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            break;\n        case 2:\n            c = D.R[Decoding.get(rans0, TF_SHIFT)];\n            Decoding.advanceSymbol(rans0, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            c = D.R[Decoding.get(rans1, TF_SHIFT)];\n            Decoding.advanceSymbol(rans1, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            break;\n        case 3:\n            c = D.R[Decoding.get(rans0, TF_SHIFT)];\n            Decoding.advanceSymbol(rans0, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            c = D.R[Decoding.get(rans1, TF_SHIFT)];\n            Decoding.advanceSymbol(rans1, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            c = D.R[Decoding.get(rans2, TF_SHIFT)];\n            Decoding.advanceSymbol(rans2, input, syms[0xff & c], TF_SHIFT);\n            out.put(c);\n            break;\n        default:\n            throw new CramMalformedError('invalid output size encountered during rANS decoding');\n    }\n    out.setPosition(0);\n}\n//# sourceMappingURL=d04.js.map","// @ts-nocheck\nimport { TF_SHIFT } from './constants';\nimport Decoding from './decoding';\nexport default function uncompress(\n/* ByteBuffer */ input, \n/* ByteBuffer */ output, \n/* Decoding.AriDecoder[] */ D, \n/* Decoding.Symbol[][] */ syms) {\n    const /* int */ outputSize = output.remaining();\n    let rans0 = input.getInt();\n    let rans1 = input.getInt();\n    let rans2 = input.getInt();\n    let rans7 = input.getInt();\n    const /* int */ isz4 = outputSize >> 2;\n    let /* int */ i0 = 0;\n    let /* int */ i1 = isz4;\n    let /* int */ i2 = 2 * isz4;\n    let /* int */ i7 = 3 * isz4;\n    let /* int */ l0 = 0;\n    let /* int */ l1 = 0;\n    let /* int */ l2 = 0;\n    let /* int */ l7 = 0;\n    for (; i0 < isz4; i0 += 1, i1 += 1, i2 += 1, i7 += 1) {\n        const /* int */ c0 = 0xff & D[l0].R[Decoding.get(rans0, TF_SHIFT)];\n        const /* int */ c1 = 0xff & D[l1].R[Decoding.get(rans1, TF_SHIFT)];\n        const /* int */ c2 = 0xff & D[l2].R[Decoding.get(rans2, TF_SHIFT)];\n        const /* int */ c7 = 0xff & D[l7].R[Decoding.get(rans7, TF_SHIFT)];\n        output.putAt(i0, c0);\n        output.putAt(i1, c1);\n        output.putAt(i2, c2);\n        output.putAt(i7, c7);\n        rans0 = Decoding.advanceSymbolStep(rans0, syms[l0][c0], TF_SHIFT);\n        rans1 = Decoding.advanceSymbolStep(rans1, syms[l1][c1], TF_SHIFT);\n        rans2 = Decoding.advanceSymbolStep(rans2, syms[l2][c2], TF_SHIFT);\n        rans7 = Decoding.advanceSymbolStep(rans7, syms[l7][c7], TF_SHIFT);\n        rans0 = Decoding.renormalize(rans0, input);\n        rans1 = Decoding.renormalize(rans1, input);\n        rans2 = Decoding.renormalize(rans2, input);\n        rans7 = Decoding.renormalize(rans7, input);\n        l0 = c0;\n        l1 = c1;\n        l2 = c2;\n        l7 = c7;\n    }\n    // Remainder\n    for (; i7 < outputSize; i7 += 1) {\n        const /* int */ c7 = 0xff & D[l7].R[Decoding.get(rans7, TF_SHIFT)];\n        output.putAt(i7, c7);\n        rans7 = Decoding.advanceSymbol(rans7, input, syms[l7][c7], TF_SHIFT);\n        l7 = c7;\n    }\n}\n//# sourceMappingURL=d14.js.map","// @ts-nocheck\nimport { Buffer } from 'buffer';\nimport { CramMalformedError } from '../errors';\nimport Decoding from './decoding';\nimport { readStatsO0, readStatsO1 } from './frequencies';\nimport D04 from './d04';\nimport D14 from './d14';\n// const /* int */ ORDER_BYTE_LENGTH = 1\n// const /* int */ COMPRESSED_BYTE_LENGTH = 4\nconst /* int */ RAW_BYTE_LENGTH = 4;\n// const /* int */ PREFIX_BYTE_LENGTH =\n//   ORDER_BYTE_LENGTH + COMPRESSED_BYTE_LENGTH + RAW_BYTE_LENGTH\n// enum ORDER {\n//     ZERO, ONE;\n//     static ORDER fromInt(const /* int */ value) {\n//         try {\n//             return ORDER.values()[value];\n//         } catch (const ArrayIndexOutOfBoundsException e) {\n//             throw new RuntimeException(\"Unknown rANS order: \" + value);\n//         }\n//     }\n// }\n// static ByteBuffer compress(const ByteBuffer input, const ORDER order, const ByteBuffer out) {\n//     if (input.remaining() == 0)\n//         return EMPTY_BUFFER;\n//     if (input.remaining() < 4)\n//         return encode_order0_way4(input, out);\n//     switch (order) {\n//         case ZERO:\n//             return encode_order0_way4(input, out);\n//         case ONE:\n//             return encode_order1_way4(input, out);\n//         default:\n//             throw new RuntimeException(\"Unknown rANS order: \" + order);\n//     }\n// }\n// static /* ByteBuffer */ allocateIfNeeded(/* const int */ in_size,\n//                                            /* const ByteBuffer */ out_buf) {\n//     const /* int */ compressedSize = (/* int */) (1.05 * in_size + 257 * 257 * 3 + 4);\n//     if (out_buf == null)\n//         return ByteBuffer.allocate(compressedSize);\n//     if (out_buf.remaining() < compressedSize)\n//         throw new RuntimeException(\"Insufficient buffer size.\");\n//     out_buf.order(ByteOrder.LITTLE_ENDIAN);\n//     return out_buf;\n// }\n// static ByteBuffer encode_order0_way4(const ByteBuffer input,\n//                                              ByteBuffer out_buf) {\n//     const /* int */ in_size = input.remaining();\n//     out_buf = allocateIfNeeded(in_size, out_buf);\n//     const /* int */ freqTableStart = PREFIX_BYTE_LENGTH;\n//     out_buf.position(freqTableStart);\n//     const /* int */[] F = Frequencies.calcFrequencies_o0(in);\n//     const RansEncSymbol[] syms = Frequencies.buildSyms_o0(F);\n//     const ByteBuffer cp = out_buf.slice();\n//     const /* int */ frequencyTable_size = Frequencies.writeFrequencies_o0(cp, F);\n//     input.rewind();\n//     const /* int */ compressedBlob_size = E04.compress(input, syms, cp);\n//     finalizeCompressed(0, out_buf, in_size, frequencyTable_size,\n//             compressedBlob_size);\n//     return out_buf;\n// }\n// static ByteBuffer encode_order1_way4(const ByteBuffer input,\n//                                              ByteBuffer out_buf) {\n//     const /* int */ in_size = input.remaining();\n//     out_buf = allocateIfNeeded(in_size, out_buf);\n//     const /* int */ freqTableStart = PREFIX_BYTE_LENGTH;\n//     out_buf.position(freqTableStart);\n//     const /* int */[][] F = Frequencies.calcFrequencies_o1(in);\n//     const RansEncSymbol[][] syms = Frequencies.buildSyms_o1(F);\n//     const ByteBuffer cp = out_buf.slice();\n//     const /* int */ frequencyTable_size = Frequencies.writeFrequencies_o1(cp, F);\n//     input.rewind();\n//     const /* int */ compressedBlob_size = E14.compress(input, syms, cp);\n//     finalizeCompressed(1, out_buf, in_size, frequencyTable_size,\n//             compressedBlob_size);\n//     return out_buf;\n// }\n// static void finalizeCompressed(const /* int */ order, const ByteBuffer out_buf,\n//                                        const /* int */ in_size, const /* int */ frequencyTable_size, const /* int */ compressedBlob_size) {\n//     out_buf.limit(PREFIX_BYTE_LENGTH + frequencyTable_size\n//             + compressedBlob_size);\n//     out_buf.put(0, (byte) order);\n//     out_buf.order(ByteOrder.LITTLE_ENDIAN);\n//     const /* int */ compressedSizeOffset = ORDER_BYTE_LENGTH;\n//     out_buf.putInt(compressedSizeOffset, frequencyTable_size\n//             + compressedBlob_size);\n//     const /* int */ rawSizeOffset = ORDER_BYTE_LENGTH + COMPRESSED_BYTE_LENGTH;\n//     out_buf.putInt(rawSizeOffset, in_size);\n//     out_buf.rewind();\n// }\nfunction uncompressOrder0Way4(\n/* const ByteBuffer  */ input, \n/* const ByteBuffer  */ out) {\n    // input.order(ByteOrder.LITTLE_ENDIAN);\n    const D = new Decoding.AriDecoder();\n    const syms = new Array(256);\n    for (let i = 0; i < syms.length; i += 1) {\n        syms[i] = new Decoding.DecodingSymbol();\n    }\n    readStatsO0(input, D, syms);\n    D04(input, D, syms, out);\n    return out;\n}\nfunction uncompressOrder1Way4(\n/* const ByteBuffer */ input, \n/* const ByteBuffer */ output) {\n    const D = new Array(256);\n    for (let i = 0; i < D.length; i += 1) {\n        D[i] = new Decoding.AriDecoder();\n    }\n    const /* Decoding.RansDecSymbol[][]  */ syms = new Array(256);\n    for (let i = 0; i < syms.length; i += 1) {\n        syms[i] = new Array(256);\n        for (let j = 0; j < syms[i].length; j += 1) {\n            syms[i][j] = new Decoding.DecodingSymbol();\n        }\n    }\n    readStatsO1(input, D, syms);\n    D14(input, output, D, syms);\n    return output;\n}\n/* compat layer to make a node buffer act like a java ByteBuffer */\nclass ByteBuffer {\n    constructor(nodeBuffer, initialInputPosition = 0) {\n        this._buffer = nodeBuffer;\n        this._position = initialInputPosition;\n        this.length = nodeBuffer.length;\n    }\n    get() {\n        const b = this._buffer[this._position];\n        this._position += 1;\n        return b;\n    }\n    getByte() {\n        return this.get();\n    }\n    getByteAt(position) {\n        return this._buffer[position];\n    }\n    position() {\n        return this._position;\n    }\n    put(val) {\n        this._buffer[this._position] = val;\n        this._position += 1;\n        return val;\n    }\n    putAt(position, val) {\n        this._buffer[position] = val;\n        return val;\n    }\n    setPosition(pos) {\n        this._position = pos;\n        return pos;\n    }\n    getInt() {\n        const i = this._buffer.readInt32LE(this._position);\n        this._position += 4;\n        return i;\n    }\n    remaining() {\n        return this._buffer.length - this._position;\n    }\n}\n// static /* const */ ByteBuffer EMPTY_BUFFER = ByteBuffer.allocate(0);\nexport default function uncompress(inputBuffer, outputBuffer, initialInputPosition = 0) {\n    if (inputBuffer.length === 0) {\n        outputBuffer.fill(0);\n        return outputBuffer;\n    }\n    const input = new ByteBuffer(inputBuffer, initialInputPosition);\n    // input.order(ByteOrder.LITTLE_ENDIAN);\n    const order = input.get();\n    if (order !== 0 && order !== 1) {\n        throw new CramMalformedError(`Invalid rANS order ${order}`);\n    }\n    const /* int */ inputSize = input.getInt();\n    if (inputSize !== input.remaining() - RAW_BYTE_LENGTH) {\n        throw new CramMalformedError('Incorrect input length.');\n    }\n    const /* int */ outputSize = input.getInt();\n    const output = new ByteBuffer(outputBuffer || Buffer.allocUnsafe(outputSize));\n    // TODO output.limit(outputSize)\n    if (output.length < outputSize) {\n        throw new CramMalformedError(`Output buffer too small to fit ${outputSize} bytes.`);\n    }\n    switch (order) {\n        case 0:\n            return uncompressOrder0Way4(input, output);\n        case 1:\n            return uncompressOrder1Way4(input, output);\n        default:\n            throw new CramMalformedError(`Invalid rANS order: ${order}`);\n    }\n}\n//# sourceMappingURL=index.js.map","export class CramBufferOverrunError extends Error {\n}\nexport function getBits(data, cursor, numBits) {\n    let val = 0;\n    if (cursor.bytePosition + (7 - cursor.bitPosition + numBits) / 8 >\n        data.length) {\n        throw new CramBufferOverrunError('read error during decoding. the file seems to be truncated.');\n    }\n    for (let dlen = numBits; dlen; dlen--) {\n        // get the next `dlen` bits in the input, put them in val\n        val <<= 1;\n        val |= (data[cursor.bytePosition] >> cursor.bitPosition) & 1;\n        cursor.bitPosition -= 1;\n        if (cursor.bitPosition < 0) {\n            cursor.bytePosition += 1;\n        }\n        cursor.bitPosition &= 7;\n    }\n    return val;\n}\n//# sourceMappingURL=getBits.js.map","import md5 from 'md5';\nimport Long from 'long';\nimport { CramBufferOverrunError } from './codecs/getBits';\nexport function itf8Size(v) {\n    if (!(v & ~0x7f)) {\n        return 1;\n    }\n    if (!(v & ~0x3fff)) {\n        return 2;\n    }\n    if (!(v & ~0x1fffff)) {\n        return 3;\n    }\n    if (!(v & ~0xfffffff)) {\n        return 4;\n    }\n    return 5;\n}\nexport function parseItf8(buffer, initialOffset) {\n    let offset = initialOffset;\n    const countFlags = buffer[offset];\n    let result;\n    if (countFlags < 0x80) {\n        result = countFlags;\n        offset = offset + 1;\n    }\n    else if (countFlags < 0xc0) {\n        result = ((countFlags << 8) | buffer[offset + 1]) & 0x3fff;\n        offset = offset + 2;\n    }\n    else if (countFlags < 0xe0) {\n        result =\n            ((countFlags << 16) | (buffer[offset + 1] << 8) | buffer[offset + 2]) &\n                0x1fffff;\n        offset = offset + 3;\n    }\n    else if (countFlags < 0xf0) {\n        result =\n            ((countFlags << 24) |\n                (buffer[offset + 1] << 16) |\n                (buffer[offset + 2] << 8) |\n                buffer[offset + 3]) &\n                0x0fffffff;\n        offset = offset + 4;\n    }\n    else {\n        result =\n            ((countFlags & 0x0f) << 28) |\n                (buffer[offset + 1] << 20) |\n                (buffer[offset + 2] << 12) |\n                (buffer[offset + 3] << 4) |\n                (buffer[offset + 4] & 0x0f);\n        // x=((0xff & 0x0f)<<28) | (0xff<<20) | (0xff<<12) | (0xff<<4) | (0x0f & 0x0f);\n        // TODO *val_p = uv < 0x80000000UL ? uv : -((int32_t) (0xffffffffUL - uv)) - 1;\n        offset = offset + 5;\n    }\n    if (offset > buffer.length) {\n        throw new CramBufferOverrunError('Attempted to read beyond end of buffer; this file seems truncated.');\n    }\n    return [result, offset - initialOffset];\n}\nexport function parseLtf8(buffer, initialOffset) {\n    let offset = initialOffset;\n    const countFlags = buffer[offset];\n    let n;\n    if (countFlags < 0x80) {\n        n = countFlags;\n        offset += 1;\n    }\n    else if (countFlags < 0xc0) {\n        n = ((buffer[offset] << 8) | buffer[offset + 1]) & 0x3fff;\n        offset += 2;\n    }\n    else if (countFlags < 0xe0) {\n        n =\n            ((buffer[offset] << 16) |\n                (buffer[offset + 1] << 8) |\n                buffer[offset + 2]) &\n                0x1fffff;\n        n = ((countFlags & 63) << 16) | buffer.readUInt16LE(offset + 1);\n        offset += 3;\n    }\n    else if (countFlags < 0xf0) {\n        n =\n            ((buffer[offset] << 24) |\n                (buffer[offset + 1] << 16) |\n                (buffer[offset + 2] << 8) |\n                buffer[offset + 3]) &\n                0x0fffffff;\n        offset += 4;\n    }\n    else if (countFlags < 0xf8) {\n        n =\n            ((buffer[offset] & 15) * 2 ** 32 + (buffer[offset + 1] << 24)) |\n                ((buffer[offset + 2] << 16) |\n                    (buffer[offset + 3] << 8) |\n                    buffer[offset + 4]);\n        // TODO *val_p = uv < 0x80000000UL ? uv : -((int32_t) (0xffffffffUL - uv)) - 1;\n        offset += 5;\n    }\n    else if (countFlags < 0xfc) {\n        n =\n            ((((buffer[offset] & 7) << 8) | buffer[offset + 1]) * 2 ** 32 +\n                (buffer[offset + 2] << 24)) |\n                ((buffer[offset + 3] << 16) |\n                    (buffer[offset + 4] << 8) |\n                    buffer[offset + 5]);\n        offset += 6;\n    }\n    else if (countFlags < 0xfe) {\n        n =\n            ((((buffer[offset] & 3) << 16) |\n                (buffer[offset + 1] << 8) |\n                buffer[offset + 2]) *\n                2 ** 32 +\n                (buffer[offset + 3] << 24)) |\n                ((buffer[offset + 4] << 16) |\n                    (buffer[offset + 5] << 8) |\n                    buffer[offset + 6]);\n        offset += 7;\n    }\n    else if (countFlags < 0xff) {\n        n = Long.fromBytesBE(buffer.slice(offset + 1, offset + 8));\n        if (n.greaterThan(Number.MAX_SAFE_INTEGER) ||\n            n.lessThan(Number.MIN_SAFE_INTEGER)) {\n            throw new Error('integer overflow');\n        }\n        n = n.toNumber();\n        offset += 8;\n    }\n    else {\n        n = Long.fromBytesBE(buffer.slice(offset + 1, offset + 9));\n        if (n.greaterThan(Number.MAX_SAFE_INTEGER) ||\n            n.lessThan(Number.MIN_SAFE_INTEGER)) {\n            throw new Error('integer overflow');\n        }\n        n = n.toNumber();\n        offset += 9;\n    }\n    return [n, offset - initialOffset];\n}\nexport function parseItem(buffer, parser, startBufferPosition = 0, startFilePosition = 0) {\n    const { offset, value } = parser(buffer, startBufferPosition);\n    return {\n        ...value,\n        _endPosition: offset + startFilePosition,\n        _size: offset - startBufferPosition,\n    };\n}\n// this would be nice as a decorator, but i'm a little worried about babel\n// support for it going away or changing. memoizes a method in the stupidest\n// possible way, with no regard for the arguments.  actually, this only works\n// on methods that take no arguments\nexport function tinyMemoize(_class, methodName) {\n    const method = _class.prototype[methodName];\n    const memoAttrName = `_memo_${methodName}`;\n    _class.prototype[methodName] = function _tinyMemoized() {\n        if (!(memoAttrName in this)) {\n            const res = method.call(this);\n            this[memoAttrName] = res;\n            Promise.resolve(res).catch(() => {\n                delete this[memoAttrName];\n            });\n        }\n        return this[memoAttrName];\n    };\n}\nexport function sequenceMD5(seq) {\n    return md5(seq.toUpperCase().replaceAll(/[^\\u0021-\\u007e]/g, ''));\n}\n//# sourceMappingURL=util.js.map","import { parseItf8, parseLtf8 } from './util';\nexport function cramFileDefinition() {\n    return {\n        parser: (buffer, _startOffset = 0) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            let offset = 0;\n            const magic = buffer.subarray(offset, offset + 4).toString();\n            offset += 4;\n            const majorVersion = dataView.getUint8(offset);\n            offset += 1;\n            const minorVersion = dataView.getUint8(offset);\n            offset += 1;\n            const fileId = b\n                .subarray(offset, offset + 20)\n                .toString()\n                .replaceAll('\\0', '');\n            offset += 20;\n            return {\n                value: {\n                    magic,\n                    majorVersion,\n                    minorVersion,\n                    fileId,\n                },\n                offset,\n            };\n        },\n        maxLength: 26,\n    };\n}\nexport function cramBlockHeader() {\n    const parser = (buffer, _startOffset = 0) => {\n        const b = buffer;\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        const d = dataView.getUint8(offset);\n        const compressionMethod = [\n            'raw',\n            'gzip',\n            'bzip2',\n            'lzma',\n            'rans',\n            'rans4x16',\n            'arith',\n            'fqzcomp',\n            'tok3',\n        ][d];\n        if (!compressionMethod) {\n            throw new Error(`compression method number ${d} not implemented`);\n        }\n        offset += 1;\n        const c = dataView.getUint8(offset);\n        const contentType = [\n            'FILE_HEADER',\n            'COMPRESSION_HEADER',\n            'MAPPED_SLICE_HEADER',\n            'UNMAPPED_SLICE_HEADER', // < only used in cram v1\n            'EXTERNAL_DATA',\n            'CORE_DATA',\n        ][c];\n        if (!contentType) {\n            throw new Error(`invalid block content type id ${c}`);\n        }\n        offset += 1;\n        const [contentId, newOffset1] = parseItf8(buffer, offset);\n        offset += newOffset1;\n        const [compressedSize, newOffset2] = parseItf8(buffer, offset);\n        offset += newOffset2;\n        const [uncompressedSize, newOffset3] = parseItf8(buffer, offset);\n        offset += newOffset3;\n        return {\n            offset,\n            value: {\n                uncompressedSize,\n                compressedSize,\n                contentId,\n                contentType: contentType,\n                compressionMethod: compressionMethod,\n            },\n        };\n    };\n    return { parser, maxLength: 17 };\n}\nexport function cramBlockCrc32() {\n    return {\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const crc32 = dataView.getUint32(offset, true);\n            offset += 4;\n            return {\n                offset,\n                value: {\n                    crc32,\n                },\n            };\n        },\n        maxLength: 4,\n    };\n}\nfunction makeTagSet(buffer, stringStart, stringEnd) {\n    const str = buffer.toString('utf8', stringStart, stringEnd);\n    const tags = [];\n    for (let i = 0; i < str.length; i += 3) {\n        tags.push(str.slice(i, i + 3));\n    }\n    return tags;\n}\nexport function cramTagDictionary() {\n    return {\n        parser: (buffer, offset) => {\n            const [size, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const subbuf = buffer.subarray(offset, offset + size);\n            offset += size;\n            const tagSets = [];\n            let stringStart = 0;\n            let i = 0;\n            for (; i < subbuf.length; i++) {\n                if (!subbuf[i]) {\n                    tagSets.push(makeTagSet(subbuf, stringStart, i));\n                    stringStart = i + 1;\n                }\n            }\n            if (i > stringStart) {\n                tagSets.push(makeTagSet(subbuf, stringStart, i));\n            }\n            return {\n                value: {\n                    size,\n                    ents: tagSets,\n                },\n                offset,\n            };\n        },\n    };\n}\nexport function cramPreservationMap() {\n    return {\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const [mapSize, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [mapCount, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const ents = [];\n            for (let i = 0; i < mapCount; i++) {\n                const key = String.fromCharCode(buffer[offset]) +\n                    String.fromCharCode(buffer[offset + 1]);\n                offset += 2;\n                if (key === 'MI' ||\n                    key === 'UI' ||\n                    key === 'PI' ||\n                    key === 'RN' ||\n                    key === 'AP' ||\n                    key === 'RR') {\n                    ents.push({\n                        key,\n                        value: !!dataView.getUint8(offset),\n                    });\n                    offset += 1;\n                }\n                else if (key === 'SM') {\n                    ents.push({\n                        key,\n                        value: [\n                            dataView.getUint8(offset),\n                            dataView.getUint8(offset + 1),\n                            dataView.getUint8(offset + 2),\n                            dataView.getUint8(offset + 3),\n                            dataView.getUint8(offset + 4),\n                        ],\n                    });\n                    offset += 5;\n                }\n                else if (key === 'TD') {\n                    const { offset: offsetRet, value } = cramTagDictionary().parser(buffer, offset);\n                    ents.push({ key, value: value.ents });\n                    offset = offsetRet;\n                }\n                else {\n                    throw new Error(`unknown key ${key}`);\n                }\n            }\n            return {\n                value: {\n                    mapSize,\n                    mapCount,\n                    ents,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction formatMap(data) {\n    const map = {};\n    for (const { key, value } of data.ents) {\n        if (map[key]) {\n            console.warn(`duplicate key ${key} in map`);\n        }\n        map[key] = value;\n    }\n    return map;\n}\nexport function isMappedSliceHeader(header) {\n    return typeof header.refSeqId === 'number';\n}\n// assemble a section parser for the unmapped slice header, with slight\n// variations depending on the major version of the cram file\nfunction cramUnmappedSliceHeader(majorVersion) {\n    let maxLength = 0;\n    maxLength += 5;\n    maxLength += 9;\n    maxLength += 5 * 2;\n    maxLength += 16;\n    const parser = (buffer, offset) => {\n        const [numRecords, newOffset1] = parseItf8(buffer, offset);\n        offset += newOffset1;\n        let recordCounter = 0;\n        // recordCounter is itf8 in a CRAM v2 file, absent in CRAM v1\n        if (majorVersion >= 3) {\n            const [rc, newOffset2] = parseLtf8(buffer, offset);\n            offset += newOffset2;\n            recordCounter = rc;\n        }\n        else if (majorVersion === 2) {\n            const [rc, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            recordCounter = rc;\n        }\n        else {\n            console.warn('recordCounter=0');\n        }\n        const [numBlocks, newOffset3] = parseItf8(buffer, offset);\n        offset += newOffset3;\n        const [numContentIds, newOffset4] = parseItf8(buffer, offset);\n        offset += newOffset4;\n        const contentIds = [];\n        for (let i = 0; i < numContentIds; i++) {\n            const [id, newOffset5] = parseItf8(buffer, offset);\n            offset += newOffset5;\n            contentIds.push(id);\n        }\n        // the md5 sum is missing in cram v1\n        let md5;\n        if (majorVersion >= 2) {\n            md5 = [...buffer.subarray(offset, offset + 16)];\n            offset += 16;\n        }\n        return {\n            value: {\n                recordCounter,\n                md5,\n                contentIds,\n                numContentIds,\n                numBlocks,\n                numRecords,\n            },\n            offset,\n        };\n    };\n    return {\n        parser,\n        maxLength: (numContentIds) => maxLength + numContentIds * 5,\n    };\n}\n// assembles a section parser for the unmapped slice header, with slight\n// variations depending on the major version of the cram file\nfunction cramMappedSliceHeader(majorVersion) {\n    let maxLength = 0;\n    maxLength += 5 * 4; // EL0\n    maxLength += 9; // EL1\n    maxLength += 5 * 3; // EL2 ITF8s\n    maxLength += 16; // MD5\n    return {\n        parser: (buffer, offset) => {\n            // L0\n            const [refSeqId, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [refSeqStart, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const [refSeqSpan, newOffset3] = parseItf8(buffer, offset);\n            offset += newOffset3;\n            const [numRecords, newOffset4] = parseItf8(buffer, offset);\n            offset += newOffset4;\n            // EL0\n            // L1\n            let recordCounter = 0;\n            if (majorVersion >= 3) {\n                const [rc, newOffset5] = parseLtf8(buffer, offset);\n                offset += newOffset5;\n                recordCounter = rc;\n            }\n            else if (majorVersion === 2) {\n                const [rc, newOffset5] = parseItf8(buffer, offset);\n                offset += newOffset5;\n                recordCounter = rc;\n            }\n            else {\n                console.warn('majorVersion is <2, recordCounter set to 0');\n            }\n            // EL1\n            // L2\n            const [numBlocks, newOffset6] = parseItf8(buffer, offset);\n            offset += newOffset6;\n            const [numContentIds, newOffset7] = parseItf8(buffer, offset);\n            offset += newOffset7;\n            const contentIds = [];\n            for (let i = 0; i < numContentIds; i++) {\n                const [id, newOffset5] = parseItf8(buffer, offset);\n                offset += newOffset5;\n                contentIds.push(id);\n            }\n            const [refBaseBlockId, newOffset8] = parseItf8(buffer, offset);\n            offset += newOffset8;\n            // EL2\n            // the md5 sum is missing in cram v1\n            let md5;\n            if (majorVersion >= 2) {\n                md5 = [...buffer.subarray(offset, offset + 16)];\n                offset += 16;\n            }\n            return {\n                value: {\n                    md5,\n                    numBlocks,\n                    numRecords,\n                    numContentIds,\n                    refSeqSpan,\n                    refSeqId,\n                    refSeqStart,\n                    recordCounter,\n                    refBaseBlockId,\n                    contentIds,\n                },\n                offset,\n            };\n        },\n        maxLength: (numContentIds) => maxLength + numContentIds * 5,\n    };\n}\nfunction cramEncoding() {\n    return {\n        parser: (buffer, offset) => cramEncodingSub(buffer, offset),\n    };\n}\nfunction cramEncodingSub(buffer, offset) {\n    const b = buffer;\n    const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n    const [codecId, newOffset1] = parseItf8(buffer, offset);\n    offset += newOffset1;\n    const [parametersBytes, newOffset2] = parseItf8(buffer, offset);\n    offset += newOffset2;\n    const parameters = {};\n    if (codecId === 0) {\n        // NULL\n    }\n    else if (codecId === 1) {\n        // EXTERNAL\n        const [bc, newOffset3] = parseItf8(buffer, offset);\n        parameters.blockContentId = bc;\n        offset += newOffset3;\n    }\n    else if (codecId === 2) {\n        // GOLUMB\n        const [off, newOffset3] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset3;\n        const [M2, newOffset4] = parseItf8(buffer, offset);\n        parameters.M = M2;\n        offset += newOffset4;\n    }\n    else if (codecId === 3) {\n        // HUFFMAN_INT\n        const val = parseItf8(buffer, offset);\n        const numCodes = val[0];\n        offset += val[1];\n        const symbols = [];\n        for (let i = 0; i < numCodes; i++) {\n            const code = parseItf8(buffer, offset);\n            symbols.push(code[0]);\n            offset += code[1];\n        }\n        parameters.symbols = symbols;\n        const val2 = parseItf8(buffer, offset);\n        const numLengths = val[0];\n        parameters.numLengths = numLengths;\n        parameters.numCodes = numCodes;\n        parameters.numLengths = numLengths;\n        offset += val2[1];\n        const bitLengths = [];\n        for (let i = 0; i < numLengths; i++) {\n            const len = parseItf8(buffer, offset);\n            offset += len[1];\n            bitLengths.push(len[0]);\n        }\n        parameters.bitLengths = bitLengths;\n    }\n    else if (codecId === 4) {\n        // BYTE_ARRAY_LEN\n        const { value: lengthsEncoding, offset: newOffset1 } = cramEncodingSub(buffer, offset);\n        parameters.lengthsEncoding = lengthsEncoding;\n        offset = newOffset1;\n        const { value: valuesEncoding, offset: newOffset2 } = cramEncodingSub(buffer, offset);\n        parameters.valuesEncoding = valuesEncoding;\n        offset = newOffset2;\n    }\n    else if (codecId === 5) {\n        // BYTE_ARRAY_STOP\n        parameters.stopByte = dataView.getUint8(offset);\n        offset += 1;\n        const [blockContentId, newOffset1] = parseItf8(buffer, offset);\n        parameters.blockContentId = blockContentId;\n        offset += newOffset1;\n    }\n    else if (codecId === 6) {\n        // BETA\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n        const [len, newOffset2] = parseItf8(buffer, offset);\n        parameters.length = len;\n        offset += newOffset2;\n    }\n    else if (codecId === 7) {\n        // SUBEXP\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n        const [K, newOffset2] = parseItf8(buffer, offset);\n        parameters.K = K;\n        offset += newOffset2;\n    }\n    else if (codecId === 8) {\n        // GOLOMB_RICE\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n        const [l2m, newOffset2] = parseItf8(buffer, offset);\n        parameters.log2m = l2m;\n        offset += newOffset2;\n    }\n    else if (codecId === 9) {\n        // GAMMA\n        const [off, newOffset1] = parseItf8(buffer, offset);\n        parameters.offset = off;\n        offset += newOffset1;\n    }\n    else {\n        throw new Error(`unknown codecId ${codecId}`);\n    }\n    return {\n        value: {\n            codecId,\n            parametersBytes,\n            parameters,\n        },\n        offset,\n    };\n}\nfunction cramDataSeriesEncodingMap() {\n    return {\n        parser: (buffer, offset) => {\n            const [mapSize, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [mapCount, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const ents = [];\n            for (let i = 0; i < mapCount; i++) {\n                const key = String.fromCharCode(buffer[offset]) +\n                    String.fromCharCode(buffer[offset + 1]);\n                offset += 2;\n                const { value, offset: newOffset4 } = cramEncodingSub(buffer, offset);\n                offset = newOffset4;\n                ents.push({ key, value });\n            }\n            return {\n                value: {\n                    mapSize,\n                    ents,\n                    mapCount,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramTagEncodingMap() {\n    return {\n        parser: (buffer, offset) => {\n            const [mapSize, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [mapCount, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const ents = [];\n            for (let i = 0; i < mapCount; i++) {\n                const [k0, newOffset3] = parseItf8(buffer, offset);\n                offset += newOffset3;\n                const key = String.fromCharCode((k0 >> 16) & 0xff) +\n                    String.fromCharCode((k0 >> 8) & 0xff) +\n                    String.fromCharCode(k0 & 0xff);\n                const { value, offset: newOffset4 } = cramEncodingSub(buffer, offset);\n                offset = newOffset4;\n                ents.push({ key, value });\n            }\n            return {\n                value: {\n                    mapSize,\n                    ents,\n                    mapCount,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramCompressionHeader() {\n    return {\n        parser: (buffer, offset) => {\n            // TODO: if we want to support CRAM v1, we will need to refactor\n            // compression header into 2 parts to parse the landmarks, like the\n            // container header\n            const { value: preservation, offset: newOffset1 } = cramPreservationMap().parser(buffer, offset);\n            offset = newOffset1;\n            const { value: dataSeriesEncoding, offset: newOffset2 } = cramDataSeriesEncodingMap().parser(buffer, offset);\n            offset = newOffset2;\n            const { value: tagEncoding, offset: newOffset3 } = cramTagEncodingMap().parser(buffer, offset);\n            offset = newOffset3;\n            return {\n                value: {\n                    dataSeriesEncoding: formatMap(dataSeriesEncoding),\n                    preservation: formatMap(preservation),\n                    tagEncoding: formatMap(tagEncoding),\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramContainerHeader1(majorVersion) {\n    let maxLength = 4;\n    maxLength += 5 * 4;\n    maxLength += 9;\n    maxLength += 9;\n    maxLength += 5 + 5;\n    return {\n        maxLength,\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            // byte size of the container data (blocks)\n            const length = dataView.getInt32(offset, true);\n            offset += 4;\n            // reference sequence identifier, -1 for unmapped reads, -2 for multiple\n            // reference sequences\n            const [refSeqId, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const [refSeqStart, newOffset2] = parseItf8(buffer, offset);\n            offset += newOffset2;\n            const [alignmentSpan, newOffset3] = parseItf8(buffer, offset);\n            offset += newOffset3;\n            const [numRecords, newOffset4] = parseItf8(buffer, offset);\n            offset += newOffset4;\n            let recordCounter = 0;\n            if (majorVersion >= 3) {\n                const [rc, newOffset5] = parseLtf8(buffer, offset);\n                recordCounter = rc;\n                offset += newOffset5;\n            }\n            else if (majorVersion === 2) {\n                const [rc, newOffset5] = parseItf8(buffer, offset);\n                recordCounter = rc;\n                offset += newOffset5;\n            }\n            else {\n                console.warn('setting recordCounter=0');\n            }\n            let numBases;\n            if (majorVersion > 1) {\n                const [n, newOffset5] = parseLtf8(buffer, offset);\n                numBases = n;\n                offset += newOffset5;\n            }\n            const [numBlocks, newOffset6] = parseItf8(buffer, offset);\n            offset += newOffset6;\n            const [numLandmarks, newOffset7] = parseItf8(buffer, offset);\n            offset += newOffset7;\n            return {\n                value: {\n                    length,\n                    refSeqId,\n                    refSeqStart,\n                    alignmentSpan,\n                    numBlocks,\n                    numLandmarks,\n                    numBases,\n                    recordCounter,\n                    numRecords,\n                },\n                offset,\n            };\n        },\n    };\n}\nfunction cramContainerHeader2(majorVersion) {\n    return {\n        parser: (buffer, offset) => {\n            const b = buffer;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            const [numLandmarks, newOffset1] = parseItf8(buffer, offset);\n            offset += newOffset1;\n            const landmarks = [];\n            for (let i = 0; i < numLandmarks; i++) {\n                const [landmark, newOffset2] = parseItf8(buffer, offset);\n                offset += newOffset2;\n                landmarks.push(landmark);\n            }\n            let crc32;\n            if (majorVersion >= 3) {\n                crc32 = dataView.getUint32(offset, true);\n                offset += 4;\n            }\n            return {\n                value: {\n                    ...(crc32 === undefined ? {} : { crc32 }),\n                    numLandmarks,\n                    landmarks,\n                },\n                offset,\n            };\n        },\n        maxLength: (numLandmarks) => 5 + 5 * numLandmarks + 4,\n    };\n}\nexport function getSectionParsers(majorVersion) {\n    return {\n        cramFileDefinition: cramFileDefinition(),\n        cramBlockHeader: cramBlockHeader(),\n        cramBlockCrc32: cramBlockCrc32(),\n        cramDataSeriesEncodingMap: cramDataSeriesEncodingMap(),\n        cramTagEncodingMap: cramTagEncodingMap(),\n        cramCompressionHeader: cramCompressionHeader(),\n        cramEncoding: cramEncoding(),\n        cramUnmappedSliceHeader: cramUnmappedSliceHeader(majorVersion),\n        cramMappedSliceHeader: cramMappedSliceHeader(majorVersion),\n        cramContainerHeader1: cramContainerHeader1(majorVersion),\n        cramContainerHeader2: cramContainerHeader2(majorVersion),\n    };\n}\n//# sourceMappingURL=sectionParsers.js.map","import { CramMalformedError } from '../../errors';\nimport { BamFlagsDecoder, CramFlagsDecoder, MateFlagsDecoder, } from '../record';\nimport { isMappedSliceHeader } from '../sectionParsers';\n/**\n * given a Buffer, read a string up to the first null character\n * @private\n */\nfunction readNullTerminatedString(buffer) {\n    let r = '';\n    for (let i = 0; i < buffer.length && buffer[i] !== 0; i++) {\n        r += String.fromCharCode(buffer[i]);\n    }\n    return r;\n}\n/**\n * parse a BAM tag's array value from a binary buffer\n * @private\n */\nfunction parseTagValueArray(buffer) {\n    const arrayType = String.fromCharCode(buffer[0]);\n    const dataView = new DataView(buffer.buffer);\n    const littleEndian = true;\n    const length = dataView.getUint32(1, littleEndian);\n    const array = new Array(length);\n    buffer = buffer.slice(5);\n    if (arrayType === 'c') {\n        const arr = new Int8Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'C') {\n        const arr = new Uint8Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 's') {\n        const arr = new Int16Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'S') {\n        const arr = new Uint16Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'i') {\n        const arr = new Int32Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'I') {\n        const arr = new Uint32Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else if (arrayType === 'f') {\n        const arr = new Float32Array(buffer.buffer);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = arr[i];\n        }\n    }\n    else {\n        throw new Error(`unknown type: ${arrayType}`);\n    }\n    return array;\n}\nfunction parseTagData(tagType, buffer) {\n    if (tagType === 'Z') {\n        return readNullTerminatedString(buffer);\n    }\n    if (tagType === 'A') {\n        return String.fromCharCode(buffer[0]);\n    }\n    if (tagType === 'I') {\n        return new Uint32Array(buffer.buffer)[0];\n    }\n    if (tagType === 'i') {\n        return new Int32Array(buffer.buffer)[0];\n    }\n    if (tagType === 's') {\n        return new Int16Array(buffer.buffer)[0];\n    }\n    if (tagType === 'S') {\n        return new Uint16Array(buffer.buffer)[0];\n    }\n    if (tagType === 'c') {\n        return new Int8Array(buffer.buffer)[0];\n    }\n    if (tagType === 'C') {\n        return buffer[0];\n    }\n    if (tagType === 'f') {\n        return new Float32Array(buffer.buffer)[0];\n    }\n    if (tagType === 'H') {\n        return Number.parseInt(readNullTerminatedString(buffer).replace(/^0x/, ''), 16);\n    }\n    if (tagType === 'B') {\n        return parseTagValueArray(buffer);\n    }\n    throw new CramMalformedError(`Unrecognized tag type ${tagType}`);\n}\nfunction decodeReadFeatures(alignmentStart, readFeatureCount, decodeDataSeries, compressionScheme, majorVersion) {\n    let currentReadPos = 0;\n    let currentRefPos = alignmentStart - 1;\n    const readFeatures = new Array(readFeatureCount);\n    function decodeRFData([type, dataSeriesName]) {\n        const data = decodeDataSeries(dataSeriesName);\n        if (type === 'character') {\n            return String.fromCharCode(data);\n        }\n        if (type === 'string') {\n            let r = '';\n            for (let i = 0; i < data.byteLength; i++) {\n                r += String.fromCharCode(data[i]);\n            }\n            return r;\n        }\n        if (type === 'numArray') {\n            return data.toArray();\n        }\n        // else if (type === 'number') {\n        //   return data[0]\n        // }\n        return data;\n    }\n    for (let i = 0; i < readFeatureCount; i += 1) {\n        const code = String.fromCharCode(decodeDataSeries('FC'));\n        const readPosDelta = decodeDataSeries('FP');\n        // map of operator name -> data series name\n        const data1Schema = {\n            B: ['character', 'BA'],\n            S: ['string', majorVersion > 1 ? 'SC' : 'IN'], // IN if cram v1, SC otherwise\n            X: ['number', 'BS'],\n            D: ['number', 'DL'],\n            I: ['string', 'IN'],\n            i: ['character', 'BA'],\n            b: ['string', 'BB'],\n            q: ['numArray', 'QQ'],\n            Q: ['number', 'QS'],\n            H: ['number', 'HC'],\n            P: ['number', 'PD'],\n            N: ['number', 'RS'],\n        }[code];\n        if (!data1Schema) {\n            throw new CramMalformedError(`invalid read feature code \"${code}\"`);\n        }\n        let data = decodeRFData(data1Schema);\n        // if this is a tag with two data items, make the data an array and add the second item\n        const data2Schema = { B: ['number', 'QS'] }[code];\n        if (data2Schema) {\n            data = [data, decodeRFData(data2Schema)];\n        }\n        currentReadPos += readPosDelta;\n        const pos = currentReadPos;\n        currentRefPos += readPosDelta;\n        const refPos = currentRefPos;\n        // for gapping features, adjust the reference position for read features that follow\n        if (code === 'D' || code === 'N') {\n            currentRefPos += data;\n        }\n        else if (code === 'I' || code === 'S') {\n            currentRefPos -= data.length;\n        }\n        else if (code === 'i') {\n            currentRefPos -= 1;\n        }\n        readFeatures[i] = { code, pos, refPos, data };\n    }\n    return readFeatures;\n}\nexport default function decodeRecord(slice, decodeDataSeries, compressionScheme, sliceHeader, coreDataBlock, blocksByContentId, cursors, majorVersion, recordNumber) {\n    let flags = decodeDataSeries('BF');\n    // note: the C data type of compressionFlags is byte in cram v1\n    // and int32 in cram v2+, but that does not matter for us here\n    // in javascript land.\n    const cramFlags = decodeDataSeries('CF');\n    if (!isMappedSliceHeader(sliceHeader.parsedContent)) {\n        throw new Error('slice header not mapped');\n    }\n    const sequenceId = majorVersion > 1 && sliceHeader.parsedContent.refSeqId === -2\n        ? decodeDataSeries('RI')\n        : sliceHeader.parsedContent.refSeqId;\n    const readLength = decodeDataSeries('RL');\n    // if APDelta, will calculate the true start in a second pass\n    let alignmentStart = decodeDataSeries('AP');\n    if (compressionScheme.APdelta) {\n        alignmentStart = alignmentStart + cursors.lastAlignmentStart;\n    }\n    cursors.lastAlignmentStart = alignmentStart;\n    const readGroupId = decodeDataSeries('RG');\n    let readName;\n    if (compressionScheme.readNamesIncluded) {\n        readName = readNullTerminatedString(decodeDataSeries('RN'));\n    }\n    let mateToUse;\n    let templateSize;\n    let mateRecordNumber;\n    // mate record\n    if (CramFlagsDecoder.isDetached(cramFlags)) {\n        // note: the MF is a byte in 1.0, int32 in 2+, but once again this doesn't\n        // matter for javascript\n        const mateFlags = decodeDataSeries('MF');\n        let mateReadName;\n        if (!compressionScheme.readNamesIncluded) {\n            mateReadName = readNullTerminatedString(decodeDataSeries('RN'));\n            readName = mateReadName;\n        }\n        const mateSequenceId = decodeDataSeries('NS');\n        const mateAlignmentStart = decodeDataSeries('NP');\n        if (mateFlags || mateSequenceId > -1) {\n            mateToUse = {\n                mateFlags,\n                mateSequenceId,\n                mateAlignmentStart,\n                mateReadName,\n            };\n        }\n        templateSize = decodeDataSeries('TS');\n        // set mate unmapped if needed\n        if (MateFlagsDecoder.isUnmapped(mateFlags)) {\n            flags = BamFlagsDecoder.setMateUnmapped(flags);\n        }\n        // set mate reversed if needed\n        if (MateFlagsDecoder.isOnNegativeStrand(mateFlags)) {\n            flags = BamFlagsDecoder.setMateReverseComplemented(flags);\n        }\n        // detachedCount++\n    }\n    else if (CramFlagsDecoder.isWithMateDownstream(cramFlags)) {\n        mateRecordNumber = decodeDataSeries('NF') + recordNumber + 1;\n    }\n    // TODO: the aux tag parsing will have to be refactored if we want to support\n    // cram v1\n    const TLindex = decodeDataSeries('TL');\n    if (TLindex < 0) {\n        /* TODO: check nTL: TLindex >= compressionHeader.tagEncoding.size */\n        throw new CramMalformedError('invalid TL index');\n    }\n    const tags = {};\n    // TN = tag names\n    const TN = compressionScheme.getTagNames(TLindex);\n    const ntags = TN.length;\n    for (let i = 0; i < ntags; i += 1) {\n        const tagId = TN[i];\n        const tagName = tagId.slice(0, 2);\n        const tagType = tagId.slice(2, 3);\n        const tagData = compressionScheme\n            .getCodecForTag(tagId)\n            .decode(slice, coreDataBlock, blocksByContentId, cursors);\n        tags[tagName] =\n            typeof tagData === 'number' ? tagData : parseTagData(tagType, tagData);\n    }\n    let readFeatures;\n    let lengthOnRef;\n    let mappingQuality;\n    let qualityScores;\n    let readBases = undefined;\n    if (!BamFlagsDecoder.isSegmentUnmapped(flags)) {\n        // reading read features\n        const readFeatureCount = decodeDataSeries('FN');\n        if (readFeatureCount) {\n            readFeatures = decodeReadFeatures(alignmentStart, readFeatureCount, decodeDataSeries, compressionScheme, majorVersion);\n        }\n        // compute the read's true span on the reference sequence, and the end\n        // coordinate of the alignment on the reference\n        lengthOnRef = readLength;\n        if (readFeatures) {\n            for (const { code, data } of readFeatures) {\n                if (code === 'D' || code === 'N') {\n                    lengthOnRef += data;\n                }\n                else if (code === 'I' || code === 'S') {\n                    lengthOnRef = lengthOnRef - data.length;\n                }\n                else if (code === 'i') {\n                    lengthOnRef = lengthOnRef - 1;\n                }\n            }\n        }\n        if (Number.isNaN(lengthOnRef)) {\n            console.warn(`${readName || `${sequenceId}:${alignmentStart}`} record has invalid read features`);\n            lengthOnRef = readLength;\n        }\n        // mapping quality\n        mappingQuality = decodeDataSeries('MQ');\n        if (CramFlagsDecoder.isPreservingQualityScores(cramFlags)) {\n            qualityScores = new Array(readLength);\n            for (let i = 0; i < qualityScores.length; i++) {\n                qualityScores[i] = decodeDataSeries('QS');\n            }\n        }\n    }\n    else if (CramFlagsDecoder.isDecodeSequenceAsStar(cramFlags)) {\n        readBases = null;\n        qualityScores = null;\n    }\n    else {\n        const bases = new Array(readLength);\n        for (let i = 0; i < bases.length; i += 1) {\n            bases[i] = decodeDataSeries('BA');\n        }\n        readBases = String.fromCharCode(...bases);\n        if (CramFlagsDecoder.isPreservingQualityScores(cramFlags)) {\n            qualityScores = new Array(readLength);\n            for (let i = 0; i < bases.length; i += 1) {\n                qualityScores[i] = decodeDataSeries('QS');\n            }\n        }\n    }\n    return {\n        readLength,\n        sequenceId,\n        cramFlags,\n        flags,\n        alignmentStart,\n        readGroupId,\n        readName,\n        mateToUse,\n        templateSize,\n        mateRecordNumber,\n        readFeatures,\n        lengthOnRef,\n        mappingQuality,\n        qualityScores,\n        readBases,\n        tags,\n    };\n}\n//# sourceMappingURL=decodeRecord.js.map","import { CramArgumentError, CramMalformedError } from '../../errors';\nimport { parseItem, sequenceMD5, tinyMemoize } from '../util';\nimport Constants from '../constants';\nimport decodeRecord from './decodeRecord';\nimport CramRecord from '../record';\nimport { getSectionParsers, isMappedSliceHeader, } from '../sectionParsers';\nimport { CramBufferOverrunError } from '../codecs/getBits';\n/**\n * @private\n * Try to estimate the template length from a bunch of interrelated multi-segment reads.\n * @param {Array[CramRecord]} allRecords\n * @param {number} currentRecordNumber\n * @param {CramRecord} thisRecord\n */\nfunction calculateMultiSegmentMatedTemplateLength(allRecords, currentRecordNumber, thisRecord) {\n    function getAllMatedRecords(startRecord) {\n        const records = [startRecord];\n        if (startRecord.mateRecordNumber !== undefined &&\n            startRecord.mateRecordNumber >= 0) {\n            const mateRecord = allRecords[startRecord.mateRecordNumber];\n            if (!mateRecord) {\n                throw new CramMalformedError('intra-slice mate record not found, this file seems malformed');\n            }\n            records.push(...getAllMatedRecords(mateRecord));\n        }\n        return records;\n    }\n    const matedRecords = getAllMatedRecords(thisRecord);\n    const starts = matedRecords.map(r => r.alignmentStart);\n    const ends = matedRecords.map(r => r.alignmentStart + r.readLength - 1);\n    const estimatedTemplateLength = Math.max(...ends) - Math.min(...starts) + 1;\n    if (estimatedTemplateLength >= 0) {\n        matedRecords.forEach(r => {\n            if (r.templateLength !== undefined) {\n                throw new CramMalformedError('mate pair group has some members that have template lengths already, this file seems malformed');\n            }\n            r.templateLength = estimatedTemplateLength;\n        });\n    }\n}\n/**\n * @private\n * Attempt to calculate the `templateLength` for a pair of intra-slice paired reads.\n * Ported from htslib. Algorithm is imperfect.\n * @param {CramRecord} thisRecord\n * @param {CramRecord} mateRecord\n */\nfunction calculateIntraSliceMatePairTemplateLength(thisRecord, mateRecord) {\n    // this just estimates the template length by using the simple (non-gapped) end coordinate of each\n    // read, because gapping in the alignment doesn't mean the template is longer or shorter\n    const start = Math.min(thisRecord.alignmentStart, mateRecord.alignmentStart);\n    const end = Math.max(thisRecord.alignmentStart + thisRecord.readLength - 1, mateRecord.alignmentStart + mateRecord.readLength - 1);\n    const lengthEstimate = end - start + 1;\n    thisRecord.templateLength = lengthEstimate;\n    mateRecord.templateLength = lengthEstimate;\n}\n/**\n * @private establishes a mate-pair relationship between two records in the\n * same slice. CRAM compresses mate-pair relationships between records in the\n * same slice down into just one record having the index in the slice of its\n * mate\n */\nfunction associateIntraSliceMate(allRecords, currentRecordNumber, thisRecord, mateRecord) {\n    const complicatedMultiSegment = !!(mateRecord.mate ||\n        (mateRecord.mateRecordNumber !== undefined &&\n            mateRecord.mateRecordNumber !== currentRecordNumber));\n    // Deal with lossy read names\n    if (!thisRecord.readName) {\n        thisRecord.readName = String(thisRecord.uniqueId);\n        mateRecord.readName = thisRecord.readName;\n    }\n    thisRecord.mate = {\n        sequenceId: mateRecord.sequenceId,\n        alignmentStart: mateRecord.alignmentStart,\n        uniqueId: mateRecord.uniqueId,\n    };\n    if (mateRecord.readName) {\n        thisRecord.mate.readName = mateRecord.readName;\n    }\n    // the mate record might have its own mate pointer, if this is some kind of\n    // multi-segment (more than paired) scheme, so only relate that one back to this one\n    // if it does not have any other relationship\n    if (!mateRecord.mate && mateRecord.mateRecordNumber === undefined) {\n        mateRecord.mate = {\n            sequenceId: thisRecord.sequenceId,\n            alignmentStart: thisRecord.alignmentStart,\n            uniqueId: thisRecord.uniqueId,\n        };\n        if (thisRecord.readName) {\n            mateRecord.mate.readName = thisRecord.readName;\n        }\n    }\n    // make sure the proper flags and cramFlags are set on both records\n    // paired\n    thisRecord.flags |= Constants.BAM_FPAIRED;\n    // set mate unmapped if needed\n    if (mateRecord.flags & Constants.BAM_FUNMAP) {\n        thisRecord.flags |= Constants.BAM_FMUNMAP;\n        // thisRecord.templateLength = 0\n    }\n    if (thisRecord.flags & Constants.BAM_FUNMAP) {\n        // thisRecord.templateLength = 0\n        mateRecord.flags |= Constants.BAM_FMUNMAP;\n    }\n    // set mate reversed if needed\n    if (mateRecord.flags & Constants.BAM_FREVERSE) {\n        thisRecord.flags |= Constants.BAM_FMREVERSE;\n    }\n    if (thisRecord.flags & Constants.BAM_FREVERSE) {\n        mateRecord.flags |= Constants.BAM_FMREVERSE;\n    }\n    if (thisRecord.templateLength === undefined) {\n        if (complicatedMultiSegment) {\n            calculateMultiSegmentMatedTemplateLength(allRecords, currentRecordNumber, thisRecord);\n        }\n        else {\n            calculateIntraSliceMatePairTemplateLength(thisRecord, mateRecord);\n        }\n    }\n    // delete this last because it's used by the\n    // complicated template length estimation\n    thisRecord.mateRecordNumber = undefined;\n}\nexport default class CramSlice {\n    constructor(container, containerPosition, sliceSize) {\n        this.container = container;\n        this.containerPosition = containerPosition;\n        this.sliceSize = sliceSize;\n        this.file = container.file;\n    }\n    // memoize\n    async getHeader() {\n        // fetch and parse the slice header\n        const { majorVersion } = await this.file.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const containerHeader = await this.container.getHeader();\n        if (!containerHeader) {\n            throw new Error('no container header detected');\n        }\n        const header = await this.file.readBlock(containerHeader._endPosition + this.containerPosition);\n        if (header === undefined) {\n            throw new Error('block header undefined');\n        }\n        if (header.contentType === 'MAPPED_SLICE_HEADER') {\n            const content = parseItem(header.content, sectionParsers.cramMappedSliceHeader.parser, 0, containerHeader._endPosition);\n            return { ...header, parsedContent: content };\n        }\n        else if (header.contentType === 'UNMAPPED_SLICE_HEADER') {\n            const content = parseItem(header.content, sectionParsers.cramUnmappedSliceHeader.parser, 0, containerHeader._endPosition);\n            return { ...header, parsedContent: content };\n        }\n        else {\n            throw new CramMalformedError(`error reading slice header block, invalid content type ${header.contentType}`);\n        }\n    }\n    // memoize\n    async getBlocks() {\n        const header = await this.getHeader();\n        // read all the blocks into memory and store them\n        let blockPosition = header._endPosition;\n        const blocks = new Array(header.parsedContent.numBlocks);\n        for (let i = 0; i < blocks.length; i++) {\n            const block = await this.file.readBlock(blockPosition);\n            if (block === undefined) {\n                throw new Error('block undefined');\n            }\n            blocks[i] = block;\n            blockPosition = blocks[i]._endPosition;\n        }\n        return blocks;\n    }\n    // no memoize\n    async getCoreDataBlock() {\n        const blocks = await this.getBlocks();\n        return blocks[0];\n    }\n    // memoize\n    async _getBlocksContentIdIndex() {\n        const blocks = await this.getBlocks();\n        const blocksByContentId = {};\n        blocks.forEach(block => {\n            if (block.contentType === 'EXTERNAL_DATA') {\n                blocksByContentId[block.contentId] = block;\n            }\n        });\n        return blocksByContentId;\n    }\n    async getBlockByContentId(id) {\n        const blocksByContentId = await this._getBlocksContentIdIndex();\n        return blocksByContentId[id];\n    }\n    async getReferenceRegion() {\n        // read the slice header\n        const sliceHeader = (await this.getHeader()).parsedContent;\n        if (!isMappedSliceHeader(sliceHeader)) {\n            throw new Error('slice header not mapped');\n        }\n        if (sliceHeader.refSeqId < 0) {\n            return undefined;\n        }\n        const compressionScheme = await this.container.getCompressionScheme();\n        if (compressionScheme === undefined) {\n            throw new Error('compression scheme undefined');\n        }\n        if (sliceHeader.refBaseBlockId >= 0) {\n            const refBlock = await this.getBlockByContentId(sliceHeader.refBaseBlockId);\n            if (!refBlock) {\n                throw new CramMalformedError('embedded reference specified, but reference block does not exist');\n            }\n            // TODO: we do not read anything named 'span'\n            // if (sliceHeader.span > refBlock.uncompressedSize) {\n            //   throw new CramMalformedError('Embedded reference is too small')\n            // }\n            // TODO verify\n            return {\n                seq: refBlock.data.toString('utf8'),\n                start: sliceHeader.refSeqStart,\n                end: sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1,\n                span: sliceHeader.refSeqSpan,\n            };\n        }\n        if (compressionScheme.referenceRequired ||\n            this.file.fetchReferenceSequenceCallback) {\n            if (!this.file.fetchReferenceSequenceCallback) {\n                throw new Error('reference sequence not embedded, and seqFetch callback not provided, cannot fetch reference sequence');\n            }\n            const seq = await this.file.fetchReferenceSequenceCallback(sliceHeader.refSeqId, sliceHeader.refSeqStart, sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1);\n            if (seq.length !== sliceHeader.refSeqSpan) {\n                throw new CramArgumentError('seqFetch callback returned a reference sequence of the wrong length');\n            }\n            return {\n                seq,\n                start: sliceHeader.refSeqStart,\n                end: sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1,\n                span: sliceHeader.refSeqSpan,\n            };\n        }\n        return undefined;\n    }\n    getAllRecords() {\n        return this.getRecords(() => true);\n    }\n    async _fetchRecords() {\n        var _a, _b;\n        const { majorVersion } = await this.file.getDefinition();\n        const compressionScheme = await this.container.getCompressionScheme();\n        if (compressionScheme === undefined) {\n            throw new Error('compression scheme undefined');\n        }\n        const sliceHeader = await this.getHeader();\n        const blocksByContentId = await this._getBlocksContentIdIndex();\n        // check MD5 of reference if available\n        if (majorVersion > 1 &&\n            this.file.options.checkSequenceMD5 &&\n            isMappedSliceHeader(sliceHeader.parsedContent) &&\n            sliceHeader.parsedContent.refSeqId >= 0 &&\n            ((_a = sliceHeader.parsedContent.md5) === null || _a === void 0 ? void 0 : _a.join('')) !== '0000000000000000') {\n            const refRegion = await this.getReferenceRegion();\n            if (refRegion) {\n                const { seq, start, end } = refRegion;\n                const seqMd5 = sequenceMD5(seq);\n                const storedMd5 = (_b = sliceHeader.parsedContent.md5) === null || _b === void 0 ? void 0 : _b.map(byte => (byte < 16 ? '0' : '') + byte.toString(16)).join('');\n                if (seqMd5 !== storedMd5) {\n                    throw new CramMalformedError(`MD5 checksum reference mismatch for ref ${sliceHeader.parsedContent.refSeqId} pos ${start}..${end}. recorded MD5: ${storedMd5}, calculated MD5: ${seqMd5}`);\n                }\n            }\n        }\n        // tracks the read position within the block. codec.decode() methods\n        // advance the byte and bit positions in the cursor as they decode\n        // data note that we are only decoding a single block here, the core\n        // data block\n        const coreDataBlock = await this.getCoreDataBlock();\n        const cursors = {\n            lastAlignmentStart: isMappedSliceHeader(sliceHeader.parsedContent)\n                ? sliceHeader.parsedContent.refSeqStart\n                : 0,\n            coreBlock: { bitPosition: 7, bytePosition: 0 },\n            externalBlocks: {\n                map: new Map(),\n                getCursor(contentId) {\n                    let r = this.map.get(contentId);\n                    if (r === undefined) {\n                        r = { bitPosition: 7, bytePosition: 0 };\n                        this.map.set(contentId, r);\n                    }\n                    return r;\n                },\n            },\n        };\n        const decodeDataSeries = (dataSeriesName) => {\n            const codec = compressionScheme.getCodecForDataSeries(dataSeriesName);\n            if (!codec) {\n                throw new CramMalformedError(`no codec defined for ${dataSeriesName} data series`);\n            }\n            // console.log(dataSeriesName, Object.getPrototypeOf(codec))\n            const decoded = codec.decode(this, coreDataBlock, blocksByContentId, cursors);\n            return decoded;\n        };\n        const records = new Array(sliceHeader.parsedContent.numRecords);\n        for (let i = 0; i < records.length; i += 1) {\n            try {\n                const init = decodeRecord(this, decodeDataSeries, compressionScheme, sliceHeader, coreDataBlock, blocksByContentId, cursors, majorVersion, i);\n                records[i] = new CramRecord({\n                    ...init,\n                    uniqueId: sliceHeader.contentPosition +\n                        sliceHeader.parsedContent.recordCounter +\n                        i +\n                        1,\n                });\n            }\n            catch (e) {\n                if (e instanceof CramBufferOverrunError) {\n                    console.warn('read attempted beyond end of buffer, file seems truncated.');\n                    break;\n                }\n                else {\n                    throw e;\n                }\n            }\n        }\n        // interpret `recordsToNextFragment` attributes to make standard `mate`\n        // objects Resolve mate pair cross-references between records in this slice\n        for (let i = 0; i < records.length; i += 1) {\n            const { mateRecordNumber } = records[i];\n            if (mateRecordNumber !== undefined && mateRecordNumber >= 0) {\n                associateIntraSliceMate(records, i, records[i], records[mateRecordNumber]);\n            }\n        }\n        return records;\n    }\n    async getRecords(filterFunction) {\n        // fetch the features if necessary, using the file-level feature cache\n        const cacheKey = this.container.filePosition + this.containerPosition;\n        let recordsPromise = this.file.featureCache.get(cacheKey.toString());\n        if (!recordsPromise) {\n            recordsPromise = this._fetchRecords();\n            this.file.featureCache.set(cacheKey.toString(), recordsPromise);\n        }\n        const unfiltered = await recordsPromise;\n        const records = unfiltered.filter(filterFunction);\n        // if we can fetch reference sequence, add the reference sequence to the records\n        if (records.length && this.file.fetchReferenceSequenceCallback) {\n            const sliceHeader = await this.getHeader();\n            if (isMappedSliceHeader(sliceHeader.parsedContent) &&\n                (sliceHeader.parsedContent.refSeqId >= 0 || // single-ref slice\n                    sliceHeader.parsedContent.refSeqId === -2) // multi-ref slice\n            ) {\n                const singleRefId = sliceHeader.parsedContent.refSeqId >= 0\n                    ? sliceHeader.parsedContent.refSeqId\n                    : undefined;\n                const compressionScheme = await this.container.getCompressionScheme();\n                if (compressionScheme === undefined) {\n                    throw new Error('compression scheme undefined');\n                }\n                const refRegions = {};\n                // iterate over the records to find the spans of the reference\n                // sequences we need to fetch\n                for (const record of records) {\n                    const seqId = singleRefId !== undefined ? singleRefId : record.sequenceId;\n                    let refRegion = refRegions[seqId];\n                    if (!refRegion) {\n                        refRegion = {\n                            id: seqId,\n                            start: record.alignmentStart,\n                            end: Number.NEGATIVE_INFINITY,\n                            seq: null,\n                        };\n                        refRegions[seqId] = refRegion;\n                    }\n                    const end = record.alignmentStart +\n                        (record.lengthOnRef || record.readLength) -\n                        1;\n                    if (end > refRegion.end) {\n                        refRegion.end = end;\n                    }\n                    if (record.alignmentStart < refRegion.start) {\n                        refRegion.start = record.alignmentStart;\n                    }\n                }\n                // fetch the `seq` for all of the ref regions\n                await Promise.all(Object.values(refRegions).map(async (refRegion) => {\n                    if (refRegion.id !== -1 &&\n                        refRegion.start <= refRegion.end &&\n                        this.file.fetchReferenceSequenceCallback) {\n                        refRegion.seq = await this.file.fetchReferenceSequenceCallback(refRegion.id, refRegion.start, refRegion.end);\n                    }\n                }));\n                // now decorate all the records with them\n                for (const record of records) {\n                    const seqId = singleRefId !== undefined ? singleRefId : record.sequenceId;\n                    const refRegion = refRegions[seqId];\n                    if (refRegion === null || refRegion === void 0 ? void 0 : refRegion.seq) {\n                        const seq = refRegion.seq;\n                        record.addReferenceSequence({ ...refRegion, seq }, compressionScheme);\n                    }\n                }\n            }\n        }\n        return records;\n    }\n}\n// memoize several methods in the class for performance\n'getHeader getBlocks _getBlocksContentIdIndex'.split(' ').forEach(method => {\n    tinyMemoize(CramSlice, method);\n});\n//# sourceMappingURL=index.js.map","// codec base class\nexport default class CramCodec {\n    constructor(parameters, dataType) {\n        this.parameters = parameters;\n        this.dataType = dataType;\n    }\n}\n//# sourceMappingURL=_base.js.map","import { CramMalformedError } from '../../errors';\nimport CramCodec from './_base';\nimport { getBits } from './getBits';\nfunction numberOfSetBits(ii) {\n    let i = (ii - (ii >> 1)) & 0x55555555;\n    i = (i & 0x33333333) + ((i >> 2) & 0x33333333);\n    return (((i + (i >> 4)) & 0x0f0f0f0f) * 0x01010101) >> 24;\n}\nexport default class HuffmanIntCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        this.codes = {};\n        this.codeBook = {};\n        this.sortedCodes = [];\n        this.sortedValuesByBitCode = [];\n        this.sortedBitCodes = [];\n        this.sortedBitLengthsByBitCode = [];\n        this.bitCodeToValue = [];\n        if (!['byte', 'int'].includes(this.dataType)) {\n            throw new TypeError(`${this.dataType} decoding not yet implemented by HUFFMAN_INT codec`);\n        }\n        this.buildCodeBook();\n        this.buildCodes();\n        this.buildCaches();\n        // if this is a degenerate zero-length huffman code, special-case the\n        // decoding\n        if (this.sortedCodes[0].bitLength === 0) {\n            this._decode = this._decodeZeroLengthCode;\n        }\n    }\n    buildCodeBook() {\n        // parse the parameters together into a `codes` data structure\n        let codes = new Array(this.parameters.numCodes);\n        for (let i = 0; i < this.parameters.numCodes; i++) {\n            codes[i] = {\n                symbol: this.parameters.symbols[i],\n                bitLength: this.parameters.bitLengths[i],\n            };\n        }\n        // sort the codes by bit length and symbol value\n        codes = codes.sort((a, b) => a.bitLength - b.bitLength || a.symbol - b.symbol);\n        this.codeBook = {};\n        codes.forEach(code => {\n            if (!this.codeBook[code.bitLength]) {\n                this.codeBook[code.bitLength] = [];\n            }\n            this.codeBook[code.bitLength].push(code.symbol);\n        });\n    }\n    buildCodes() {\n        this.codes = {}; /*  new TreeMap<Integer, HuffmanBitCode>(); */\n        let codeLength = 0;\n        let codeValue = -1;\n        Object.entries(this.codeBook).forEach(([bitLength, symbols]) => {\n            const bitLengthInt = Number.parseInt(bitLength, 10);\n            symbols.forEach(symbol => {\n                const code = {\n                    bitLength: bitLengthInt,\n                    value: symbol,\n                    bitCode: 0,\n                };\n                codeValue = codeValue + 1;\n                const delta = bitLengthInt - codeLength; // new length?\n                codeValue = codeValue << delta; // pad with 0's\n                code.bitCode = codeValue; // calculated: huffman code\n                codeLength = codeLength + delta; // adjust current code length\n                if (numberOfSetBits(codeValue) > bitLengthInt) {\n                    throw new CramMalformedError('Symbol out of range');\n                }\n                this.codes[symbol] = code;\n            });\n        });\n    }\n    buildCaches() {\n        this.sortedCodes = Object.values(this.codes).sort((a, b) => a.bitLength - b.bitLength || a.bitCode - b.bitCode);\n        this.sortedValuesByBitCode = this.sortedCodes.map(c => c.value);\n        this.sortedBitCodes = this.sortedCodes.map(c => c.bitCode);\n        this.sortedBitLengthsByBitCode = this.sortedCodes.map(c => c.bitLength);\n        const maxBitCode = Math.max(...this.sortedBitCodes);\n        this.bitCodeToValue = new Array(maxBitCode + 1).fill(-1);\n        for (let i = 0; i < this.sortedBitCodes.length; i += 1) {\n            this.bitCodeToValue[this.sortedCodes[i].bitCode] = i;\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        return this._decode(slice, coreDataBlock, cursors.coreBlock);\n    }\n    // _decodeNull() {\n    //   return -1\n    // }\n    // the special case for zero-length codes\n    _decodeZeroLengthCode() {\n        return this.sortedCodes[0].value;\n    }\n    _decode(slice, coreDataBlock, coreCursor) {\n        const input = coreDataBlock.content;\n        let prevLen = 0;\n        let bits = 0;\n        for (let i = 0; i < this.sortedCodes.length; i += 1) {\n            const length = this.sortedCodes[i].bitLength;\n            bits <<= length - prevLen;\n            bits |= getBits(input, coreCursor, length - prevLen);\n            prevLen = length;\n            {\n                const index = this.bitCodeToValue[bits];\n                if (index > -1 && this.sortedBitLengthsByBitCode[index] === length) {\n                    return this.sortedValuesByBitCode[index];\n                }\n                for (let j = i; this.sortedCodes[j + 1].bitLength === length &&\n                    j < this.sortedCodes.length; j += 1) {\n                    i += 1;\n                }\n            }\n        }\n        throw new CramMalformedError('Huffman symbol not found.');\n    }\n}\n//# sourceMappingURL=huffman.js.map","import { CramMalformedError, CramUnimplementedError } from '../../errors';\nimport CramCodec from './_base';\nimport { parseItf8 } from '../util';\nimport { CramBufferOverrunError } from './getBits';\nexport default class ExternalCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType === 'int') {\n            this._decodeData = this._decodeInt;\n        }\n        else if (this.dataType === 'byte') {\n            this._decodeData = this._decodeByte;\n        }\n        else {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by EXTERNAL codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const { blockContentId } = this.parameters;\n        const contentBlock = blocksByContentId[blockContentId];\n        if (!contentBlock) {\n            throw new CramMalformedError(`no block found with content ID ${blockContentId}}`);\n        }\n        const cursor = cursors.externalBlocks.getCursor(blockContentId);\n        return this._decodeData(contentBlock, cursor);\n    }\n    _decodeInt(contentBlock, cursor) {\n        const [result, bytesRead] = parseItf8(contentBlock.content, cursor.bytePosition);\n        cursor.bytePosition = cursor.bytePosition + bytesRead;\n        return result;\n    }\n    _decodeByte(contentBlock, cursor) {\n        if (cursor.bytePosition >= contentBlock.content.length) {\n            throw new CramBufferOverrunError('attempted to read beyond end of block. this file seems truncated.');\n        }\n        return contentBlock.content[cursor.bytePosition++];\n    }\n}\n//# sourceMappingURL=external.js.map","import { CramMalformedError } from '../../errors';\nimport CramCodec from './_base';\nimport { CramBufferOverrunError } from './getBits';\nexport default class ByteArrayStopCodec extends CramCodec {\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const { blockContentId } = this.parameters;\n        const contentBlock = blocksByContentId[blockContentId];\n        if (!contentBlock) {\n            throw new CramMalformedError(`no block found with content ID ${blockContentId}`);\n        }\n        const cursor = cursors.externalBlocks.getCursor(blockContentId);\n        return this._decodeByteArray(contentBlock, cursor);\n    }\n    _decodeByteArray(contentBlock, cursor) {\n        const dataBuffer = contentBlock.content;\n        const { stopByte } = this.parameters;\n        // scan to the next stop byte\n        const startPosition = cursor.bytePosition;\n        let stopPosition = cursor.bytePosition;\n        while (dataBuffer[stopPosition] !== stopByte &&\n            stopPosition < dataBuffer.length) {\n            if (stopPosition === dataBuffer.length) {\n                throw new CramBufferOverrunError('byteArrayStop reading beyond length of data buffer?');\n            }\n            stopPosition = stopPosition + 1;\n        }\n        cursor.bytePosition = stopPosition + 1;\n        return dataBuffer.subarray(startPosition, stopPosition);\n    }\n}\n//# sourceMappingURL=byteArrayStop.js.map","import CramCodec from './_base';\nimport { tinyMemoize } from '../util';\nexport default class ByteArrayStopCodec extends CramCodec {\n    constructor(parameters, dataType, instantiateCodec) {\n        super(parameters, dataType);\n        this.instantiateCodec = instantiateCodec;\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const lengthCodec = this._getLengthCodec();\n        const arrayLength = lengthCodec.decode(slice, coreDataBlock, blocksByContentId, cursors);\n        const dataCodec = this._getDataCodec();\n        const data = new Uint8Array(arrayLength);\n        for (let i = 0; i < arrayLength; i += 1) {\n            data[i] = dataCodec.decode(slice, coreDataBlock, blocksByContentId, cursors);\n        }\n        return data;\n    }\n    // memoize\n    _getLengthCodec() {\n        const encodingParams = this.parameters.lengthsEncoding;\n        return this.instantiateCodec(encodingParams, 'int');\n    }\n    // memoize\n    _getDataCodec() {\n        const encodingParams = this.parameters.valuesEncoding;\n        return this.instantiateCodec(encodingParams, 'byte');\n    }\n}\n'_getLengthCodec _getDataCodec'.split(' ').forEach(method => {\n    tinyMemoize(ByteArrayStopCodec, method);\n});\n//# sourceMappingURL=byteArrayLength.js.map","import { CramUnimplementedError } from '../../errors';\nimport CramCodec from './_base';\nimport { getBits } from './getBits';\nexport default class BetaCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType !== 'int') {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by BETA codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        const fromBits = getBits(coreDataBlock.content, cursors.coreBlock, this.parameters.length);\n        return fromBits - this.parameters.offset;\n    }\n}\n//# sourceMappingURL=beta.js.map","import { CramUnimplementedError } from '../../errors';\nimport CramCodec from './_base';\nimport { getBits } from './getBits';\nexport default class GammaCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType !== 'int') {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by GAMMA codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        let length = 1;\n        while (getBits(coreDataBlock.content, cursors.coreBlock, 1) === 0) {\n            length = length + 1;\n        }\n        const readBits = getBits(coreDataBlock.content, cursors.coreBlock, length - 1);\n        const value = readBits | (1 << (length - 1));\n        return value - this.parameters.offset;\n    }\n}\n//# sourceMappingURL=gamma.js.map","import { CramUnimplementedError } from '../../errors';\nimport CramCodec from './_base';\nimport { getBits } from './getBits';\nexport default class SubexpCodec extends CramCodec {\n    constructor(parameters, dataType) {\n        super(parameters, dataType);\n        if (this.dataType !== 'int') {\n            throw new CramUnimplementedError(`${this.dataType} decoding not yet implemented by SUBEXP codec`);\n        }\n    }\n    decode(slice, coreDataBlock, blocksByContentId, cursors) {\n        let numLeadingOnes = 0;\n        while (getBits(coreDataBlock.content, cursors.coreBlock, 1)) {\n            numLeadingOnes = numLeadingOnes + 1;\n        }\n        let b;\n        let n;\n        if (numLeadingOnes === 0) {\n            b = this.parameters.K;\n            n = getBits(coreDataBlock.content, cursors.coreBlock, b);\n        }\n        else {\n            b = numLeadingOnes + this.parameters.K - 1;\n            const bits = getBits(coreDataBlock.content, cursors.coreBlock, b);\n            n = (1 << b) | bits;\n        }\n        return n - this.parameters.offset;\n    }\n}\n//# sourceMappingURL=subexp.js.map","import { CramUnimplementedError } from '../../errors';\nimport HuffmanIntCodec from './huffman';\nimport ExternalCodec from './external';\nimport ByteArrayStopCodec from './byteArrayStop';\nimport ByteArrayLengthCodec from './byteArrayLength';\nimport BetaCodec from './beta';\nimport GammaCodec from './gamma';\nimport SubexpCodec from './subexp';\nconst codecClasses = {\n    1: ExternalCodec,\n    // 2: GolombCodec,\n    3: HuffmanIntCodec,\n    4: ByteArrayLengthCodec,\n    5: ByteArrayStopCodec,\n    6: BetaCodec,\n    7: SubexpCodec,\n    // 8: GolombRiceCodec,\n    9: GammaCodec,\n};\nfunction getCodecClassWithId(id) {\n    return codecClasses[id];\n}\nexport function instantiateCodec(encodingData, dataType) {\n    const CodecClass = getCodecClassWithId(dataType === 'ignore' ? 0 : encodingData.codecId);\n    if (!CodecClass) {\n        throw new CramUnimplementedError(`no codec implemented for codec ID ${encodingData.codecId}`);\n    }\n    return new CodecClass(encodingData.parameters, dataType, instantiateCodec);\n}\n//# sourceMappingURL=index.js.map","import { instantiateCodec } from '../codecs';\nimport { CramMalformedError } from '../../errors';\n// the hardcoded data type to be decoded for each core\n// data field\nconst dataSeriesTypes = {\n    BF: 'int',\n    CF: 'int',\n    RI: 'int',\n    RL: 'int',\n    AP: 'int',\n    RG: 'int',\n    MF: 'int',\n    NS: 'int',\n    NP: 'int',\n    TS: 'int',\n    NF: 'int',\n    TC: 'byte',\n    TN: 'int',\n    FN: 'int',\n    FC: 'byte',\n    FP: 'int',\n    BS: 'byte',\n    IN: 'byteArray',\n    SC: 'byteArray',\n    DL: 'int',\n    BA: 'byte',\n    BB: 'byteArray',\n    RS: 'int',\n    PD: 'int',\n    HC: 'int',\n    MQ: 'int',\n    RN: 'byteArray',\n    QS: 'byte',\n    QQ: 'byteArray',\n    TL: 'int',\n    // TM: 'ignore',\n    // TV: 'ignore',\n};\nfunction parseSubstitutionMatrix(byteArray) {\n    const matrix = new Array(5);\n    for (let i = 0; i < 5; i += 1) {\n        matrix[i] = new Array(4);\n    }\n    matrix[0][(byteArray[0] >> 6) & 3] = 'C';\n    matrix[0][(byteArray[0] >> 4) & 3] = 'G';\n    matrix[0][(byteArray[0] >> 2) & 3] = 'T';\n    matrix[0][(byteArray[0] >> 0) & 3] = 'N';\n    matrix[1][(byteArray[1] >> 6) & 3] = 'A';\n    matrix[1][(byteArray[1] >> 4) & 3] = 'G';\n    matrix[1][(byteArray[1] >> 2) & 3] = 'T';\n    matrix[1][(byteArray[1] >> 0) & 3] = 'N';\n    matrix[2][(byteArray[2] >> 6) & 3] = 'A';\n    matrix[2][(byteArray[2] >> 4) & 3] = 'C';\n    matrix[2][(byteArray[2] >> 2) & 3] = 'T';\n    matrix[2][(byteArray[2] >> 0) & 3] = 'N';\n    matrix[3][(byteArray[3] >> 6) & 3] = 'A';\n    matrix[3][(byteArray[3] >> 4) & 3] = 'C';\n    matrix[3][(byteArray[3] >> 2) & 3] = 'G';\n    matrix[3][(byteArray[3] >> 0) & 3] = 'N';\n    matrix[4][(byteArray[4] >> 6) & 3] = 'A';\n    matrix[4][(byteArray[4] >> 4) & 3] = 'C';\n    matrix[4][(byteArray[4] >> 2) & 3] = 'G';\n    matrix[4][(byteArray[4] >> 0) & 3] = 'T';\n    return matrix;\n}\nexport default class CramContainerCompressionScheme {\n    constructor(content) {\n        this.dataSeriesCodecCache = {};\n        this.tagCodecCache = {};\n        this.tagEncoding = {};\n        // interpret some of the preservation map tags for convenient use\n        this.readNamesIncluded = content.preservation.RN;\n        this.APdelta = content.preservation.AP;\n        this.referenceRequired = !!content.preservation.RR;\n        this.tagIdsDictionary = content.preservation.TD;\n        this.substitutionMatrix = parseSubstitutionMatrix(content.preservation.SM);\n        this.dataSeriesEncoding = content.dataSeriesEncoding;\n        this.tagEncoding = content.tagEncoding;\n    }\n    /**\n     * @param {string} tagName three-character tag name\n     * @private\n     */\n    getCodecForTag(tagName) {\n        const test = this.tagCodecCache[tagName];\n        if (!test) {\n            const encodingData = this.tagEncoding[tagName];\n            if (!encodingData) {\n                throw new Error('Error, no tag encoding');\n            }\n            const ret = instantiateCodec(encodingData, 'byteArray');\n            this.tagCodecCache[tagName] = ret;\n            return ret;\n        }\n        else {\n            return test;\n        }\n    }\n    /**\n     *\n     * @param {number} tagListId ID of the tag list to fetch from the tag dictionary\n     * @private\n     */\n    getTagNames(tagListId) {\n        return this.tagIdsDictionary[tagListId];\n    }\n    getCodecForDataSeries(dataSeriesName) {\n        let r = this.dataSeriesCodecCache[dataSeriesName];\n        if (r === undefined) {\n            const encodingData = this.dataSeriesEncoding[dataSeriesName];\n            // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n            if (encodingData) {\n                const dataType = dataSeriesTypes[dataSeriesName];\n                // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n                if (!dataType) {\n                    throw new CramMalformedError(`data series name ${dataSeriesName} not defined in file compression header`);\n                }\n                r = instantiateCodec(encodingData, dataType);\n                // didn't find a way to make TS understand this\n                this.dataSeriesCodecCache[dataSeriesName] = r;\n            }\n        }\n        return r;\n    }\n    toJSON() {\n        const data = {};\n        Object.keys(this).forEach(k => {\n            if (k.endsWith('Cache')) {\n                return;\n            }\n            data[k] = this[k];\n        });\n        return data;\n    }\n}\n//# sourceMappingURL=compressionScheme.js.map","import { Buffer } from 'buffer';\nimport { CramMalformedError } from '../../errors';\n// locals\nimport { itf8Size, parseItem, tinyMemoize } from '../util';\nimport CramSlice from '../slice';\nimport CramContainerCompressionScheme from './compressionScheme';\nimport { getSectionParsers } from '../sectionParsers';\nexport default class CramContainer {\n    constructor(file, filePosition) {\n        this.file = file;\n        this.filePosition = filePosition;\n    }\n    getHeader() {\n        return this._readContainerHeader(this.filePosition);\n    }\n    async getCompressionHeaderBlock() {\n        const containerHeader = await this.getHeader();\n        // if there are no records in the container, there will be no compression\n        // header\n        if (!(containerHeader === null || containerHeader === void 0 ? void 0 : containerHeader.numRecords)) {\n            return null;\n        }\n        const { majorVersion } = await this.file.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const block = await this.getFirstBlock();\n        if (block === undefined) {\n            return undefined;\n        }\n        if (block.contentType !== 'COMPRESSION_HEADER') {\n            throw new CramMalformedError(`invalid content type ${block.contentType} in compression header block`);\n        }\n        const content = parseItem(block.content, sectionParsers.cramCompressionHeader.parser, 0, block.contentPosition);\n        return {\n            ...block,\n            parsedContent: content,\n        };\n    }\n    async getFirstBlock() {\n        const containerHeader = await this.getHeader();\n        if (!containerHeader) {\n            return undefined;\n        }\n        return this.file.readBlock(containerHeader._endPosition);\n    }\n    // parses the compression header data into a CramContainerCompressionScheme\n    // object\n    async getCompressionScheme() {\n        const header = await this.getCompressionHeaderBlock();\n        if (!header) {\n            return undefined;\n        }\n        return new CramContainerCompressionScheme(header.parsedContent);\n    }\n    getSlice(slicePosition, sliceSize) {\n        // note: slicePosition is relative to the end of the container header\n        // TODO: perhaps we should cache slices?\n        return new CramSlice(this, slicePosition, sliceSize);\n    }\n    async _readContainerHeader(position) {\n        const { majorVersion } = await this.file.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const { cramContainerHeader1, cramContainerHeader2 } = sectionParsers;\n        const { size: fileSize } = await this.file.stat();\n        if (position >= fileSize) {\n            console.warn(`pos:${position}>=fileSize:${fileSize} in cram container`);\n            return undefined;\n        }\n        // parse the container header. do it in 2 pieces because you cannot tell\n        // how much to buffer until you read numLandmarks\n        const bytes1 = Buffer.allocUnsafe(cramContainerHeader1.maxLength);\n        await this.file.read(bytes1, 0, cramContainerHeader1.maxLength, position);\n        const header1 = parseItem(bytes1, cramContainerHeader1.parser);\n        const numLandmarksSize = itf8Size(header1.numLandmarks);\n        if (position + header1.length >= fileSize) {\n            // header indicates container goes beyond fileSize\n            console.warn(`container at ${position} is beyond fileSize:${fileSize}, skipping`);\n            return undefined;\n        }\n        const bytes2 = Buffer.allocUnsafe(cramContainerHeader2.maxLength(header1.numLandmarks));\n        await this.file.read(bytes2, 0, cramContainerHeader2.maxLength(header1.numLandmarks), position + header1._size - numLandmarksSize);\n        const header2 = parseItem(bytes2, cramContainerHeader2.parser);\n        if (this.file.validateChecksums && header2.crc32 !== undefined) {\n            await this.file.checkCrc32(position, header1._size + header2._size - numLandmarksSize - 4, header2.crc32, `container header beginning at position ${position}`);\n        }\n        const completeHeader = Object.assign(header1, header2, {\n            _size: header1._size + header2._size - numLandmarksSize,\n            _endPosition: header1._size + header2._size - numLandmarksSize + position,\n        });\n        return completeHeader;\n    }\n}\n'getHeader getCompressionHeaderBlock getCompressionScheme'\n    .split(' ')\n    .forEach(method => {\n    tinyMemoize(CramContainer, method);\n});\n//# sourceMappingURL=index.js.map","import { LocalFile, RemoteFile } from 'generic-filehandle';\nfunction open(maybeUrl, maybePath, maybeFilehandle) {\n    if (maybeFilehandle) {\n        return maybeFilehandle;\n    }\n    if (maybeUrl) {\n        return new RemoteFile(maybeUrl);\n    }\n    if (maybePath) {\n        return new LocalFile(maybePath);\n    }\n    throw new Error('no url, path, or filehandle provided, cannot open');\n}\nexport { open };\nexport { LocalFile, RemoteFile } from 'generic-filehandle';\n//# sourceMappingURL=index.js.map","export function parseHeaderText(text) {\n    const lines = text.split(/\\r?\\n/);\n    const data = [];\n    for (const line of lines) {\n        const [tag, ...fields] = line.split(/\\t/);\n        if (tag) {\n            data.push({\n                tag: tag.slice(1),\n                data: fields.map(f => {\n                    const r = f.indexOf(':');\n                    return r !== -1\n                        ? {\n                            tag: f.slice(0, r),\n                            value: f.slice(r + 1),\n                        }\n                        : // @CO lines are not comma separated.\n                            // See \"samtools view -H c2\\#pad.3.0.cram\"\n                            // so, just store value tag and value itself\n                            {\n                                tag: f,\n                                value: '',\n                            };\n                }),\n            });\n        }\n    }\n    return data;\n}\n//# sourceMappingURL=sam.js.map","import { Buffer } from 'buffer';\nimport crc32 from 'crc/crc32';\nimport QuickLRU from 'quick-lru';\nimport htscodecs from '../htscodecs';\nimport bzip2 from 'bzip2';\nimport { XzReadableStream } from 'xz-decompress';\nimport { CramMalformedError, CramUnimplementedError } from '../errors';\n// locals\nimport { unzip } from '../unzip';\nimport ransuncompress from '../rans';\nimport { cramFileDefinition, getSectionParsers, } from './sectionParsers';\nimport CramContainer from './container';\nimport { open } from '../io';\nimport { parseItem, tinyMemoize } from './util';\nimport { parseHeaderText } from '../sam';\nfunction bufferToStream(buf) {\n    return new ReadableStream({\n        start(controller) {\n            controller.enqueue(buf);\n            controller.close();\n        },\n    });\n}\n// source: https://abdulapopoola.com/2019/01/20/check-endianness-with-javascript/\nfunction getEndianness() {\n    const uInt32 = new Uint32Array([0x11223344]);\n    const uInt8 = new Uint8Array(uInt32.buffer);\n    if (uInt8[0] === 0x44) {\n        return 0; // little-endian\n    }\n    else if (uInt8[0] === 0x11) {\n        return 1; // big-endian\n    }\n    else {\n        return 2; // mixed-endian?\n    }\n}\nexport default class CramFile {\n    constructor(args) {\n        var _a;\n        this.file = open(args.url, args.path, args.filehandle);\n        this.validateChecksums = true;\n        this.fetchReferenceSequenceCallback = args.seqFetch;\n        this.options = {\n            checkSequenceMD5: args.checkSequenceMD5,\n            cacheSize: (_a = args.cacheSize) !== null && _a !== void 0 ? _a : 20000,\n        };\n        // cache of features in a slice, keyed by the slice offset. caches all of\n        // the features in a slice, or none. the cache is actually used by the\n        // slice object, it's just kept here at the level of the file\n        this.featureCache = new QuickLRU({\n            maxSize: this.options.cacheSize,\n        });\n        if (getEndianness() > 0) {\n            throw new Error('Detected big-endian machine, may be unable to run');\n        }\n    }\n    // can just read this object like a filehandle\n    read(buffer, offset, length, position) {\n        return this.file.read(buffer, offset, length, position);\n    }\n    // can just stat this object like a filehandle\n    stat() {\n        return this.file.stat();\n    }\n    // memoized\n    async getDefinition() {\n        const { maxLength, parser } = cramFileDefinition();\n        const headbytes = Buffer.allocUnsafe(maxLength);\n        await this.file.read(headbytes, 0, maxLength, 0);\n        const definition = parser(headbytes).value;\n        if (definition.majorVersion !== 2 && definition.majorVersion !== 3) {\n            throw new CramUnimplementedError(`CRAM version ${definition.majorVersion} not supported`);\n        }\n        return definition;\n    }\n    // memoize\n    async getSamHeader() {\n        const firstContainer = await this.getContainerById(0);\n        if (!firstContainer) {\n            throw new CramMalformedError('file contains no containers');\n        }\n        const firstBlock = await firstContainer.getFirstBlock();\n        if (firstBlock === undefined) {\n            return parseHeaderText('');\n        }\n        const content = firstBlock.content;\n        const headerLength = content.readInt32LE(0);\n        const textStart = 4;\n        const text = content.toString('utf8', textStart, textStart + headerLength);\n        this.header = text;\n        return parseHeaderText(text);\n    }\n    async getHeaderText() {\n        await this.getSamHeader();\n        return this.header;\n    }\n    async getContainerById(containerNumber) {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        let position = sectionParsers.cramFileDefinition.maxLength;\n        const { size: fileSize } = await this.file.stat();\n        const { cramContainerHeader1 } = sectionParsers;\n        // skip with a series of reads to the proper container\n        let currentContainer;\n        for (let i = 0; i <= containerNumber; i++) {\n            // if we are about to go off the end of the file\n            // and have not found that container, it does not exist\n            if (position + cramContainerHeader1.maxLength + 8 >= fileSize) {\n                return undefined;\n            }\n            currentContainer = this.getContainerAtPosition(position);\n            const currentHeader = await currentContainer.getHeader();\n            if (!currentHeader) {\n                throw new CramMalformedError(`container ${containerNumber} not found in file`);\n            }\n            // if this is the first container, read all the blocks in the container\n            // to determine its length, because we cannot trust the container\n            // header's given length due to a bug somewhere in htslib\n            if (i === 0) {\n                position = currentHeader._endPosition;\n                for (let j = 0; j < currentHeader.numBlocks; j++) {\n                    const block = await this.readBlock(position);\n                    if (block === undefined) {\n                        return undefined;\n                    }\n                    position = block._endPosition;\n                }\n            }\n            else {\n                // otherwise, just traverse to the next container using the container's\n                // length\n                position += currentHeader._size + currentHeader.length;\n            }\n        }\n        return currentContainer;\n    }\n    async checkCrc32(position, length, recordedCrc32, description) {\n        const b = Buffer.allocUnsafe(length);\n        await this.file.read(b, 0, length, position);\n        const calculatedCrc32 = crc32.unsigned(b);\n        if (calculatedCrc32 !== recordedCrc32) {\n            throw new CramMalformedError(`crc mismatch in ${description}: recorded CRC32 = ${recordedCrc32}, but calculated CRC32 = ${calculatedCrc32}`);\n        }\n    }\n    /**\n     * @returns {Promise[number]} the number of containers in the file\n     */\n    async containerCount() {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const { size: fileSize } = await this.file.stat();\n        const { cramContainerHeader1 } = sectionParsers;\n        let containerCount = 0;\n        let position = sectionParsers.cramFileDefinition.maxLength;\n        while (position + cramContainerHeader1.maxLength + 8 < fileSize) {\n            const currentHeader = await this.getContainerAtPosition(position).getHeader();\n            if (!currentHeader) {\n                break;\n            }\n            // if this is the first container, read all the blocks in the container,\n            // because we cannot trust the container header's given length due to a\n            // bug somewhere in htslib\n            if (containerCount === 0) {\n                position = currentHeader._endPosition;\n                for (let j = 0; j < currentHeader.numBlocks; j++) {\n                    const block = await this.readBlock(position);\n                    if (block === undefined) {\n                        return undefined;\n                    }\n                    position = block._endPosition;\n                }\n            }\n            else {\n                // otherwise, just traverse to the next container using the container's\n                // length\n                position += currentHeader._size + currentHeader.length;\n            }\n            containerCount += 1;\n        }\n        return containerCount;\n    }\n    getContainerAtPosition(position) {\n        return new CramContainer(this, position);\n    }\n    async readBlockHeader(position) {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const { cramBlockHeader } = sectionParsers;\n        const { size: fileSize } = await this.file.stat();\n        if (position + cramBlockHeader.maxLength >= fileSize) {\n            return undefined;\n        }\n        const buffer = Buffer.allocUnsafe(cramBlockHeader.maxLength);\n        await this.file.read(buffer, 0, cramBlockHeader.maxLength, position);\n        return parseItem(buffer, cramBlockHeader.parser, 0, position);\n    }\n    async _parseSection(section, position, size = section.maxLength, preReadBuffer) {\n        let buffer;\n        if (preReadBuffer) {\n            buffer = preReadBuffer;\n        }\n        else {\n            const { size: fileSize } = await this.file.stat();\n            if (position + size >= fileSize) {\n                return undefined;\n            }\n            buffer = Buffer.allocUnsafe(size);\n            await this.file.read(buffer, 0, size, position);\n        }\n        const data = parseItem(buffer, section.parser, 0, position);\n        if (data._size !== size) {\n            throw new CramMalformedError(`section read error: requested size ${size} does not equal parsed size ${data._size}`);\n        }\n        return data;\n    }\n    async _uncompress(compressionMethod, inputBuffer, outputBuffer) {\n        if (compressionMethod === 'gzip') {\n            const result = unzip(inputBuffer);\n            result.copy(outputBuffer);\n        }\n        else if (compressionMethod === 'bzip2') {\n            const bits = bzip2.array(inputBuffer);\n            let size = bzip2.header(bits);\n            let j = 0;\n            let chunk;\n            do {\n                chunk = bzip2.decompress(bits, size);\n                if (chunk !== -1) {\n                    Buffer.from(chunk).copy(outputBuffer, j);\n                    j += chunk.length;\n                    size -= chunk.length;\n                }\n            } while (chunk !== -1);\n        }\n        else if (compressionMethod === 'lzma') {\n            const decompressedResponse = new Response(new XzReadableStream(bufferToStream(inputBuffer)));\n            const ret = Buffer.from(await decompressedResponse.arrayBuffer());\n            ret.copy(outputBuffer);\n        }\n        else if (compressionMethod === 'rans') {\n            ransuncompress(inputBuffer, outputBuffer);\n            // htscodecs r4x8 is slower, but compatible.\n            // htscodecs.r4x8_uncompress(inputBuffer, outputBuffer);\n        }\n        else if (compressionMethod === 'rans4x16') {\n            htscodecs.r4x16_uncompress(inputBuffer, outputBuffer);\n        }\n        else if (compressionMethod === 'arith') {\n            htscodecs.arith_uncompress(inputBuffer, outputBuffer);\n        }\n        else if (compressionMethod === 'fqzcomp') {\n            htscodecs.fqzcomp_uncompress(inputBuffer, outputBuffer);\n        }\n        else if (compressionMethod === 'tok3') {\n            htscodecs.tok3_uncompress(inputBuffer, outputBuffer);\n        }\n        else {\n            throw new CramUnimplementedError(`${compressionMethod} decompression not yet implemented`);\n        }\n    }\n    async readBlock(position) {\n        const { majorVersion } = await this.getDefinition();\n        const sectionParsers = getSectionParsers(majorVersion);\n        const blockHeader = await this.readBlockHeader(position);\n        if (blockHeader === undefined) {\n            return undefined;\n        }\n        const blockContentPosition = blockHeader._endPosition;\n        const uncompressedData = Buffer.allocUnsafe(blockHeader.uncompressedSize);\n        const block = {\n            ...blockHeader,\n            _endPosition: blockContentPosition,\n            contentPosition: blockContentPosition,\n            content: uncompressedData,\n        };\n        if (blockHeader.compressionMethod !== 'raw') {\n            const compressedData = Buffer.allocUnsafe(blockHeader.compressedSize);\n            await this.read(compressedData, 0, blockHeader.compressedSize, blockContentPosition);\n            await this._uncompress(blockHeader.compressionMethod, compressedData, uncompressedData);\n        }\n        else {\n            await this.read(uncompressedData, 0, blockHeader.uncompressedSize, blockContentPosition);\n        }\n        if (majorVersion >= 3) {\n            // parse the crc32\n            const crc = await this._parseSection(sectionParsers.cramBlockCrc32, blockContentPosition + blockHeader.compressedSize);\n            if (crc === undefined) {\n                return undefined;\n            }\n            block.crc32 = crc.crc32;\n            // check the block data crc32\n            if (this.validateChecksums) {\n                await this.checkCrc32(position, blockHeader._size + blockHeader.compressedSize, crc.crc32, 'block data');\n            }\n            // make the endposition and size reflect the whole block\n            block._endPosition = crc._endPosition;\n            block._size =\n                block.compressedSize + sectionParsers.cramBlockCrc32.maxLength;\n        }\n        else {\n            block._endPosition = blockContentPosition + block.compressedSize;\n            block._size = block.compressedSize;\n        }\n        return block;\n    }\n}\n'getDefinition getSectionParsers getSamHeader'.split(' ').forEach(method => {\n    tinyMemoize(CramFile, method);\n});\n//# sourceMappingURL=file.js.map","export { default as CramRecord } from './record';\nexport { default } from './file';\n//# sourceMappingURL=index.js.map","import { unzip } from './unzip';\nimport { open } from './io';\nimport { CramMalformedError } from './errors';\nconst BAI_MAGIC = 21578050; // BAI\\1\nfunction addRecordToIndex(index, record) {\n    const [seqId, start, span, containerStart, sliceStart, sliceBytes] = record;\n    const s = seqId;\n    if (!index[s]) {\n        index[s] = [];\n    }\n    index[s].push({\n        start: start,\n        span: span,\n        containerStart: containerStart,\n        sliceStart: sliceStart,\n        sliceBytes: sliceBytes,\n    });\n}\nfunction maybeUnzip(data) {\n    if (data[0] === 31 && data[1] === 139) {\n        return unzip(data);\n    }\n    return data;\n}\nexport default class CraiIndex {\n    /**\n     *\n     * @param {object} args\n     * @param {string} [args.path]\n     * @param {string} [args.url]\n     * @param {FileHandle} [args.filehandle]\n     */\n    constructor(args) {\n        this.filehandle = open(args.url, args.path, args.filehandle);\n    }\n    async parseIndex() {\n        const index = {};\n        const uncompressedBuffer = maybeUnzip(await this.filehandle.readFile());\n        if (uncompressedBuffer.length > 4 &&\n            uncompressedBuffer.readUInt32LE(0) === BAI_MAGIC) {\n            throw new CramMalformedError('invalid .crai index file. note: file appears to be a .bai index. this is technically legal but please open a github issue if you need support');\n        }\n        // interpret the text as regular ascii, since it is\n        // supposed to be only digits and whitespace characters\n        // this is written in a deliberately low-level fashion for performance,\n        // because some .crai files can be pretty large.\n        let currentRecord = [];\n        let currentString = '';\n        for (const charCode of uncompressedBuffer) {\n            if ((charCode >= 48 && charCode <= 57) /* 0-9 */ ||\n                (!currentString && charCode === 45) /* leading - */) {\n                currentString += String.fromCharCode(charCode);\n            }\n            else if (charCode === 9 /* \\t */) {\n                currentRecord.push(Number.parseInt(currentString, 10));\n                currentString = '';\n            }\n            else if (charCode === 10 /* \\n */) {\n                currentRecord.push(Number.parseInt(currentString, 10));\n                currentString = '';\n                addRecordToIndex(index, currentRecord);\n                currentRecord = [];\n            }\n            else if (charCode !== 13 /* \\r */ && charCode !== 32 /* space */) {\n                // if there are other characters in the file besides\n                // space and \\r, something is wrong.\n                throw new CramMalformedError('invalid .crai index file');\n            }\n        }\n        // if the file ends without a \\n, we need to flush our buffers\n        if (currentString) {\n            currentRecord.push(Number.parseInt(currentString, 10));\n        }\n        if (currentRecord.length === 6) {\n            addRecordToIndex(index, currentRecord);\n        }\n        // sort each of them by start\n        Object.entries(index).forEach(([seqId, ent]) => {\n            const e2 = ent;\n            index[seqId] = e2.sort((a, b) => a.start - b.start || a.span - b.span);\n        });\n        return index;\n    }\n    getIndex() {\n        if (!this.parseIndexP) {\n            this.parseIndexP = this.parseIndex().catch((e) => {\n                this.parseIndexP = undefined;\n                throw e;\n            });\n        }\n        return this.parseIndexP;\n    }\n    /**\n     * @param {number} seqId\n     * @returns {Promise} true if the index contains entries for\n     * the given reference sequence ID, false otherwise\n     */\n    async hasDataForReferenceSequence(seqId) {\n        return !!(await this.getIndex())[seqId];\n    }\n    /**\n     * fetch index entries for the given range\n     *\n     * @param {number} seqId\n     * @param {number} queryStart\n     * @param {number} queryEnd\n     *\n     * @returns {Promise} promise for\n     * an array of objects of the form\n     * `{start, span, containerStart, sliceStart, sliceBytes }`\n     */\n    async getEntriesForRange(seqId, queryStart, queryEnd) {\n        const seqEntries = (await this.getIndex())[seqId];\n        if (!seqEntries) {\n            return [];\n        }\n        const compare = (entry) => {\n            const entryStart = entry.start;\n            const entryEnd = entry.start + entry.span;\n            if (entryStart > queryEnd) {\n                return -1;\n            } // entry is ahead of query\n            if (entryEnd <= queryStart) {\n                return 1;\n            } // entry is behind query\n            return 0; // entry overlaps query\n        };\n        const bins = [];\n        for (const entry of seqEntries) {\n            if (compare(entry) === 0) {\n                bins.push(entry);\n            }\n        }\n        return bins;\n    }\n}\n//# sourceMappingURL=craiIndex.js.map","import { CramUnimplementedError } from './errors';\nimport CramFile from './cramFile';\nexport default class IndexedCramFile {\n    /**\n     *\n     * @param {object} args\n     * @param {CramFile} args.cram\n     * @param {Index-like} args.index object that supports getEntriesForRange(seqId,start,end) -> Promise[Array[index entries]]\n     * @param {number} [args.cacheSize] optional maximum number of CRAM records to cache.  default 20,000\n     * @param {boolean} [args.checkSequenceMD5] - default true. if false, disables verifying the MD5\n     * checksum of the reference sequence underlying a slice. In some applications, this check can cause an inconvenient amount (many megabases) of sequences to be fetched.\n     */\n    constructor(args) {\n        var _a;\n        // { cram, index, seqFetch /* fasta, fastaIndex */ }) {\n        this.cram =\n            (_a = args.cram) !== null && _a !== void 0 ? _a : new CramFile({\n                url: args.cramUrl,\n                path: args.cramPath,\n                filehandle: args.cramFilehandle,\n                seqFetch: args.seqFetch,\n                checkSequenceMD5: args.checkSequenceMD5,\n                cacheSize: args.cacheSize,\n            });\n        if (!(this.cram instanceof CramFile)) {\n            throw new Error('invalid arguments: no cramfile');\n        }\n        this.index = args.index;\n    }\n    /**\n     *\n     * @param {number} seq numeric ID of the reference sequence\n     * @param {number} start start of the range of interest. 1-based closed coordinates.\n     * @param {number} end end of the range of interest. 1-based closed coordinates.\n     * @returns {Promise[Array[CramRecord]]}\n     */\n    async getRecordsForRange(seq, start, end, opts = {}) {\n        opts.viewAsPairs = opts.viewAsPairs || false;\n        opts.pairAcrossChr = opts.pairAcrossChr || false;\n        opts.maxInsertSize = opts.maxInsertSize || 200000;\n        if (typeof seq === 'string') {\n            // TODO: support string reference sequence names somehow\n            throw new CramUnimplementedError('string sequence names not yet supported');\n        }\n        const seqId = seq;\n        const slices = await this.index.getEntriesForRange(seqId, start, end);\n        // TODO: do we need to merge or de-duplicate the blocks?\n        // fetch all the slices and parse the feature data\n        const filter = (feature) => feature.sequenceId === seq &&\n            feature.alignmentStart <= end &&\n            feature.lengthOnRef !== undefined &&\n            feature.alignmentStart + feature.lengthOnRef - 1 >= start;\n        const sliceResults = await Promise.all(slices.map(slice => this.getRecordsInSlice(slice, filter)));\n        let ret = Array.prototype.concat(...sliceResults);\n        if (opts.viewAsPairs) {\n            const readNames = {};\n            const readIds = {};\n            for (const read of ret) {\n                const name = read.readName;\n                if (name === undefined) {\n                    throw new Error('readName undefined');\n                }\n                const id = read.uniqueId;\n                if (!readNames[name]) {\n                    readNames[name] = 0;\n                }\n                readNames[name] += 1;\n                readIds[id] = 1;\n            }\n            const unmatedPairs = {};\n            Object.entries(readNames).forEach(([k, v]) => {\n                if (v === 1) {\n                    unmatedPairs[k] = true;\n                }\n            });\n            const matePromises = [];\n            for (const cramRecord of ret) {\n                const name = cramRecord.readName;\n                if (name === undefined) {\n                    throw new Error('readName undefined');\n                }\n                if (unmatedPairs[name] &&\n                    cramRecord.mate &&\n                    (cramRecord.mate.sequenceId === seqId || opts.pairAcrossChr) &&\n                    Math.abs(cramRecord.alignmentStart - cramRecord.mate.alignmentStart) <\n                        opts.maxInsertSize) {\n                    const mateSlices = this.index.getEntriesForRange(cramRecord.mate.sequenceId, cramRecord.mate.alignmentStart, cramRecord.mate.alignmentStart + 1);\n                    matePromises.push(mateSlices);\n                }\n            }\n            const mateBlocks = await Promise.all(matePromises);\n            let mateChunks = [];\n            for (const block of mateBlocks) {\n                mateChunks.push(...block);\n            }\n            // filter out duplicates\n            mateChunks = mateChunks\n                .sort((a, b) => a.toString().localeCompare(b.toString()))\n                .filter((item, pos, ary) => !pos || item.toString() !== ary[pos - 1].toString());\n            const mateRecordPromises = [];\n            const mateFeatPromises = [];\n            for (const c of mateChunks) {\n                let recordPromise = this.cram.featureCache.get(c.toString());\n                if (!recordPromise) {\n                    recordPromise = this.getRecordsInSlice(c, () => true);\n                    this.cram.featureCache.set(c.toString(), recordPromise);\n                }\n                mateRecordPromises.push(recordPromise);\n                const featPromise = recordPromise.then(feats => {\n                    const mateRecs = [];\n                    for (const feature of feats) {\n                        if (feature.readName === undefined) {\n                            throw new Error('readName undefined');\n                        }\n                        if (unmatedPairs[feature.readName] && !readIds[feature.uniqueId]) {\n                            mateRecs.push(feature);\n                        }\n                    }\n                    return mateRecs;\n                });\n                mateFeatPromises.push(featPromise);\n            }\n            const newMateFeats = await Promise.all(mateFeatPromises);\n            if (newMateFeats.length) {\n                const newMates = newMateFeats.reduce((result, current) => result.concat(current));\n                ret = ret.concat(newMates);\n            }\n        }\n        return ret;\n    }\n    getRecordsInSlice({ containerStart, sliceStart, sliceBytes, }, filterFunction) {\n        const container = this.cram.getContainerAtPosition(containerStart);\n        const slice = container.getSlice(sliceStart, sliceBytes);\n        return slice.getRecords(filterFunction);\n    }\n    /**\n     *\n     * @param {number} seqId\n     * @returns {Promise} true if the CRAM file contains data for the given\n     * reference sequence numerical ID\n     */\n    hasDataForReferenceSequence(seqId) {\n        return this.index.hasDataForReferenceSequence(seqId);\n    }\n}\n//# sourceMappingURL=indexedCramFile.js.map","export { default as CramFile, CramRecord } from './cramFile';\nexport { default as CraiIndex } from './craiIndex';\nexport { default as IndexedCramFile } from './indexedCramFile';\n//# sourceMappingURL=index.js.map","export function readFeaturesToMismatches(readFeatures, start, qual) {\n    if (!readFeatures) {\n        return [];\n    }\n    const mismatches = new Array(readFeatures.length);\n    let j = 0;\n    let insLen = 0;\n    let refPos = 0;\n    let sublen = 0;\n    let lastPos = start;\n    for (const { refPos: p, code, pos, data, sub, ref } of readFeatures) {\n        sublen = refPos - lastPos;\n        lastPos = refPos;\n        if (sublen && insLen > 0) {\n            mismatches[j++] = {\n                start: refPos,\n                type: 'insertion',\n                base: `${insLen}`,\n                length: 0,\n            };\n            insLen = 0;\n        }\n        refPos = p - 1 - start;\n        if (code === 'X') {\n            mismatches[j++] = {\n                start: refPos,\n                length: 1,\n                base: sub,\n                qual: qual === null || qual === void 0 ? void 0 : qual[pos - 1],\n                altbase: ref === null || ref === void 0 ? void 0 : ref.toUpperCase(),\n                type: 'mismatch',\n            };\n        }\n        else if (code === 'I') {\n            mismatches[j++] = {\n                start: refPos,\n                type: 'insertion',\n                base: `${data.length}`,\n                length: 0,\n            };\n        }\n        else if (code === 'N') {\n            mismatches[j++] = {\n                type: 'skip',\n                length: data,\n                start: refPos,\n                base: 'N',\n            };\n        }\n        else if (code === 'S') {\n            const len = data.length;\n            mismatches[j++] = {\n                start: refPos,\n                type: 'softclip',\n                base: `S${len}`,\n                cliplen: len,\n                length: 1,\n            };\n        }\n        else if (code === 'P') {\n        }\n        else if (code === 'H') {\n            const len = data;\n            mismatches[j++] = {\n                start: refPos,\n                type: 'hardclip',\n                base: `H${len}`,\n                cliplen: len,\n                length: 1,\n            };\n        }\n        else if (code === 'D') {\n            mismatches[j++] = {\n                type: 'deletion',\n                length: data,\n                start: refPos,\n                base: '*',\n            };\n        }\n        else if (code === 'b') {\n        }\n        else if (code === 'q') {\n        }\n        else if (code === 'B') {\n        }\n        else if (code === 'i') {\n            insLen++;\n        }\n        else if (code === 'Q') {\n        }\n    }\n    if (sublen && insLen > 0) {\n        mismatches[j++] = {\n            start: refPos,\n            type: 'insertion',\n            base: `${insLen}`,\n            length: 0,\n        };\n        insLen = 0;\n    }\n    return mismatches.slice(0, j);\n}\nexport function readFeaturesToCIGAR(readFeatures, alignmentStart, readLen, refRegion) {\n    let seq = '';\n    let cigar = '';\n    let op = 'M';\n    let oplen = 0;\n    if (!refRegion) {\n        return '';\n    }\n    const ref = refRegion.seq;\n    const refStart = refRegion.start;\n    let lastPos = alignmentStart;\n    let sublen = 0;\n    let insLen = 0;\n    if (readFeatures !== undefined) {\n        for (const { code, refPos, sub, data } of readFeatures) {\n            sublen = refPos - lastPos;\n            seq += ref.slice(lastPos - refStart, refPos - refStart);\n            lastPos = refPos;\n            if (insLen > 0 && sublen) {\n                cigar += `${insLen}I`;\n                insLen = 0;\n            }\n            if (oplen && op !== 'M') {\n                cigar += `${oplen}${op}`;\n                oplen = 0;\n            }\n            if (sublen) {\n                op = 'M';\n                oplen += sublen;\n            }\n            if (code === 'b') {\n                const ret = data.split(',');\n                const added = String.fromCharCode(...ret);\n                seq += added;\n                lastPos += added.length;\n                oplen += added.length;\n            }\n            else if (code === 'B') {\n                seq += sub;\n                lastPos++;\n                oplen++;\n            }\n            else if (code === 'X') {\n                seq += sub;\n                lastPos++;\n                oplen++;\n            }\n            else if (code === 'D' || code === 'N') {\n                lastPos += data;\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += data + code;\n                oplen = 0;\n            }\n            else if (code === 'I' || code === 'S') {\n                seq += data;\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += data.length + code;\n                oplen = 0;\n            }\n            else if (code === 'i') {\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                insLen++;\n                seq += data;\n                oplen = 0;\n            }\n            else if (code === 'P') {\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += `${data}P`;\n            }\n            else if (code === 'H') {\n                if (oplen) {\n                    cigar += `${oplen}${op}`;\n                }\n                cigar += `${data}H`;\n                oplen = 0;\n            }\n        }\n    }\n    else {\n        sublen = readLen - seq.length;\n    }\n    if (seq.length !== readLen) {\n        sublen = readLen - seq.length;\n        seq += ref.slice(lastPos - refStart, lastPos - refStart + sublen);\n        if (oplen && op !== 'M') {\n            cigar += `${oplen}${op}`;\n            oplen = 0;\n        }\n        op = 'M';\n        oplen += sublen;\n    }\n    if (sublen && insLen > 0) {\n        cigar += `${insLen}I`;\n    }\n    if (oplen) {\n        cigar += `${oplen}${op}`;\n    }\n    return cigar;\n}\n","import { readFeaturesToCIGAR, readFeaturesToMismatches } from './util';\nimport { cacheGetter } from '../shared/util';\nexport default class CramSlightlyLazyFeature {\n    constructor(record, _store) {\n        this.record = record;\n        this._store = _store;\n    }\n    get name() {\n        return this.record.readName;\n    }\n    get start() {\n        return this.record.alignmentStart - 1;\n    }\n    get end() {\n        var _a;\n        return this.start + ((_a = this.record.lengthOnRef) !== null && _a !== void 0 ? _a : 1);\n    }\n    get score() {\n        return this.record.mappingQuality;\n    }\n    get flags() {\n        return this.record.flags;\n    }\n    get strand() {\n        return this.record.isReverseComplemented() ? -1 : 1;\n    }\n    get qual() {\n        return (this.record.qualityScores || []).join(' ');\n    }\n    get qualRaw() {\n        return this.record.qualityScores;\n    }\n    get refName() {\n        return this._store.refIdToName(this.record.sequenceId);\n    }\n    get pair_orientation() {\n        return this.record.isPaired() ? this.record.getPairOrientation() : undefined;\n    }\n    get template_length() {\n        return this.record.templateLength || this.record.templateSize;\n    }\n    get next_ref() {\n        return this.record.mate\n            ? this._store.refIdToName(this.record.mate.sequenceId)\n            : undefined;\n    }\n    get next_segment_position() {\n        return this.record.mate\n            ? `${this._store.refIdToName(this.record.mate.sequenceId)}:${this.record.mate.alignmentStart}`\n            : undefined;\n    }\n    get is_paired() {\n        return !!this.record.mate;\n    }\n    get next_pos() {\n        var _a;\n        return (_a = this.record.mate) === null || _a === void 0 ? void 0 : _a.alignmentStart;\n    }\n    get tags() {\n        var _a;\n        const RG = (_a = this._store.samHeader.readGroups) === null || _a === void 0 ? void 0 : _a[this.record.readGroupId];\n        return RG !== undefined ? { ...this.record.tags, RG } : this.record.tags;\n    }\n    get seq() {\n        return this.record.getReadBases();\n    }\n    get CIGAR() {\n        return readFeaturesToCIGAR(this.record.readFeatures, this.record.alignmentStart, this.record.readLength, this.record._refRegion);\n    }\n    id() {\n        return `${this._store.id}-${this.record.uniqueId}`;\n    }\n    get(field) {\n        return field === 'mismatches'\n            ? this.mismatches\n            : field === 'qual'\n                ? this.qual\n                : field === 'CIGAR'\n                    ? this.CIGAR\n                    : this.fields[field];\n    }\n    parent() {\n        return undefined;\n    }\n    children() {\n        return undefined;\n    }\n    get mismatches() {\n        return readFeaturesToMismatches(this.record.readFeatures, this.start, this.qualRaw);\n    }\n    get fields() {\n        return {\n            start: this.start,\n            name: this.name,\n            end: this.end,\n            score: this.score,\n            strand: this.strand,\n            template_length: this.template_length,\n            flags: this.flags,\n            tags: this.tags,\n            refName: this.refName,\n            seq: this.seq,\n            type: 'match',\n            pair_orientation: this.pair_orientation,\n            next_ref: this.next_ref,\n            next_pos: this.next_pos,\n            next_segment_position: this.next_segment_position,\n            uniqueId: this.id(),\n        };\n    }\n    toJSON() {\n        return {\n            ...this.fields,\n            CIGAR: this.CIGAR,\n            qual: this.qual,\n        };\n    }\n}\ncacheGetter(CramSlightlyLazyFeature, 'fields');\ncacheGetter(CramSlightlyLazyFeature, 'CIGAR');\ncacheGetter(CramSlightlyLazyFeature, 'mismatches');\n","import { CraiIndex, IndexedCramFile } from '@gmod/cram';\nimport { BaseFeatureDataAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { toLocale, updateStatus } from '@jbrowse/core/util';\nimport QuickLRU from '@jbrowse/core/util/QuickLRU';\nimport { openLocation } from '@jbrowse/core/util/io';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport { checkStopToken } from '@jbrowse/core/util/stopToken';\nimport { firstValueFrom } from 'rxjs';\nimport { toArray } from 'rxjs/operators';\nimport CramSlightlyLazyFeature from './CramSlightlyLazyFeature';\nimport { filterReadFlag, filterTagValue } from '../shared/util';\nexport default class CramAdapter extends BaseFeatureDataAdapter {\n    constructor() {\n        super(...arguments);\n        this.samHeader = {};\n        this.ultraLongFeatureCache = new QuickLRU({\n            maxSize: 500,\n        });\n        this.seqIdToOriginalRefName = [];\n    }\n    async configurePre() {\n        const cramLocation = this.getConf('cramLocation');\n        const craiLocation = this.getConf('craiLocation');\n        const pm = this.pluginManager;\n        const cram = new IndexedCramFile({\n            cramFilehandle: openLocation(cramLocation, pm),\n            index: new CraiIndex({ filehandle: openLocation(craiLocation, pm) }),\n            seqFetch: (...args) => this.seqFetch(...args),\n            checkSequenceMD5: false,\n        });\n        if (!this.getSubAdapter) {\n            throw new Error('Error getting subadapter');\n        }\n        const seqConf = this.getConf('sequenceAdapter');\n        if (!seqConf) {\n            throw new Error('no sequenceAdapter supplied to CramAdapter config');\n        }\n        const subadapter = await this.getSubAdapter(seqConf);\n        return {\n            cram,\n            sequenceAdapter: subadapter.dataAdapter,\n        };\n    }\n    async configure() {\n        if (!this.configureP) {\n            this.configureP = this.configurePre().catch((e) => {\n                this.configureP = undefined;\n                throw e;\n            });\n        }\n        return this.configureP;\n    }\n    async getHeader(_opts) {\n        const { cram } = await this.configure();\n        return cram.cram.getHeaderText();\n    }\n    async seqFetch(seqId, start, end) {\n        start -= 1;\n        const { sequenceAdapter } = await this.configure();\n        const refName = this.refIdToOriginalName(seqId) || this.refIdToName(seqId);\n        if (!refName) {\n            throw new Error('unknown');\n        }\n        const seqChunks = await firstValueFrom(sequenceAdapter\n            .getFeatures({\n            refName,\n            start,\n            end,\n            assemblyName: '',\n        })\n            .pipe(toArray()));\n        const sequence = seqChunks\n            .sort((a, b) => a.get('start') - b.get('start'))\n            .map(chunk => {\n            const chunkStart = chunk.get('start');\n            const chunkEnd = chunk.get('end');\n            const trimStart = Math.max(start - chunkStart, 0);\n            const trimEnd = Math.min(end - chunkStart, chunkEnd - chunkStart);\n            const trimLength = trimEnd - trimStart;\n            const chunkSeq = chunk.get('seq') || chunk.get('residues');\n            return chunkSeq.slice(trimStart, trimStart + trimLength);\n        })\n            .join('');\n        const qlen = end - start;\n        if (sequence.length !== qlen) {\n            throw new Error(`fetching ${refName}:${toLocale(start - 1)}-${toLocale(end)} returned ${toLocale(sequence.length)} bases, should have returned ${toLocale(qlen)}`);\n        }\n        return sequence;\n    }\n    async setupPre(opts) {\n        const { statusCallback = () => { } } = opts || {};\n        return updateStatus('Downloading index', statusCallback, async () => {\n            const conf = await this.configure();\n            const { cram } = conf;\n            const samHeader = await cram.cram.getSamHeader();\n            const idToName = [];\n            const nameToId = {};\n            samHeader\n                .filter(l => l.tag === 'SQ')\n                .forEach((sqLine, refId) => {\n                const SN = sqLine.data.find(item => item.tag === 'SN');\n                if (SN) {\n                    const refName = SN.value;\n                    nameToId[refName] = refId;\n                    idToName[refId] = refName;\n                }\n            });\n            const readGroups = samHeader\n                .filter(l => l.tag === 'RG')\n                .map(rgLine => { var _a; return (_a = rgLine.data.find(item => item.tag === 'ID')) === null || _a === void 0 ? void 0 : _a.value; });\n            const data = { idToName, nameToId, readGroups };\n            this.samHeader = data;\n            return { samHeader: data, ...conf };\n        });\n    }\n    async setup(opts) {\n        if (!this.setupP) {\n            this.setupP = this.setupPre(opts).catch((e) => {\n                this.setupP = undefined;\n                throw e;\n            });\n        }\n        return this.setupP;\n    }\n    async getRefNames(opts) {\n        const { samHeader } = await this.setup(opts);\n        if (!samHeader.idToName) {\n            throw new Error('CRAM file has no header lines');\n        }\n        return samHeader.idToName;\n    }\n    refNameToId(refName) {\n        if (this.samHeader.nameToId) {\n            return this.samHeader.nameToId[refName];\n        }\n        if (this.seqIdToRefName) {\n            return this.seqIdToRefName.indexOf(refName);\n        }\n        return undefined;\n    }\n    refIdToName(refId) {\n        var _a, _b;\n        return ((_a = this.samHeader.idToName) === null || _a === void 0 ? void 0 : _a[refId]) || ((_b = this.seqIdToRefName) === null || _b === void 0 ? void 0 : _b[refId]);\n    }\n    refIdToOriginalName(refId) {\n        return this.seqIdToOriginalRefName[refId];\n    }\n    getFeatures(region, opts) {\n        const { stopToken, filterBy, statusCallback = () => { } } = opts || {};\n        const { refName, start, end, originalRefName } = region;\n        return ObservableCreate(async (observer) => {\n            const { cram, samHeader } = await this.setup(opts);\n            const refId = this.refNameToId(refName);\n            if (refId === undefined) {\n                console.warn('Unknown refName', refName);\n                observer.complete();\n                return;\n            }\n            if (originalRefName) {\n                this.seqIdToOriginalRefName[refId] = originalRefName;\n            }\n            const records = await updateStatus('Downloading alignments', statusCallback, () => cram.getRecordsForRange(refId, start, end));\n            checkStopToken(stopToken);\n            await updateStatus('Processing alignments', statusCallback, () => {\n                var _a;\n                const { flagInclude = 0, flagExclude = 0, tagFilter, readName, } = filterBy || {};\n                for (const record of records) {\n                    if (filterReadFlag(record.flags, flagInclude, flagExclude)) {\n                        continue;\n                    }\n                    if (tagFilter &&\n                        filterTagValue(tagFilter.tag === 'RG'\n                            ? (_a = samHeader.readGroups) === null || _a === void 0 ? void 0 : _a[record.readGroupId]\n                            : record.tags[tagFilter.tag], tagFilter.value)) {\n                        continue;\n                    }\n                    if (readName && record.readName !== readName) {\n                        continue;\n                    }\n                    const ret = this.ultraLongFeatureCache.get(`${record.uniqueId}`);\n                    if (!ret) {\n                        const elt = this.cramRecordToFeature(record);\n                        this.ultraLongFeatureCache.set(`${record.uniqueId}`, elt);\n                        observer.next(elt);\n                    }\n                    else {\n                        observer.next(ret);\n                    }\n                }\n                observer.complete();\n            });\n        }, stopToken);\n    }\n    freeResources() { }\n    cramRecordToFeature(record) {\n        return new CramSlightlyLazyFeature(record, this);\n    }\n    async getMultiRegionFeatureDensityStats(regions, opts) {\n        const bytes = await this.bytesForRegions(regions, opts);\n        const fetchSizeLimit = this.getConf('fetchSizeLimit');\n        return {\n            bytes,\n            fetchSizeLimit,\n        };\n    }\n    async bytesForRegions(regions, _opts) {\n        const { cram } = await this.configure();\n        const blockResults = await Promise.all(regions.map(region => {\n            const { refName, start, end } = region;\n            const chrId = this.refNameToId(refName);\n            return chrId !== undefined\n                ? cram.index.getEntriesForRange(chrId, start, end)\n                : [{ sliceBytes: 0 }];\n        }));\n        return blockResults.flat().reduce((a, b) => a + b.sliceBytes, 0);\n    }\n}\n","/*\nbzip2.js - a small bzip2 decompression implementation\n\nCopyright 2011 by antimatter15 (antimatter15@gmail.com)\n\nBased on micro-bunzip by Rob Landley (rob@landley.net).\n\nBased on bzip2 decompression code by Julian R Seward (jseward@acm.org),\nwhich also acknowledges contributions by Mike Burrows, David Wheeler,\nPeter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,\nRobert Sedgewick, and Jon L. Bentley.\n\nI hereby release this code under the GNU Library General Public License\n(LGPL) version 2, available at http://www.gnu.org/copyleft/lgpl.html\n*/\n\nvar bzip2 = {};\n\nbzip2.array = function (bytes) {\n    var bit = 0,\n        byte = 0;\n    var BITMASK = [0, 0x01, 0x03, 0x07, 0x0F, 0x1F, 0x3F, 0x7F, 0xFF];\n    return function (n) {\n        var result = 0;\n        while (n > 0) {\n            var left = 8 - bit;\n            if (n >= left) {\n                result <<= left;\n                result |= (BITMASK[left] & bytes[byte++]);\n                bit = 0;\n                n -= left;\n            } else {\n                result <<= n;\n                result |= ((bytes[byte] & (BITMASK[n] << (8 - n - bit))) >> (8 - n - bit));\n                bit += n;\n                n = 0;\n            }\n        }\n        return result\n    }\n}\n\nbzip2.simple = function (bits) {\n    var size = bzip2.header(bits);\n    var all, chunk, chunks = [];\n    var index = 0;\n    do {\n        //all += chunk;\n        chunk = bzip2.decompress(bits, size);\n        //all.set(chunk, index);\n        if (chunk != -1) {\n            chunks.push(chunk);\n            index += chunk.byteLength;\n        }\n    } while (chunk != -1);\n    all = new Uint8Array(index);\n    index = 0;\n    for (var i = 0; i < chunks.length; ++i) {\n        chunk = chunks[i];\n        all.set(chunk, index);\n        index += chunk.byteLength;\n    }\n    return all;\n}\n\nbzip2.header = function (bits) {\n    if (bits(8 * 3) != 4348520)\n        throw \"No magic number found\";\n    var i = bits(8) - 48;\n    if (i < 1 || i > 9)\n        throw \"Not a BZIP archive\";\n    return i;\n};\n\n//takes a function for reading the block data (starting with 0x314159265359)\n//a block size (0-9) (optional, defaults to 9)\n//a length at which to stop decompressing and return the output\nbzip2.decompress = function (bits, size, len) {\n    var MAX_HUFCODE_BITS = 20;\n    var MAX_SYMBOLS = 258;\n    var SYMBOL_RUNA = 0;\n    var SYMBOL_RUNB = 1;\n    var GROUP_SIZE = 50;\n\n    var bufsize = 100000 * 9;\n    for (var h = '', i = 0; i < 6; i++)\n        h += bits(8).toString(16);\n    if (h == \"177245385090\")\n        return -1; //last block\n    if (h != \"314159265359\")\n        throw \"eek not valid bzip data\";\n    bits(32); //ignore CRC codes\n    if (bits(1))\n        throw \"unsupported obsolete version\";\n    var origPtr = bits(24);\n    if (origPtr > bufsize)\n        throw \"Initial position larger than buffer size\";\n    var t = bits(16);\n    var symToByte = new Uint8Array(256),\n        symTotal = 0;\n    for (i = 0; i < 16; i++) {\n        if (t & (1 << (15 - i))) {\n            var k = bits(16);\n            for (j = 0; j < 16; j++) {\n                if (k & (1 << (15 - j))) {\n                    symToByte[symTotal++] = (16 * i) + j;\n                }\n            }\n        }\n    }\n\n    var groupCount = bits(3);\n    if (groupCount < 2 || groupCount > 6)\n        throw \"another error\";\n    var nSelectors = bits(15);\n    if (nSelectors == 0)\n        throw \"meh\";\n    var mtfSymbol = []; //TODO: possibly replace JS array with typed arrays\n    for (var i = 0; i < groupCount; i++)\n        mtfSymbol[i] = i;\n    var selectors = new Uint8Array(32768);\n\n    for (var i = 0; i < nSelectors; i++) {\n        for (var j = 0; bits(1); j++)\n            if (j >= groupCount)\n                throw \"whoops another error\";\n        var uc = mtfSymbol[j];\n        mtfSymbol.splice(j, 1); //this is a probably inefficient MTF transform\n        mtfSymbol.splice(0, 0, uc);\n        selectors[i] = uc;\n    }\n\n    var symCount = symTotal + 2;\n    var groups = [];\n    for (var j = 0; j < groupCount; j++) {\n        var length = new Uint8Array(MAX_SYMBOLS),\n            temp = new Uint8Array(MAX_HUFCODE_BITS + 1);\n        t = bits(5); //lengths\n        for (var i = 0; i < symCount; i++) {\n            while (true) {\n                if (t < 1 || t > MAX_HUFCODE_BITS)\n                    throw \"I gave up a while ago on writing error messages\";\n                if (!bits(1))\n                    break;\n                if (!bits(1))\n                    t++;\n                else\n                    t--;\n            }\n            length[i] = t;\n        }\n        var minLen, maxLen;\n        minLen = maxLen = length[0];\n        for (var i = 1; i < symCount; i++) {\n            if (length[i] > maxLen)\n                maxLen = length[i];\n            else if (length[i] < minLen)\n                minLen = length[i];\n        }\n        var hufGroup;\n        hufGroup = groups[j] = {};\n        hufGroup.permute = new Uint32Array(MAX_SYMBOLS);\n        hufGroup.limit = new Uint32Array(MAX_HUFCODE_BITS + 1);\n        hufGroup.base = new Uint32Array(MAX_HUFCODE_BITS + 1);\n        hufGroup.minLen = minLen;\n        hufGroup.maxLen = maxLen;\n        var base = hufGroup.base.subarray(1);\n        var limit = hufGroup.limit.subarray(1);\n        var pp = 0;\n        for (var i = minLen; i <= maxLen; i++)\n            for (var t = 0; t < symCount; t++)\n                if (length[t] == i)\n                    hufGroup.permute[pp++] = t;\n        for (i = minLen; i <= maxLen; i++)\n            temp[i] = limit[i] = 0;\n        for (i = 0; i < symCount; i++)\n            temp[length[i]]++;\n        pp = t = 0;\n        for (i = minLen; i < maxLen; i++) {\n            pp += temp[i];\n            limit[i] = pp - 1;\n            pp <<= 1;\n            base[i + 1] = pp - (t += temp[i]);\n        }\n        limit[maxLen] = pp + temp[maxLen] - 1;\n        base[minLen] = 0;\n    }\n    var byteCount = new Uint32Array(256);\n    for (var i = 0; i < 256; i++)\n        mtfSymbol[i] = i;\n    var runPos, count, symCount, selector;\n    runPos = count = symCount = selector = 0;\n    var buf = new Uint32Array(bufsize);\n    while (true) {\n        if (!(symCount--)) {\n            symCount = GROUP_SIZE - 1;\n            if (selector >= nSelectors)\n                throw \"meow i'm a kitty, that's an error\";\n            hufGroup = groups[selectors[selector++]];\n            base = hufGroup.base.subarray(1);\n            limit = hufGroup.limit.subarray(1);\n        }\n        i = hufGroup.minLen;\n        j = bits(i);\n        while (true) {\n            if (i > hufGroup.maxLen)\n                throw \"rawr i'm a dinosaur\";\n            if (j <= limit[i])\n                break;\n            i++;\n            j = (j << 1) | bits(1);\n        }\n        j -= base[i];\n        if (j < 0 || j >= MAX_SYMBOLS)\n            throw \"moo i'm a cow\";\n        var nextSym = hufGroup.permute[j];\n        if (nextSym == SYMBOL_RUNA || nextSym == SYMBOL_RUNB) {\n            if (!runPos) {\n                runPos = 1;\n                t = 0;\n            }\n            if (nextSym == SYMBOL_RUNA)\n                t += runPos;\n            else\n                t += 2 * runPos;\n            runPos <<= 1;\n            continue;\n        }\n        if (runPos) {\n            runPos = 0;\n            if (count + t >= bufsize)\n                throw \"Boom.\";\n            uc = symToByte[mtfSymbol[0]];\n            byteCount[uc] += t;\n            while (t--)\n                buf[count++] = uc;\n        }\n        if (nextSym > symTotal)\n            break;\n        if (count >= bufsize)\n            throw \"I can't think of anything. Error\";\n        i = nextSym - 1;\n        uc = mtfSymbol[i];\n        mtfSymbol.splice(i, 1);\n        mtfSymbol.splice(0, 0, uc);\n        uc = symToByte[uc];\n        byteCount[uc]++;\n        buf[count++] = uc;\n    }\n    if (origPtr < 0 || origPtr >= count)\n        throw \"I'm a monkey and I'm throwing something at someone, namely you\";\n    var j = 0;\n    for (var i = 0; i < 256; i++) {\n        k = j + byteCount[i];\n        byteCount[i] = j;\n        j = k;\n    }\n    for (var i = 0; i < count; i++) {\n        uc = buf[i] & 0xff;\n        buf[byteCount[uc]] |= (i << 8);\n        byteCount[uc]++;\n    }\n    var pos = 0,\n        current = 0,\n        run = 0;\n    if (count) {\n        pos = buf[origPtr];\n        current = (pos & 0xff);\n        pos >>= 8;\n        run = -1;\n    }\n    count = count;\n    var output = new Uint8Array(bufsize);\n    var copies, previous, outbyte;\n    var index = 0;\n    if (!len)\n        len = Infinity;\n    while (count) {\n        count--;\n        previous = current;\n        pos = buf[pos];\n        current = pos & 0xff;\n        pos >>= 8;\n        if (run++ == 3) {\n            copies = current;\n            outbyte = previous;\n            current = -1;\n        } else {\n            copies = 1;\n            outbyte = current;\n        }\n        while (copies--) {\n            //output += (String.fromCharCode(outbyte));\n            output[index++] = outbyte;\n            //index++;\n            if (!--len)\n                return output;\n        }\n        if (current != previous)\n            run = 0;\n    }\n    //return output;\n    //return output.subarray(0,index-1);\n    return output.subarray(0, index);\n}\n\nmodule.exports = bzip2;\n","var charenc = {\n  // UTF-8 encoding\n  utf8: {\n    // Convert a string to a byte array\n    stringToBytes: function(str) {\n      return charenc.bin.stringToBytes(unescape(encodeURIComponent(str)));\n    },\n\n    // Convert a byte array to a string\n    bytesToString: function(bytes) {\n      return decodeURIComponent(escape(charenc.bin.bytesToString(bytes)));\n    }\n  },\n\n  // Binary encoding\n  bin: {\n    // Convert a string to a byte array\n    stringToBytes: function(str) {\n      for (var bytes = [], i = 0; i < str.length; i++)\n        bytes.push(str.charCodeAt(i) & 0xFF);\n      return bytes;\n    },\n\n    // Convert a byte array to a string\n    bytesToString: function(bytes) {\n      for (var str = [], i = 0; i < bytes.length; i++)\n        str.push(String.fromCharCode(bytes[i]));\n      return str.join('');\n    }\n  }\n};\n\nmodule.exports = charenc;\n","(function() {\n  var base64map\n      = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',\n\n  crypt = {\n    // Bit-wise rotation left\n    rotl: function(n, b) {\n      return (n << b) | (n >>> (32 - b));\n    },\n\n    // Bit-wise rotation right\n    rotr: function(n, b) {\n      return (n << (32 - b)) | (n >>> b);\n    },\n\n    // Swap big-endian to little-endian and vice versa\n    endian: function(n) {\n      // If number given, swap endian\n      if (n.constructor == Number) {\n        return crypt.rotl(n, 8) & 0x00FF00FF | crypt.rotl(n, 24) & 0xFF00FF00;\n      }\n\n      // Else, assume array and swap all items\n      for (var i = 0; i < n.length; i++)\n        n[i] = crypt.endian(n[i]);\n      return n;\n    },\n\n    // Generate an array of any length of random bytes\n    randomBytes: function(n) {\n      for (var bytes = []; n > 0; n--)\n        bytes.push(Math.floor(Math.random() * 256));\n      return bytes;\n    },\n\n    // Convert a byte array to big-endian 32-bit words\n    bytesToWords: function(bytes) {\n      for (var words = [], i = 0, b = 0; i < bytes.length; i++, b += 8)\n        words[b >>> 5] |= bytes[i] << (24 - b % 32);\n      return words;\n    },\n\n    // Convert big-endian 32-bit words to a byte array\n    wordsToBytes: function(words) {\n      for (var bytes = [], b = 0; b < words.length * 32; b += 8)\n        bytes.push((words[b >>> 5] >>> (24 - b % 32)) & 0xFF);\n      return bytes;\n    },\n\n    // Convert a byte array to a hex string\n    bytesToHex: function(bytes) {\n      for (var hex = [], i = 0; i < bytes.length; i++) {\n        hex.push((bytes[i] >>> 4).toString(16));\n        hex.push((bytes[i] & 0xF).toString(16));\n      }\n      return hex.join('');\n    },\n\n    // Convert a hex string to a byte array\n    hexToBytes: function(hex) {\n      for (var bytes = [], c = 0; c < hex.length; c += 2)\n        bytes.push(parseInt(hex.substr(c, 2), 16));\n      return bytes;\n    },\n\n    // Convert a byte array to a base-64 string\n    bytesToBase64: function(bytes) {\n      for (var base64 = [], i = 0; i < bytes.length; i += 3) {\n        var triplet = (bytes[i] << 16) | (bytes[i + 1] << 8) | bytes[i + 2];\n        for (var j = 0; j < 4; j++)\n          if (i * 8 + j * 6 <= bytes.length * 8)\n            base64.push(base64map.charAt((triplet >>> 6 * (3 - j)) & 0x3F));\n          else\n            base64.push('=');\n      }\n      return base64.join('');\n    },\n\n    // Convert a base-64 string to a byte array\n    base64ToBytes: function(base64) {\n      // Remove non-base-64 characters\n      base64 = base64.replace(/[^A-Z0-9+\\/]/ig, '');\n\n      for (var bytes = [], i = 0, imod4 = 0; i < base64.length;\n          imod4 = ++i % 4) {\n        if (imod4 == 0) continue;\n        bytes.push(((base64map.indexOf(base64.charAt(i - 1))\n            & (Math.pow(2, -2 * imod4 + 8) - 1)) << (imod4 * 2))\n            | (base64map.indexOf(base64.charAt(i)) >>> (6 - imod4 * 2)));\n      }\n      return bytes;\n    }\n  };\n\n  module.exports = crypt;\n})();\n","/*!\n * Determine if an object is a Buffer\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n\n// The _isBuffer check is for Safari 5-7 support, because it's missing\n// Object.prototype.constructor. Remove this eventually\nmodule.exports = function (obj) {\n  return obj != null && (isBuffer(obj) || isSlowBuffer(obj) || !!obj._isBuffer)\n}\n\nfunction isBuffer (obj) {\n  return !!obj.constructor && typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)\n}\n\n// For Node v0.10 support. Remove this eventually.\nfunction isSlowBuffer (obj) {\n  return typeof obj.readFloatLE === 'function' && typeof obj.slice === 'function' && isBuffer(obj.slice(0, 0))\n}\n","(function(){\r\n  var crypt = require('crypt'),\r\n      utf8 = require('charenc').utf8,\r\n      isBuffer = require('is-buffer'),\r\n      bin = require('charenc').bin,\r\n\r\n  // The core\r\n  md5 = function (message, options) {\r\n    // Convert to byte array\r\n    if (message.constructor == String)\r\n      if (options && options.encoding === 'binary')\r\n        message = bin.stringToBytes(message);\r\n      else\r\n        message = utf8.stringToBytes(message);\r\n    else if (isBuffer(message))\r\n      message = Array.prototype.slice.call(message, 0);\r\n    else if (!Array.isArray(message) && message.constructor !== Uint8Array)\r\n      message = message.toString();\r\n    // else, assume byte array already\r\n\r\n    var m = crypt.bytesToWords(message),\r\n        l = message.length * 8,\r\n        a =  1732584193,\r\n        b = -271733879,\r\n        c = -1732584194,\r\n        d =  271733878;\r\n\r\n    // Swap endian\r\n    for (var i = 0; i < m.length; i++) {\r\n      m[i] = ((m[i] <<  8) | (m[i] >>> 24)) & 0x00FF00FF |\r\n             ((m[i] << 24) | (m[i] >>>  8)) & 0xFF00FF00;\r\n    }\r\n\r\n    // Padding\r\n    m[l >>> 5] |= 0x80 << (l % 32);\r\n    m[(((l + 64) >>> 9) << 4) + 14] = l;\r\n\r\n    // Method shortcuts\r\n    var FF = md5._ff,\r\n        GG = md5._gg,\r\n        HH = md5._hh,\r\n        II = md5._ii;\r\n\r\n    for (var i = 0; i < m.length; i += 16) {\r\n\r\n      var aa = a,\r\n          bb = b,\r\n          cc = c,\r\n          dd = d;\r\n\r\n      a = FF(a, b, c, d, m[i+ 0],  7, -680876936);\r\n      d = FF(d, a, b, c, m[i+ 1], 12, -389564586);\r\n      c = FF(c, d, a, b, m[i+ 2], 17,  606105819);\r\n      b = FF(b, c, d, a, m[i+ 3], 22, -1044525330);\r\n      a = FF(a, b, c, d, m[i+ 4],  7, -176418897);\r\n      d = FF(d, a, b, c, m[i+ 5], 12,  1200080426);\r\n      c = FF(c, d, a, b, m[i+ 6], 17, -1473231341);\r\n      b = FF(b, c, d, a, m[i+ 7], 22, -45705983);\r\n      a = FF(a, b, c, d, m[i+ 8],  7,  1770035416);\r\n      d = FF(d, a, b, c, m[i+ 9], 12, -1958414417);\r\n      c = FF(c, d, a, b, m[i+10], 17, -42063);\r\n      b = FF(b, c, d, a, m[i+11], 22, -1990404162);\r\n      a = FF(a, b, c, d, m[i+12],  7,  1804603682);\r\n      d = FF(d, a, b, c, m[i+13], 12, -40341101);\r\n      c = FF(c, d, a, b, m[i+14], 17, -1502002290);\r\n      b = FF(b, c, d, a, m[i+15], 22,  1236535329);\r\n\r\n      a = GG(a, b, c, d, m[i+ 1],  5, -165796510);\r\n      d = GG(d, a, b, c, m[i+ 6],  9, -1069501632);\r\n      c = GG(c, d, a, b, m[i+11], 14,  643717713);\r\n      b = GG(b, c, d, a, m[i+ 0], 20, -373897302);\r\n      a = GG(a, b, c, d, m[i+ 5],  5, -701558691);\r\n      d = GG(d, a, b, c, m[i+10],  9,  38016083);\r\n      c = GG(c, d, a, b, m[i+15], 14, -660478335);\r\n      b = GG(b, c, d, a, m[i+ 4], 20, -405537848);\r\n      a = GG(a, b, c, d, m[i+ 9],  5,  568446438);\r\n      d = GG(d, a, b, c, m[i+14],  9, -1019803690);\r\n      c = GG(c, d, a, b, m[i+ 3], 14, -187363961);\r\n      b = GG(b, c, d, a, m[i+ 8], 20,  1163531501);\r\n      a = GG(a, b, c, d, m[i+13],  5, -1444681467);\r\n      d = GG(d, a, b, c, m[i+ 2],  9, -51403784);\r\n      c = GG(c, d, a, b, m[i+ 7], 14,  1735328473);\r\n      b = GG(b, c, d, a, m[i+12], 20, -1926607734);\r\n\r\n      a = HH(a, b, c, d, m[i+ 5],  4, -378558);\r\n      d = HH(d, a, b, c, m[i+ 8], 11, -2022574463);\r\n      c = HH(c, d, a, b, m[i+11], 16,  1839030562);\r\n      b = HH(b, c, d, a, m[i+14], 23, -35309556);\r\n      a = HH(a, b, c, d, m[i+ 1],  4, -1530992060);\r\n      d = HH(d, a, b, c, m[i+ 4], 11,  1272893353);\r\n      c = HH(c, d, a, b, m[i+ 7], 16, -155497632);\r\n      b = HH(b, c, d, a, m[i+10], 23, -1094730640);\r\n      a = HH(a, b, c, d, m[i+13],  4,  681279174);\r\n      d = HH(d, a, b, c, m[i+ 0], 11, -358537222);\r\n      c = HH(c, d, a, b, m[i+ 3], 16, -722521979);\r\n      b = HH(b, c, d, a, m[i+ 6], 23,  76029189);\r\n      a = HH(a, b, c, d, m[i+ 9],  4, -640364487);\r\n      d = HH(d, a, b, c, m[i+12], 11, -421815835);\r\n      c = HH(c, d, a, b, m[i+15], 16,  530742520);\r\n      b = HH(b, c, d, a, m[i+ 2], 23, -995338651);\r\n\r\n      a = II(a, b, c, d, m[i+ 0],  6, -198630844);\r\n      d = II(d, a, b, c, m[i+ 7], 10,  1126891415);\r\n      c = II(c, d, a, b, m[i+14], 15, -1416354905);\r\n      b = II(b, c, d, a, m[i+ 5], 21, -57434055);\r\n      a = II(a, b, c, d, m[i+12],  6,  1700485571);\r\n      d = II(d, a, b, c, m[i+ 3], 10, -1894986606);\r\n      c = II(c, d, a, b, m[i+10], 15, -1051523);\r\n      b = II(b, c, d, a, m[i+ 1], 21, -2054922799);\r\n      a = II(a, b, c, d, m[i+ 8],  6,  1873313359);\r\n      d = II(d, a, b, c, m[i+15], 10, -30611744);\r\n      c = II(c, d, a, b, m[i+ 6], 15, -1560198380);\r\n      b = II(b, c, d, a, m[i+13], 21,  1309151649);\r\n      a = II(a, b, c, d, m[i+ 4],  6, -145523070);\r\n      d = II(d, a, b, c, m[i+11], 10, -1120210379);\r\n      c = II(c, d, a, b, m[i+ 2], 15,  718787259);\r\n      b = II(b, c, d, a, m[i+ 9], 21, -343485551);\r\n\r\n      a = (a + aa) >>> 0;\r\n      b = (b + bb) >>> 0;\r\n      c = (c + cc) >>> 0;\r\n      d = (d + dd) >>> 0;\r\n    }\r\n\r\n    return crypt.endian([a, b, c, d]);\r\n  };\r\n\r\n  // Auxiliary functions\r\n  md5._ff  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (b & c | ~b & d) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n  md5._gg  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (b & d | c & ~d) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n  md5._hh  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (b ^ c ^ d) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n  md5._ii  = function (a, b, c, d, x, s, t) {\r\n    var n = a + (c ^ (b | ~d)) + (x >>> 0) + t;\r\n    return ((n << s) | (n >>> (32 - s))) + b;\r\n  };\r\n\r\n  // Package private blocksize\r\n  md5._blocksize = 16;\r\n  md5._digestsize = 16;\r\n\r\n  module.exports = function (message, options) {\r\n    if (message === undefined || message === null)\r\n      throw new Error('Illegal argument ' + message);\r\n\r\n    var digestbytes = crypt.wordsToBytes(md5(message, options));\r\n    return options && options.asBytes ? digestbytes :\r\n        options && options.asString ? bin.bytesToString(digestbytes) :\r\n        crypt.bytesToHex(digestbytes);\r\n  };\r\n\r\n})();\r\n","/*!\n * Based on xzwasm (c) Steve Sanderson. License: MIT - https://github.com/SteveSanderson/xzwasm\n * Contains xz-embedded by Lasse Collin and Igor Pavlov. License: Public domain - https://tukaani.org/xz/embedded.html\n * and walloc (c) 2020 Igalia, S.L. License: MIT - https://github.com/wingo/walloc\n */\n(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"stream/web\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"stream/web\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"xz-decompress\"] = factory(require(\"stream/web\"));\n\telse\n\t\troot[\"xz-decompress\"] = factory(root[\"stream/web\"]);\n})(this, (__WEBPACK_EXTERNAL_MODULE__2__) => {\nreturn /******/ (() => { // webpackBootstrap\n/******/ \t\"use strict\";\n/******/ \tvar __webpack_modules__ = ([\n/* 0 */,\n/* 1 */\n/***/ ((module) => {\n\nmodule.exports = \"data:application/wasm;base64,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\";\n\n/***/ }),\n/* 2 */\n/***/ ((module) => {\n\nmodule.exports = __WEBPACK_EXTERNAL_MODULE__2__;\n\n/***/ })\n/******/ \t]);\n/************************************************************************/\n/******/ \t// The module cache\n/******/ \tvar __webpack_module_cache__ = {};\n/******/ \t\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/ \t\t// Check if module is in cache\n/******/ \t\tvar cachedModule = __webpack_module_cache__[moduleId];\n/******/ \t\tif (cachedModule !== undefined) {\n/******/ \t\t\treturn cachedModule.exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = __webpack_module_cache__[moduleId] = {\n/******/ \t\t\t// no module.id needed\n/******/ \t\t\t// no module.loaded needed\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/ \t\n/******/ \t\t// Execute the module function\n/******/ \t\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n/******/ \t\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/ \t\n/************************************************************************/\n/******/ \t/* webpack/runtime/define property getters */\n/******/ \t(() => {\n/******/ \t\t// define getter functions for harmony exports\n/******/ \t\t__webpack_require__.d = (exports, definition) => {\n/******/ \t\t\tfor(var key in definition) {\n/******/ \t\t\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n/******/ \t\t\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n/******/ \t\t\t\t}\n/******/ \t\t\t}\n/******/ \t\t};\n/******/ \t})();\n/******/ \t\n/******/ \t/* webpack/runtime/hasOwnProperty shorthand */\n/******/ \t(() => {\n/******/ \t\t__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))\n/******/ \t})();\n/******/ \t\n/******/ \t/* webpack/runtime/make namespace object */\n/******/ \t(() => {\n/******/ \t\t// define __esModule on exports\n/******/ \t\t__webpack_require__.r = (exports) => {\n/******/ \t\t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n/******/ \t\t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n/******/ \t\t\t}\n/******/ \t\t\tObject.defineProperty(exports, '__esModule', { value: true });\n/******/ \t\t};\n/******/ \t})();\n/******/ \t\n/************************************************************************/\nvar __webpack_exports__ = {};\n// This entry need to be wrapped in an IIFE because it need to be isolated against other modules in the chunk.\n(() => {\n__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   XzReadableStream: () => (/* binding */ XzReadableStream)\n/* harmony export */ });\n/* harmony import */ var _dist_native_xz_decompress_wasm__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(1);\n\n\nconst ReadableStream = globalThis.ReadableStream\n    // Node < 18 support web streams, but it's not available as a global, so we need to require it.\n    // This won't be reached in modern browsers, and bundlers will ignore due to 'browser' field in package.json:\n    || (__webpack_require__(2).ReadableStream);\n\nconst XZ_OK = 0;\nconst XZ_STREAM_END = 1;\n\nclass XzContext {\n    constructor(moduleInstance) {\n        this.exports = moduleInstance.exports;\n        this.memory = this.exports.memory;\n        this.ptr = this.exports.create_context();\n        this._refresh();\n        this.bufSize = this.mem32[0];\n        this.inStart = this.mem32[1] - this.ptr;\n        this.inEnd = this.inStart + this.bufSize;\n        this.outStart = this.mem32[4] - this.ptr;\n    }\n\n    supplyInput(sourceDataUint8Array) {\n        this._refresh();\n        const inBuffer = this.mem8.subarray(this.inStart, this.inEnd);\n        inBuffer.set(sourceDataUint8Array, 0);\n        this.exports.supply_input(this.ptr, sourceDataUint8Array.byteLength);\n        this._refresh();\n    }\n\n    getNextOutput() {\n        const result = this.exports.get_next_output(this.ptr);\n        this._refresh();\n        if (result !== XZ_OK && result !== XZ_STREAM_END) {\n            throw new Error(`get_next_output failed with error code ${result}`);\n        }\n        const outChunk = this.mem8.slice(this.outStart, this.outStart + /* outPos */ this.mem32[5]);\n        return { outChunk, finished: result === XZ_STREAM_END };\n    }\n\n    needsMoreInput() {\n        return /* inPos */ this.mem32[2] === /* inSize */ this.mem32[3];\n    }\n\n    outputBufferIsFull() {\n        return /* outPos */ this.mem32[5] === this.bufSize;\n    }\n\n    resetOutputBuffer() {\n        this.outPos = this.mem32[5] = 0;\n    }\n\n    dispose() {\n        this.exports.destroy_context(this.ptr);\n        this.exports = null;\n    }\n\n    _refresh() {\n        if (this.memory.buffer !== this.mem8?.buffer) {\n            this.mem8 = new Uint8Array(this.memory.buffer, this.ptr);\n            this.mem32 = new Uint32Array(this.memory.buffer, this.ptr);\n        }\n    }\n}\n\nclass XzReadableStream extends ReadableStream {\n    static _moduleInstancePromise;\n    static _moduleInstance;\n    static async _getModuleInstance() {\n        const base64Wasm = _dist_native_xz_decompress_wasm__WEBPACK_IMPORTED_MODULE_0__.replace('data:application/wasm;base64,', '');\n        const wasmBytes = Uint8Array.from(atob(base64Wasm), c => c.charCodeAt(0)).buffer;\n        const wasmOptions = {};\n        const module = await WebAssembly.instantiate(wasmBytes, wasmOptions);\n        XzReadableStream._moduleInstance = module.instance;\n    }\n\n    constructor(compressedStream) {\n        let xzContext;\n        let unconsumedInput = null;\n        const compressedReader = compressedStream.getReader();\n\n        super({\n            async start(controller) {\n                if (!XzReadableStream._moduleInstance) {\n                    await (XzReadableStream._moduleInstancePromise || (XzReadableStream._moduleInstancePromise = XzReadableStream._getModuleInstance()));\n                }\n                xzContext = new XzContext(XzReadableStream._moduleInstance);\n            },\n\n            async pull(controller) {\n                if (xzContext.needsMoreInput()) {\n                    if (unconsumedInput === null || unconsumedInput.byteLength === 0) {\n                        const { done, value } = await compressedReader.read();\n                        if (!done) {\n                            unconsumedInput = value;\n                        }\n                    }\n                    const nextInputLength = Math.min(xzContext.bufSize, unconsumedInput.byteLength);\n                    xzContext.supplyInput(unconsumedInput.subarray(0, nextInputLength));\n                    unconsumedInput = unconsumedInput.subarray(nextInputLength);\n                }\n\n                const nextOutputResult = xzContext.getNextOutput();\n                controller.enqueue(nextOutputResult.outChunk);\n                xzContext.resetOutputBuffer();\n\n                if (nextOutputResult.finished) {\n                    xzContext.dispose(); // Not sure if this always happens\n                    controller.close();\n                }\n            },\n            cancel() {\n                xzContext.dispose(); // Not sure if this always happens\n                return compressedReader.cancel();\n            }\n        });\n    }\n}\n\n})();\n\n/******/ \treturn __webpack_exports__;\n/******/ })()\n;\n});","// Generated by `./pycrc.py --algorithm=table-driven --model=crc-32 --generate=c`\nlet TABLE = [\n    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f, 0xe963a535, 0x9e6495a3,\n    0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91,\n    0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,\n    0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5,\n    0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n    0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,\n    0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599, 0xb8bda50f,\n    0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924, 0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d,\n    0x76dc4190, 0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,\n    0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n    0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457,\n    0x65b0d9c6, 0x12b7e950, 0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,\n    0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb,\n    0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9,\n    0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad,\n    0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683,\n    0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,\n    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7,\n    0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n    0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,\n    0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79,\n    0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236, 0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f,\n    0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,\n    0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n    0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21,\n    0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,\n    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45,\n    0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db,\n    0xaed16a4a, 0xd9d65adc, 0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf,\n    0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d,\n];\nif (typeof Int32Array !== 'undefined') {\n    TABLE = new Int32Array(TABLE);\n}\nconst crc32 = (current, previous) => {\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    let crc = previous === 0 ? 0 : ~~previous ^ -1;\n    for (let index = 0; index < current.length; index++) {\n        crc = TABLE[(crc ^ current[index]) & 0xff] ^ (crc >>> 8);\n    }\n    return crc ^ -1;\n};\nexport default crc32;\n","/* eslint-disable @typescript-eslint/no-explicit-any */\n/* eslint-disable no-prototype-builtins */\nimport { Buffer } from 'buffer';\nconst createBuffer = (value, encoding) => Buffer.from(value, encoding);\nexport default createBuffer;\n","import createBuffer from './create_buffer.js';\nexport default function defineCrc(model, calculator) {\n    const result = (value, previous) => calculator(createBuffer(value), previous) >>> 0;\n    result.signed = (value, previous) => calculator(createBuffer(value), previous);\n    result.unsigned = result;\n    result.model = model;\n    return result;\n}\n","import crc32 from './calculators/crc32.js';\nimport defineCrc from './define_crc.js';\nexport default defineCrc('crc-32', crc32);\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54]}